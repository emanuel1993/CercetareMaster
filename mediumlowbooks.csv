id	conf	title	author	year	abstract	conf_short	theme
1	ICDE	A Rule-based Language for Deductive Object-Oriented Databases.	A. M. Alashqur,Stanley Y. W. Su,Herman Lam	1990	A Rule-based Language for Deductive Object-Oriented Databases.	ICDE	database
2	ICDE	Bill-of-Material Configuration Generation.	Michael R. Blaha,William J. Premerlani,A. R. Bender,R. M. Salemme,M. M. Kornfein,C. K. Harkins	1990	Bill-of-Material Configuration Generation.	ICDE	database
3	ICDE	Title, General Chairman's Message, Program Chairman's Message, Reviewers, Table of Contents, Author Index.		1990	Title, General Chairman's Message, Program Chairman's Message, Reviewers, Table of Contents, Author Index.	ICDE	database
4	ICDE	The Generalized Grid File: Description and Performance Aspects.	Henk M. Blanken,Alle IJbema,Paul Meek,Bert van den Akker	1990	The Generalized Grid File: Description and Performance Aspects.	ICDE	database
5	ICDE	Join Index, Materialized View, and Hybrid-Hash Join: A Performance Analysis.	José A. Blakeley,Nancy L. Martin	1990	Join Index, Materialized View, and Hybrid-Hash Join: A Performance Analysis.	ICDE	database
6	ICDE	Compilation of Logic Programs to Implement Very Large Knowledge Base Systems - A Case Study: Educe*.	Jorge B. Bocca	1990	Compilation of Logic Programs to Implement Very Large Knowledge Base Systems - A Case Study: Educe*.	ICDE	database
7	ICDE	Attribute Inheritance Implemented on Top of a Relational Database System.	Stefan Böttcher	1990	Attribute Inheritance Implemented on Top of a Relational Database System.	ICDE	database
8	ICDE	Update Propagation in Distributed Memory Hierarchy.	Matthew Bellew,Meichun Hsu,Va-On Tam	1990	Update Propagation in Distributed Memory Hierarchy.	ICDE	database
9	ICDE	Modeling Design Object Relationships in PEGASUS.	Alexandros Biliris	1990	Modeling Design Object Relationships in PEGASUS.	ICDE	database
10	ICDE	Experimental Evaluation of Concurrency Checkpointing and Rollback-Recovery Algorithms.	Bharat K. Bhargava,Shy-Renn Lian,Pei-Jyun Leu	1990	Experimental Evaluation of Concurrency Checkpointing and Rollback-Recovery Algorithms.	ICDE	database
11	ICDE	An Attribute-Oriented Approach for Learning Classification Rules from Relational Databases.	Yandong Cai,Nick Cercone,Jiawei Han	1990	An Attribute-Oriented Approach for Learning Classification Rules from Relational Databases.	ICDE	database
12	ICDE	Generalization and a Framework for Query Modification.	Surajit Chaudhuri	1990	Generalization and a Framework for Query Modification.	ICDE	database
13	ICDE	Selectivity Estimation Using Homogeneity Measurement.	Meng Chang Chen,Lawrence McNamee,Norman S. Matloff	1990	Selectivity Estimation Using Homogeneity Measurement.	ICDE	database
14	ICDE	The Grid Protocol: A High Performance Scheme for Maintaining Replicated Data.	Shun Yan Cheung,Mostafa H. Ammar,Mustaque Ahamad	1990	A new protocol for maintaining replicated data that can provide both high data availability and low response time is presented. In the protocol, the nodes are organized in a logical grid. Existing protocols are designed primarily to achieve high availability by updating a large fraction of the copies, which provides some (although not significant) load sharing. In the new protocol, transaction processing is shared effectively among nodes storing copies of the data, and both the response time experienced by transactions and the system throughput are improved significantly. The authors analyze the availability of the new protocol and use simulation to study the effect of load sharing on the response time of transactions. They also compare the new protocol with a voting-based scheme.	ICDE	database
15	ICDE	Cost of Distributed Deadlock Detection: A Performance Study.	Alok N. Choudhary	1990	Cost of Distributed Deadlock Detection: A Performance Study.	ICDE	database
16	ICDE	Extending Object-Oriented Concepts to Support Engineering Applications.	Aloysius Cornelio,Shamkant B. Navathe,Keith L. Doty	1990	Extending Object-Oriented Concepts to Support Engineering Applications.	ICDE	database
17	ICDE	Database Buffer Model for the Data Sharing Environment.	Asit Dan,Daniel M. Dias,Philip S. Yu	1990	Database Buffer Model for the Data Sharing Environment.	ICDE	database
18	ICDE	A Paradigm for Concurrency Control in Heterogeneous Distributed Database Systems.	Ahmed K. Elmagarmid,Weimin Du	1990	A Paradigm for Concurrency Control in Heterogeneous Distributed Database Systems.	ICDE	database
19	ICDE	A Temporal Model and Query Language for ER Databases.	Ramez Elmasri,Gene T. J. Wuu	1990	A Temporal Model and Query Language for ER Databases.	ICDE	database
20	ICDE	Access Invariance and Its Use in High Contention Environments.	Peter A. Franaszek,John T. Robinson,Alexander Thomasian	1990	Access Invariance and Its Use in High Contention Environments.	ICDE	database
21	ICDE	A Multiuser Performance Analysis of Alternative Declustering Strategies.	Shahram Ghandeharizadeh,David J. DeWitt	1990	A Multiuser Performance Analysis of Alternative Declustering Strategies.	ICDE	database
22	ICDE	Multi-User View Integration System (MUVIS): An Expert System for View Integration.	Stephen Hayne,Sudha Ram	1990	Multi-User View Integration System (MUVIS): An Expert System for View Integration.	ICDE	database
23	ICDE	Object Views: Extending the Vision.	Sandra Heiler,Stanley B. Zdonik	1990	Object Views: Extending the Vision.	ICDE	database
24	ICDE	A Shared Conceptual Schema for Four Medical Expert Systems.	James P. Held,John V. Carlis	1990	A Shared Conceptual Schema for Four Medical Expert Systems.	ICDE	database
25	ICDE	Using a Meta Model to Represent Object-Oriented Data Models.	Shuguang Hong,Fred J. Maryanski	1990	Using a Meta Model to Represent Object-Oriented Data Models.	ICDE	database
26	ICDE	Chained Declustering: A New Availability Strategy for Multiprocessor Database Machines.	Hui-I Hsiao,David J. DeWitt	1990	Chained Declustering: A New Availability Strategy for Multiprocessor Database Machines.	ICDE	database
27	ICDE	The R-File: An Efficient Access Structure for Proximity Queries.	Andreas Hutflesz,Hans-Werner Six,Peter Widmayer	1990	The R-File: An Efficient Access Structure for Proximity Queries.	ICDE	database
28	ICDE	Parallelism in Object-Oriented Query Processing.	Kyung-Chang Kim	1990	Parallelism in Object-Oriented Query Processing.	ICDE	database
29	ICDE	A Flexible Transaction Model for Software Engineering.	Gail E. Kaiser	1990	A Flexible Transaction Model for Software Engineering.	ICDE	database
30	ICDE	System Issues in Parallel Sorting for Database Systems.	Balakrishna R. Iyer,Daniel M. Dias	1990	System Issues in Parallel Sorting for Database Systems.	ICDE	database
31	ICDE	Spatial Search with Polyhedra.	H. V. Jagadish	1990	Spatial Search with Polyhedra.	ICDE	database
32	ICDE	ViewSystem: Integrating Heterogeneous Information Bases by Object-Oriented Views.	Manfred Kaul,Klaus Drosten,Erich J. Neuhold	1990	ViewSystem: Integrating Heterogeneous Information Bases by Object-Oriented Views.	ICDE	database
33	ICDE	Alternatives in Complex Object Representation: A Performance Perspective.	Anant Jhingran,Michael Stonebraker	1990	Alternatives in Complex Object Representation: A Performance Perspective.	ICDE	database
34	ICDE	A Suitable Algorithm for Computing Partial Transitive Closures in Databases.	Bin Jiang	1990	A Suitable Algorithm for Computing Partial Transitive Closures in Databases.	ICDE	database
35	ICDE	Multilevel Secure Database Concurrency Control.	Thomas F. Keefe,Wei-Tek Tsai,Jaideep Srivastava	1990	Multilevel Secure Database Concurrency Control.	ICDE	database
36	ICDE	Long-Duration Transactions in Software Design Projects.	Henry F. Korth,Gregory D. Speegle	1990	Computer-assisted design applications pose many problems for database systems. Standard notions of correctness are insufficient, but some notion of correctness is still required. Formal transaction models have been proposed for such applications. However, the practicality of such models has not been clearly established. In this paper, we consider an example of a software development application and apply the NT/PV model to show how this example could be represented as a set of database transactions. We show that although the standard notion of correctness (serializability) is too strict, the notion of correctness in the NT/PV model allows sufficient concurrency with acceptable overhead. We extrapolate from this example to draw some conclusions regarding the potential usefulness of a formal approach to the management of long-duration design transactions.	ICDE	database
37	ICDE	An Object-Oriented Approach to Data/Knowledge Modeling Based on Logic.	Kyuchul Lee,Sukho Lee	1990	An Object-Oriented Approach to Data/Knowledge Modeling Based on Logic.	ICDE	database
38	ICDE	A Partitioned Signature File Structure for Multiattribute and Text Retrieval.	Dik Lun Lee,Chun-Wu Roger Leng	1990	A Partitioned Signature File Structure for Multiattribute and Text Retrieval.	ICDE	database
39	ICDE	Buffer and Load Balancing in Locally Distributed Database Systems.	Hongjun Lu,Kian-Lee Tan	1990	Buffer and Load Balancing in Locally Distributed Database Systems.	ICDE	database
40	ICDE	Propagating Updates in a Highly Replicated Database.	Tony P. Ng	1990	Propagating Updates in a Highly Replicated Database.	ICDE	database
41	ICDE	An Analysis of Borrowing Policies for Escrow Transactions in a Replicated Data Environment.	Akhil Kumar	1990	An Analysis of Borrowing Policies for Escrow Transactions in a Replicated Data Environment.	ICDE	database
42	ICDE	Query Processing for Temporal Databases.	T. Y. Cliff Leung,Richard R. Muntz	1990	Query Processing for Temporal Databases.	ICDE	database
43	ICDE	Multimedia Object Models for Synchronisation and Databases.	Thomas D. C. Little,Arif Ghafoor	1990	Multimedia Object Models for Synchronisation and Databases.	ICDE	database
44	ICDE	On Representing Indefinite and Maybe Information in Relational Databases: A Generalization.	Ken-Chih Liu,Rajshekhar Sunderraman	1990	On Representing Indefinite and Maybe Information in Relational Databases: A Generalization.	ICDE	database
45	ICDE	A Brief Overview of LILOG-DB.	Thomas Ludwig	1990	A Brief Overview of LILOG-DB.	ICDE	database
46	ICDE	Representing Processes in the Extended Entity-Relationship Model.	Victor M. Markowitz	1990	Representing Processes in the Extended Entity-Relationship Model.	ICDE	database
47	ICDE	A ``Greedy'' Approach to the Write Problem in Shadowed Disk Systems.	Norman S. Matloff,Raymond Wai-Man Lo	1990	A ``Greedy'' Approach to the Write Problem in Shadowed Disk Systems.	ICDE	database
48	ICDE	Structuring Knowledge Bases Using Automatic Learning.	Guy W. Mineau,Jan Gecsei,Robert Godin	1990	Structuring Knowledge Bases Using Automatic Learning.	ICDE	database
49	ICDE	An Algorithmic Basis for Integrating Production Systems and Large Databases.	Daniel P. Miranker,David A. Brant	1990	An Algorithmic Basis for Integrating Production Systems and Large Databases.	ICDE	database
50	ICDE	Concurrency Control of Bulk Access Transactions on Shared Nothing Parallel Database Machines.	Tadashi Ohmori,Masaru Kitsuregawa,Hidehiko Tanaka	1990	Concurrency Control of Bulk Access Transactions on Shared Nothing Parallel Database Machines.	ICDE	database
51	ICDE	A New Tree Type Data Structure with Homogeneous Nodes Suitable for a Very Large Spatial Database.	Yutaka Ohsawa,Masao Sakauchi	1990	A New Tree Type Data Structure with Homogeneous Nodes Suitable for a Very Large Spatial Database.	ICDE	database
52	ICDE	Serializability in Object-Oriented Database Systems.	Thomas C. Rakow,Junzhong Gu,Erich J. Neuhold	1990	Serializability in Object-Oriented Database Systems.	ICDE	database
53	ICDE	A Cooperative Approach to Large Knowledge Based Systems.	C. V. Ramamoorthy,Shashi Shekhar	1990	A Cooperative Approach to Large Knowledge Based Systems.	ICDE	database
54	ICDE	How to Share Work on Shared Objects in Design Databases.	Michael Ranft,Simone Rehm,Klaus R. Dittrich	1990	How to Share Work on Shared Objects in Design Databases.	ICDE	database
55	ICDE	Scheduling Data Redistribution in Distributed Databases.	Pedro I. Rivera-Vega,Ravi Varadarajan,Shamkant B. Navathe	1990	Scheduling Data Redistribution in Distributed Databases.	ICDE	database
56	ICDE	A Query Algebra for Object-Oriented Databases.	Gail M. Shaw,Stanley B. Zdonik	1990	We define an algebra that synthesizes relational query concepts with object-oriented databases. The algebra fully supports abstract data types and object identity while providing associative access to objects, including a unique join capability. The operations take an abstract view of objects and access typed collections of objects through the public interface defined for the type. The algebra supports access to relationships implied by the structure of the objects, as well as the definition and creation of new relationships between objects. The structure of the algebra and the abstract access to objects offer opportunities for query optimization.	ICDE	database
57	ICDE	A Modular Query Optimizer Generator.	Edward Sciore,John Sieg Jr.	1990	A Modular Query Optimizer Generator.	ICDE	database
58	ICDE	Currency-Based Updates to Distributed Materialized Views.	Arie Segev,Weiping Fang	1990	Currency-Based Updates to Distributed Materialized Views.	ICDE	database
59	ICDE	Extended Relations.	John Sieg Jr.,Edward Sciore	1990	Extended Relations.	ICDE	database
60	ICDE	The Semantic Data Model for Security: Representing the Security Semantics of an Application.	Gary W. Smith	1990	The Semantic Data Model for Security: Representing the Security Semantics of an Application.	ICDE	database
61	ICDE	Performance Evaluation of Multiversion Database Systems.	Sang Hyuk Son,Navid Haghighi	1990	Performance Evaluation of Multiversion Database Systems.	ICDE	database
62	ICDE	Parallelism in Database Production Systems.	Jaideep Srivastava,Kuo-Wei Hwang,Jack S. Eddy Tan	1990	Parallelism in Database Production Systems.	ICDE	database
63	ICDE	Distributed RAID - A New Multiple Copy Algorithm.	Michael Stonebraker,Gerhard A. Schloss	1990	Distributed RAID - A New Multiple Copy Algorithm.	ICDE	database
64	ICDE	Supporting Universal Quantification in a Two-Dimensional Database Query Language.	Kyu-Young Whang,Ashok Malhotra,Gary H. Sockut,Luanne M. Burns	1990	Supporting Universal Quantification in a Two-Dimensional Database Query Language.	ICDE	database
65	ICDE	The Fingerprinted Database.	Neal R. Wagner,Robert L. Fountain,Robert J. Hazy	1990	The Fingerprinted Database.	ICDE	database
66	ICDE	Concurrency Control Using Locking with Deferred Blocking.	Philip S. Yu,Daniel M. Dias	1990	Concurrency Control Using Locking with Deferred Blocking.	ICDE	database
67	ICDE	Experiences with Distributed Query Processing.	Clement T. Yu,Chengwen Liu	1990	Experiences with Distributed Query Processing.	ICDE	database
68	SIGMOD Conference	Efficient Updates to Independent Schemes in the Weak Instance Model.	Paolo Atzeni,Riccardo Torlone	1990	The weak instance model is a framework to consider the relations in a database as a whole, regardless of the way attributes are grouped in the individual relations. Queries and updates can be performed involving any set of attributes. The management of updates is based on a lattice structure on the set of legal states, and inconsistencies and ambiguities can arise In the general case, the test for inconsistency and determinism may involve the application of the chase algorithm to the whole database. In this paper it is shown how, for the highly significant class of independent schemes, updates can be handled efficiently, considering only the relevant portion of the database.	SIGMOD Conferen	database
69	SIGMOD Conference	OdeView: The Graphical Interface to Ode.	Rakesh Agrawal,Narain H. Gehani,J. Srinivasan	1990	OdeView is the graphical front end for Ode, an object-oriented database system and environment. Ode's data model supports data encapsulation, type inheritance, and complex objects. OdeView provides facilities for examining the database schema (i.e., the object type or class hierarchy), examining class definitions, browsing objects, following chains of references starting from an object, synchronized browsing, displaying selected portions of objects (projection), and retrieving objects with specific characteristics (selection). OdeView does not need to know about the internals of Ode objects. Consequently, the internals of specific classes are not hardwired into OdeView and new classes can be added to the Ode database without requiring any changes to or recompilation of OdeView. Just as OdeView does not know about the object internals, class functions (methods) for displaying objects are written without knowing about the specifics of the windowing software used by OdeView or the graphical user interface provided by it. In this paper, we present OdeView, and discuss its design and implementation.	SIGMOD Conferen	database
70	SIGMOD Conference	OdeView: A User-Friendly Graphical Interface to Ode.	Rakesh Agrawal,Narain H. Gehani,J. Srinivasan	1990	OdeView is the graphical front end for Ode, an object-oriented database system and environment. It is intended for users who do not want to write programs in Ode's database programming language O++ to interact with Ode but instead want to use a friendlier interface to Ode. OdeView is based on the graphical direct manipulation paradigm that involves selection of items from pop-up menus and icons that can be clicked on and dragged. OdeView provides facilities for examining the database schema examining class definitions, browsing objects, following chains of references, displaying selected portions of objects or selecting a subset of the ways in which an object can be displayed (projection), and retrieving specific objects (selection). Upon entering OdeView, the user is presented with a scrollable &ldquo;database&rdquo; window containing the names and iconified images of the current Ode databases. The user can select a database to interact with by using the mouse to click on the appropriate icon. OdeView then opens a &ldquo;class relationship&rdquo; window which displays the hierarchy relationship between the object classes database. The hierarchy relationship between classes is a set of dags. The user can zoom in and zoom out to examine this dag at various levels of detail. The user can also examine a class in detail by clicking at the node labeled with the class of interest. Clicking results in the opening of a &ldquo;class information&rdquo; window that has three scrollable subwindows, one showing its superclasses, the second its subclasses, and the third showing the meta data associated with this class. The class information window also has a button, clicking which shows the class definition. The user may continue schema browsing by selecting another node in the schema graph, or may click on one of the superclasses or subclasses. Associated with each class in Ode a the set of persistent objects of that class, called cluster. The class definition window has an &ldquo;objects&rdquo; button that allows users to browse through the objects in the cluster. Clicking this button opens the &ldquo;object set&rdquo; window which consists of two parts the control and object panels. The control panel consists of buttons reset, next, and previous to sequence through the objects. The object panel has buttons to view the object, projection (to view parts of the object), and to specify the selection criteria. An Ode object can be displayed in one or more formats depending upon the semantics of the display function associated with the corresponding class. The object set window supplies one button each for each of the object display formats. For example, an employee object can be displayed textually or in pictorial form, the object panel for employee will provides appropriate buttons to see these displays. An object may contain embedded references to other objects. The object panel of an object set window provides buttons for viewing these referenced objects. The basic browsing paradigm encouraged by OdeView is to start from an object and then explore the related objects in the database by following the embedded chains of references. To speed up such repetitive navigations, OdeView supports synchronized browsing. Once the user has displayed a network of objects and the user applies a sequencing operation to any object in this network, the sequencing operation is automatically propagated over the network. OdeView is implemented using X-Windows and HP-Widgets on a SUN workstation running the UNIX system. The video takes the viewers on a tour of OdeView, showing how a user interacts with OdeView to examine the database schema and the objects in the database.	SIGMOD Conferen	database
71	SIGMOD Conference	The Object-Oriented Database System Manifesto.	Malcolm P. Atkinson,François Bancilhon,David J. DeWitt,Klaus R. Dittrich,David Maier,Stanley B. Zdonik	1990	The Object-Oriented Database System Manifesto.	SIGMOD Conferen	database
72	SIGMOD Conference	Performance Evaluation of Semantics-based Multilevel Concurrency Control Protocols.	B. R. Badrinath,Krithi Ramamritham	1990	For next generation information systems, concurrency control mechanisms are required to handle high level abstract operations and to meet high throughput demands. The currently available single level concurrency control mechanisms for reads and writes are inadequate for future complex information systems. In this paper, we will present a new multilevel concurrency protocol that uses a semantics-based notion of conflict, which is weaker than commutativity, called recoverability. Further, operations are scheduled according to relative conflict, a conflict notion based on the structure of operations. Performance evaluation via extensive simulation studies show that with our multilevel concurrency control protocol, the performance improvement is significant when compared to that of a single level two-phase locking based concurrency control scheme or to that of a multilevel concurrency control scheme based on commutativity alone. Further, simulation studies show that our new multilevel concurrency control protocol performs better even with resource contention.	SIGMOD Conferen	database
73	SIGMOD Conference	Implementing Recoverable Requests Using Queues.	Philip A. Bernstein,Meichun Hsu,Bruce Mann	1990	Transactions have been rigorously defined and extensively studied in the database and transaction processing literature, but little has been said about the handling of the requests for transaction execution in commercial TP systems, especially distributed ones, managing the flow of requests is often as important as executing the transactions themselves. This paper studies fault-tolerant protocols for managing the flow of transaction requests between clients that issue requests and servers that process them. We discuss how to implement these protocols using transactions and recoverable queuing systems. Queuing systems are used to move requests reliably between clients and servers. The protocols use queuing systems to ensure that the server processes each request exactly once and that a client processes each reply at least once. We treat request-reply protocols for single-transaction requests, for multi-transaction requests, and for requests that require interaction with the display after the request is submitted.	SIGMOD Conferen	database
74	SIGMOD Conference	The INA: A Simple Query Language with Only Attribute Names.	Bruce I. Blum,Ralph D. Semmel	1990	Current query languages, such as SQL, assume that the user is familiar with the database schema including the attribute names, types, and relation associations. When a user has imperfect knowledge of this information (or when he balks at the data-processing orientation of the required statements), he normally asks an experienced analyst to perform his and hoc query. The Intelligent Navigational Assistant (INA) was developed for the U S Army as a prototype query tool that permits the users to specify requests using only domain terms familiar to them. Once a request is made, it is converted into SQL for processing1,2 To facilitate query formulation, the INA supports an interface that allows the user to identify attributes without relation associations (i.e., treats the data model as a universal relation). Because an attribute may appear in many relations, one of the principal tasks of the INA is the determination of the appropriate relation bindings. To aid in the selection of terms, the INA maintains a user vocabulary and provides facilities for browsing the vocabulary and examining term definitions. Thus, the INA has two primary functions it provides an easy-to-use interface for query definition, and it converts a request into SQL. The INA prototype has been implemented as a PC-resident knowledge-based system linked to a host-based DBMS. Its knowledge base is the logical schema of the target database, and the query transformation relies on the dependencies implicit in that schema. Supporting the knowledge-processing functions are the query definition interface, various tools to manage the target data model description, and facilities for communicating with other computers. The system was developed using TEDIUM@@@@,3 and the user interface and query resolution mechanism are extensions of earlier work with Tequila4 (which accessed the semantically-richer TEDIUM@@@@ data model) Work on the INA began in 1987 and was terminated in 1988. The system was demonstrated as a prototype with an Army-supplied logical model consisting of approximately 40 relations and 200 attributes. After query definition, reformation, and user acceptance, the SQL queries were submitted to the mainframe for processing. In those tests, the INA often produced better queries than those manually coded by analysts. The INA currently is undergoing a beta test with a much larger database schema. Its algorithms are described in reference 5, and reference 3 contains details regarding its implementation and semantic data model. Current research includes the development of improved query resolution algorithms based on an enriched semantic data model	SIGMOD Conferen	database
75	SIGMOD Conference	The R*-Tree: An Efficient and Robust Access Method for Points and Rectangles.	Norbert Beckmann,Hans-Peter Kriegel,Ralf Schneider,Bernhard Seeger	1990	The R-tree, one of the most popular access methods for rectangles, is based on the heuristic optimization of the area of the enclosing rectangle in each inner node. By running numerous experiments in a standardized testbed under highly varying data, queries and operations, we were able to design the R*-tree which incorporates a combined optimization of area, margin and overlap of each enclosing rectangle in the directory. Using our standardized testbed in an exhaustive performance comparison, it turned out that the R*-tree clearly outperforms the existing R-tree variants. Guttman's linear and quadratic R-tree and Greene's variant of the R-tree. This superiority of the R*-tree holds for different types of queries and operations, such as map overlay, for both rectangles and multidimensional points in all experiments. From a practical point of view the R*-tree is very attractive because of the following two reasons 1 it efficiently supports point and spatial data at the same time and 2 its implementation cost is only slightly higher than that of other R-trees.	SIGMOD Conferen	database
76	SIGMOD Conference	Reliable Transaction Management in a Multidatabase System.	Yuri Breitbart,Abraham Silberschatz,Glenn R. Thompson	1990	A model of a multidatabase system is defined in which each local DBMS uses the two-phase locking protocol Locks are released by a global transaction only after the transaction commits or aborts at each local site. Failures may occur during the processing of transactions. We design a fault tolerant transaction management algorithm and recovery procedures that retain global database consistency. We also show that our algorithms ensure freedom from global deadlocks of any kind.	SIGMOD Conferen	database
77	SIGMOD Conference	Integrating Object-Oriented Data Modeling with a Rule-Based Programming Paradigm.	Filippo Cacace,Stefano Ceri,Stefano Crespi-Reghizzi,Letizia Tanca,Roberto Zicari	1990	LOGRES is a new project for the development of extended database systems which is based on the integration of the object-oriented data modelling paradigm and of the rule-based approach for the specification of queries and updates. The data model supports generalization hierarchies and object sharing, the rule-based language extends Datalog to support generalized type constructors (sets, multisets, and sequences), rule-based integrity constraints are automatically produced by analyzing schema definitions. Modularization is a fundamental feature, as modules encapsulate queries and updates, when modules are applied to a LOGRES database, their side effects can be controlled. The LOGRES project is a follow-up of the ALGRES project, and takes advantage of the ALGRES programming environment for the development of a fast prototype.	SIGMOD Conferen	database
78	SIGMOD Conference	Kaleidoscope: A Cooperative Menu-Guided Query Interface.	Sang Kyun Cha,Gio Wiederhold	1990	Querying databases to obtain information requires the user's knowledge of query language and underlying data. However, because the knowledge in human long-term memory is imprecise, incomplete, and often incorrect, user queries are subject to various types of failure. These may include spelling mistakes, the violation of the syntax and semantics of a query language, and the misconception of the entities and relationships in a database. Kaleidoscope is a cooperative query interface whose knowledge guides users to avoid most failure during query creation. We call this type of cooperative behavior intraquery guidance. To enable this early, active engagement in the user's process of query creation, Kaleidoscope reduces the granularity of user-system interaction via a context-sensitive menu. The system generates valid query constituents as menu choices step-by-step by interpreting a language grammar, and the user creates a query following this menu guidance[2]. For instance, it takes four steps to create the following query [Q1] Who/1 authored/2 'Al'/3 journal papers/(3+) in 'Postquery COOP'/4 At each of such steps, as the user selects one of menu choices, the system updates its partial query status window. If a choice is unique as in (3+), it is taken automatically. To guide the user's entry of values, the system provides a pop-up menu for each value domain. With Kaleidoscope's process of choice generation tightly controlled by the system's knowledge of query language and underlying data, users need not remember the query language and the underlying database structure but merely recognize or identify the constituents coming one after another that match their intended query. The system provides additional guidance for users to avoid creating semantically inconsistent queries. It informs the user of any derived predicates on the completion of a user-selected predicate. To illustrate this, consider a partially constructed SQL query [Q2] SELECT * FROM professor p#1 WHERE p#1 dept = 'CS' AND p#1 salary < 40000 Suppose that the system has an integrity constraint [IC] FROM professor p IF p dept = 'CS' AND p salary < 45000 THEN p rank = 'Assistant' This rules states that a CS professor whose salary is less than 45000 is an assistant professor. With the replacement of rule variable p in IC by Q2's range variable p#1, IC's leading two predicates subsume Q2's query condition, producing p#1 rank = 'Assistant'. Because this derived predicate is not subsumed by Q2's query condition, the system suspects that the user may not know of it and presents it to the user. Derived predicates, together with user-selected ones, constrain the user's further conjunctive extension of the partial query condition. For example, the system prunes the field rank (as well as the field dept) in the conjunctive extension of Q2, because the derived condition restricts the value of this field to a constant. As shown in examples, we apply Kaleidoscope's approach to two linear-syntax languages in different levels of abstraction SQL[1] and a query language whose syntax and semantics cover a subset of wh-queries. To implement the intraquery guidance, we extend context-free grammar by associating context variables with each grammar symbol and attaching several types of procedural decorations to grammar rules. This extension enables the system to capture the semantic constraints and its user-guiding actions in a domain-independent grammar. As the grammar is interpreted, the database-specific information is fed from the system's lexicon and knowledge base. The current implementation of Kaleidoscope runs on a XEROX-1186 LISP machine with a SUN server configured with a relational DBMS. The approach of Kaleidoscope is based on the normative system assumption. The system presents its capability transparently to the user in a context-dependent manner during the user's query creation. This makes the system usable even with a small amount of stored knowledge.	SIGMOD Conferen	database
79	SIGMOD Conference	ACTA: A Framework for Specifying and Reasoning about Transaction Structure and Behavior.	Panos K. Chrysanthis,Krithi Ramamritham	1990	Recently, a number of extensions to the traditional transaction model have been proposed to support new information-intensive applications such as CAD/CAM and software development. However, these extended models capture only a subset of interactions that can be found in such applications, and represent only some of the points within the spectrum of interactions possible in competitive and cooperative environments. ACTA is a formalizable framework developed for characterizing the whole spectrum of interactions. The ACTA framework is not yet another transaction model, but is intended to unify the existing models. ACTA allows for specifying the structure and the behavior of transactions as well as for reasoning about the concurrency and recovery properties of the transactions. In ACTA, the semantics of interactions are expressed in terms of transactions' effects on the commit and abort of other transactions and on objects' state and concurrency status (i.e., synchronization state). Its ability to capture the semantics of previously proposed transaction models is indicative of its generality. The reasoning capabilities of this framework have also been tested by using the framework to study the properties of a new model that is derived by combining two existing transaction models.	SIGMOD Conferen	database
80	SIGMOD Conference	The G+/GraphLog Visual Query System.	Mariano P. Consens,Alberto O. Mendelzon	1990	The video presentation &ldquo;The G+/GraphLog Visual Query System&rdquo; gives an overview of the capabilities of the ongoing implementation of the G+ Visual Query System for visualizing both data and queries as graphs. The system provides an environment for expressing queries in GraphLog [Con89, CM89, CM90], as well as for browsing, displaying and editing graphs. The visual query system also supports displaying the answers in several different ways. Graphs are a very natural representation for data in many application domains, for example, transportation networks, project scheduling, parts hierarchies, family trees, concept hierarchies, and Hypertext. From a broader perspective, many databases can be naturally viewed as graphs. In particular, any relational database in which we can identify one or more sets of objects of interest and relationships between them can be represented by mapping these objects into nodes and relationships into edges. In the case of semantic and object-oriented databases, there is a natural mapping of objects to nodes and attributes to edges. GraphLog is a visual query language, based on a graph representation of both data and queries, that has evolved from the earlier language G+ [CMW87, CMW89, MW89]. GraphLog queries ask for patterns that must be present or absent in the database graph. Each such pattern, called a query graph, defines new edges that are added to the graph whenever the pattern is found. GraphLog queries are sets of query graphs, called graphical queries. If, when looking at a query graph in a graphical query, we do not find an edge label in the database, then there must exist another query graph in the graphical query defining that edge. The language also supports computing aggregate functions and summarizing along paths. The G+ Visual Query System is currently implemented in Smalltalk-80&trade;, and runs on Sun 3, Sun 4 and Macintosh II workstations. A Graph Editor is available for editing query graphs and displaying database graphs. It supports graph &ldquo;cutting and pasting&rdquo;, as well as text editing of node and edge labels, node and edge repositioning and re-shaping, storage and retrieval of graphs as text files, etc. Automatic graph layout is also provided. For editing collections of graphs (such as graphical queries) a Graph Browser is available. The first answer mode supported by the G+ Visual Query System is to return as the result of a GraphLog query a graph with the new edges defined by the graphical query added to the database graph. An alternative way of visualizing answers is by high-lighting on the database graph, one at a time, the paths (or just the nodes) described by the query. This mode is particularly useful to locate interesting starting points for browsing. Rather than viewing the answers superimposed on the database graph, the user may choose to view them in a Graph Browser. The Graph Browser contains the set of subgraphs of the database graph that were found to satisfy the query. Finally, the user may select to collect all the subgraphs of the database graph that satisfy the query together into one new graph. This graph (as well as any other result graph from any of the above mentioned answer modes) in turn may be queried, providing a mechanism for iterative filtering of irrelevant information until a manageable subgraph is obtained.	SIGMOD Conferen	database
81	SIGMOD Conference	Organizing Long-Running Activities with Triggers and Transactions.	Umeshwar Dayal,Meichun Hsu,Rivka Ladin	1990	This paper addresses the problem of organising and controlling activities that involve multiple steps of processing and that typically are of long duration. We explore the use of triggers and transactions to specify and organize such long-running activities. Triggers offer data- or event-driven specification of control flow, and thus provide a flexible and modular framework with which the control structures of the activities can be extended or modified. We describe a model based on event-condition-action rules and coupling modes. The execution of these rules is governed by an extended nested transaction model. Through a detailed example, we illustrate the utility of the various features of the model for chaining related steps without sacrificing concurrency, for enforcing integrity constraints, and for providing flexible failure and exception handling.	SIGMOD Conferen	database
82	SIGMOD Conference	Encapsulation of Parallelism in the Volcano Query Processing System.	Goetz Graefe	1990	Volcano is a new dataflow query processing system we have developed for database systems research and education. The uniform interface between operators makes Volcano extensible by new operators. All operators are designed and coded as if they were meant for a single-process system only. When attempting to parallelize Volcano, we had to choose between two models of parallelization, called here the bracket and operator models. We describe the reasons for not choosing the bracket model, introduce the novel operator model, and provide details of Volcano's exchange operator that parallelizes all other operators. It allows intra-operator parallelism on partitioned datasets and both vertical and horizontal inter-operator parallelism. The exchange operator encapsulates all parallelism issues and therefore makes implementation of parallel database algorithms significantly easier and more robust. Included in this encapsulation is the translation between demand-driven dataflow within processes and data-driven dataflow between processes. Since the interface between Volcano operators is similar to the one used in &ldquo;real,&rdquo; commercial systems, the techniques described here can be used to parallelize other query processing engines.	SIGMOD Conferen	database
83	SIGMOD Conference	A Framework for the Parallel Processing of Datalog Queries.	Sumit Ganguly,Abraham Silberschatz,Shalom Tsur	1990	This paper presents several complementary methods for the parallel, bottom-up evaluation of Datalog queries. We introduce the notion of a discriminating predicate, based on hash functions, that partitions the computation between the processors in order to achieve parallelism. A parallelization scheme with the property of non-redundant computation (no duplication of computation by processors) is then studied in detail. The mapping of Datalog programs onto a network of processors, such that the results is a non-redundant computation, is also studied. The methods reported in this paper clearly demonstrate the trade-offs between redundancy and interprocessor-communication for this class of problems.	SIGMOD Conferen	database
84	SIGMOD Conference	A Graph-Oriented Object Model for Database End-User Interfaces.	Marc Gyssens,Jan Paredaens,Dirk Van Gucht	1990	A Graph-Oriented Object Model for Database End-User Interfaces.	SIGMOD Conferen	database
85	SIGMOD Conference	A Predicate Matching Algorithm for Database Rule Systems.	Eric N. Hanson,Moez Chaabouni,Chang-Ho Kim,Yu-Wang Wang	1990	Forward-chaining rule systems must test each newly asserted fact against a collection of predicates to find those rules that match the fact. Expert system rule engines use a simple combination of hashing and sequential search for this matching. We introduce an algorithm for finding the matching predicates that is more efficient than the standard algorithm when the number of predicates is large. We focus on equality and inequality predicates on totally ordered domains. This algorithm is well-suited for database rule systems, where predicate-testing speed is critical. A key component of the algorithm is the interval binary search tree (IBS-tree). The IBS-tree is designed to allow efficient retrieval of all intervals (e.g. range predicates) that overlap a point, while allowing dynamic insertion and deletion of intervals. The algorithm could also be used to improve the performance of forward-chaining inference engines for large expert systems applications.	SIGMOD Conferen	database
86	SIGMOD Conference	Randomized Algorithms for Optimizing Large Join Queries.	Yannis E. Ioannidis,Younkyung Cha Kang	1990	Query optimization for relational database systems is a combinatorial optimization problem, which makes exhaustive search unacceptable as the query size grows. Randomized algorithms, such as Simulated Annealing (SA) and Iterative Improvement (II), are viable alternatives to exhaustive search. We have adapted these algorithms to the optimization of project-select-join queries. We have tested them on large queries of various types with different databases, concluding that in most cases SA identifies a lower cost access plan than II. To explain this result, we have studied the shape of the cost function over the solution space associated with such queries and we have conjectured that it resembles a 'cup' with relatively small variations at the bottom. This has inspired a new Two Phase Optimization algorithm, which is a combination of Simulated Annealing and Iterative Improvement. Experimental results show that Two Phase Optimization outperforms the original algorithms in terms of both output quality and running time.	SIGMOD Conferen	database
87	SIGMOD Conference	Linear Clustering of Objects with Multiple Atributes.	H. V. Jagadish	1990	There is often a need to map a multi-dimensional space on to a one-dimensional space. For example, this kind of mapping has been proposed to permit the use of one-dimensional indexing techniques to a multi-dimensional index space such as in a spatial database. This kind of mapping is also of value in assigning physical storage, such as assigning buckets to records that have been indexed on multiple attributes, to minimize the disk access effort. In this paper, we discuss what the desired properties of such a mapping are, and evaluate, through analysis and simulation, several mappings that have been proposed in the past. We present a mapping based on Hilbert's space-filling curve, which out-performs previously proposed mappings on average over a variety of different operating conditions.	SIGMOD Conferen	database
88	SIGMOD Conference	Access Support in Object Bases.	Alfons Kemper,Guido Moerkotte	1990	In this work access support relations are introduced as a means for optimizing query processing in object-oriented database systems. The general idea is to maintain redundant separate structures (disassociated from the object representation) to store object references that are frequently traversed in database queries. The proposed access support relation technique is no longer restricted to relate an object (tuple) to an atomic value (attribute value) as in conventional indexing. Rather, access support relations relate objects with each other and can span over reference chains which may contain collection-valued components in order to support queries involving path expressions. We present several alternative extensions of access support relations for a given path expression, the best of which has to be determined according to the application-specific database usage profile. An analytical cost model for access support relations and their application is developed. This analytical cost model is, in particular, used to determine the best access support relation extension and decomposition with respect to the specific database configuration and application profile.	SIGMOD Conferen	database
89	SIGMOD Conference	The Iris Database System.	William Kent,Peter Lyngbæk,Samir Mathur,W. Kevin Wilkinson	1990	The Iris Database System.	SIGMOD Conferen	database
90	SIGMOD Conference	Making Deductive Databases a Practical Technology: A Step Forward.	Gerald Kiernan,Christophe de Maindreville,Eric Simon	1990	Deductive databases provide a formal framework to study rule-based query languages that are extensions of first-order logic. However, deductive database languages and their current implementations do not seem appropriate for improving the development of real applications or even sample of them. Our goal is to make deductive database technology practical. The design and implementation of the RDL1 system, presented in this paper, constitute a step toward this goal. Our approach is based on the integration of a production rule language within a relational database system, the development of a rule-based programming environment and the support of system extensibility using Abstract Data Types. We discuss important practical experience gained during the implementation of the system. Also, comparisons with related work such as LDL, STARBURST and POSTGRES are given.	SIGMOD Conferen	database
91	SIGMOD Conference	Bayan: An Arabic Text Database Management System.	Roger King,Ali Morfeq	1990	Most existing databases lack features which allow for the convenient manipulation of text. It is even more difficult to use them if the text language is not based on the Roman alphabet. The Arabic language is a very good example of this case. Many projects have attempted to use conventional database systems for Arabic data manipulation (including text data), but because of Arabic's many differences with English, these projects have met with limited success. In the Bayan project, the approach has been different. Instead of simply trying to adopt an environment to Arabic, the properties of the Arabic language were the starting point and everything was designed to meet the needs of Arabic, thus avoiding the shortcomings of other projects. A text database management system was designed to overcome the shortcomings of conventional database management systems in manipulating text data. Bayan's data model is based on an object-oriented approach which helps the extensibility of the system for future use. In Bayan, we designed the database with the Arabic text properties in mind. We designed it to support the way Arabic words are derived, classified, and constructed. Furthermore, linguistic algorithms (for word generation and morphological decomposition of words) were designed, leading to a formalization of rules of Arabic language writing and sentence construction. A user interface was designed on top of this environment. A new representation of the Arabic characters was designed, a complete Arabic keyboard layout was created, and a window-based Arabic user interface was also designed.	SIGMOD Conferen	database
92	SIGMOD Conference	Concurrency Control in Multilevel-Secure Databases Based on Replicated Architecture.	Boris Kogan,Sushil Jajodia	1990	In a multilevel secure database management system based on the replicated architecture, there is a separate database management system to manage data at or below each security level, and lower level data are replicated in all databases containing higher level data. In this paper, we address the open issue of concurrency control in such a system. We give a secure protocol that guarantees one-copy serializability of concurrent transaction executions and can be implemented in such a way that the size of the trusted code (including the code required for concurrency and recovery) is small.	SIGMOD Conferen	database
93	SIGMOD Conference	Pasta-3: A Graphical Direct Manipulation Interface for Knowledge Base Management Systems.	Michel Kuntz	1990	Pasta-3 is an end-user interface for D/KBMSs based on the graphical Direct Manipulation (DM) interaction paradigm, which relies on a bit-mapped, multi-window screen and a mouse to implement clickable icons as the main representation of information. This style of interaction enables end users to learn quickly and remember easily how the system works. Pasta-3 gives complete access to the D/KBMS, since its users can carry out all manipulation tasks through it schema definition, schema and data browsing, query formulation, and updating. These tasks can be freely mixed, combined, and switched Pasta-3 interfaces to the KB2 knowledge base system, implemented in Prolog and built over the EDUCE system which provides a tight coupling to a relational DBMS KB2 uses the Entity-Relationship data model, extended with inheritance and deduction rules. KB2 was developed by the KB Group at ECRC. Pasta-3 uses Direct Manipulation in the strong sense of the term DM of the actual graphical representations of the application data and not just DM of commands operating on that data. Besides the high degree of integration in the overall design, major innovations with respect to earlier work include enhanced schema browsing with active functionalities to facilitate correct user understanding of the KB structure, &ldquo;synchronized&rdquo; data browsing that exploits the underlying semantic data model to make browsing more powerful, and a graphical query language providing full expressive power (including certain recursive queries, nested subsequeries, quantification). Pasta-3 provides interactive design support that has significant ergonomic advantages over the usual approach to this problem. In Pasta-3 different types of schema information &mdash; the basic E-R diagram, and inheritance lattices, the properties of each E-R item &mdash; are displayed in separate windows, which makes accurate reading of such information much less difficult than in the usual case where all these layers are thrown together in a single graph, which makes misinterpretation hard to avoid. For schema and data browsing, Pasta-3 offers facilities that build more semantics into the browsing processes. One type of schema browsing tool is a subgraph computation capability which automatically finds and displays the paths that connect arbitrary E-R items. This helps end users to correctly perceive the schema structure. Data browsing includes &ldquo;synchronised&rdquo; browsing, a functionality which shows simultaneously data from several Entities all sharing the same Relationship and indicates which values from each Entity are associated with given values from the others. Pasta-3's DM query language replaces the textual language without loss of expressive power it offers a new, sophisticated DM editing capability for the same formal constructs. Query specification takes place in a window containing icons representing the components of the query expression which can be created, destroyed, and modified all by clicking and dragging through the mouse. Queries can be recursive and involve logical variables, quantification, and subqueries. Expressions mixing both KB2 statements and Prolog predicates can also be formulated. The video shows Pasta-3 actually being used, in real time and under normal conditions. It includes sequences demonstrating all three major functionalities schema design browsing, and querying. It gives an example of the subgraph computation capability and builds a simple query from scratch, going through all the steps needed to do so. The demonstration also includes work with other types of Pasta-3 windows (e g property sheets). The video has an English-language sound track explaining everything that is seen on the screen. The camera zooms in and out in order to show full screen overviews (giving a good idea of the general &ldquo;feel&rdquo; of the interface) and close-ups of work with mouse and icons (allowing the viewer to see as much detail in the video as an actual user would, seated in front of the workstation).	SIGMOD Conferen	database
94	SIGMOD Conference	Extending Logic Programming.	Els Laenens,Domenico Saccà,Dirk Vermeir	1990	An extension of logic programming, called &ldquo;ordered logic programming&rdquo;, which includes some abstractions of the object-oriented paradigm, is presented. An ordered program consists of a number of modules (objects), where each module is composed by a number of rules possibly with negated head predicates. A sort of &ldquo;isa&rdquo; hierarchy can be defined among the modules in order to allow for rule inheritance. Therefore, every module sees its own rules as local rules and the rules of the other modules to which it is connected by the &ldquo;isa&rdquo; hierarchy as global rules. In this way, as local rules may hide global rules, it is possible to deal with default properties and exceptions. This new approach represents a novel attempt to combine the logic paradigm with the object-oriented one in knowledge base systems. Moreover, this approach provides a new ground for explaining some recent proposals of semantics for classical logic programs with negation in the rule bodies and gives an interesting semantics to logic programs with negated rule heads.	SIGMOD Conferen	database
95	SIGMOD Conference	A Starburst is Born.	George Lapis,Guy M. Lohman,Hamid Pirahesh	1990	A Starburst is Born.	SIGMOD Conferen	database
96	SIGMOD Conference	The Performance of a Multiversion Access Method.	David B. Lomet,Betty Salzberg	1990	The Time-Split B-tree is an integrated index structure for a versioned timestamped database. It gradually migrates data from a current database to an historical database, records migrating when nodes split. Records valid at the split time are placed in both an historical node and a current node. This implies some redundancy. Using both analysis and simulation, we characterise the amount of redundancy, the space utilization, and the record addition (insert or update) performance for a spectrum of different rates of insertion versus update. Three splitting policies are studied which alter the conditions under which either time splits or key space splits are performed.	SIGMOD Conferen	database
97	SIGMOD Conference	Practical Selectivity Estimation through Adaptive Sampling.	Richard J. Lipton,Jeffrey F. Naughton,Donovan A. Schneider	1990	Recently we have proposed an adaptive, random sampling algorithm for general query size estimation. In earlier work we analyzed the asymptotic efficiency and accuracy of the algorithm, in this paper we investigate its practicality as applied to selects and joins. First, we extend our previous analysis to provide significantly improved bounds on the amount of sampling necessary for a given level of accuracy. Next, we provide &ldquo;sanity bounds&rdquo; to deal with queries for which the underlying data is extremely skewed or the query result is very small. Finally, we report on the performance of the estimation algorithm as implemented in a host language on a commercial relational system. The results are encouraging, even with this loose coupling between the estimation algorithm and the DBMS.	SIGMOD Conferen	database
98	SIGMOD Conference	Querying Database Knowledge.	Amihai Motro,Qiuhui Yuan	1990	The role of database knowledge is usually limited to the evaluation of data queries. In this paper we argue that when this knowledge is of substantial volume and complexity, there is genuine need to query this repository of information. Moreover, since users of the database may not be able to distinguish between information that is data and information that is knowledge, access to knowledge and data should be provided with a single, coherent instrument. We provide an informal review of various kinds of knowledge queries, with possible syntax and semantics. We then formalize a framework of knowledge-rich databases, and a simple query language consisting of a pair of retrieve and describe statements. The retrieve statement is for querying the data (it corresponds to the basic retrieval statement of various knowledge-rich database systems). The describe statement is for querying the knowledge. Essentially, it inquires about the meaning of a concept under specified circumstances. We provide algorithms for evaluating sound and finite knowledge answers to describe queries, and we demonstrate them with examples.	SIGMOD Conferen	database
99	SIGMOD Conference	Magic is Relevant.	Inderpal Singh Mumick,Sheldon J. Finkelstein,Hamid Pirahesh,Raghu Ramakrishnan	1990	We define the magic-sets transformation for traditional relational systems (with duplicates, aggregation and grouping), as well as for relational systems extended with recursion. We compare the magic-sets rewriting to traditional optimization techniques for nonrecursive queries, and use performance experiments to argue that the magic-sets transformation is often a better optimization technique.	SIGMOD Conferen	database
100	SIGMOD Conference	Random Sampling from Hash Files.	Frank Olken,Doron Rotem,Ping Xu	1990	In this paper we discuss simple random sampling from hash files on secondary storage. We consider both iterative and batch sampling algorithms from both static and dynamic hashing methods. The static methods considered are open addressing hash files and hash files with separate overflow chains. The dynamic hashing methods considered are Linear Hash files [Lit80] and Extendible Hash files [FNPS79]. We give the cost of sampling in terms of the cost of successfully searching a hash file and show how to exploit features of the dynamic hashing methods to improve sampling efficiency.	SIGMOD Conferen	database
101	SIGMOD Conference	A Comparison of Spatial Query Processing Techniques for Native and Parameter Spaces.	Jack A. Orenstein	1990	Spatial queries can be evaluated in native space or in a parameter space. In the latter case, data objects are transformed into points and query objects are transformed into search regions. The requirement for different data and query representations may prevent the use of parameter-space searching in some applications. Native-space and parameter-space searching are compared in the context of a z order-based spatial access method. Experimental results show that when there is a single query object, searching in parameter space can be faster than searching in native space, if the data and query objects are large enough, and if sufficient redundancy is used for the query representation. The result is, however, less accurate than the native space result. When there are multiple query objects, native-space searching is better initially, but as the number of query objects increases, parameter space searching with low redundancy is superior. Native-space searching is much more accurate for multiple-object queries.	SIGMOD Conferen	database
102	SIGMOD Conference	Database Management Issues of the Human Genome Project.	Robert M. Pecherer	1990	Database Management Issues of the Human Genome Project.	SIGMOD Conferen	database
103	SIGMOD Conference	Query Graphs, Implementing Trees, and Freely-Reorderable Outerjoins.	Arnon Rosenthal,César A. Galindo-Legaria	1990	We determine when a join/outerjoin query can be expressed unambiguously as a query graph, without an explicit specification of the order of evaluation. To do so, we first characterize the set of expression trees that implement a given join/outerjoin query graph, and investigate the existence of transformations among the various trees. Our main theorem is that a join/outerjoin query is freely reorderable if the query graph derived from it falls within a particular class, every tree that &ldquo;implements&rdquo; such a graph evaluates to the same result. The result has applications to language design and query optimization. Languages that generate queries within such a class do not require the user to indicate priority among join operations, and hence may present a simplified syntax. And it is unnecessary to add extensive analyses to a conventional query optimizer in order to generate legal reorderings for a freely-reorderable language.	SIGMOD Conferen	database
104	SIGMOD Conference	FastSort: A Distributed Single-Input Single-Output External Sort.	Betty Salzberg,Alex Tsukerman,Jim Gray,Michael Stewart,Susan Uren,Bonnie Vaughan	1990	External single-input single-output sorts can use multiple processors each with a large tournament replacement-selection in memory, and each with private disks to sort an input stream in linear elapsed time. Of course, increased numbers of processors, memories, and disks are required as the input file size grows. This paper analyzes the algorithm and reports the performance of an implementation.	SIGMOD Conferen	database
105	SIGMOD Conference	Hard Problems for Simple Logic Programs.	Yatin P. Saraiya	1990	A number of optimizations have been proposed for Datalog programs involving a single intensional predicate (&ldquo;single-IDB programs&rdquo;). Examples include the detection of commutativity and separability ([Naug88],[RSUV89], [Ioan89a]) in linear logic programs, and the detection of ZYT-linearizability ([ZYT88], [RSUV89], [Sara89], [Sara90]) in nonlinear programs. We show that the natural generalizations of the commutativity and ZYT-linearizability problems (respectively, the sequencability and base-case linearizability problems) are undecidable. Our constructions involve the simulation of context-free grammars using single-IDB programs that have a bounded number of initialisation rules. The constructions may be used to show that containment (or equivalence) is undecidable for such programs, even if the programs are linear, or if each program contains a single recursive rule. These results tighten those of [Shmu87] and [Abit89].	SIGMOD Conferen	database
106	SIGMOD Conference	A Performance Evaluation of Pointer-Based Joins.	Eugene J. Shekita,Michael J. Carey	1990	In this paper we describe three pointer-based join algorithms that are simple variants of the nested-loops, sort-merge, and hybrid-hash join algorithms used in relational database systems. Each join algorithm is described and an analysis is carried out to compare the performance of the pointer-based algorithms to their standard, non-pointer-based counterparts. The results of the analysis show that the pointer-based algorithms can provide significant performance gains in many situations. The results also show that the pointer-based nested-loops join algorithm, which is perhaps the most natural pointer-based join algorithm to consider using in an object-oriented database system, performs quite poorly on most medium to large joins.	SIGMOD Conferen	database
107	SIGMOD Conference	IDLOG: Extending the Expressive Power of Deductive Database Languages.	Yeh-Heng Sheng	1990	The expressive power of pure deductive database languages, such as DATALOG and stratified DATALOGS, is limited in a sense that some useful queries such as functions involving aggregation are not definable in these languages. Our concern in this paper is to provide a uniform logic framework for deductive databases with greater expressive power. It has been shown that with a linear ordering on the domain of the database, the expressive power of some database languages can be enhanced so that some functions involving aggregation can be defined. Yet, a direct implementation of the linear ordering in deductive database languages may seem unintuitive, and may not be very efficient to use in practice. We propose a logic for deductive databases which employs the notion of &ldquo;identifying each tuple in a relation&rdquo;. Through the use of these tuple-identifications, different linear orderings are defined as a result. This intuitively explains the reason why our logic has greater expressive power. The proposed logic language is non-deterministu in nature. However, non-determinism is not the real reason for the enhanced expressive power. A deterministic subset of the programs in this language is computational complete in the sense that it defines all the computable deterministic queries. Although the problem of deciding whether a program is in this subset is in general undecidable, we do provide a rather general sufficient test for identifying such programs. Also discussed in this paper is an extended notion of queries which allows both the input and the output of a query to contain interpreted constants of an infinite domain. We show that extended queries involving aggregation can also be defined in the language.	SIGMOD Conferen	database
108	SIGMOD Conference	Write-Only Disk Caches.	Jon A. Solworth,Cyril U. Orji	1990	With recent declines in the cost of semiconductor memory and the increasing need for high performance I/O disk systems, it makes sense to consider the design of large caches. In this paper, we consider the effect of caching writes. We show that cache sizes in the range of a few percent allow writes to be performed at negligible or no cost and independently of locality considerations.	SIGMOD Conferen	database
109	SIGMOD Conference	The Postgres DBMS.	Michael Stonebraker	1990	The Postgres DBMS.	SIGMOD Conferen	database
110	SIGMOD Conference	On Rules, Procedures, Caching and Views in Data Base Systems.	Michael Stonebraker,Anant Jhingran,Jeffrey Goh,Spyros Potamianos	1990	This paper demonstrates that a simple rule system can be constructed that supports a more powerful view system than available in current commercial systems. Not only can views be specified by using rules but also special semantics for resolving ambiguous view updates are simply additional rules. Moreover, procedural data types as proposed in POSTGRES are also efficiently simulated by the same rules system. Lastly, caching of the action part of certain rules is a possible performance enhancement and can be applied to materialize views as well as to cache procedural data items. Hence, we conclude that a rule system is a fundamental concept in a next generation DBMS, and it subsumes both views and procedures as special cases.	SIGMOD Conferen	database
111	SIGMOD Conference	The Committee for Advanced DBMS Function: Third Generation Data Base System Manifesto.	Michael Stonebraker,Lawrence A. Rowe,Bruce G. Lindsay,Jim Gray,Michael J. Carey,David Beech	1990	The Committee for Advanced DBMS Function: Third Generation Data Base System Manifesto.	SIGMOD Conferen	database
112	SIGMOD Conference	The Input/Output Complexity of Transitive Closure.	Jeffrey D. Ullman,Mihalis Yannakakis	1990	Suppose a directed graph has its arcs stored in secondary memory, and we wish to compute its transitive closure, also storing the result in secondary memory. We assume that an amount of main memory capable of holding s &ldquo;values&rdquo; is available, and that s lies between n, the number of nodes of the graph, and e, the number of arcs. The cost measure we use for algorithms is the I/O complexity of Kung and Hong, where we count 1 every time a value is moved into main memory from secondary memory, or vice versa. In the dense case, where e is close to n2, we show that I/O equal to &Ogr;(n3 / &radic;s) is sufficient to compute the transitive closure of an n-node graph, using main memory of size s. Moreover, it is necessary for any algorithm that is &ldquo;standard,&rdquo; in a sense to be defined precisely in the paper. Roughly, &ldquo;standard&rdquo; means that paths are constructed only by concatenating arcs and previously discovered paths. This class includes the usual algorithms that work for the generalization of transitive closure to semiring problems. For the sparse case, we show that I/O equal to &Ogr;(n2 &radic;e/s) is sufficient, although the algorithm we propose meets our definition of &ldquo;standard&rdquo; only if the underlying graph is acyclic. We also show that &OHgr;(n2 &radic;e/s) is necessary for any standard algorithm in the sparse case. That settles the I/O complexity of the sparse/acyclic case, for standard algorithms. It is unknown whether this complexity can be achieved in the sparse, cyclic case, by a standard algorithm, and it is unknown whether the bound can be beaten by nonstandard algorithms. We then consider a special kind of standard algorithm, in which paths are constructed only by concatenating arcs and old paths, never by concatenating two old paths. This restriction seems essential if we are to take advantage of sparseness. Unfortunately, we show that almost another factor of n I/O is necessary. That is, there is an algorithm in this class using I/O &Ogr;(n3 &radic;e/s) for arbitrary sparse graphs, including cyclic ones. Moreover, every algorithm in the restricted class must use &OHgr;(n3 &radic;e/s/log3 n) I/O, on some cyclic graphs.	SIGMOD Conferen	database
113	SIGMOD Conference	Polynomial Time Designs toward Both BCNF and Efficient Data Manipulation.	Ke Wang	1990	We define the independence-reducibility based on a modification of key dependencies, which has better computational properties and is more practically useful than the original one based on key dependencies. Using this modification as a tool, we design BCNF databases that are highly desirable with respect to updates and/or query answering. In particular, given a set U of attributes and a set F of functional dependencies over U, we characterize when F can be embedded in a database scheme over U that is independent and is BCNF with respect to F, a polynomial time algorithm that tests this characterization and produces such a database scheme whenever possible is presented. The produced database scheme contains the fewest possible number of relation schemes. Then we show that designs of embedding constant-time-maintainable BCNF schemes and of embedding independence-reducible schemes share exactly the same method with the above design. Finally, a simple modification of this method yields a polynomial time algorithm for designing embedding separable BCNF schemes.	SIGMOD Conferen	database
114	SIGMOD Conference	Set-Oriented Production Rules in Relational Database Systems.	Jennifer Widom,Sheldon J. Finkelstein	1990	We propose incorporating a production rules facility into a relational database system. Such a facility allows definition of database operations that are automatically executed whenever certain conditions are met. In keeping with the set-oriented approach of relational data manipulation languages, our production rules are also set-oriented&mdash;they are triggered by sets of changes to the database and may perform sets of changes. The condition and action parts of our production rules may refer to the current state of the database as well as to the sets of changes triggering the rules. We define a syntax for production rule definition as an extension to SQL. A model of system behavior is used to give an exact semantics for production rule execution, taking into account externally-generated operations, self-triggering rules, and simultaneous triggering of multiple rules.	SIGMOD Conferen	database
115	SIGMOD Conference	A New Paradigm for Parallel and Distributed Rule-Processing.	Ouri Wolfson,Aya Ozeri	1990	This paper is concerned with the parallel evaluation of datalog rule programs, mainly by processors that are interconnected by a communication network. We introduce a paradigm, called data-reduction, for the parallel evaluation of a general datalog program. Several parallelization strategies discussed previously in [CW, GST, W, WS] are special cases of this paradigm. The paradigm parallelizes the evaluation by partitioning among the processors the instantiations of the rules. After presenting the paradigm, we discuss the following issues, that we see fundamental for parallelization strategies derived from the paradigm properties of the strategies that enable a reduction in the communication overhead, decomposability, load balancing, and application to programs with negation. We prove that decomposability, a concept introduced previously in [WS, CW], is undecidable.	SIGMOD Conferen	database
116	VLDB	The C-based Database Programming Language Jasmine/C.	Masaaki Aoshima,Yoshio Izumida,Akifumi Makinouchi,Fumio Suzuki,Yasuo Yamane	1990	The C-based Database Programming Language Jasmine/C.	VLDB	database
117	VLDB	Hybrid Transitive Closure Algorithms.	Rakesh Agrawal,H. V. Jagadish	1990	Hybrid Transitive Closure Algorithms.	VLDB	database
118	VLDB	The Tree Quorum Protocol: An Efficient Approach for Managing Replicated Data.	Divyakant Agrawal,Amr El Abbadi	1990	The Tree Quorum Protocol: An Efficient Approach for Managing Replicated Data.	VLDB	database
119	VLDB	Adaptable Recovery Using Dynamic Quorum Assignments.	Bharat K. Bhargava,Shirley Browne	1990	Adaptable Recovery Using Dynamic Quorum Assignments.	VLDB	database
120	VLDB	An Incremental Join Attachment for Starburst.	Michael J. Carey,Eugene J. Shekita,George Lapis,Bruce G. Lindsay,John McPherson	1990	An Incremental Join Attachment for Starburst.	VLDB	database
121	VLDB	Concept Description Language for Statistical Data Modeling.	Tiziana Catarci,Giovanna D'Angiolini,Maurizio Lenzerini	1990	Concept Description Language for Statistical Data Modeling.	VLDB	database
122	VLDB	Consistency of Versions in Object-Oriented Databases.	Wojciech Cellary,Geneviève Jomier	1990	Consistency of Versions in Object-Oriented Databases.	VLDB	database
123	VLDB	Deriving Production Rules for Constraint Maintainance.	Stefano Ceri,Jennifer Widom	1990	Deriving Production Rules for Constraint Maintainance.	VLDB	database
124	VLDB	Indexing in a Hypertext Database.	Chris Clifton,Hector Garcia-Molina	1990	Indexing in a Hypertext Database.	VLDB	database
125	VLDB	A Parallel Strategy for Transitive Closure usind Double Hash-Based Clustering.	Jean-Pierre Cheiney,Christophe de Maindreville	1990	A Parallel Strategy for Transitive Closure usind Double Hash-Based Clustering.	VLDB	database
126	VLDB	The Effect of Skewed Data Access on Buffer Hits and Data Contention an a Data Sharing Environment.	Asit Dan,Daniel M. Dias,Philip S. Yu	1990	The Effect of Skewed Data Access on Buffer Hits and Data Contention an a Data Sharing Environment.	VLDB	database
127	VLDB	The Performance and Utility of the Cactis Implementation Algorithms.	Pamela Drew,Roger King,Scott E. Hudson	1990	The Performance and Utility of the Cactis Implementation Algorithms.	VLDB	database
128	VLDB	A Study of Three Alternative Workstation-Server Architectures for Object Oriented Database Systems.	David J. DeWitt,Philippe Futtersack,David Maier,Fernando Vélez	1990	A Study of Three Alternative Workstation-Server Architectures for Object Oriented Database Systems.	VLDB	database
129	VLDB	A Multidatabase Transaction Model for InterBase.	Ahmed K. Elmagarmid,Yungho Leu,Witold Litwin,Marek Rusinkiewicz	1990	A Multidatabase Transaction Model for InterBase.	VLDB	database
130	VLDB	The Time Index: An Access Structure for Temporal Data.	Ramez Elmasri,Gene T. J. Wuu,Yeong-Joon Kim	1990	The Time Index: An Access Structure for Temporal Data.	VLDB	database
131	VLDB	Non-Monotonic Knowledge Evolution in VLKDBs.	Christian Esculier	1990	Non-Monotonic Knowledge Evolution in VLKDBs.	VLDB	database
132	VLDB	Two Epoch Algorithms for Disaster Recovery.	Hector Garcia-Molina,Christos A. Polyzois,Robert B. Hagmann	1990	Two Epoch Algorithms for Disaster Recovery.	VLDB	database
133	VLDB	Hybrid-Range Partitioning Strategy: A New Declustering Strategy for Multiprocessor Database Machines.	Shahram Ghandeharizadeh,David J. DeWitt	1990	Hybrid-Range Partitioning Strategy: A New Declustering Strategy for Multiprocessor Database Machines.	VLDB	database
134	VLDB	A Probabilistic Framework for Vague Queries and Imprecise Information in Databases.	Norbert Fuhr	1990	A Probabilistic Framework for Vague Queries and Imprecise Information in Databases.	VLDB	database
135	VLDB	Parity Striping of Disk Arrays: Low-Cost Reliable Storage with Acceptable Throughput.	Jim Gray,Bob Horst,Mark Walker	1990	Parity Striping of Disk Arrays: Low-Cost Reliable Storage with Acceptable Throughput.	VLDB	database
136	VLDB	Query Processing for Multi-Attribute Clustered Records.	Lilian Harada,Miyuki Nakano,Masaru Kitsuregawa,Mikio Takagi	1990	Query Processing for Multi-Attribute Clustered Records.	VLDB	database
137	VLDB	Search Key Substitution in the Encipherment of B-Trees.	Thomas Hardjono,Jennifer Seberry	1990	Search Key Substitution in the Encipherment of B-Trees.	VLDB	database
138	VLDB	Distributed Transitive Closure Computations: The Disconnection Set Approach.	Maurice A. W. Houtsma,Peter M. G. Apers,Stefano Ceri	1990	Distributed Transitive Closure Computations: The Disconnection Set Approach.	VLDB	database
139	VLDB	An Adaptive Data Placement Scheme for Parallel Database Computer Systems.	Kien A. Hua,Chiang Lee	1990	An Adaptive Data Placement Scheme for Parallel Database Computer Systems.	VLDB	database
140	VLDB	On Restructuring Nested Relations in Partitioned Normal Form.	Guy Hulin	1990	On Restructuring Nested Relations in Partitioned Normal Form.	VLDB	database
141	VLDB	ILOG: Declarative Creation and Manipulation of Object Identifiers.	Richard Hull,Masatoshi Yoshikawa	1990	ILOG: Declarative Creation and Manipulation of Object Identifiers.	VLDB	database
142	VLDB	On Indexing Line Segments.	H. V. Jagadish	1990	On Indexing Line Segments.	VLDB	database
143	VLDB	Priority-Hints: An Algorithm for Priority-Based Buffer Management.	Rajiv Jauhari,Michael J. Carey,Miron Livny	1990	Priority-Hints: An Algorithm for Priority-Based Buffer Management.	VLDB	database
144	VLDB	Database Application Development as an Object Modeling Activity.	Manfred A. Jeusfeld,Michael Mertikas,Ingrid Wetzel,Matthias Jarke,Joachim W. Schmidt	1990	Database Application Development as an Object Modeling Activity.	VLDB	database
145	VLDB	Support for Temporal Data by Complex Objects.	Wolfgang Käfer,Norbert Ritter,Harald Schöning	1990	Support for Temporal Data by Complex Objects.	VLDB	database
146	VLDB	Database Updates through Abduction.	Antonis C. Kakas,Paolo Mancarella	1990	Database Updates through Abduction.	VLDB	database
147	VLDB	Right-, left- and multi-linear rule transformations that maintain context information.	David B. Kemp,Kotagiri Ramamohanarao,Zoltan Somogyi	1990	Right-, left- and multi-linear rule transformations that maintain context information.	VLDB	database
148	VLDB	Advanced Query Processing in Object Bases Using Access Support Relations.	Alfons Kemper,Guido Moerkotte	1990	Advanced Query Processing in Object Bases Using Access Support Relations.	VLDB	database
149	VLDB	Bucket Spreading Parallel Hash: A New, Robust, Parallel Hash Join Method for Data Skew in the Super Database Computer (SDC).	Masaru Kitsuregawa,Yasushi Ogawa	1990	Bucket Spreading Parallel Hash: A New, Robust, Parallel Hash Join Method for Data Skew in the Super Database Computer (SDC).	VLDB	database
150	VLDB	A Formal Approach to Recovery by Compensating Transactions.	Henry F. Korth,Eliezer Levy,Abraham Silberschatz	1990	Compensating transactions are intended to handle situations where it is required to undo either committed or uncommitted transactions that affect other transactions, without resorting to cascading aborts. This stands in sharp contrast to the standard approach to transaction recovery where cascading aborts are avoided by requiring transactions to read only committed data, and where committed transactions are treated as permanent and irreversible. We argue that this standard approach to recovery is not suitable for a wide range of advanced database applications, in particular those applications that incorporate long-duration or nested transactions. We show how compensating transactions can be effectively used to handle these types of applications. We present a model that allows the definition of a variety of types of correct compensation. These types of compensation range from traditional undo, at one extreme, to application-dependent, special-purpose compensating transactions, at the other extreme.	VLDB	database
151	VLDB	Triggered Real-Time Databases with Consistency Constraints.	Henry F. Korth,Nandit Soparkar,Abraham Silberschatz	1990	Triggered Real-Time Databases with Consistency Constraints.	VLDB	database
152	VLDB	Efficient Implementation of Loops in Bottom-Up Evaluation of Logic Queries.	Juhani Kuittinen,Otto Nurmi,Seppo Sippu,Eljas Soisalon-Soininen	1990	Efficient Implementation of Loops in Bottom-Up Evaluation of Logic Queries.	VLDB	database
153	VLDB	Hash-Based Join Algorithms for Multiprocessor Computers.	Hongjun Lu,Kian-Lee Tan,Ming-Chien Shan	1990	Hash-Based Join Algorithms for Multiprocessor Computers.	VLDB	database
154	VLDB	Referential Integrity Revisited: An Object-Oriented Perspective.	Victor M. Markowitz	1990	Referential Integrity Revisited: An Object-Oriented Perspective.	VLDB	database
155	VLDB	ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes.	C. Mohan	1990	ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes.	VLDB	database
156	VLDB	Commit_LSN: A Novel and Simple Method for Reducing Locking and Latching in Transaction Processing Systems.	C. Mohan	1990	Commit_LSN: A Novel and Simple Method for Reducing Locking and Latching in Transaction Processing Systems.	VLDB	database
157	VLDB	The Magic of Duplicates and Aggregates.	Inderpal Singh Mumick,Hamid Pirahesh,Raghu Ramakrishnan	1990	The Magic of Duplicates and Aggregates.	VLDB	database
158	VLDB	Performance Analysis of Disk Arrays under Failure.	Richard R. Muntz,John C. S. Lui	1990	Performance Analysis of Disk Arrays under Failure.	VLDB	database
159	VLDB	How to Forget the Past Without Repeating It.	Jeffrey F. Naughton,Raghu Ramakrishnan	1990	Bottom-up evaluation of deductive database programs has the advantage that it avoids repeated computations by storing all intermediate results and replacing recomputation by table lookup. However, in general, storing all intermediate results for the duration of a computation wastes space. In this paper, we propose an evaluation scheme that avoids recomputation, yet for a fairly general class of programs at any given time stores only a small subset of the facts generated. The results constitute a significant first step in compile-time garbage collection for bottom-up evaluation of deductive database programs.	VLDB	database
160	VLDB	Cooperative Transaction Hierarchies: A Transaction Model to Support Design Applications.	Marian H. Nodine,Stanley B. Zdonik	1990	Cooperative Transaction Hierarchies: A Transaction Model to Support Design Applications.	VLDB	database
161	VLDB	Measuring the Complexity of Join Enumeration in Query Optimization.	Kiyoshi Ono,Guy M. Lohman	1990	Measuring the Complexity of Join Enumeration in Query Optimization.	VLDB	database
162	VLDB	Efficient Main Memory Data Management Using the DBGraph Storage Model.	Philippe Pucheral,Jean-Marc Thévenin,Patrick Valduriez	1990	Efficient Main Memory Data Management Using the DBGraph Storage Model.	VLDB	database
163	VLDB	Synthesizing Database Transactions.	Xiaolei Qian	1990	Synthesizing Database Transactions.	VLDB	database
164	VLDB	Rule Ordering in Bottom-Up Fixpoint Evaluation of Logic Programs.	Raghu Ramakrishnan,Divesh Srivastava,S. Sudarshan	1990	Logic programs can be evaluated bottom-up by repeatedly applying all rules, in iterations, until the fixpoint is reached. However, it is often desirable-and, in some cases, e.g. programs with stratified negation, it is even necessary to guarantee the semantics-to apply the rules in some order. We present two algorithms that apply rules in a specified order without repeating inferences. One of them (GSN) is capable of dealing with a wide range of rule orderings, but with a little more overhead than the well-known seminaive algorithm (which we call BSN). The other (PSN) handles a smaller class of rule orderings, but with no overheads beyond those in BSN. We also demonstrate that by choosing a good ordering, we can reduce the number of rule applications (and thus the number of joins). We present a theoretical analysis of rule orderings and identify orderings that minimize the number of rule applications (for all possible instances of the base relations) with respect to a class of orderings called fair orderings. We also show that though nonfair orderings may do a little better on some data sets, they can do much worse on others. The analysis is supplemented by performance results.	VLDB	database
165	VLDB	Tradeoffs in Processing Complex Join Queries via Hashing in Multiprocessor Database Machines.	Donovan A. Schneider,David J. DeWitt	1990	Tradeoffs in Processing Complex Join Queries via Hashing in Multiprocessor Database Machines.	VLDB	database
166	VLDB	The Buddy-Tree: An Efficient and Robust Access Method for Spatial Data Base Systems.	Bernhard Seeger,Hans-Peter Kriegel	1990	The Buddy-Tree: An Efficient and Robust Access Method for Spatial Data Base Systems.	VLDB	database
167	VLDB	Transaction Support in Read Optimizied and Write Optimized File Systems.	Margo I. Seltzer,Michael Stonebraker	1990	Transaction Support in Read Optimizied and Write Optimized File Systems.	VLDB	database
168	VLDB	Distributed Linear Hashing and Parallel Projection in Main Memory Databases.	Charles Severance,Sakti Pramanik,P. Wolberg	1990	Distributed Linear Hashing and Parallel Projection in Main Memory Databases.	VLDB	database
169	VLDB	Elimination of View and Redundant Variables in a SQL-like Database Language for Extended NF2 Structures.	Norbert Südkamp,Volker Linnemann	1990	Elimination of View and Redundant Variables in a SQL-like Database Language for Extended NF2 Structures.	VLDB	database
170	VLDB	A Temporal Relational Algebra as Basis for Temporal Relational Completeness.	Alexander Tuzhilin,James Clifford	1990	A Temporal Relational Algebra as Basis for Temporal Relational Completeness.	VLDB	database
171	VLDB	A Polygen Model for Heterogeneous Database Systems: The Source Tagging Perspective.	Y. Richard Wang,Stuart E. Madnick	1990	A Polygen Model for Heterogeneous Database Systems: The Source Tagging Perspective.	VLDB	database
172	VLDB	Query Processing for Distance Metrics.	Jason Tsong-Li Wang,Dennis Shasha	1990	Query Processing for Distance Metrics.	VLDB	database
173	VLDB	Maintaining Consistency of Client-Cached Data.	W. Kevin Wilkinson,Marie-Anne Neimat	1990	Maintaining Consistency of Client-Cached Data.	VLDB	database
174	VLDB	Factoring Augmented Regular Chain Programs.	Peter T. Wood	1990	Factoring Augmented Regular Chain Programs.	VLDB	database
175	VLDB	An Adaptive Hash Join Algorithm for Multiuser Environments.	Hansjörg Zeller,Jim Gray	1990	An Adaptive Hash Join Algorithm for Multiuser Environments.	VLDB	database
176	SIGMOD Record	An SQL-Based Query Language For Networks of Relations.	Amit Basu,Rafiul Ahad	1990	A set of relations can be modeled as a network through the use of image attributes, which are attributes defined on the domain of relation names. Such networks of relations can effectively meet many of the modeling requirements of advanced database applications such as engineering design and knowledge base systems. In this paper, we describe the features of ESQL, a novel query language that is an extension of SQL [Cham74] to exploit the added semantics of image attributes. Details of ESQL and its underlying principles can be found in [Ahad88] and [Ahad89].	SIGMOD Record	database
177	SIGMOD Record	New Hope on Data Models and Types: Report of an NSF-INRIA Workshop.	Serge Abiteboul,Peter Buneman,Claude Delobel,Richard Hull,Paris C. Kanellakis,Victor Vianu	1990	In May, 1990, a small workshop was held in New Hope, Pennsylvania, to discuss the fundamental issues raised by continuing work on the interface between databases and programming languages. Four topics were addressed: new directions stemming from object-oriented data models, contributions of type theory to database programming languages (DBPLs), applications of logic to DBPL issues, and DBPL implementations. This workshop was organized under the auspices of the INRIA-NSF program, Languages for Databases and Knowledge Bases.	SIGMOD Record	database
178	SIGMOD Record	Object-Oriented Database Systems: In Transition.	François Bancilhon,Won Kim	1990	Object-Oriented Database Systems: In Transition.	SIGMOD Record	database
179	SIGMOD Record	Announcements and Calls for Papers: POS 90, Management of Replicated Data 90, IFIP WG8.4 90, ICDT 90, Multimedia Inf. Systems 91, JCIT-5, Software Eng. J., ER 90, DEXA 90, ...		1990	Announcements and Calls for Papers: POS 90, Management of Replicated Data 90, IFIP WG8.4 90, ICDT 90, Multimedia Inf. Systems 91, JCIT-5, Software Eng. J., ER 90, DEXA 90, ...	SIGMOD Record	database
180	SIGMOD Record	Multidatabase Interoperability.	Yuri Breitbart	1990	Multidatabase Interoperability.	SIGMOD Record	database
181	SIGMOD Record	Announcements and Calls for Papers: VLDB Journal, Critical Issues 90, CR, SIGIR Forum, IEEE Computer, CCW 91, ICDCS 91, JCIT-5, ...		1990	Announcements and Calls for Papers: VLDB Journal, Critical Issues 90, CR, SIGIR Forum, IEEE Computer, CCW 91, ICDCS 91, JCIT-5, ...	SIGMOD Record	database
182	SIGMOD Record	Announcements and Calls for Papers: SIGMOD 91, PODS 91, VLDB 91, ER 91, SIGIR 91, SSD 91, BNCOD-9, ECOOP 91, DEXA 91, WADS 91, SIGSOFT 91		1990	Announcements and Calls for Papers: SIGMOD 91, PODS 91, VLDB 91, ER 91, SIGIR 91, SSD 91, BNCOD-9, ECOOP 91, DEXA 91, WADS 91, SIGSOFT 91	SIGMOD Record	database
183	SIGMOD Record	Extensible Database Management Systems.	Michael J. Carey,Laura M. Haas	1990	Extensible Database Management Systems.	SIGMOD Record	database
184	SIGMOD Record	Response to R. T. Snodgrass's Letter in SIGMOD Record.	C. J. Date	1990	Response to R. T. Snodgrass's Letter in SIGMOD Record.	SIGMOD Record	database
185	SIGMOD Record	Parallel Database Systems: The Future of Database Processing or a Passing Fad?	David J. DeWitt,Jim Gray	1990	The concept of parallel database machines consisting of exotic hardware has been replaced by a fairly conventional shared-nothing hardware base along with a highly parallel dataflow software architecture. Such a design provides speedup and scaleup in processing relational database queries. This paper reviews the techniques used by such systems, and surveys current commercial and research systems.	SIGMOD Record	database
186	SIGMOD Record	Summary of the Final Report of the NSF Workshop on Scientific Database Management.	James C. French,Anita K. Jones,John L. Pfaltz	1990	The National Science Foundation sponsored a two day workshop hosted by the University of Virginia on March 12-13, 1990 at which representatives from the earth, life, and space sciences met with computer scientists to discuss the issues facing the scientific community in the area of database management. The workshop1 participants concluded that initiatives by the National Science Foundation and other funding agencies, as well as specific discipline professional societies are urgently needed to address the problems facing scientists with respect to data management. This article presents a condensed version of the workshop final report emphasizing the technical research issues.	SIGMOD Record	database
187	SIGMOD Record	Research Directions for Distributed Databases.	Hector Garcia-Molina,Bruce G. Lindsay	1990	Research Directions for Distributed Databases.	SIGMOD Record	database
188	SIGMOD Record	Four Valued Logic for Relational Database Systems.	G. H. Gessert	1990	This paper proposes a specific four-valued logic (4VL) as a means of handling missing data in Relational Data Base Management systems. The proposed 4VL is a minor variant of the standard 4VL in which the &ldquo;least true&rdquo; condition is interpreted as &ldquo;inapplicable&rdquo; rather than &ldquo;false&rdquo;. The use of this 4VL is defended on the grounds that by defining several additional unary operators, the 4VL can be rendered intuitively manageable. The proposed unary operators contribute to the conceptual utility of the 4VL by providing an explicit way for users to relate familiar results of two-valued logic to analogous results in 4VL.	SIGMOD Record	database
189	SIGMOD Record	A Note on the Translation of SQL to Tuple Calculus.	Martin Gogolla	1990	This note presents a translation of a subset of the relational query language SQL into the well known tuple calculus. Roughly speaking, tuple calculus corresponds to first order predicate calculus. The SQL subset is relationally complete and represents a &ldquo;relational core&rdquo; of the language. Nevertheless, our translation is simple and elegant. Therefore it is especially well suited as a beginners course into the principles of a formal definition of SQL.	SIGMOD Record	database
190	SIGMOD Record	Directions For Future Database Research & Development - Letter from the Issue Editor.	Won Kim	1990	Directions For Future Database Research & Development - Letter from the Issue Editor.	SIGMOD Record	database
191	SIGMOD Record	Research Issues in Spatial Databases.	Oliver Günther,Alejandro P. Buchmann	1990	Research Issues in Spatial Databases.	SIGMOD Record	database
192	SIGMOD Record	Database Security: Current Status and Key Issues.	Sushil Jajodia,Ravi S. Sandhu	1990	Database Security: Current Status and Key Issues.	SIGMOD Record	database
193	SIGMOD Record	Semantic Modeling through Identification and Characterization of Objects.	Jan Jonsson	1990	Semantic Modeling through Identification and Characterization of Objects.	SIGMOD Record	database
194	SIGMOD Record	Selected Database Research at Stanford.	Arthur M. Keller,Peter Rathmann,Jeffrey D. Ullman,Gio Wiederhold	1990	This report describes seven projects at the Computer Science Department of Stanford University that may be relevant to SIGMOD community.	SIGMOD Record	database
195	SIGMOD Record	Chair's Message.	Won Kim	1990	Chair's Message.	SIGMOD Record	database
196	SIGMOD Record	Chair's Message.	Won Kim	1990	Chair's Message.	SIGMOD Record	database
197	SIGMOD Record	Chair's Message.	Won Kim	1990	Chair's Message.	SIGMOD Record	database
198	SIGMOD Record	Database Security.	Teresa F. Lunt,Eduardo B. Fernández	1990	Database Security.	SIGMOD Record	database
199	SIGMOD Record	A Deductive Database Architecture Based on Partial Evaluation.	Li Lei,Georges-Henri Moll,Jacques Kouloumdjian	1990	The implementation of a logic programming language for database management systems is a possible way to build a knowledge base management system. It allows to re-use the know-how in the fields: of inference engines, of data management. However, the strategy of each component is very different. SLD resolution leads to a one tuple at a time access to facts, opposed to the set oriented approach of databases. To face this problem, a new strategy, has been designed to keep the advantages of each part avoiding the drawbacks. The kernel of the system is a Partial Evaluator, designed as a metaprogram, which allows to bridge the impedance mismatch gap.	SIGMOD Record	database
200	SIGMOD Record	The Implication Problem for Inclusion Dependencies: A Graph Approach.	Rokia Missaoui,Robert Godin	1990	In this paper, we propose a graph theoretic approach to deal with the implication problem for inclusion dependencies. By analogy with functional dependencies, we define and present algorithms for computing the following concepts: the closure of a relation scheme R for X according to a set of inclusion dependencies and the minimal cover for inclusion dependencies.	SIGMOD Record	database
201	SIGMOD Record	Accommodating Imprecision in Database Systems: Issues and Solutions.	Amihai Motro	1990	Most database systems are designed under assumptions of precision of both the data stored in their databases, and the requests to retrieve data. In reality, however, these assumptions are often invalid, and in recent years considerable attention has been given to issues of imprecision in database systems. In this paper we review the major solutions for accommodating imprecision, and we describe issues that have yet to addressed, offering possible research directions.	SIGMOD Record	database
202	SIGMOD Record	ACM News		1990	ACM News	SIGMOD Record	database
203	SIGMOD Record	News		1990	News	SIGMOD Record	database
204	SIGMOD Record	Yet Another Note on Minimal Covers.	Jyrki Nummenmaa,Peter Thanisch	1990	In [Atk88] Atkins corrects a widely spread error in the algorithm for finding a minimal cover for a given set of functional dependencies. The erroneous form of the algorithm has been presented in [Sa186,StW83,Ul182,Yan88]. Unfortunately, though, there is an error also in the corrected algorithm. Atkins proposed the following algorithm for determining a minimal cover for a given set of functional dependencies F.	SIGMOD Record	database
205	SIGMOD Record	Extending the Transaction Model to Capture more Meaning.	Marek Rusinkiewicz,Ahmed K. Elmagarmid,Yungho Leu,Witold Litwin	1990	Extending the Transaction Model to Capture more Meaning.	SIGMOD Record	database
206	SIGMOD Record	Congresses on Databases.	Fèlix Saltor	1990	Congresses on Databases.	SIGMOD Record	database
207	SIGMOD Record	Report on the Workshop on Heterogenous Database Systems held at Northwestern University, Evanston, Illinois, December 11-13, 1989, Sponsored by NSF.	Peter Scheuermann,Ahmed K. Elmagarmid,Hector Garcia-Molina,Frank Manola,Dennis McLeod,Arnon Rosenthal,Marjorie Templeton	1990	Report on the Workshop on Heterogenous Database Systems held at Northwestern University, Evanston, Illinois, December 11-13, 1989, Sponsored by NSF.	SIGMOD Record	database
208	SIGMOD Record	Editor's Notes.	Arie Segev	1990	Editor's Notes.	SIGMOD Record	database
209	SIGMOD Record	Editor's Notes.	Arie Segev	1990	Editor's Notes.	SIGMOD Record	database
210	SIGMOD Record	Editor's Notes.	Arie Segev	1990	Editor's Notes.	SIGMOD Record	database
211	SIGMOD Record	SIGMOD Institutional Sponsors		1990	SIGMOD Institutional Sponsors	SIGMOD Record	database
212	SIGMOD Record	SIGMOD Institutional Sponsors		1990	SIGMOD Institutional Sponsors	SIGMOD Record	database
213	SIGMOD Record	Database Research at Bellcore.	Amit P. Sheth	1990	Database Research at Bellcore.	SIGMOD Record	database
214	SIGMOD Record	Database Systems: Achievements and Opportunities - The Lagunita Report of the NSF Invitational Workshop on the Future of Database System Research held in Palo Alto, California, February 22-23, 1990.	Abraham Silberschatz,Michael Stonebraker,Jeffrey D. Ullman	1990	Database Systems: Achievements and Opportunities - The Lagunita Report of the NSF Invitational Workshop on the Future of Database System Research held in Palo Alto, California, February 22-23, 1990.	SIGMOD Record	database
215	SIGMOD Record	Data Base Research at Berkeley.	Michael Stonebraker	1990	Data Base Research at Berkeley.	SIGMOD Record	database
216	SIGMOD Record	Third-Generation Database System Manifesto - The Committee for Advanced DBMS Function.	Michael Stonebraker,Lawrence A. Rowe,Bruce G. Lindsay,Jim Gray,Michael J. Carey,Michael L. Brodie,Philip A. Bernstein,David Beech	1990	Third-Generation Database System Manifesto - The Committee for Advanced DBMS Function.	SIGMOD Record	database
217	SIGMOD Record	Temporal Databases - Status and Research Directions.	Richard T. Snodgrass	1990	It seems somehow fitting to begin this paper on databases that store historical information with a chronology, touching briefly on all work that I am aware of in this area. I discuss in some detail what I consider to be the ten most important papers and events in terms of their impact on the discipline of temporal databases. These are emphatically not meant to detract from the other excellent papers in temporal databases. My goal is to characterize the evolution of this field, as an introduction to the approximately 350 papers specifically relating time to databases that have appeared thus far. I then identify and discuss areas where more work is needed.	SIGMOD Record	database
218	SIGMOD Record	Correction.	Toby J. Teorey	1990	Correction.	SIGMOD Record	database
219	SIGMOD Record	Computing Transitive Closures of Multilevel Relations.	Bhavani M. Thuraisingham	1990	Recently many attempts have been made to implement recursive queries. Such queries are essential for the new generation intelligent database system applications. Much of the effort in recursive queries is focussed on transitive closure queries which are of practical significance. None of the work described investigates recursive query processing in secure database management systems. In this paper we propose centralized and distributed algorithms for implementing transitive closure queries for multilevel secure relational database management systems.	SIGMOD Record	database
220	SIGMOD Record	Deductive Databases: Achievements and Future Directions.	Jeffrey D. Ullman,Carlo Zaniolo	1990	In the recent years, Deductive Databases have been the focus of intense research, which has brought dramatic advances in theory, systems and applications. A salient feature of deductive databases is their capability of supporting a declarative, rule-based style of expressing queries and applications on databases. As such, they find applications in disparate areas, such as knowledge mining from databases, and computer-aided design and manufacturing systems. In this paper, we briefly review the key concepts behind deductive databases and their newly developed enabling technology. Then, we describe current research on extending the functionality and usability of deductive databases and on providing a synthesis of deductive databases with procedural and object-oriented approaches.	SIGMOD Record	database
221	SIGMOD Record	Incomplete Information in Object-Oriented Databases.	Roberto Zicari	1990	We present a way to handle incomplete information both at schema and object instance level in an object-oriented database. Incremental schema design becomes possible with the introduction of generic classes. Incomplete data in an object instance is handled with the introduction of explicit null values in a similar way as in the relational and nested relations data models.	SIGMOD Record	database
222	Artificial Intelligence in Medicine	LIMES: a hypertext interface to a cholesterol management expert system.	Beverly Kane	1990	LIMES: a hypertext interface to a cholesterol management expert system.	Artificial Inte	medical
223	Artificial Intelligence in Medicine	MKS: An expert system shell for HIS environment.	Dan Qiu,Joachim Dudeck	1990	MKS: An expert system shell for HIS environment.	Artificial Inte	medical
224	Artificial Intelligence in Medicine	Medical informatics, computer applications in health care: E.H. Shortliffe and L.E. Perreault, eds., G. Wiederhold and L.M. Fagan, associate eds., (Addison-Wesley, Reading, MA, 1990) 715 pp., $45.25.	Lawrence E. Widman	1990	Medical informatics, computer applications in health care: E.H. Shortliffe and L.E. Perreault, eds., G. Wiederhold and L.M. Fagan, associate eds., (Addison-Wesley, Reading, MA, 1990) 715 pp., $45.25.	Artificial Inte	medical
225	Artificial Intelligence in Medicine	A hypermedia document collection for primary care: why, what, and how?	Toomas Timpka,Per Hedblom,Gösta Tibblin	1990	A hypermedia document collection for primary care: why, what, and how?	Artificial Inte	medical
226	Artificial Intelligence in Medicine	A temporal reasoning framework used in the diagnosis of skeletal dysplasias.	Elpida T. Keravnou,John Washbrook	1990	A temporal reasoning framework used in the diagnosis of skeletal dysplasias.	Artificial Inte	medical
227	Artificial Intelligence in Medicine	Software review: Schindler and Partners, Expert System AUTOKLAS, Version 5.0, Riesweiler, FRG, 1989. DM 10500.	Norbert Paul	1990	Software review: Schindler and Partners, Expert System AUTOKLAS, Version 5.0, Riesweiler, FRG, 1989. DM 10500.	Artificial Inte	medical
228	Artificial Intelligence in Medicine	Structure and significance of analogical reasoning.	J. A. Campbell,John Wolstencroft	1990	Structure and significance of analogical reasoning.	Artificial Inte	medical
229	Artificial Intelligence in Medicine	Deep models for medical expert systems.	Elpida Keravnou	1990	Deep models for medical expert systems.	Artificial Inte	medical
230	Artificial Intelligence in Medicine	Editorial: Medical expertext.	Roy Rada	1990	Editorial: Medical expertext.	Artificial Inte	medical
231	Artificial Intelligence in Medicine	A report on medical expert systems research in Italy.	Pietro Torasso	1990	A report on medical expert systems research in Italy.	Artificial Inte	medical
232	Artificial Intelligence in Medicine	Medical expertext as regularity in semantic nets.	Hafedh Mili,Roy Rada	1990	Medical expertext as regularity in semantic nets.	Artificial Inte	medical
233	Artificial Intelligence in Medicine	Guides for hypertext: an overview.	Mark E. Frisse,Steve B. Cousins	1990	Guides for hypertext: an overview.	Artificial Inte	medical
234	Artificial Intelligence in Medicine	Some causal models are deeper than others.	Tom Bylander	1990	Some causal models are deeper than others.	Artificial Inte	medical
235	Artificial Intelligence in Medicine	The construction of knowledge in neurology: implications for hypermedia system development.	James M. Nyce,William Graves III	1990	The construction of knowledge in neurology: implications for hypermedia system development.	Artificial Inte	medical
236	Artificial Intelligence in Medicine	The 1990 AAAI Spring Symposium on Artificial Intelligence in Medicine.	Gregory F. Cooper,Mark A. Musen	1990	The 1990 AAAI Spring Symposium on Artificial Intelligence in Medicine.	Artificial Inte	medical
237	Artificial Intelligence in Medicine	Logic engineering for knowledge engineering: design and implementation of the Oxford System of Medicine.	John Fox,Andrzej J. Glowinski,Colin Gordon,Saki Hajnal,Mike O'Neil	1990	Logic engineering for knowledge engineering: design and implementation of the Oxford System of Medicine.	Artificial Inte	medical
238	Artificial Intelligence in Medicine	Knowledge acquisition for knowledge-based systems: B.R. Gaines and J.H. Boose (eds.), Academic Press, London, 1988. Xix + 355 pages, £ 16.95.	Ulrich Müller-Kolck	1990	Knowledge acquisition for knowledge-based systems: B.R. Gaines and J.H. Boose (eds.), Academic Press, London, 1988. Xix + 355 pages, £ 16.95.	Artificial Inte	medical
239	Artificial Intelligence in Medicine	A clinical information system for oncology: John P. Enterline, Raymond E. Lenhard and Bruce I. Blum, Springer, Berlin, 1989. Xvii + 268 pages, 103 figures, hard cover, DM 90.00.	S. T. Horwiczky	1990	A clinical information system for oncology: John P. Enterline, Raymond E. Lenhard and Bruce I. Blum, Springer, Berlin, 1989. Xvii + 268 pages, 103 figures, hard cover, DM 90.00.	Artificial Inte	medical
240	Artificial Intelligence in Medicine	An introduction to formal language theory (with a contribution by James Pustejovsky): Robert N. Moll Michael A. Arbib, Springer, Berlin, 1988. X + 203 pages, 61 figures, hard cover, DM 68.00.	P. J. Nevisti	1990	An introduction to formal language theory (with a contribution by James Pustejovsky): Robert N. Moll Michael A. Arbib, Springer, Berlin, 1988. X + 203 pages, 61 figures, hard cover, DM 68.00.	Artificial Inte	medical
241	Artificial Intelligence in Medicine	Diagnostic efficiency of deep and surface knowledge in KARDIO.	Igor Mozetic	1990	Diagnostic efficiency of deep and surface knowledge in KARDIO.	Artificial Inte	medical
242	Artificial Intelligence in Medicine	Automating the knowledge acquisition process in the construction of medical expert systems.	Andrew K. C. Wong,Keith C. C. Chan	1990	Automating the knowledge acquisition process in the construction of medical expert systems.	Artificial Inte	medical
243	Artificial Intelligence in Medicine	Qualitative models in medical diagnosis.	Liliana Ironi,Mario Stefanelli,Giordano Lanzola	1990	Qualitative models in medical diagnosis.	Artificial Inte	medical
244	Artificial Intelligence in Medicine	Coupling hypertext to an object-oriented environment.	Isabelle de Zegher,Philippe Jassem	1990	Coupling hypertext to an object-oriented environment.	Artificial Inte	medical
245	Artificial Intelligence in Medicine	Expert system support for the therapeutic management of cerebrovascular disease.	Ulrich Müller-Kolck	1990	Expert system support for the therapeutic management of cerebrovascular disease.	Artificial Inte	medical
246	Artificial Intelligence in Medicine	In dubio pro aegro.	Kazem Sadegh-Zadeh	1990	In dubio pro aegro.	Artificial Inte	medical
247	Artificial Intelligence in Medicine	Automation of cytogenetics: Claes Lundsteen and Jim Piper (eds.), Springer, Berlin, 1989, Xvi + 316 pages, 103 figures, hard cover, DM 128.00.	B. D. Leppelt	1990	Automation of cytogenetics: Claes Lundsteen and Jim Piper (eds.), Springer, Berlin, 1989, Xvi + 316 pages, 103 figures, hard cover, DM 128.00.	Artificial Inte	medical
248	Artificial Intelligence in Medicine	Making deepness explicit.	John Washbrook,Elpida T. Keravnou	1990	Making deepness explicit.	Artificial Inte	medical
249	Artificial Intelligence in Medicine	Monitoring diseases with empirical and model-generated histories.	Enrico W. Coiera	1990	Monitoring diseases with empirical and model-generated histories.	Artificial Inte	medical
250	Artificial Intelligence in Medicine	The qualitative criticism of circulatory models via bipartite teleological analysis.	Keith L. Downing	1990	The qualitative criticism of circulatory models via bipartite teleological analysis.	Artificial Inte	medical
251	Artificial Intelligence in Medicine	Knowledge acquisition: James F. Brulé and Alexander Blount, McGraw Hill, New York/Hamburg, 1989. Xxvii + 253 pages, paperback, DM 75.33.	G. L. Gracia-Moret	1990	Knowledge acquisition: James F. Brulé and Alexander Blount, McGraw Hill, New York/Hamburg, 1989. Xxvii + 253 pages, paperback, DM 75.33.	Artificial Inte	medical
252	Artificial Intelligence in Medicine	Towards computer-assisted maintenance of medical knowledge bases.	Dario A. Giuse,Nunzia Bettinsoli Giuse,Randolph A. Miller	1990	Towards computer-assisted maintenance of medical knowledge bases.	Artificial Inte	medical
253	Artificial Intelligence in Medicine	Expertext for medical care and literature retrieval.	Roy Rada,Judith Barlow,Pieter E. Zanstra,Pieter de Vries Robbé,Djujan Bijstra,Jan Potharst	1990	Expertext for medical care and literature retrieval.	Artificial Inte	medical
254	Artificial Intelligence in Medicine	Uncertainty and intelligent systems: B. Bouchon, L. Saitta and R.R. Yager (eds.), Springer, Berlin, 1988. Viii + 408 pages, soft cover, DM 55.00.	R. L. Hurlicz	1990	Uncertainty and intelligent systems: B. Bouchon, L. Saitta and R.R. Yager (eds.), Springer, Berlin, 1988. Viii + 408 pages, soft cover, DM 55.00.	Artificial Inte	medical
255	FOCS	Parallel Linear Programming in Fixed Dimension Almost Surely in Constant Time	Noga Alon,Nimrod Megiddo	1990	It is shown that, for any fixed dimension d, the linear programming problem with n inequality constraints can be solvent on a probabilistic CRCW PRAM (concurrent-read-concurrent-write parallel random-access machine) with O(n) processors almost surely in constant time. The algorithm always finds the correct solution. With nd/log/sup 2/d processors, the probability that the algorithm will not finish within O(d/sup 2/log/sup 2/d) time tends to zero exponentially with n.	FOCS	theory
256	FOCS	Coin-Flipping Games Immune against Linear-Sized Coalitions (Extended Abstract)	Noga Alon,Moni Naor	1990	Coin-Flipping Games Immune against Linear-Sized Coalitions (Extended Abstract)	FOCS	theory
257	FOCS	A Time-Space Tradeoff for Boolean Matrix Multiplication	Karl R. Abrahamson	1990	A time-space tradeoff is established in the branching program model for the problem of computing the product of two n*n matrices over a certain semiring. It is assumed that each element of each n*n input matrix is chosen independently to be 1 with probability n/sup -1/2/ and to be 0 with probability 1-n/sup -1/2/. Letting S and T denote expected space and time of a deterministic algorithm, the tradeoff is ST= Omega (n/sup 3.5/) for T0. The lower bounds are matched to within a logarithmic factor by upper bounds in the branching program model. Thus, the tradeoff possesses a sharp break at T= Theta (n/sup 2.5/). These expected case lower bounds are also the best known lower bounds for the worst case.	FOCS	theory
258	FOCS	A Markovian Extension of Valiant's Learning Model (Extended Abstract)	David Aldous,Umesh V. Vazirani	1990	A Markovian Extension of Valiant's Learning Model (Extended Abstract)	FOCS	theory
259	FOCS	An Approach for Proving Lower Bounds: Solution of Gilbert-Pollak's Conjecture on Steiner Ratio	Ding-Zhu Du,Frank K. Hwang	1990	A family of finitely many continuous functions on a polytope X, namely (g/sub i/(x))/sub i in I/, is considered, and the problem of minimizing the function f(x)=max/sub i in I/g/sub i/(x) on X is treated. It is shown that if every g/sub i/(x) is a concave function, then the minimum value of f(x) is achieved at finitely many special points in X. As an application, a long-standing problem about Steiner minimum trees and minimum spanning trees is solved. In particular, if P is a set of n points on the Euclidean plane and L/sub s/(P) and L/sub m/(P) denote the lengths of a Steiner minimum tree and a minimum spanning tree on P, respectively, it is proved that, for any P, L/sub S/(P)>or= square root 3L/sub m/(P)/2, as conjectured by E.N. Gilbert and H.O. Pollak (1968).	FOCS	theory
260	FOCS	Uniform Memory Hierarchies	Bowen Alpern,Larry Carter,Ephraim Feig	1990	The authors introduce a model, called the uniform memory hierarchy (UMH) model, which reflects the hierarchical nature of computer memory more accurately than the RAM (random-access-machine) model, which assumes that any item in memory can be accessed with unit cost. In the model memory occurs as a sequence of increasingly large levels. Data are transferred between levels in fixed-size blocks (the size is level dependent). Within a level blocks are random access. The model is easily extended to handle parallelism. The UMH model is really a family of models parameterized by the rate at which the bandwidth decays as one travels up the hierarchy. A program is parsimonious on a UMH if the leading terms of the program's (time) complexity on the UMH and on a RAM are identical. If these terms differ by more than a constant factor, then the program is inefficient. The authors analyze two standard FFT programs with the same RAM complexity. One is efficient; the other is not.	FOCS	theory
261	FOCS	Simple Constructions of Almost k-Wise Independent Random Variables	Noga Alon,Oded Goldreich,Johan Håstad,René Peralta	1990	The authors present three alternative simple constructions of small probability spaces on n bits for which any k bits are almost independent. The number of bits used to specify a point in the sample space is O(log log n+k+log 1/ epsilon ), where epsilon is the statistical difference between the distribution induced on any k-bit locations and the uniform distribution. This is asymptotically comparable to the construction recently presented by J. Naor and M. Naor (1990). An advantage of the present constructions is their simplicity. Two of the constructions are based on bit sequences that are widely believed to possess randomness properties, and the results can be viewed as an explanation and establishment of these beliefs.	FOCS	theory
262	FOCS	Learning Conjunctions of Horn Clauses (Extended Abstract)	Dana Angluin,Michael Frazier,Leonard Pitt	1990	Learning Conjunctions of Horn Clauses (Extended Abstract)	FOCS	theory
263	FOCS	Fault Tolerant Sorting Network	Shay Assaf,Eli Upfal	1990	A general technique for enhancing the reliability of sorting networks and other comparator-based networks is presented. The technique converts any network that uses unreliable comparators to a fault-tolerant network that produces the correct output with overwhelming probability, even if each comparator is faulty with some probability smaller than 1/2, independently of other comparators. The depth of the fault-tolerant network is only a constant times the depth of the original network, and the width of the network is increased by a logarithmic factor.	FOCS	theory
264	FOCS	Are Wait-Free Algorithms Fast? (Extended Abstract)	Hagit Attiya,Nancy A. Lynch,Nir Shavit	1990	Are Wait-Free Algorithms Fast? (Extended Abstract)	FOCS	theory
265	FOCS	Communication-Optimal Maintenance of Replicated Information	Baruch Awerbuch,Israel Cidon,Shay Kutten	1990	It is shown that keeping track of history allows significant improvements in the realistic model of communication complexity of dynamic network protocols. The communication complexity for solving an arbitrary graph problem is improved from Theta (E) to Theta (V), thus achieving the lower bound. Moreover, O(V) is also the amortized complexity of solving an arbitrary function (not only graph functions) defined on the local inputs of the nodes. As a corollary, it is found that amortized communication complexity, i.e. incremental cost of adapting to a single topology change, can be smaller than the communication complexity of solving the problem from scratch. The first stage in the solution is a communication-optimal maintenance of a spanning tree in a dynamic network. The second stage is the optimal maintenance of replicas of databases. An important example of this task is the problem of updating the description of the network's topology at every node. For this problem the message complexity is improved from O(EV) to Theta (V). The improvement for a general database is even larger if the size of the database is larger than E.	FOCS	theory
266	FOCS	Sparse Partitions (Extended Abstract)	Baruch Awerbuch,David Peleg	1990	Sparse Partitions (Extended Abstract)	FOCS	theory
267	FOCS	Network Synchronization with Polylogarithmic Overhead	Baruch Awerbuch,David Peleg	1990	The synchronizer is a simulation methodology for simulating a synchronous network by an asynchronous one, thus enabling the execution of a synchronous algorithm on an asynchronous network. Previously known synchronizers require each processor in the network to participate in each pulse of the synchronization process. The resulting communication overhead depends linearly on the number n of network nodes. A synchronizer with overhead only polylogarithmically dependent on n is introduced. This synchronizer can also be realized with polylog(n) space. The polylog-overhead synchronizer is based on involving only the relevant portions of the network in the synchronization process.	FOCS	theory
268	FOCS	A Dining Philosophers Algorithm with Polynomial Response Time	Baruch Awerbuch,Michael E. Saks	1990	Presents an efficient distributed online algorithm for scheduling jobs that are created dynamically, subject to resource constraints that require that certain pairs of jobs not run concurrently. The focus is on the response time of the system to each job, i.e. the length of the time interval that starts when the job is created or assigned to a processor and ends at the instant the execution of the job begins. The goal is to provide guarantees on the response time to each job j in terms of the density of arrivals of jobs that conflict with j. The model is completely asynchronous and includes various resource allocation problems that have been studied extensively, including the dining philosophers problem and its generalizations to arbitrary networks. In these versions of the problem, the resource requirements of each new job j determines an upper bound delta /sub j/ on the number of jobs that can exist concurrently in the system and conflict with j. Given such upper bounds, no scheduling algorithm can guarantee a response time better than delta /sub j/ times the maximum execution or message transmission time. A simple algorithm that guarantees response time that is essentially polynomial in delta /sub j/ is presented. It is based on the notion of a distribution queue and has a compact implementation.	FOCS	theory
269	FOCS	A Characterization of \sharp P Arithmetic Straight Line Programs	László Babai,Lance Fortnow	1990	A Characterization of \sharp P Arithmetic Straight Line Programs	FOCS	theory
270	FOCS	Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols	László Babai,Lance Fortnow,Carsten Lund	1990	Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols	FOCS	theory
271	FOCS	On the Diameter of Finite Groups	László Babai,Gábor Hetyei,William M. Kantor,Alexander Lubotzky,Ákos Seress	1990	The diameter of a group G with respect to a set S of generators is the maximum over g in G of the length of the shortest word in S union S/sup -1/ representing g. This concept arises in the contexts of efficient communication networks and Rubik's-cube-type puzzles. 'Best' generators are pertinent to networks, whereas 'worst' and 'average' generators seem more adequate models for puzzles. A substantial body of recent work on these subjects by the authors is surveyed. Regarding the 'best' case, it is shown that, although the structure of the group is essentially irrelevant if mod S mod is allowed to exceed (log mod G mod )/sup 1+c/(c>0), it plays a strong role when mod S mod =O(1).	FOCS	theory
272	FOCS	Deterministic On-Line Routing on Area-Universal Networks (Extended Abstract)	Paul Bay,Gianfranco Bilardi	1990	Deterministic On-Line Routing on Area-Universal Networks (Extended Abstract)	FOCS	theory
273	FOCS	Time-Space Tradeoffs for Undirected Graph Traversal	Paul Beame,Allan Borodin,Prabhakar Raghavan,Walter L. Ruzzo,Martin Tompa	1990	Time-space tradeoffs for traversing undirected graphs are proved. One of these tradeoffs is a quadratic lower bound on a deterministic model that closely matches the probabilistic upper bound of A.Z. Broder et al. (1989). The models used are variants of S.A. Cook and C.W. Rackoff's (1980) jumping automata for graphs. Some open problems are stated.	FOCS	theory
274	FOCS	Communication-Space Tradeoffs for Unrestricted Protocols	Paul Beame,Martin Tompa,Peiyuan Yan	1990	Communicating branching programs are introduced, and a general technique for demonstrating communication-space tradeoffs for pairs of communicating branching programs is developed. The technique is used to prove communication-space tradeoffs for any pair of communicating branching programs that hashes according to a universal family of hash functions. Other tradeoffs follow from this result. For example any pair of communicating Boolean branching programs that computes matrix-vector products over GF(2) requires communication-space product Omega (n/sup 2/). These are the first examples of communication-space tradeoffs on a completely general model of communicating processes.	FOCS	theory
275	FOCS	Randomness in Interactive Proofs	Mihir Bellare,Oded Goldreich,Shafi Goldwasser	1990	The quantitative aspects of randomness in interactive proof systems are studied. The result is a randomness-efficient error-reduction technique: given an Arthur-Merlin proof system (error probability	FOCS	theory
276	FOCS	Hidden Surface Removal for Axis-Parallel Polyhedra (Extended Abstract)	Mark de Berg,Mark H. Overmars	1990	Hidden Surface Removal for Axis-Parallel Polyhedra (Extended Abstract)	FOCS	theory
277	FOCS	Some Triply-Logarithmic Parallel Algorithms (Extended Abstract)	Omer Berkman,Joseph JáJá,Sridhar Krishnamurthy,Ramakrishna Thurimella,Uzi Vishkin	1990	Some Triply-Logarithmic Parallel Algorithms (Extended Abstract)	FOCS	theory
278	FOCS	Provably Good Mesh Generation	Marshall W. Bern,David Eppstein,John R. Gilbert	1990	Several versions of the problem of generating triangular meshes for finite-element methods are studied. It is shown how to triangulate a planar point set or a polygonally bounded domain with triangles of bounded aspect ratio, how to triangulate a planar point set with triangles having no obtuse angles, how to triangulate a point set in arbitrary dimension with simplices of bounded aspect ratio, and how to produce a linear-size Delaunay triangulation of a multidimensional point set by adding a linear number of extra points. All the triangulations have size within a constant factor of optimal and run in optimal time O(n log n+k) with input of size n and output of size k. No previous work on mesh generation simultaneously guarantees well-shaped elements and small total size.	FOCS	theory
279	FOCS	Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean Domain	Avrim Blum	1990	Two of the most commonly used models in computational learning theory are the distribution-free model, in which examples are chosen from a fixed but arbitrary distribution, and the absolute mistake-bound model, in which examples are presented in order by an adversary. Over the Boolean domain	FOCS	theory
280	FOCS	Some Tools for Approximate 3-Coloring (Extended Abstract)	Avrim Blum	1990	Some Tools for Approximate 3-Coloring (Extended Abstract)	FOCS	theory
281	FOCS	Polynomial Threshold Functions, AC^0 Functions and Spectral Norms (Extended Abstract)	Jehoshua Bruck,Roman Smolensky	1990	Polynomial Threshold Functions, AC^0 Functions and Spectral Norms (Extended Abstract)	FOCS	theory
282	FOCS	On the Predictability of Coupled Automata: An Allegory about Chaos	Samuel R. Buss,Christos H. Papadimitriou,John N. Tsitsiklis	1990	The authors show a sharp dichotomy between systems of identical automata with symmetric global control whose behavior is easy to predict and those whose behavior is hard to predict. The division pertains to whether the global control rule is invariant with respect to permutations of the states of the automaton. It is also shown that testing whether the global control rule has this invariance property is an undecidable problem. It is argued that there is a natural analog between complexity in the present model and chaos in dynamical systems.	FOCS	theory
283	FOCS	Triangulating a Simple Polygon in Linear Time	Bernard Chazelle	1990	A linear-time deterministic algorithm for triangulating a simple polygon is developed. The algorithm is elementary in that it does not require the use of any complicated data structures; in particular, it does not need dynamic search trees, finger trees, or fancy point location structures.	FOCS	theory
284	FOCS	Counting and Cutting Cycles of Lines and Rods in Space	Bernard Chazelle,Herbert Edelsbrunner,Leonidas J. Guibas,Richard Pollack,Raimund Seidel,Micha Sharir,Jack Snoeyink	1990	A number of rendering algorithms in computer graphics sort three-dimensional objects by depth and assume that there is no cycle that makes the sorting impossible. One way to resolve the problem caused by cycles is to cut the objects into smaller pieces. The problem of estimating how many such cuts are always sufficient is addressed. A few related algorithmic and combinatorial geometry problems are considered.	FOCS	theory
285	FOCS	New Results on Dynamic Planar Point Location	Siu-Wing Cheng,Ravi Janardan	1990	A point location scheme is presented for an n-vertex dynamic planar subdivision whose underlying graph is only required to be connected. The scheme uses O(n) space and yields an O(log/sup 2/n) query time and an O(log n) update time. Insertion (respectively, deletion) of an arbitrary k-edge chain inside a region can be performed in O(k log(n+k)) (respectively, O(k log n)) time. The scheme is then extended to speed up the insertion/deletion of a k-edge monotone chain to O(log/sup 2/n log log n+k) time (or O(log n log log n+k) time for an alternative model of input), but at the expense of increasing the other time bounds slightly. All bounds are worst case. Additional results include a generalization to planar subdivisions consisting of algebraic segments of bounded degree and a persistent scheme for planar point location.	FOCS	theory
286	FOCS	Bounds on Tradeoffs between Randomness and Communication Complexity	Ran Canetti,Oded Goldreich	1990	A quantitative investigation of the power of randomness in the context of communication complexity is initiated. The authors prove general lower bounds on the length of the random input of parties computing a function f, depending on the number of bits communicated and the deterministic communication complexity of f. Four standard models for communication complexity are considered: the random input of the parties may be shared or local, and the communication may be one-way or two-way. The bounds are shown to be tight for all the models, for all values of the deterministic communication complexity, and for all possible quantities of bits exchanged. It is shown that it is possible to reduce the number of random bits required by any protocol, without increasing the number of bits exchanged (up to a limit depending on the advantage achieved by the protocol).	FOCS	theory
287	FOCS	Private Computations Over the Integers (Extended Abstract)	Benny Chor,Mihály Geréb-Graus,Eyal Kushilevitz	1990	Private Computations Over the Integers (Extended Abstract)	FOCS	theory
288	FOCS	Approximate String Matching in Sublinear Expected Time	William I. Chang,Eugene L. Lawler	1990	The k differences approximate string matching problem specifies a text string of length n, a pattern string of length m, and the number k of differences (insertions, deletions, substitutions) allowed in a match, and asks for every location in the text where a match occurs. Previous algorithms required at least O(nk) time. When k is as large as a fraction of m, no substantial progress has been made over O(nm) dynamic programming. The authors have investigated much faster algorithms for restricted cases of the problem, such as when the text string is random and errors are not too frequent. They have devised an algorithm that, for k	FOCS	theory
289	FOCS	Online Algorithms for Finger Searching (Extended Abstract)	Richard Cole,Arvind Raghunathan	1990	Online Algorithms for Finger Searching (Extended Abstract)	FOCS	theory
290	FOCS	On the Exact Complexity of String Matching (Extended Abstract)	Livio Colussi,Zvi Galil,Raffaele Giancarlo	1990	On the Exact Complexity of String Matching (Extended Abstract)	FOCS	theory
291	FOCS	Exploring an Unknown Graph (Extended Abstract)	Xiaotie Deng,Christos H. Papadimitriou	1990	Exploring an Unknown Graph (Extended Abstract)	FOCS	theory
292	FOCS	Perfectly Secure Message Transmission	Danny Dolev,Cynthia Dwork,Orli Waarts,Moti Yung	1990	The problem of perfectly secure communication in a general network in which processors and communication lines may be faulty is studied. Lower bounds are obtained on the connectivity required for successful secure communication. Efficient algorithms that operate with this connectivity and rely on no complexity theoretic assumptions are derived. These are the first algorithms for secure communication in a general network to achieve simultaneously the goals of perfect secrecy, perfect resiliency, and a worst case time which is linear in the diameter of the network.	FOCS	theory
293	FOCS	Faster Tree Pattern Matching	Moshe Dubiner,Zvi Galil,Edith Magen	1990	Recently, R. Kosaraju (Proc. 30th IEEE Symp. on Foundations of Computer Science, 1989, p.178-83) gave an O(nm/sup 0.75/ polylog(m))-step algorithm for tree pattern matching. The authors improve this result by designing a simple O(n square root m polylog (m)) algorithm.	FOCS	theory
294	FOCS	Computing with Snakes in Directed Networks of Automata (Extended Abstract)	Shimon Even,Ami Litman,Peter Winkler	1990	Computing with Snakes in Directed Networks of Automata (Extended Abstract)	FOCS	theory
295	FOCS	Multiple Non-Interactive Zero Knowledge Proofs Based on a Single Random String (Extended Abstract)	Uriel Feige,Dror Lapidot,Adi Shamir	1990	Multiple Non-Interactive Zero Knowledge Proofs Based on a Single Random String (Extended Abstract)	FOCS	theory
296	FOCS	Drawing Graphs in the Plane with High Resolution	Michael Formann,Torben Hagerup,James Haralambides,Michael Kaufmann,Frank Thomson Leighton,Antonios Symvonis,Emo Welzl,Gerhard J. Woeginger	1990	The problem of drawing a graph in the plane so that edges appear as straight lines and the minimum angle formed by any pair of incident edges is maximized is studied. The resolution of a layout is defined to be the size of the minimum angle formed by incident edges of the graph, and the resolution of a graph is defined to be the maximum resolution of any layout of the graph. The resolution R of a graph is characterized in terms of the maximum node degree d of the graph by proving that Omega (1/d/sup 2/)	FOCS	theory
297	FOCS	Augmenting Graphs to Meet Edge-Connectivity Requirements	András Frank	1990	The problem of determining the minimum number gamma of edges to be added to a graph G so that in the resulting graph the edge-connectivity between every pair (u,v) of nodes is at least a prescribed value r(u,v) is treated. A min-max formula for gamma is derived, and a polynomial-time algorithm for computing gamma is described. The directed counterpart of the problem is also solved for the case in which r(u,v)=k>or=1. The approach used makes it possible to solve a degree-constrained version of the problem. The minimum-cost augmentation problem can also be solved in polynomial time provided that the edge costs arise from node costs.	FOCS	theory
298	FOCS	Competitive k-Server Algorithms (Extended Abstract)	Amos Fiat,Yuval Rabani,Yiftach Ravid	1990	Competitive k-Server Algorithms (Extended Abstract)	FOCS	theory
299	FOCS	Permuting	Faith E. Fich,J. Ian Munro,Patricio V. Poblete	1990	The fundamental problem of permuting the elements of an array according to some given permutation is addressed. The goal is to perform the permutation quickly using only a polylogarithmic number of bits of extra storage. The main result is an O(n log n)-time, O(log/sup 2/n)-space worst case method. A simpler method is presented for the case in which both the permutation and its inverse can be computed at (amortized) unit cost. This algorithm requires O(n log n) time and O(log n) bits in the worst case. These results are extended to the situation in which a power of the permutation is to be applied. A linear time, O(log n)-bit method is presented for the special case in which the data values are all distinct and are either initially in sorted order or will be when permuted.	FOCS	theory
300	FOCS	Trans-dichotomous Algorithms for Minimum Spanning Trees and Shortest Paths	Michael L. Fredman,Dan E. Willard	1990	The fusion tree method is extended to develop a linear-time algorithm for the minimum spanning tree problem and an O(m+n log n/log log n) implementation of Dijkstra's shortest-path algorithm for a graph with n vertices and m edges. The shortest-path algorithm surpasses information-theoretic limitations. The extension of the fusion tree method involves the development of a new data structure, the atomic heap. The atomic heap accommodates heap (priority queue) operations in constant amortized time under suitable polylog restrictions on the heap size. The linear-time minimum spanning tree algorithm results from a direct application of the atomic heap. To obtain the shortest path algorithm, the atomic heap is used as a building block to construct a new data structure, the AF-heap, which has no size restrictions and surpasses information theoretic limitations. The AF-heap belongs to the Fibonacci heap family.	FOCS	theory
301	FOCS	Robust Separations in Inductive Inference	Mark A. Fulk	1990	Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. J.M. Barzdin (1974) proposed a way of ruling out such examples and conjectured that one of the earliest results of inductive inference theory would fall if his method were used. The author refutes Barzdin's conjecture and proposes a new line of research examining robust separations which are defined using a strengthening of Barzdin's original idea. Preliminary results are presented, and the most important open problem is stated as a conjecture. The extension of this work from function learning to formal language learning is discussed.	FOCS	theory
302	FOCS	Exact Identification of Circuits Using Fixed Points of Amplification Functions (Extended Abstract)	Sally A. Goldman,Michael J. Kearns,Robert E. Schapire	1990	Exact Identification of Circuits Using Fixed Points of Amplification Functions (Extended Abstract)	FOCS	theory
303	FOCS	Security Preserving Amplification of Hardness	Oded Goldreich,Russell Impagliazzo,Leonid A. Levin,Ramarathnam Venkatesan,David Zuckerman	1990	The task of transforming a weak one-way function (which may be easily inverted on all but a polynomial fraction of the range) into a strong one-way function (which can be easily inverted only on a negligible function of the range) is considered. The previously known transformation does not preserve the security (i.e. the running time of the inverting algorithm) within any polynomial. Its resulting function, F(x), applies the weak one-way function to many small (of length mod x mod /sup theta /, theta	FOCS	theory
304	FOCS	Interpolation of Sparse Rational Functions Without Knowing Bounds on Exponents	Dima Grigoriev,Marek Karpinski,Michael F. Singer	1990	The authors present the first algorithm for the (black box) interpolation of t-sparse, n-variate, rational functions without knowing bounds on exponents of their sparse representation, with the number of queries independent of exponents. In fact, the algorithm uses O(nt/sup t/) queries to the black box, and it can be implemented for a fixed t in a polynomially bounded storage (or polynomial parallel time).	FOCS	theory
305	FOCS	Matrix Decomposition Problem Is Complete for the Average Case	Yuri Gurevich	1990	The first algebraic average-case complete problem is presented. The focus of attention is the modular group, i.e., the multiplicative group SL/sub 2/(Z) of two-by-two integer matrices of determinant 1. By default, in this study matrices are elements of the modular group. The problem is arguably the simplest natural average-case complete problem to date.	FOCS	theory
306	FOCS	Deciding Properties of Nonregular Programs (Preliminary Version)	David Harel,Danny Raz	1990	Deciding Properties of Nonregular Programs (Preliminary Version)	FOCS	theory
307	FOCS	On the Power of Small-Depth Threshold Circuits	Johan Håstad,Mikael Goldmann	1990	The power of threshold circuits of small depth is investigated. In particular, functions that require exponential-size unweighted threshold circuits of depth 3 when the bottom fan-in is restricted are given. It is proved that there are monotone functions f/sub k/ that can be computed on depth k and linear size AND, OR circuits but require exponential-size to be computed by a depth-(k-1) monotone weighted threshold circuit.	FOCS	theory
308	FOCS	Simplifying Nested Radicals and Solving Polynomials by Radicals in Minimum Depth	Gwoboa Horng,Ming-Deh A. Huang	1990	The notion of pure nested radicals and its field-theoretic counterpart, pure root extensions, are defined and used for investigating exact radical solutions.	FOCS	theory
309	FOCS	No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random	Russell Impagliazzo,Leonid A. Levin	1990	No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random	FOCS	theory
310	FOCS	Coloring Inductive Graphs On-Line	Sandy Irani	1990	Online graph coloring, in which the vertices are presented one at a time, is considered. Each vertex must be assigned a color, different from the colors of its neighbors, before the next vertex is given. The class of d-inductive graphs is treated. A graph G is said to be d-inductive if the vertices of G can be numbered so that each vertex has at most d edges to higher numbered vertices. First Fit (FF) is the algorithm that assigns each vertex the lowest numbered color possible. It is shown that if G is d-inductive, then FF uses O(d log n) colors on G. This yields an upper bound of O(log n) on the performance ratio of FF on chordal and planar graphs. FF does as well as any online algorithm for d-inductive graphs; it is shown that for any d and any online graph-coloring algorithm A, there is a d-inductive graph that forces A to use Omega (d log n) colors to color G. Online graph coloring with lookahead is also investigated.	FOCS	theory
311	FOCS	Constructing Generalized Universal Traversing Sequences of Polynomial Size for Graphs with Small Diameter (Extended Abstract)	Sorin Istrail	1990	Constructing Generalized Universal Traversing Sequences of Polynomial Size for Graphs with Small Diameter (Extended Abstract)	FOCS	theory
312	FOCS	Asymptotically Tight Bounds for Computing with Faulty Arrays of Processors (Extended Abstract)	Christos Kaklamanis,Anna R. Karlin,Frank Thomson Leighton,Victor Milenkovic,Prabhakar Raghavan,Satish Rao,Clark D. Thomborson,A. Tsantilas	1990	Asymptotically Tight Bounds for Computing with Faulty Arrays of Processors (Extended Abstract)	FOCS	theory
313	FOCS	Finite-Memory Automata (Extended Abstract)	Michael Kaminski,Nissim Francez	1990	Finite-Memory Automata (Extended Abstract)	FOCS	theory
314	FOCS	Inferring Evolutionary History from DNA Sequences (Extended Abstract)	Sampath Kannan,Tandy Warnow	1990	Inferring Evolutionary History from DNA Sequences (Extended Abstract)	FOCS	theory
315	FOCS	Efficient Distribution-free Learning of Probabilistic Concepts (Extended Abstract)	Michael J. Kearns,Robert E. Schapire	1990	Efficient Distribution-free Learning of Probabilistic Concepts (Extended Abstract)	FOCS	theory
316	FOCS	Approximation through Multicommodity Flow	Philip N. Klein,Ajit Agrawal,R. Ravi,Satish Rao	1990	The first approximate max-flow-min-cut theorem for general multicommodity flow is proved. It is used to obtain approximation algorithms for minimum deletion of clauses of a 2-CNF identical to formula, via minimization problems, and other problems. Also presented are approximation algorithms for chordalization of a graph and for register sufficiency that are based on undirected and directed node separators.	FOCS	theory
317	FOCS	Towards a DNA Sequencing Theory (Learning a String) (Preliminary Version)	Ming Li	1990	Towards a DNA Sequencing Theory (Learning a String) (Preliminary Version)	FOCS	theory
318	FOCS	Efficient Parallel Algorithms for Tree-Decomposition and Related Problems	Jens Lagergren	1990	An efficient parallel algorithm for the tree-decomposition problem for fixed width w is presented. The algorithm runs in time O(log/sup 3/ n) and uses O(n) processors on a concurrent-read, concurrent-write parallel random access machine (CRCW PRAM). This result can be used to construct efficient parallel algorithms for three important classes of problems: MS (monadic second-order) properties, linear EMS (extended monadic second-order) extremum problems, and enumeration problems for MS properties, for graphs of tree width at most w. The sequential time complexity of the tree-composition problem for fixed w is improved, and some implications for this improvement are stated.	FOCS	theory
319	FOCS	A Tree-Partitioning Technique with Applications to Expression Evaluation and Term Matching (Extended Abstract)	S. Rao Kosaraju,Arthur L. Delcher	1990	A Tree-Partitioning Technique with Applications to Expression Evaluation and Term Matching (Extended Abstract)	FOCS	theory
320	FOCS	Complexity of Unification in Free Groups and Free Semi-groups	Antoni Koscielski,Leszek Pacholski	1990	It is proved that the exponent of periodicity of a minimal solution of a word equation is at most 2/sup 2.54n/, where n is the length of the equation. Since the best known lower bound is 2/sup 0.31n/, this upper bound is almost optimal and exponentially better than the original bound. Thus the result implies exponential improvement of known upper bounds on complexity of word-unification algorithms. Evidence is given that, contrary to common belief, the algorithm deciding satisfiability of equations in free groups, given by G.S. Makanin (1977), is not primitive recursive.	FOCS	theory
321	FOCS	A (fairly) Simple Circuit that (usually) Sorts	Frank Thomson Leighton,C. Greg Plaxton	1990	A (fairly) Simple Circuit that (usually) Sorts	FOCS	theory
322	FOCS	Decision Problems for Propositional Linear Logic	Patrick Lincoln,John C. Mitchell,Andre Scedrov,Natarajan Shankar	1990	It is shown that, unlike most other propositional (quantifier-free) logics, full propositional linear logic is undecidable. Further, it is provided that without the model storage operator, which indicates unboundedness of resources, the decision problem becomes PSPACE-complete. Also established are membership in NP for the multiplicative fragment, NP-completeness for the multiplicative fragment extended with unrestricted weakening, and undecidability for certain fragments of noncommutative propositional linear logic.	FOCS	theory
323	FOCS	Tight Bounds on the Complexity of Cascaded Decomposition of Automata	Oded Maler,Amir Pnueli	1990	Exponential upper and lower bounds on the size of the cascaded (Krohn-Rhodes) decomposition of automata are given. These results are used to obtain elementary algorithms for various translations between automata and temporal logic, where the previously known translations were nonelementary. The relevance of the result is discussed.	FOCS	theory
324	FOCS	Asynchronous PRAMs Are (Almost) as Good as Synchronous PRAMs	Charles U. Martel,Ramesh Subramonian,Arvin Park	1990	A PRAM (parallel random-access-machine) model that allows processors to have arbitrary asynchronous behavior is introduced. The main result shows that any n-processor CRCW (concurrent-read, concurrent-write) PRAM program can be simulated on an asynchronous CRCW PRAM using O(n) expected work per parallel step and up to n/log n log*n asynchronous processors. It is shown that a synchronization primitive for n parallel instructions can be computed using O(n) expected work by a system of asynchronous processors. Since a special case of asynchronous behavior is a fail-stop error, the simulation technique described above can convert any PRAM program into a PRAM program that is resistant to all fail-stop errors and has the same expected work as the original program.	FOCS	theory
325	FOCS	The Mixing Rate of Markov Chains, an Isoperimetric Inequality, and Computing the Volume	László Lovász,Miklós Simonovits	1990	A. Sinclair and M. Jerrum (1988) derived a bound on the mixing rate of time-reversible Markov chains in terms of their conductance. The authors generalize this result by not assuming time reversibility and using a weaker notion of conductance. They prove an isoperimetric inequality for subsets of a convex body. These results are combined to simplify an algorithm of M. Dyer et al. (1989) for approximating the volume of a convex body and to improve running-time bounds.	FOCS	theory
326	FOCS	Algebraic Methods for Interactive Proof Systems	Carsten Lund,Lance Fortnow,Howard J. Karloff,Noam Nisan	1990	An algebraic technique for the construction of interactive proof systems is proposed. The technique is used to prove that every language in the polynomial-time hierarchy has an interactive proof system. For the proof, a method is developed for reducing the problem of verifying the value of a low-degree polynomial at two points to verifying the value at one new point. The results have implications for program checking, verification, and self-correction.	FOCS	theory
327	FOCS	Communication Complexity of Algebraic Computation (Extended Abstract)	Zhi-Quan Luo,John N. Tsitsiklis	1990	Communication Complexity of Algebraic Computation (Extended Abstract)	FOCS	theory
328	FOCS	Probabilities of Sentences about Very Sparse Random Graphs	James F. Lynch	1990	The author considers random graphs with edge probability beta n/sup - alpha /, where n is the number of vertices of the graph, beta >0 is fixed, and alpha =1 or alpha =(l+1)/l for some fixed positive integer l. It is proved that, for every first-order sentence, the probability that the sentence is true for the random graph has an asymptotic limit. Also, there is an effective procedure for generating the value of the limit in closed form.	FOCS	theory
329	FOCS	On the Complexity of Learning from Counterexamples and Membership Queries	Wolfgang Maass,György Turán	1990	It is shown that for any concept class C the number of equivalence and membership queries that are needed to learn C is bounded from below by Omega (VC-dimension(C)). Furthermore, it is shown that the required number of equivalence and membership queries is also bounded from below by Omega (LC-ARB(C)/log(1+LC-ARB(C))), where LC-ARB(C) is the required number of steps in a different model where no membership queries but equivalence queries with arbitrary subsets of the domain are permitted. These two relationships are the only relationships between the learning complexities of the common online learning models and the related combinatorial parameters that have remained open. As an application of the first lower bound, the number of equivalence and membership queries that are needed to learn monomials of k out of n variables is determined. Learning algorithms for threshold gates that are based on equivalence queries are examined. It is shown that a threshold gate can learn not only concepts but also nondecreasing functions in polynomially many steps.	FOCS	theory
330	FOCS	On Graph-Theoretic Lemmata and Complexity Classes (Extended Abstract)	Christos H. Papadimitriou	1990	On Graph-Theoretic Lemmata and Complexity Classes (Extended Abstract)	FOCS	theory
331	FOCS	A Fast Algorithm for Optimally Increasing the Edge-Connectivity	Dalit Naor,Dan Gusfield,Charles U. Martel	1990	An undirected, unweighted graph G=(V, E with n nodes, m edges, and connectivity lambda ) is considered. Given an input parameter delta , the edge augmentation problem is to find the smallest set of edges to add to G so that its edge-connectivity is increased by delta . A solution to this problem that runs in time O( delta /sup 2/nm+nF(n)), where F(n) is the time to perform one maximum flow on G, is given. The solution gives the optimal augmentation for every delta ', 1	FOCS	theory
332	FOCS	Faster Circuits and Shorter Formulae for Multiple Addition, Multiplication and Symmetric Boolean Functions	Mike Paterson,Nicholas Pippenger,Uri Zwick	1990	A general theory is developed for constructing the shallowest possible circuits and the shortest possible formulas for the carry-save addition of n numbers using any given basic addition unit. More precisely, it is shown that if BA is a basic addition unit with occurrence matrix N, then the shortest multiple carry-save addition formulas that could be obtained by composing BA units are of size n/sup 1/p+o(1)/, where p is the unique real number for which the L/sub p/ norm of the matrix N equals 1. An analogous result connects the delay matrix M of the basic addition unit BA and the minimal q such that multiple carry-save addition circuits of depth (q+o(1)) log n could be constructed by combining BA units. On the basis of these optimal constructions of multiple carry-save adders, the shallowest known multiplication circuits are constructed.	FOCS	theory
333	FOCS	Specified Precision Polynomial Root Isolation is in NC	C. Andrew Neff	1990	Given a polynomial p(z) od degree n with integer coefficients, whose absolute values are bounded above by 2/sup m/, and a specified integer mu , it is shown that the problem of determining all roots of p with error less than 2/sup - mu / is in the parallel complexity class NC. To do this, an algorithm that runs on at most POLY(n+m+ mu ) processors with a parallel time complexity of O(log/sup 3/(n+m+ mu )) is constructed. This algorithm extends the algorithm of M. Ben-Or et al. (SIAM J. Comput., vol.17, p.1081-92, 1988) by removing the severe restriction that all the roots of p(z) should be real.	FOCS	theory
334	FOCS	On Threshold Circuits for Parity	Ramamohan Paturi,Michael E. Saks	1990	Motivated by, the problem of understanding the limitations of neural networks for representing Boolean functions, the authors consider size-depth tradeoffs for threshold circuits that compute the parity function. They give an almost optimal lower bound on the number of edges of any depth-2 threshold circuit that computes the parity function with polynomially bounded weights. The main technique used in the proof, which is based on the theory of rational approximation, appears to be a potentially useful technique for the analysis of such networks. It is conjectured that there are no linear size, bounded-depth threshold circuits for computing parity.	FOCS	theory
335	FOCS	Distributed Reactive Systems Are Hard to Synthesize	Amir Pnueli,Roni Rosner	1990	The problem of synthesizing a finite-state distributed reactive system is considered. Given a distributed architecture A, which comprises several processors P/sub 1/, . . ., P/sub k/ and their interconnection scheme, and a propositional temporal specification phi , a solution to the synthesis problem consists of finite-state programs Pi /sub 1/, . . ., Pi /sub k/ (one for each processor), whose joint (synchronous) behavior maintains phi against all possible inputs from the environment. Such a solution is referred to as the realization of the specification phi over the architecture A. Specifically, it is shown that the problem of realizing a given propositional specification over a given architecture is undecidable, and it is nonelementarily decidable for the very restricted class of hierarchical architectures. An extensive characterization of architecture classes for which the realizability problem is elementarily decidable and of classes for which it is undecidable is given.	FOCS	theory
336	FOCS	The Computability and Complexity of Optical Beam Tracing	John H. Reif,J. D. Tygar,Akitoshi Yoshida	1990	The ray-tracing problem is considered for optical systems consisting of a set of refractive or reflective surfaces. It is assumed that the position and the tangent of the incident angle of the initial light ray are rational. The computability and complexity of the ray-tracing problems are investigated for various optical models. The results show that, depending on the optical model, ray tracing is sometimes undecidable, sometimes PSPACE-hard, and sometimes in PSPACE.	FOCS	theory
337	FOCS	IP=PSPACE	Adi Shamir	1990	In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are exactly those proofs that can be generated with polynomial space.	FOCS	theory
338	FOCS	On Interpolation by Analytic Functions with Special Properties and Some Weak Lower Bounds on the Size of Circuits with Symmetric Gates	Roman Smolensky	1990	The author investigates the question of whether or not a specific Boolean function in n variables can be interpolated by an analytic function in the same variables whose partial derivatives of all orders span a subspace of low dimension in the space of analytic functions. The upper and lower bounds for this dimension yield some weak circuit lower bounds. For a particular function, an Omega (n/log n)-size lower bound is obtained for its computation by a circuit whose gates are symmetric. For the same function an Omega (n) lower bound is obtained for the circuit with mod/sub k/ gates.	FOCS	theory
339	FOCS	Efficiently Inverting Bijections Given by Straight Line Programs	Carl Sturtivant,Zhi-Li Zhang	1990	Let K be any field, and let F: K/sup n/ to K/sup n/ be a bijection with the property that both F and F/sup -1/ are computable using only arithmetic operations from K. Motivated by cryptographic considerations, the authors concern themselves with the relationship between the arithmetic complexity of F and the arithmetic complexity of F/sup -1/. They give strong relations between the complexity of F and F/sup -1/ when F is an automorphism in the sense of algebraic geometry (i.e. a formal bijection defined by n polynomials in n variables with a formal inverse of the same form). These constitute all such bijections in the case in which K is infinite. The authors show that at polynomially bounded degree, if an automorphism F has a polynomial-size arithmetic circuit, then F/sup -1/ has a polynomial-size arithmetic circuit. Furthermore, this result is uniform in the sense that there is an efficient algorithm for finding such a circuit for F/sup -1/, given such a circuit for F. This algorithm can also be used to check whether a circuit defines an automorphism F. If K is the Boolean field GF(2), then a circuit defining a bijection does not necessarily define an automorphism. However, it is shown in this case that, given any K/sup n/ to K/sup n/ bijection, there always exists an automorphism defining that bijection. This is not generally true for an arbitrary finite field.	FOCS	theory
340	FOCS	The Complexity of Finding Medians	Seinosuke Toda	1990	PF( Hash P) is characterized in a manner similar to M.W. Krentel's (1988) characterization of Pf(NP). If MidP is the class of functions that give the medians in the outputs of metric Turing machines, then it is shown that every function in PF( Hash P) is polynomial time 1-Turing reducible to a function in MidP and MidP contained in PF( Hash P); that is, PF( Hash P)=PF(MidP(1)). Intuitively, finding medians is as hard computationally as PF( Hash P); this forms a contrast to an intuitive interpretation of Krentel's result that finding maxima (or minima) is as hard as PF(NP). Several applications of the result are shown.	FOCS	theory
341	FOCS	Reducing the Parallel Complexity of Certain Linear Programming Problems (Extended Abstract)	Pravin M. Vaidya	1990	Reducing the Parallel Complexity of Certain Linear Programming Problems (Extended Abstract)	FOCS	theory
342	FOCS	The Lattice Reduction Algorithm of Gauss: An Average Case Analysis	Brigitte Vallée,Philippe Flajolet	1990	The lattice reduction algorithm of Gauss is shown to have an average-case complexity that is asymptotic to a constant. The analysis makes use of elementary properties of continued fractions and of linear fractional transformations.	FOCS	theory
343	FOCS	Randomized Online Graph Coloring (Preliminary Version)	Sundar Vishwanathan	1990	Randomized Online Graph Coloring (Preliminary Version)	FOCS	theory
344	FOCS	On ACC and Threshold Circuits	Andrew Chi-Chih Yao	1990	It is proved that any language in ACC can be approximately computed by two-level circuits of size 2 raised to the (log n)/sup k/ power, with a symmetric-function gate at the top and only AND gates on the first level. This implies that any language in ACC can be recognized by depth-3 threshold circuits of that size. This result gives the first nontrivial upper bound on the computing power of ACC circuits.	FOCS	theory
345	FOCS	General Weak Random Sources	David Zuckerman	1990	The following model for a weak random source is considered. The source is asked only once for R bits, and the source outputs an R-bit string such that no string has probability more than 2/sup - delta R/ of being output. for some fixed delta >0. A pseudorandom generator that runs in time n/sup O(log n)/ and simulates RP using as a seed a string from such a source is exhibited. Under the generalized Paley graph conjecture, a generator that runs in polynomial time and simulates RP is given, as well as a different generator that produces almost perfectly random bits at a rate arbitrarily close to optimal using as seeds strings from a constant number of independent weak random sources.	FOCS	theory
346	FOCS	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA		1990	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA	FOCS	theory
347	FOCS	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA		1990	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA	FOCS	theory
348	SODA	Incremental Evaluation of Computational Circuits.	Bowen Alpern,Roger Hoover,Barry K. Rosen,Peter F. Sweeney,F. Kenneth Zadeck	1990	Incremental Evaluation of Computational Circuits.	SODA	theory
349	SODA	Efficient Pattern Matching with Scaling.	Amihood Amir,Gad M. Landau,Uzi Vishkin	1990	Efficient Pattern Matching with Scaling.	SODA	theory
350	SODA	An Efficiently Computable Metric for Comparing Polygonal Shapes.	Esther M. Arkin,L. Paul Chew,Daniel P. Huttenlocher,Klara Kedem,Joseph S. B. Mitchell	1990	A method for comparing polygons that is a metric, invariant under translation, rotation, and change of scale, reasonably easy to compute, and intuitive is presented. The method is based on the L/sub 2/ distance between the turning functions of the two polygons. It works for both convex and nonconvex polygons and runs in time O(mn log mn), where m is the number of vertices in one polygon and n is the number of vertices in the other. Some examples showing that the method produces answers that are intuitively reasonable are presented.	SODA	theory
351	SODA	Incremental Algorithms for Minimal Length Paths.	Giorgio Ausiello,Giuseppe F. Italiano,Alberto Marchetti-Spaccamela,Umberto Nanni	1990	Incremental Algorithms for Minimal Length Paths.	SODA	theory
352	SODA	Factor Refinement.	Eric Bach,James R. Driscoll,Jeffrey Shallit	1990	Factor Refinement.	SODA	theory
353	SODA	Analysis of Boyer-Moore-Type String Searching Algorithms.	Ricardo A. Baeza-Yates,Gaston H. Gonnet,Mireille Régnier	1990	Analysis of Boyer-Moore-Type String Searching Algorithms.	SODA	theory
354	SODA	Parallel Search for Maximal Independence Given Minimal Dependence.	Paul Beame,Michael Luby	1990	Parallel Search for Maximal Independence Given Minimal Dependence.	SODA	theory
355	SODA	Experiments on Traveling Salesman Heuristics.	Jon Louis Bentley	1990	Experiments on Traveling Salesman Heuristics.	SODA	theory
356	SODA	Fast Linear Expected-Time Algorithms for Computing Maxima and Convex Hulls.	Jon Louis Bentley,Kenneth L. Clarkson,David B. Levine	1990	Fast Linear Expected-Time Algorithms for Computing Maxima and Convex Hulls.	SODA	theory
357	SODA	Approximation Algorithms for the Maximum Acyclic Subgraph Problem.	Bonnie Berger,Peter W. Shor	1990	Approximation Algorithms for the Maximum Acyclic Subgraph Problem.	SODA	theory
358	SODA	A Competitive 3-Server Algorithm.	Piotr Berman,Howard J. Karloff,Gábor Tardos	1990	A Competitive 3-Server Algorithm.	SODA	theory
359	SODA	Visibility with a Moving Point of View.	Marshall W. Bern,David P. Dobkin,David Eppstein,Robert L. Grossman	1990	Visibility with a Moving Point of View.	SODA	theory
360	SODA	Multilevel Adaptive Hashing.	Andrei Z. Broder,Anna R. Karlin	1990	Multilevel Adaptive Hashing.	SODA	theory
361	SODA	A Data Structure for Arc Insertion and Regular Path Finding.	Adam L. Buchsbaum,Paris C. Kanellakis,Jeffrey Scott Vitter	1990	If $G$ is a directed graph with labeled edges and $L$ is a fixed regular language, the {\em regular path problem}, given two nodes, $u$ and $v$, in $G$, is to find a path between $u$ and $v$ such that the labels on the arcs along that path form a string which is a member of $L$. We consider a dynamic version of this problem, adding arcs to and performing regular path queries on $G$ over $L$, and present a data structure that solves both problems in average time per operation linear in the number of nodes of the graph for any fixed regular language.	SODA	theory
362	SODA	Efficient Maintenance of the Union Intervals on a Line, with Applications.	Siu-Wing Cheng,Ravi Janardan	1990	Efficient Maintenance of the Union Intervals on a Line, with Applications.	SODA	theory
363	SODA	title=New Results on Server Problems.	Marek Chrobak,Howard J. Karloff,T. H. Payne,Sundar Vishwanathan	1990	title=New Results on Server Problems.	SODA	theory
364	SODA	First-Fit Storage of Linear Lists: Tight Probabilistic Bounds on Wasted Space.	Edward G. Coffman Jr.,Leopold Flatto,Frank Thomson Leighton	1990	First-Fit Storage of Linear Lists: Tight Probabilistic Bounds on Wasted Space.	SODA	theory
365	SODA	Shrinking Lattice Polyhedra.	John Cremona,Susan Landau	1990	Shrinking Lattice Polyhedra.	SODA	theory
366	SODA	Fast Parallel Algorithms for the Clique Separator Decomposition.	Elias Dahlhaus,Marek Karpinski,Mark B. Novick	1990	We give an efficient {\it NC} algorithm for finding a clique separator decomposition of an {\it arbitrary} graph, that is, a series of cliques whose removal disconnects the graph. This algorithm allows one to extend a large body of results which were originally formulated for chordal graphs to other classes of graphs. Our algorithm is optimal to within a polylogarithmic factor of Tarjan''s $O(mn)$ time sequential algorithm. The decomposition can also be used to find {\it NC} algorithms for some optimization problems on special families of graphs, assuming these problems can be solved in {\it NC} for the prime graphs of the decomposition. These optimization problems include: finding a maximum-weight clique, a minimum coloring, a maximum-weight independent set, and a minimum fill-in elimination order. We also give the first parallel algorithms for solving these problems by using the clique separator decomposition. Our maximum-weight independent set algorithm applied to chordal graphs yields the most efficient known parallel algorithm for finding a maximum-weight independent set of a chordal graph.	SODA	theory
367	SODA	A Practical Algorithm for Computing the Delaunay Triangulation for Convex Distance Functions.	Robert L. (Scot) Drysdale III	1990	A Practical Algorithm for Computing the Delaunay Triangulation for Convex Distance Functions.	SODA	theory
368	SODA	Sparse Dynamic Programming.	David Eppstein,Zvi Galil,Raffaele Giancarlo,Giuseppe F. Italiano	1990	Sparse Dynamic Programming.	SODA	theory
369	SODA	Maintenance of a Minimum Spanning Forest in a Dynamic Planar Graph.	David Eppstein,Giuseppe F. Italiano,Roberto Tamassia,Robert Endre Tarjan,Jeffery Westbrook,Moti Yung	1990	Maintenance of a Minimum Spanning Forest in a Dynamic Planar Graph.	SODA	theory
370	SODA	Data Structures for Weighted Matching and Nearest Common Ancestors with Linking.	Harold N. Gabow	1990	Data Structures for Weighted Matching and Nearest Common Ancestors with Linking.	SODA	theory
371	SODA	On the Parsimonious Property of Connectivity Problems.	Michel X. Goemans,Dimitris Bertsimas	1990	On the Parsimonious Property of Connectivity Problems.	SODA	theory
372	SODA	An Efficient Parallel Algorithm that Finds Independent Sets of Guaranteed Size.	Mark K. Goldberg,Thomas H. Spencer	1990	An Efficient Parallel Algorithm that Finds Independent Sets of Guaranteed Size.	SODA	theory
373	SODA	Applying Parallel Processing Techniques to Classification Problems in Constructive Solid Geometry.	Michael T. Goodrich	1990	Applying Parallel Processing Techniques to Classification Problems in Constructive Solid Geometry.	SODA	theory
374	SODA	Compact Interval Trees: A Data Structure for Convex Hulls.	Leonidas J. Guibas,John Hershberger,Jack Snoeyink	1990	Compact Interval Trees: A Data Structure for Convex Hulls.	SODA	theory
375	SODA	Efficient Algorithms for Generalized Cut Trees.	Dan Gusfield,Dalit Naor	1990	Efficient Algorithms for Generalized Cut Trees.	SODA	theory
376	SODA	Asymptotically Fast Triangularization of Matrices Over Rings.	James L. Hafner,Kevin S. McCurley	1990	Asymptotically Fast Triangularization of Matrices Over Rings.	SODA	theory
377	SODA	On the Number of Minimum Size Separating Vertex Sets in a Graph and How to Find All of Them.	Arkady Kanevsky	1990	On the Number of Minimum Size Separating Vertex Sets in a Graph and How to Find All of Them.	SODA	theory
378	SODA	Determining the Evolutionary Tree.	Sampath Kannan,Eugene L. Lawler,Tandy Warnow	1990	Determining the Evolutionary Tree.	SODA	theory
379	SODA	Competitive Randomized Algorithms for Non-Uniform Problems.	Anna R. Karlin,Mark S. Manasse,Lyle A. McGeoch,Susan S. Owicki	1990	Competitive Randomized Algorithms for Non-Uniform Problems.	SODA	theory
380	SODA	Superlinear Bounds on Matrix Searching.	Maria M. Klawe	1990	Superlinear Bounds on Matrix Searching.	SODA	theory
381	SODA	Stable Husbands.	Donald E. Knuth,Rajeev Motwani,Boris Pittel	1990	Stable Husbands.	SODA	theory
382	SODA	Length-Limited Coding.	Lawrence L. Larmore,Daniel S. Hirschberg	1990	Length-Limited Coding.	SODA	theory
383	SODA	On-Line Dynamic Programming with Applications to the Prediction of RNA Secondary Structure.	Lawrence L. Larmore,Baruch Schieber	1990	On-Line Dynamic Programming with Applications to the Prediction of RNA Secondary Structure.	SODA	theory
384	SODA	Selection and Sorting in Totally Monotone Arrays.	Dina Kravets,James K. Park	1990	Selection and Sorting in Totally Monotone Arrays.	SODA	theory
385	SODA	An Optimal Algorithm for the Maximum Two-Chain Problem.	Ruey-Der Lou,Majid Sarrafzadeh,D. T. Lee	1990	An Optimal Algorithm for the Maximum Two-Chain Problem.	SODA	theory
386	SODA	Split Decomposition of Undirected Graphs.	Tze-Heng Ma,Jeremy Spinrad	1990	Split Decomposition of Undirected Graphs.	SODA	theory
387	SODA	Coloration Neighborhood Structures for General Graph Coloring.	Craig A. Morgenstern,Harry Shapiro	1990	Coloration Neighborhood Structures for General Graph Coloring.	SODA	theory
388	SODA	Suffix Arrays: A New Method for On-Line String Searches.	Udi Manber,Gene Myers	1990	Suffix Arrays: A New Method for On-Line String Searches.	SODA	theory
389	SODA	Using Separation Algorithms in Fixed Dimension.	Carolyn Haibt Norton,Serge A. Plotkin,Éva Tardos	1990	Using Separation Algorithms in Fixed Dimension.	SODA	theory
390	SODA	On Finding Non-Intersecting Paths in Grids and Its Application in Reconfiguring VLSI/WSI Arrays.	Vwani P. Roychowdhury,Jehoshua Bruck	1990	On Finding Non-Intersecting Paths in Grids and Its Application in Reconfiguring VLSI/WSI Arrays.	SODA	theory
391	SODA	Packing Random Items of Three Colors.	Wansoo T. Rhee,Michel Talagrand	1990	Packing Random Items of Three Colors.	SODA	theory
392	SODA	The Bisection Width of Grid Graphs.	Christos H. Papadimitriou,Martha Sideri	1990	The Bisection Width of Grid Graphs.	SODA	theory
393	SODA	Optimal Binary Space Partitions for Orthogonal Objects.	Mike Paterson,F. Frances Yao	1990	A binary space partition, or BSP is a scheme for recursively dividing a configuration of objects by hyperplanes until all objects are separated. BSPs are widely used in computer graphics as the underlying data structure for computations such as real-time hidden-surface removal, ray tracing, and solid modelling. In these applications, the computational cost is directly related to the size of the BSP, ie the toal number of fragments of the objects generated by the partition. Until recently, the question of minimizing the size of BSPs for given inputs had been studied only empirically. We concentrate here on ortogonal objects, a case which arises frequently in practice and deserves special attention. We construct BSPs of linear size for any set of orthogonal line segments in the plane. In three dimensions, BSPs of size O(n^1.5) for any set of n mutually orthogonal line segments or rectangles are constructed. These bounds are optimal and may be contrasted with the omega(n^2) bound for general polygonal objects in R^3.	SODA	theory
394	SODA	Embedding Planar Graphs on the Grid.	Walter Schnyder	1990	Embedding Planar Graphs on the Grid.	SODA	theory
395	SODA	Improved Dual Network Simplex.	Serge A. Plotkin,Éva Tardos	1990	Improved Dual Network Simplex.	SODA	theory
396	SODA	New Techniques for the Union-Find Problems.	Johannes A. La Poutré	1990	New Techniques for the Union-Find Problems.	SODA	theory
397	SODA	Characterization and Algorithms for Greedily Solvable Transportation Problems.	Ron Shamir,Brenda L. Dietrich	1990	Characterization and Algorithms for Greedily Solvable Transportation Problems.	SODA	theory
398	SODA	New Techniques for Some Dynamic Closest-Point and Farthest-Point Problems.	Kenneth J. Supowit	1990	New Techniques for Some Dynamic Closest-Point and Farthest-Point Problems.	SODA	theory
399	SODA	Finding Steiner Forests in Planar Graphs.	Hitoshi Suzuki,Takehiro Akama,Takao Nishizeki	1990	Finding Steiner Forests in Planar Graphs.	SODA	theory
400	SODA	Manhattan Channel Routing with Good Theoretical and Practical Performance.	Charlotte Wieners-Lummer	1990	Manhattan Channel Routing with Good Theoretical and Practical Performance.	SODA	theory
401	SODA	Representing Sets with Constant Time Equality Testing.	Daniel M. Yellin	1990	Representing Sets with Constant Time Equality Testing.	SODA	theory
402	SODA	Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1990, San Francisco, California.	David S. Johnson	1990	Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1990, San Francisco, California.	SODA	theory
403	STOC	Solving Query-Retrieval Problems by Compacting Voronoi Diagrams (Extended Abstract)	Alok Aggarwal,Mark Hansen,Frank Thomson Leighton	1990	Solving Query-Retrieval Problems by Compacting Voronoi Diagrams (Extended Abstract)	STOC	theory
404	STOC	A Separator Theorem for Graphs with an Excluded Minor and its Applications	Noga Alon,Paul D. Seymour,Robin Thomas	1990	A Separator Theorem for Graphs with an Excluded Minor and its Applications	STOC	theory
405	STOC	On-line Algorithms for Path Selection in a Nonblocking Network (Extended Abstract)	Sanjeev Arora,Frank Thomson Leighton,Bruce M. Maggs	1990	On-line Algorithms for Path Selection in a Nonblocking Network (Extended Abstract)	STOC	theory
406	STOC	On the Power of Randomization in Online Algorithms (Extended Abstract)	Shai Ben-David,Allan Borodin,Richard M. Karp,Gábor Tardos,Avi Wigderson	1990	On the Power of Randomization in Online Algorithms (Extended Abstract)	STOC	theory
407	STOC	The Round Complexity of Secure Protocols (Extended Abstract)	Donald Beaver,Silvio Micali,Phillip Rogaway	1990	The Round Complexity of Secure Protocols (Extended Abstract)	STOC	theory
408	STOC	Perfect Zero-Knowledge in Constant Rounds	Mihir Bellare,Silvio Micali,Rafail Ostrovsky	1990	Perfect Zero-Knowledge in Constant Rounds	STOC	theory
409	STOC	The (True) Complexity of Statistical Zero Knowledge	Mihir Bellare,Silvio Micali,Rafail Ostrovsky	1990	The (True) Complexity of Statistical Zero Knowledge	STOC	theory
410	STOC	Learning Boolean Functions in an Infinite Atribute Space (Extended Abstract)	Avrim Blum	1990	Learning Boolean Functions in an Infinite Atribute Space (Extended Abstract)	STOC	theory
411	STOC	Self-Testing/Correcting with Applications to Numerical Problems	Manuel Blum,Michael Luby,Ronitt Rubinfeld	1990	Self-Testing/Correcting with Applications to Numerical Problems	STOC	theory
412	STOC	On the Necessity of Occam Algorithms	Raymond A. Board,Leonard Pitt	1990	On the Necessity of Occam Algorithms	STOC	theory
413	STOC	Online Algorithms for Locating Checkpoints	Marshall W. Bern,Daniel H. Greene,Arvind Raghunathan,Madhu Sudan	1990	Online Algorithms for Locating Checkpoints	STOC	theory
414	STOC	On the Decidability of Sparse Univariate Polynomial Interpolation (Preliminary Version)	Allan Borodin,Prasoon Tiwari	1990	On the Decidability of Sparse Univariate Polynomial Interpolation (Preliminary Version)	STOC	theory
415	STOC	Towards Optimal Simulations of Formulas by Bounded-Width Programs	Richard Cleve	1990	Towards Optimal Simulations of Formulas by Bounded-Width Programs	STOC	theory
416	STOC	On the Dynamic Finger Conjecture for Splay Trees (Extended Abstract)	Richard Cole	1990	On the Dynamic Finger Conjecture for Splay Trees (Extended Abstract)	STOC	theory
417	STOC	Random Walks on Weighted Graphs, and Applications to On-line Algorithms (Preliminary Version)	Don Coppersmith,Peter Doyle,Prabhakar Raghavan,Marc Snir	1990	Random Walks on Weighted Graphs, and Applications to On-line Algorithms (Preliminary Version)	STOC	theory
418	STOC	Deterministic Sorting in Nearly Logarithmic Time on the Hypercube and Related Computers	Robert Cypher,C. Greg Plaxton	1990	Deterministic Sorting in Nearly Logarithmic Time on the Hypercube and Related Computers	STOC	theory
419	STOC	How to Distribute a Dictionary in a Complete Network	Martin Dietzfelbinger,Friedhelm Meyer auf der Heide	1990	How to Distribute a Dictionary in a Complete Network	STOC	theory
420	STOC	The Use of a Synchronizer Yields Maximum Computation Rate in Distributed Networks (Extended Abstract)	Shimon Even,Sergio Rajsbaum	1990	The Use of a Synchronizer Yields Maximum Computation Rate in Distributed Networks (Extended Abstract)	STOC	theory
421	STOC	Computing with Unreliable Information (Preliminary Version)	Uriel Feige,David Peleg,Prabhakar Raghavan,Eli Upfal	1990	Computing with Unreliable Information (Preliminary Version)	STOC	theory
422	STOC	Witness Indistinguishable and Witness Hiding Protocols	Uriel Feige,Adi Shamir	1990	Witness Indistinguishable and Witness Hiding Protocols	STOC	theory
423	STOC	The Wakeup Problem (Extended Abstract)	Michael J. Fischer,Shlomo Moran,Steven Rudich,Gadi Taubenfeld	1990	The Wakeup Problem (Extended Abstract)	STOC	theory
424	STOC	The Information Theory Bound Is Tight for Selection in a Heap	Greg N. Frederickson	1990	The Information Theory Bound Is Tight for Selection in a Heap	STOC	theory
425	STOC	BLASTING through the Information Theoretic Barrier with FUSION TREES	Michael L. Fredman,Dan E. Willard	1990	BLASTING through the Information Theoretic Barrier with FUSION TREES	STOC	theory
426	STOC	Not All Keys Can Be Hashed in Constant Time (Preliminary Version)	Joseph Gil,Friedhelm Meyer auf der Heide,Avi Wigderson	1990	Not All Keys Can Be Hashed in Constant Time (Preliminary Version)	STOC	theory
427	STOC	Optimal Randomized Algorithms for Local Sorting and Set-Maxima	Wayne Goddard,Valerie King,Leonard J. Schulman	1990	Optimal Randomized Algorithms for Local Sorting and Set-Maxima	STOC	theory
428	STOC	Decidability of the Multiplicity Equivalence of Multitape Finite Automata	Tero Harju,Juhani Karhumäki	1990	Decidability of the Multiplicity Equivalence of Multitape Finite Automata	STOC	theory
429	STOC	Pseudo-Random Generators under Uniform Assumptions	Johan Håstad	1990	Pseudo-Random Generators under Uniform Assumptions	STOC	theory
430	STOC	Computing in Quotient Groups	William M. Kantor,Eugene M. Luks	1990	Computing in Quotient Groups	STOC	theory
431	STOC	Towards Overcoming the Transitive-Closure Bottleneck: Efficient Parallel Algorithms for Planar Digraphs	Ming-Yang Kao,Philip N. Klein	1990	Towards Overcoming the Transitive-Closure Bottleneck: Efficient Parallel Algorithms for Planar Digraphs	STOC	theory
432	STOC	An Optimal Algorithm for On-line Bipartite Matching	Richard M. Karp,Umesh V. Vazirani,Vijay V. Vazirani	1990	An Optimal Algorithm for On-line Bipartite Matching	STOC	theory
433	STOC	Efficient Robust Parallel Computations (Extended Abstract)	Zvi M. Kedem,Krishna V. Palem,Paul G. Spirakis	1990	Efficient Robust Parallel Computations (Extended Abstract)	STOC	theory
434	STOC	The Undecidability of the Semi-Unification Problem (Preliminary Report)	A. J. Kfoury,Jerzy Tiuryn,Pawel Urzyczyn	1990	The Undecidability of the Semi-Unification Problem (Preliminary Report)	STOC	theory
435	STOC	Quantitative Steinitz's Theorems with Applications to Multifingered Grasping	David G. Kirkpatrick,Bhubaneswar Mishra,Chee-Keng Yap	1990	Quantitative Steinitz's Theorems with Applications to Multifingered Grasping	STOC	theory
436	STOC	Leighton-Rao Might Be Practical: Faster Approximation Algorithms for Concurrent Flow with Uniform Capacities	Philip N. Klein,Clifford Stein,Éva Tardos	1990	Leighton-Rao Might Be Practical: Faster Approximation Algorithms for Concurrent Flow with Uniform Capacities	STOC	theory
437	STOC	On the Complexity of Computing a Gröbner Basis for the Radical of a Zero Dimensional Ideal	Yagati N. Lakshman	1990	On the Complexity of Computing a Gröbner Basis for the Radical of a Zero Dimensional Ideal	STOC	theory
438	STOC	The Number Field Sieve	Arjen K. Lenstra,Hendrik W. Lenstra Jr.,Mark S. Manasse,John M. Pollard	1990	The Number Field Sieve	STOC	theory
439	STOC	Approximate Inclusion-Exclusion	Nathan Linial,Noam Nisan	1990	Approximate Inclusion-Exclusion	STOC	theory
440	STOC	The Computational Complexity of Universal Hashing	Yishay Mansour,Noam Nisan,Prasoon Tiwari	1990	The Computational Complexity of Universal Hashing	STOC	theory
441	STOC	Separators in Two and Three Dimensions	Gary L. Miller,William P. Thurston	1990	Separators in Two and Three Dimensions	STOC	theory
442	STOC	Output Sensitive Construction of Levels and Voronoi Diagrams in R^d of Order 1 to k	Ketan Mulmuley	1990	Output Sensitive Construction of Levels and Voronoi Diagrams in R^d of Order 1 to k	STOC	theory
443	STOC	Small-bias Probability Spaces: Efficient Constructions and Applications	Joseph Naor,Moni Naor	1990	Small-bias Probability Spaces: Efficient Constructions and Applications	STOC	theory
444	STOC	Public-key Cryptosystems Provably Secure against Chosen Ciphertext Attacks	Moni Naor,Moti Yung	1990	Public-key Cryptosystems Provably Secure against Chosen Ciphertext Attacks	STOC	theory
445	STOC	Psuedorandom Generators for Space-Bounded Computation	Noam Nisan	1990	Psuedorandom Generators for Space-Bounded Computation	STOC	theory
446	STOC	On Polynomial Time Bounded Truth-Table Reducibility of NP Sets to Sparse Sets	Mitsunori Ogiwara,Osamu Watanabe	1990	On Polynomial Time Bounded Truth-Table Reducibility of NP Sets to Sparse Sets	STOC	theory
447	STOC	Efficient Computation on Oblivious RAMs	Rafail Ostrovsky	1990	Efficient Computation on Oblivious RAMs	STOC	theory
448	STOC	Quantifiers and Approximation (Extended Abstract)	Alessandro Panconesi,Desh Ranjan	1990	Quantifiers and Approximation (Extended Abstract)	STOC	theory
449	STOC	On the Complexity of Local Search (Extended Abstract)	Christos H. Papadimitriou,Alejandro A. Schäffer,Mihalis Yannakakis	1990	On the Complexity of Local Search (Extended Abstract)	STOC	theory
450	STOC	Lower Bounds for the Union-Find and the Split-Find Problem on Pointer Machines	Johannes A. La Poutré	1990	Lower Bounds for the Union-Find and the Split-Find Problem on Pointer Machines	STOC	theory
451	STOC	One-Way Functions are Necessary and Sufficient for Secure Signatures	John Rompel	1990	One-Way Functions are Necessary and Sufficient for Secure Signatures	STOC	theory
452	STOC	Monotone Circuits for Matching Require Linear Depth	Ran Raz,Avi Wigderson	1990	It is proven that monotone circuits computing the perfect matching function on n-vertex graphs require &OHgr;(n) depth. This implies an exponential gap between the depth of monotone and nonmonotone circuits.	STOC	theory
453	STOC	The Analysis of Closed Hashing under Limited Randomness (Extended Abstract)	Jeanette P. Schmidt,Alan Siegel	1990	The Analysis of Closed Hashing under Limited Randomness (Extended Abstract)	STOC	theory
454	STOC	The Discrete Log is Very Discreet	A. W. Schrift,Adi Shamir	1990	The Discrete Log is Very Discreet	STOC	theory
455	STOC	Unique Binary Search Tree Representations and Equality-testing of Sets and Sequences	Rajamani Sundar,Robert Endre Tarjan	1990	This paper studies the problem of representing sets over an ordered universe by unique binary search trees, so that dictionary operations can be performed efficiently on any set. Although efficient randomized solutions to the problem are known, its deterministic complexity has been open. The paper exhibits representations that permit the execution of dictionary operations in optimal deterministic time when the dictionary is sufficiently sparse or sufficiently dense. The results demonstrate an exponential separation between the deterministic and randomized complexities of the problem. Unique representations are applied to obtain efficient data structures for maintaining a dynamic collection of sets/sequences under queries that test the equality of a pair of objects. The data structure for set equality testing tests equality of sets in constant time and processes set updates in $O(\log m)$ amortized time and $O(\log m)$ space, where $m$ denotes the total number of updates performed. It is based on an efficient implementation of cascades of C{\vipt ONS} operations on uniquely stored S-expressions. The data structure for sequence equality testing tests equality of sequences in constant time and processes updates in $O(\sqrt{n \log m}\, + \log m)$ amortized time and $O(\sqrt{n})$ amortized space where $n$ denotes the length of the sequence that is updated and $m$ denotes the total number of updates performed.	STOC	theory
456	STOC	Functions with Bounded Symmetric Communication Complexity and Circuits with \mathop mod m Gates	Mario Szegedy	1990	Functions with Bounded Symmetric Communication Complexity and Circuits with \mathop mod m Gates	STOC	theory
457	STOC	Searching for Primitive Roots in Finite Fields	Victor Shoup	1990	Searching for Primitive Roots in Finite Fields	STOC	theory
458	STOC	Deterministic Sampling-A New Technique for Fast Pattern Matching	Uzi Vishkin	1990	Deterministic Sampling-A New Technique for Fast Pattern Matching	STOC	theory
459	STOC	Optimal Disk I/O with Parallel Block Transfer (Extended Abstract)	Jeffrey Scott Vitter,Elizabeth A. M. Shriver	1990	Optimal Disk I/O with Parallel Block Transfer (Extended Abstract)	STOC	theory
460	STOC	A Technique for Lower Bounding the Cover Time	David Zuckerman	1990	A Technique for Lower Bounding the Cover Time	STOC	theory
461	STOC	Coherent Functions and Program Checkers (Extended Abstract)	Andrew Chi-Chih Yao	1990	Coherent Functions and Program Checkers (Extended Abstract)	STOC	theory
462	STOC	Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, 14-16 May 1990, Baltimore, Maryland, USA		1990	Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, 14-16 May 1990, Baltimore, Maryland, USA	STOC	theory
463	ICCV	Shape and motion without depth.	Carlo Tomasi,Takeo Kanade	1990	Shape and motion without depth.	ICCV	visu
464	ICCV	Hypothesizing and testing geometric attributes of image data.	Kenichi Kanatani	1990	Hypothesizing and testing geometric attributes of image data.	ICCV	visu
465	ICCV	Determining back-facing curved model surfaces by analysis at the boundary.	Robert B. Fisher	1990	Determining back-facing curved model surfaces by analysis at the boundary.	ICCV	visu
466	ICCV	Computing optical flow from an overconstrained system of linear algebraic equations.	Marco Campani,Alessandro Verri	1990	Computing optical flow from an overconstrained system of linear algebraic equations.	ICCV	visu
467	ICCV	Vanishing point calculation as a statistical inference on the unit sphere.	Robert T. Collins,Richard S. Weiss	1990	Vanishing point calculation as a statistical inference on the unit sphere.	ICCV	visu
468	ICCV	A finite element method applied to new active contour models and 3D reconstruction from cross sections.	Laurent D. Cohen,Isaac Cohen	1990	A finite element method applied to new active contour models and 3D reconstruction from cross sections.	ICCV	visu
469	ICCV	Interesting patterns for model-based machine vision.	Jorja G. Henikoff,Linda G. Shapiro	1990	Interesting patterns for model-based machine vision.	ICCV	visu
470	ICCV	Computing two motions from three frames.	James R. Bergen,Peter J. Burt,Rajesh Hingorani,Shrnuel Peleg	1990	Computing two motions from three frames.	ICCV	visu
471	ICCV	Object recognition using a feature search strategy generated from a 3D model.	Yoshinori Kuno,Yasukazu Okamoto,Satoshi Okada	1990	Object recognition using a feature search strategy generated from a 3D model.	ICCV	visu
472	ICCV	A fast algorithm for active contours.	Donna J. Williams,Mubarak Shah	1990	A fast algorithm for active contours.	ICCV	visu
473	ICCV	Matching range images of human faces.	John C. Lee,Evangelos E. Milios	1990	Matching range images of human faces.	ICCV	visu
474	ICCV	Accurate corner detection: an analytical study.	Rachid Deriche,Gérard Giraudon	1990	Accurate corner detection: an analytical study.	ICCV	visu
475	ICCV	Appearance-model-based representation and matching of 3-D objects.	Jacques G. Verly,Richard L. Delanoy	1990	Appearance-model-based representation and matching of 3-D objects.	ICCV	visu
476	ICCV	Toward the automatic generation of mathematical morphology procedures using predicate logic.	Hyonam Joo,Robert M. Haralick,Linda G. Shapiro	1990	Toward the automatic generation of mathematical morphology procedures using predicate logic.	ICCV	visu
477	ICCV	Multiple light source optical flow.	Robert J. Woodham	1990	Multiple light source optical flow.	ICCV	visu
478	ICCV	Description and reconstruction from image trajectories of rotational motion.	Harpreet S. Sawhney,John Oliensis,Allen R. Hanson	1990	Description and reconstruction from image trajectories of rotational motion.	ICCV	visu
479	ICCV	Towards a computational theory of model based vision and perception.	Haim Shvaytser	1990	Towards a computational theory of model based vision and perception.	ICCV	visu
480	ICCV	Dynamic integration of height maps into a 3-D world representation from range image sequences.	Minoru Asada,Masahiro Kimura,Yoshiaki Shirai	1990	Dynamic integration of height maps into a 3-D world representation from range image sequences.	ICCV	visu
481	ICCV	Pose determination from line-to-plane correspondences: existence condition and closed-form solutions.	Homer H. Chen	1990	Pose determination from line-to-plane correspondences: existence condition and closed-form solutions.	ICCV	visu
482	ICCV	Representation and the dimensions of shape deformation.	E. Saud	1990	Representation and the dimensions of shape deformation.	ICCV	visu
483	ICCV	A locally adaptive window for signal matching.	Masatoshi Okutomi,Takeo Kanade	1990	A locally adaptive window for signal matching.	ICCV	visu
484	ICCV	Region-based reconstruction of an indoor scene using an integration of active and passive sensing techniques.	Junichi Hoshino,Tetsuya Uemura,Isao Masuda	1990	Region-based reconstruction of an indoor scene using an integration of active and passive sensing techniques.	ICCV	visu
485	ICCV	Direct computation of qualitative 3D shape and motion invariants.	Daphna Weinshall	1990	Direct computation of qualitative 3D shape and motion invariants.	ICCV	visu
486	ICCV	Segmentation by minimal description.	Trevor Darrell,Stan Sclaroff,Alex Pentland	1990	Segmentation by minimal description.	ICCV	visu
487	ICCV	Analysis of facial images using physical and anatomical models.	Demetri Terzopoulos,Keith Waters	1990	Analysis of facial images using physical and anatomical models.	ICCV	visu
488	ICCV	On the sensitivity of geometric hashing.	W. Eric L. Grimson,Daniel P. Huttenlocher	1990	On the sensitivity of geometric hashing.	ICCV	visu
489	ICCV	Computing spatiotemporal surface flow.	Mark C. Allmen,Charles R. Dyer	1990	Computing spatiotemporal surface flow.	ICCV	visu
490	ICCV	Parallel structure recognition with uncertainty: coupled segmentation and matching.	Paul R. Cooper	1990	Parallel structure recognition with uncertainty: coupled segmentation and matching.	ICCV	visu
491	ICCV	A dynamic depth extraction method.	Terunori Mori,Masanobu Yamamoto	1990	A dynamic depth extraction method.	ICCV	visu
492	ICCV	Photometric motion.	Alex Pentland	1990	Photometric motion.	ICCV	visu
493	ICCV	Direct estimation of deformable motion parameters from range image sequence.	Masanobu Yamamoto,Pierre Boulanger,J.-Angelo Beraldin,Marc Rioux,Jacques Domey	1990	Direct estimation of deformable motion parameters from range image sequence.	ICCV	visu
494	ICCV	Temporally integrated surface reconstruction.	Joachim Heel	1990	Temporally integrated surface reconstruction.	ICCV	visu
495	ICCV	Viewpoint invariant recovery of visual surfaces from sparse data.	Robert L. Stevenson,Edward J. Delp	1990	Viewpoint invariant recovery of visual surfaces from sparse data.	ICCV	visu
496	ICCV	Uniqueness, the minimum norm constraint, and analog networks for optical flow along contours.	Atul K. Chhabra,Timothy A. Grogan	1990	Uniqueness, the minimum norm constraint, and analog networks for optical flow along contours.	ICCV	visu
497	ICCV	From uncertainty to visual exploration.	Peter Whaite,Frank P. Ferrie	1990	From uncertainty to visual exploration.	ICCV	visu
498	ICCV	Dynamic edge warping: experiments in disparity estimation under weak constraints.	Kim L. Boyer,Daniel M. Wuescher,Sudeep Sarkar	1990	Dynamic edge warping: experiments in disparity estimation under weak constraints.	ICCV	visu
499	ICCV	Image interpretation using multi-relational grammars.	Staffan Truvé	1990	Image interpretation using multi-relational grammars.	ICCV	visu
500	ICCV	The integration of region and edge-based segmentation.	Chen-Chau Chu,Jake K. Aggarwal	1990	The integration of region and edge-based segmentation.	ICCV	visu
501	ICCV	Surface shape reconstruction of an undulating transparent object.	Hiroshi Murase	1990	Surface shape reconstruction of an undulating transparent object.	ICCV	visu
502	ICCV	Feed-forward recovery of motion and structure from a sequence of 2D-lines matches.	Thierry Viéville,Olivier D. Faugeras	1990	Feed-forward recovery of motion and structure from a sequence of 2D-lines matches.	ICCV	visu
503	ICCV	Tracking and grouping 3D line segments.	Zhengyou Zhang,Olivier D. Faugeras	1990	Tracking and grouping 3D line segments.	ICCV	visu
504	ICCV	Detecting height from constrained motion.	Xueyin Lin,Zhigang Zhu	1990	Detecting height from constrained motion.	ICCV	visu
505	ICCV	Dynamic stereo with self-calibration.	Arun P. Tirumalai,Brian G. Schunck,Ramesh C. Jain	1990	Dynamic stereo with self-calibration.	ICCV	visu
506	ICCV	Integrated treatment of matching and measurement errors for robust model-based motion tracking.	David G. Lowe	1990	Integrated treatment of matching and measurement errors for robust model-based motion tracking.	ICCV	visu
507	ICCV	Third International Conference on Computer Vision, ICCV 1990. Osaka, Japan, 4-7 December, 1990, Proceedings		1990	Third International Conference on Computer Vision, ICCV 1990. Osaka, Japan, 4-7 December, 1990, Proceedings	ICCV	visu
508	ICCV	BONSAI: 3D object recognition using constrained search.	Patrick J. Flynn,Anil K. Jain	1990	BONSAI: 3D object recognition using constrained search.	ICCV	visu
509	ICCV	Simple method for computing 3D motion and depth.	David J. Heeger,Allan D. Jepson	1990	Simple method for computing 3D motion and depth.	ICCV	visu
510	ICCV	Qualitative route scene description using autonomous landmark detection.	Jiang Yu Zheng,Matthew Barth,Saburo Tsuji	1990	Qualitative route scene description using autonomous landmark detection.	ICCV	visu
511	ICCV	A photometric invariant and shape constraints at parabolic points.	Lawrence B. Wolff	1990	A photometric invariant and shape constraints at parabolic points.	ICCV	visu
512	ICCV	Geometrical learning from multiple stereo views through monocular based feature grouping.	Eric Thirion,Long Quan	1990	Geometrical learning from multiple stereo views through monocular based feature grouping.	ICCV	visu
513	ICCV	Scale detection and region extraction from a scale-space primal sketch.	Tony Lindeberg,Jan-Olof Eklundh	1990	Scale detection and region extraction from a scale-space primal sketch.	ICCV	visu
514	ICCV	Hypothesis testing: a framework for analysing and optimising Hough transform performance.	John Princen,John Illingworth,Josef Kittler	1990	Hypothesis testing: a framework for analysing and optimising Hough transform performance.	ICCV	visu
515	ICCV	Invariance-a new framework for vision.	David A. Forsyth,Joseph L. Mundy,Andrew Zisserman,Christopher M. Brown	1990	Invariance-a new framework for vision.	ICCV	visu
516	ICCV	Active surface reconstruction by integrating focus, vergence, stereo, and camera calibration.	A. Lynn Abbott,Narendra Ahuja	1990	Active surface reconstruction by integrating focus, vergence, stereo, and camera calibration.	ICCV	visu
517	ICCV	An estimation-theoretic framework for image-flow computation.	Ajit Singh	1990	An estimation-theoretic framework for image-flow computation.	ICCV	visu
518	ICCV	Active 3D object models.	Ruud M. Bolle,Andrea Califano,Rick Kjeldsen,Rakesh Mohan	1990	Active 3D object models.	ICCV	visu
519	ICCV	Collaboration between computer graphics and computer vision.	André Gagalowicz	1990	Collaboration between computer graphics and computer vision.	ICCV	visu
520	ICCV	The dynamic analysis of apparent contours.	Roberto Cipolla,Andrew Blake	1990	The dynamic analysis of apparent contours.	ICCV	visu
521	ICCV	About lacunarity, some links between fractal and integral geometry, and an application to texture segmentation.	Jacques Lévy Véhel	1990	About lacunarity, some links between fractal and integral geometry, and an application to texture segmentation.	ICCV	visu
522	ICCV	A Bayesian decision theoretic approach for adaptive goal-directed sensing.	Hsiang-Lung Wu,Alec Cameron	1990	A Bayesian decision theoretic approach for adaptive goal-directed sensing.	ICCV	visu
523	ICCV	MRF model-based segmentation of range images.	Anil K. Jain,Sateesha G. Nadabar	1990	MRF model-based segmentation of range images.	ICCV	visu
524	ICCV	Reconstructing 3D lines from a sequence of 2D projections: representation and estimation.	Yuh-Lin Chang,Jake K. Aggarwal	1990	Reconstructing 3D lines from a sequence of 2D projections: representation and estimation.	ICCV	visu
525	ICCV	Dynamic 3D models with local and global deformations: deformable superquadrics.	Demetri Terzopoulos,Dimitris N. Metaxas	1990	Dynamic 3D models with local and global deformations: deformable superquadrics.	ICCV	visu
526	ICCV	Multispectral constraints for optical flow computation.	Vishal Markandey,Bruce E. Flinchbaugh	1990	Multispectral constraints for optical flow computation.	ICCV	visu
527	ICCV	Understanding assembly illustrations in an assembly manual without any model of mechanical parts.	Shoujie He,Norihiro Abe,Tadahiro Kitahashi	1990	Understanding assembly illustrations in an assembly manual without any model of mechanical parts.	ICCV	visu
528	ICCV	Occlusion detection in early vision.	Peng-Seng Toh,Andrew K. Forrest	1990	Occlusion detection in early vision.	ICCV	visu
529	ICCV	A framework for adaptive scale space tracking solutions to problems in computational vision.	Gary Whitten	1990	A framework for adaptive scale space tracking solutions to problems in computational vision.	ICCV	visu
530	ICCV	An approach to color constancy using multiple images.	Masato Tsukada,Yuichi Ohta	1990	An approach to color constancy using multiple images.	ICCV	visu
531	ICCV	The effect of indexing on the complexity of object recognition.	W. Eric L. Grimson	1990	The effect of indexing on the complexity of object recognition.	ICCV	visu
532	ICCV	Compact image representation from multiscale edges.	Sifen Zhong,Stéphane Mallat	1990	Compact image representation from multiscale edges.	ICCV	visu
533	ICCV	Shape from texture: the homogeneity hypothesis.	Constantinos Marinos,Andrew Blake	1990	Shape from texture: the homogeneity hypothesis.	ICCV	visu
534	ICCV	3D structure from a monocular sequence of images.	Jean-Luc Jezouin,Nicholas Ayache	1990	3D structure from a monocular sequence of images.	ICCV	visu
535	ICCV	Sensitivity of the pose refinement problem to accurate estimation of camera parameters.	Rakesh Kumar,Allen R. Hanson	1990	Sensitivity of the pose refinement problem to accurate estimation of camera parameters.	ICCV	visu
536	ICCV	A theory of image matching.	Juyang Weng	1990	A theory of image matching.	ICCV	visu
537	ICCV	A model for the detection of motion over time.	Michael J. Black,P. Anandan	1990	A model for the detection of motion over time.	ICCV	visu
538	ICCV	Perceptual organization of occluding contours.	Lance R. Williams	1990	Perceptual organization of occluding contours.	ICCV	visu
539	ICCV	Reconstruction without discontinuities.	Stan Z. Li	1990	Reconstruction without discontinuities.	ICCV	visu
540	ICCV	Shape from contour: straight homogeneous generalized cones.	Fatih Ulupinar,Ramakant Nevatia	1990	Shape from contour: straight homogeneous generalized cones.	ICCV	visu
541	ICCV	Decomposition theory and transformations of visual directions.	Fredrik Bergholm	1990	Decomposition theory and transformations of visual directions.	ICCV	visu
542	ICCV	On the extensive reconstruction of Hough transform.	Hiroyasu Koshimizu,Munetoshi Numada	1990	On the extensive reconstruction of Hough transform.	ICCV	visu
543	ICCV	Segmentation of 3D range images using pyramidal data structures.	Bikash Sabata,Farshid Arman,Jake K. Aggarwal	1990	Segmentation of 3D range images using pyramidal data structures.	ICCV	visu
544	ICCV	Segmentation of optical flow and 3D data for the interpretation of mobile objects.	Aimé Meygret,Monique Thonnat	1990	Segmentation of optical flow and 3D data for the interpretation of mobile objects.	ICCV	visu
545	ICCV	Determining of camera rotation from vanishing points of lines on horizontal planes.	Shigang Li,Saburo Tsuji,Masakazu Imai	1990	Determining of camera rotation from vanishing points of lines on horizontal planes.	ICCV	visu
546	ICCV	Cooperative integration of multiple stereo algorithms.	Masaki Watanabe,Yuichi Ohta	1990	Cooperative integration of multiple stereo algorithms.	ICCV	visu
547	ICCV	Object recognition by a Hopfield neural network.	Nasser M. Nasrabadi,Wei Li,Chang Y. Choo	1990	Object recognition by a Hopfield neural network.	ICCV	visu
548	ICCV	Robust curve detection by temporal geodesics.	Dan Gutfinger,R. Nishimura,H. Doi,Jack Sklansky	1990	Robust curve detection by temporal geodesics.	ICCV	visu
549	ICCV	Simultaneous estimation of shape and reflectance maps from photometric stereo.	Hemant D. Tagare,Rui J. P. de Figueiredo	1990	Simultaneous estimation of shape and reflectance maps from photometric stereo.	ICCV	visu
550	ICCV	Computing the visual potential of an articulated assembly of parts.	Maha Sallam,John H. Stewman,Kevin W. Bowyer	1990	Computing the visual potential of an articulated assembly of parts.	ICCV	visu
551	ICCV	A computational model for face location.	Venu Govindaraju,Sargur N. Srihari,David B. Sher	1990	A computational model for face location.	ICCV	visu
552	ICCV	Uncertainty in interpretation of range imagery.	David M. Chelberg	1990	Uncertainty in interpretation of range imagery.	ICCV	visu
553	ICCV	Multiple widths yield reliable finite differences.	Margaret M. Fleck	1990	Multiple widths yield reliable finite differences.	ICCV	visu
554	ICCV	Extended structure and motion analysis from monocular image sequences.	Ning Cui,Juyang Weng,Paul R. Cohen	1990	Extended structure and motion analysis from monocular image sequences.	ICCV	visu
555	ICCV	Modeling the rim appearance.	W. Brent Seales,Charles R. Dyer	1990	Modeling the rim appearance.	ICCV	visu
556	ICCV	Multiresolution image acquisition and surface reconstruction.	Subhodev Das,Narendra Ahuja	1990	Multiresolution image acquisition and surface reconstruction.	ICCV	visu
557	ICCV	The 2.1-D sketch.	Mark Nitzberg,David Mumford	1990	The 2.1-D sketch.	ICCV	visu
558	ICCV	Qualitative 3-D shape reconstruction using distributed aspect graph matching.	Sven J. Dickinson,Alex Pentland,Azriel Rosenfeld	1990	Qualitative 3-D shape reconstruction using distributed aspect graph matching.	ICCV	visu
559	ICCV	Direct motion stereo: Recovery of observer motion and scene structure.	Brian Y. Hayashi,Shahriar Negahdaripour	1990	Direct motion stereo: Recovery of observer motion and scene structure.	ICCV	visu
560	ICCV	Surface reconstruction using deformable models with interior and boundary constraints.	Yuan-Fang Wang,Jih-Fang Wang	1990	Surface reconstruction using deformable models with interior and boundary constraints.	ICCV	visu
561	ICCV	Indexing via color histograms.	Michael J. Swain,Dana H. Ballard	1990	Indexing via color histograms.	ICCV	visu
562	ICCV	Terrain matching by analysis of aerial images.	Jeffrey J. Rodríguez,Jake K. Aggarwal	1990	Terrain matching by analysis of aerial images.	ICCV	visu
563	ICCV	Steerable filters for early vision, image analysis, and wavelet decomposition.	William T. Freeman,Edward H. Adelson	1990	Steerable filters for early vision, image analysis, and wavelet decomposition.	ICCV	visu
564	ICCV	Representing surface curvature discontinuities on curved surfaces.	Hiromi T. Tanaka,Daniel T. L. Lee	1990	Representing surface curvature discontinuities on curved surfaces.	ICCV	visu
565	ICCV	Detecting and localizing edges composed of steps, peaks and roofs.	Pietro Perona,Jitendra Malik	1990	Detecting and localizing edges composed of steps, peaks and roofs.	ICCV	visu
566	ICCV	Interpolating cubic spline contours by minimizing second derivative discontinuity.	Saeid Tehrani,Terry E. Weymouth,Brian G. Schunck	1990	Interpolating cubic spline contours by minimizing second derivative discontinuity.	ICCV	visu
567	ICCV	Detection of interest points using symmetry.	Daniel Reisfeld,Haim J. Wolfson,Yehezkel Yeshurun	1990	Detection of interest points using symmetry.	ICCV	visu
568	ICCV	Determining reflectance parameters using range and brightness images.	Katsushi Ikeuchi,Kosuke Sato	1990	Determining reflectance parameters using range and brightness images.	ICCV	visu
569	ICCV	The evolution and testing of a model-based object recognition system.	Joseph L. Mundy,Aaron Heller	1990	The evolution and testing of a model-based object recognition system.	ICCV	visu
570	ICCV	Epicardial motion and deformation estimation from coronary artery bifurcation points.	Chang Wen Chen,Thomas S. Huang	1990	Epicardial motion and deformation estimation from coronary artery bifurcation points.	ICCV	visu
571	ICCV	An approach to 3D scene reconstruction from noisy binocular image sequences using information fusion.	Lang Hong,Dragana Brzakovic	1990	An approach to 3D scene reconstruction from noisy binocular image sequences using information fusion.	ICCV	visu
572	ICCV	Calculating surface reflectance using a single-bounce model of mutual reflection.	Mark S. Drew,Brian V. Funt	1990	Calculating surface reflectance using a single-bounce model of mutual reflection.	ICCV	visu
573	ICCV	An efficient method for multiple-circle detection.	Xing Cao,Farzin Deravi	1990	An efficient method for multiple-circle detection.	ICCV	visu
574	ICCV	Estimation of shape, reflection coefficients and illuminant direction from image sequences.	Naoki Mukawa	1990	Estimation of shape, reflection coefficients and illuminant direction from image sequences.	ICCV	visu
575	ICCV	Curved inertia frames and the skeleton sketch: Finding salient frames of reference.	J. Brian Subirana-Vilanova	1990	Curved inertia frames and the skeleton sketch: Finding salient frames of reference.	ICCV	visu
576	ICCV	Segmentation as the search for the best description of the image in terms of primitives.	Ales Leonardis,Alok Gupta,Ruzena Bajcsy	1990	Segmentation as the search for the best description of the image in terms of primitives.	ICCV	visu
577	ICCV	Recovering 3D motion and structure from stereo and 2D token tracking cooperation.	Nassir Navab,Rachid Deriche,Olivier D. Faugeras	1990	Recovering 3D motion and structure from stereo and 2D token tracking cooperation.	ICCV	visu
578	ICCV	Detection of convex and concave discontinuous points in a plane curve.	Joon H. Han	1990	Detection of convex and concave discontinuous points in a plane curve.	ICCV	visu
579	ICCV	Feature matching for object localization in the presence of uncertainty.	Todd A. Cass	1990	Feature matching for object localization in the presence of uncertainty.	ICCV	visu
580	ICCV	Reconstructing line drawings from wings: the polygonal case.	George C. Stockman,Greg Chungmou Lee,Sei-Wang Chen	1990	Reconstructing line drawings from wings: the polygonal case.	ICCV	visu
581	ICCV	Segmenting curves into elliptic arcs and straight lines.	Paul L. Rosin,Geoff A. W. West	1990	Segmenting curves into elliptic arcs and straight lines.	ICCV	visu
582	ICCV	Shape from interreflections.	Shree K. Nayar,Katsushi Ikeuchi,Takeo Kanade	1990	Shape from interreflections.	ICCV	visu
583	ICCV	Similarity extraction and modeling.	Luc J. Van Gool,Johan Wagemans,J. Vandeneede,André Oosterlinck	1990	Similarity extraction and modeling.	ICCV	visu
584	ICCV	Local spatial frequency analysis of image texture.	John Krumm,Steven A. Shafer	1990	Local spatial frequency analysis of image texture.	ICCV	visu
585	ICCV	Direct recovery of motion and shape in the general case by fixation.	M. Ali Taalebinezhaad	1990	Direct recovery of motion and shape in the general case by fixation.	ICCV	visu
586	ICCV	Robustness of correspondence-based structure from motion.	R. Dutta,M. A. Snyder	1990	Robustness of correspondence-based structure from motion.	ICCV	visu
587	ICCV	Learning 3D object recognition strategies.	Bruce A. Draper,Edward M. Riseman	1990	Learning 3D object recognition strategies.	ICCV	visu
588	ICCV	Omni-directional stereo for making global map.	Hiroshi Ishiguro,Masashi Yamamoto,Saburo Tsuji	1990	Omni-directional stereo for making global map.	ICCV	visu
589	ICCV	A new transform for curve detection.	Ping Liang	1990	A new transform for curve detection.	ICCV	visu
590	IEEE Visualization	Dynamic Graphics for Network Visualization.	Richard A. Becker,Stephen G. Eick,E. O. Miller,Allan R. Wilks	1990	Network data involves statistics that are associated with the nodes or links in a network. We describe several dynamic graphics tools for visualizing such data.	IEEE Visualizat	visu
591	IEEE Visualization	Shape Coding of Multidimensional Data on a Microcomputer Display.	J. Beddow	1990	The visual representation of data from complex systems, whether databases, measured scientific data, or simulation output, holds the promise of discovering patterns in the data that will increase its management efficiency while revealing relationships invisible to numeric methods. In this paper we present a simple and flexible method of shape coding for higher dimensional data sets that allows the database operator or discipline scientist quick access to promising patterns within and among records or samples. The example used is a thirteen parameter set of solar wind, magnetosphere, and ground observation data collected hourly for twenty-one days in 1976.	IEEE Visualizat	visu
592	IEEE Visualization	Visualizing Computer Memory Architectures.	Bowen Alpern,Larry Carter,Ted Selker	1990	The Memory Hierarchy Framework is a conceputal model together with a visual language for using the model. The model is more faithful to the structure of computers than the Von Neumann and Turing models. It addresses the issues of data movement and exposes and unifies storage mechanisms such as cache, translation lookaside buffers, main memory, and disks. The visual language presents the details of a computer's memory hierarchy in a concise drawing composed of rectangles and connecting segments. Using this framework, we have improved the performance of a matrix multiplication algorithm by more than an order of magnitude. We believe the framework gives insight into computer architecture and performance bottlenecks by making effective use of human visual abilities.	IEEE Visualizat	visu
593	IEEE Visualization	Design of an End-User Data Visualization System.	D. L. Brittain,J. Aller,M. Wilson,S. L. C. Wang	1990	We describe the architecture of an end-user visualization system that supports interactive analysis of 3D scalar and vector data in a heterogeneous hardware environment. The system supports a variety of visualization methods having applicability in disciplines such as computational fluid dynamics, earth and space sciences, and finite-element analysis. We discuss general concerns with current visualization methods and present how our approach simplifies the visualization process.	IEEE Visualizat	visu
594	IEEE Visualization	FAST: A Multi-Processed Environment for Visualization of Computational Fluid Dynamics.	Gordon V. Bancroft,Fergus Merrit,Todd Plessel,P. G. Kelaita,R. K. McCabe,Al Globus	1990	Three-dimensional, unsteady, multi-zoned fluid dynamics simulations over full scale aircraft is typical of problems being computed at NASA Ames' Numerical Aerodynamic Simulation (NAS) facility on CRAY2 and CRAY-YMP supercomputers. With multiple processor workstations available in the 10-30 Mflop range, we feel that these new developments in scientific computing warrant a new approach to the design and implementation of analysis tools. These larger, more complex problems create a need for new visualization techniques not possible with the existing software or systems available as of this writing and these visualization techniques will change as the supercomputing environment, and hence the scientific methods employed, evolve even further.Visualization of computational aerodynamics requires flexible, extensible, and adaptable software tools for performing analysis tasks. Flexible means the ability to handle a diverse range of problems. Extensible means the ability to interact at all levels of the software hierarchy, either through existing built-in functionality or through the implementation of custom plug-in modules. Adaptable means the ability to adapt to new software and hardware configurations through the use of modular structured programming methods, a graphics library standard, and the use of common network communication protocols (like UNIX sockets) for the distribution of processing.This paper discusses FAST (Flow Analysis Software Toolkit), an implementation of a software system for fluid mechanics analysis that is based on this approach.	IEEE Visualizat	visu
595	IEEE Visualization	Interdisciplinary Visualization: Lessons Learned at NCSA.	D. J. Cox	1990	Interdisciplinary Visualization: Lessons Learned at NCSA.	IEEE Visualizat	visu
596	IEEE Visualization	A Graphical Interface for Robotic Remediation of Underground Storage Tanks.	B. K. Christensen,L. M. Desjarlais	1990	Sensor-rich, intelligent robots that function with respect to models of their environment have significant potential to reduce the time and cost for the cleanup of hazardous waste while increasing operator safety. An animated graphical interface allows operators to easily and safely program such robots. Sandia National Laboratories is performing experimental investigations into the application of intelligent robot control technology to the problem of removing waste stored in tanks. This paper describes the experimental environment employed at Sandia with particular attention to the hardware and software control environment, and the graphical interface. Intelligent system control is achieved through the integration of extensive geometric and kinematic world models with realtime sensor based control. All operator interactions with the system are through fully animated, graphical representations which validate all operator commands before execution to provide for safe operation. Sensing is used to add information to the robot system's world model and to allow sensor based servo control during selected operations. The results of a first Critical Features Test are reported and the potential for applying advanced intelligent control concepts to the removal of waste in storage tanks is discussed.	IEEE Visualizat	visu
597	IEEE Visualization	Visualization of Non-Linear Engineering FEM Analysis in Manufacturing.	G. W. Edgar	1990	Visualization of Non-Linear Engineering FEM Analysis in Manufacturing.	IEEE Visualizat	visu
598	IEEE Visualization	Rendering and Managing Spherical Data with Sphere Quadtrees.	G. Fekete	1990	Most databases for spherically distributed data are not structured in a manner consistent with their geometry. As a result, such databases possess undesirable artifacts, including the introduction of tears in the data when they are mapped onto a flat file system. Furthermore, it is difficult to make queries about the topological relationship among the data components without performing real arithmetic. The sphere quadtree (SQT), which is based on the recursive subdivision of spherical triangles obtained by projecting the faces of an icosahedron onto a sphere, eliminates some of these problems. The SQT allows the representation of data at multiple levels and arbitrary resolution. Efficient search strategies can be implemented for the selection of data to be rendered or analyzed by a specific technique. Furthermore, sphere quadtrees offer significant potential for improving the accuracy and efficiency of spherical surface rendering algorithms as well as for spatial data management and geographic information systems. Most importantly, geometric and topological consistency with the data is maintained.	IEEE Visualizat	visu
599	IEEE Visualization	A Numerical Method for Rendering Spherical Reflections.	David P. Dobkin,E. S. Panduranga,M. Zhu	1990	A Numerical Method for Rendering Spherical Reflections.	IEEE Visualizat	visu
600	IEEE Visualization	Personal Visualization System: Applications in Research and Engineering.	Q. E. Docecek,K. Moorjani,B. F. Kim,D. G. Tilley,Thomas S. Denney Jr.	1990	This paper describes an innovative personal visualization system and its application to several research and engineering problems. The system bridges both hardware and software components to permit a user to graphically describe a visualization problem to the computer; thereby reducing program development time to a few hours. Low-cost visualization is achieved using PC-based software that can either be executed on the PC or drive graphic workstations for high resolution displays. In either case, supercomputer computation rates are made available to the visualization process. On PC's this is done with one or more PiP plug in cards, each of which is capable of 100 million floating point operations per second. On workstations this is done with the QUEN&trade; (trademark of Interstate Electronics Corporation, Anaheim, California) array processor.	IEEE Visualizat	visu
601	IEEE Visualization	Visualization of Irregular Multivariate Data.	Thomas A. Foley,David A. Lane	1990	Scientific data is often sampled at irregular spatial locations because of physical constraints, yet most visualization software applies only to gridded or regular data. We will discuss effective techniques for representing scalar and vector valued functions that interpolate to irregularly located data. Special attention will be given to the situations where the sampling domain is a 2D plane, a 3D volume, or a closed 3D surface. The globally defined interpolants can be evaluated on a fine regular grid and they can then be visualized using conventional techniques. Triangular and tetrahedral based visualization techniques are also presented.	IEEE Visualizat	visu
602	IEEE Visualization	Factors Inducing Periodic Breathing in Humans Blunted Hypoxic Sensitivity.	W. E. Fordyce,J. J. Ventrella	1990	Factors Inducing Periodic Breathing in Humans Blunted Hypoxic Sensitivity.	IEEE Visualizat	visu
603	IEEE Visualization	Automatic Illustration of 3D Geometric Models: Surfaces.	D. Dooley,Michael F. Cohen	1990	Computer-generated models are becoming increasingly complex in structure, and therefore more difficult to display within single concise images. To better convey to the viewer overall shape information about the model, the advantages of line drawings and shaded surface renderings need to be used cooperatively. A system based on the techniques of traditional illustrators is described for automatically generating illustrations of complex three dimensional models. The system relies upon a richer set of display primitives, which are also outlined. Algorithmic details for emphasizing significant model components are discussed, and some preliminary results are presented.	IEEE Visualizat	visu
604	IEEE Visualization	A Journey into the Fourth Dimension.	Y. Ke,E. S. Panduranga	1990	This paper shows that by a simple (one way) mapping from quaternions to complex numbers, the problem of generating a 4D Mandelbrot set by iteration of a quadratic function in quaternions can be reduced to iteration of the same function in the complex domain, and thus, the function values in 4D can be obtained by a simple table lookup. The computations are cut down by an order. Simple ways of displaying the fractal without shading and also of fast raytracing such a fractal using the table so generated are discussed. Further speed up in raytracing can be achieved by estimates of a distance of a point from the Mandelbrot set. Animation is a key factor in visualizing 4D objects. Three types of animation are attempted: (a) translation in 4D, (b) rotation in 4D and (c) fly-through in 3D.	IEEE Visualizat	visu
605	IEEE Visualization	Visualization and Three-Dimensional Image Processing of Positron Emission.	Nahum D. Gershon	1990	Visualization and Three-Dimensional Image Processing of Positron Emission.	IEEE Visualizat	visu
606	IEEE Visualization	Methods for Surface Interrogation.	Hans Hagen,Thomas Schreiber,Ernst Gschwind	1990	The geometric modeling of free-form curves and surfaces is of a central importance for sophisticated CAD systems. Apart from the pure construction of these curves and surfaces, the analysis of their quality is equally important in the design process. In the scope of this article, we will discuss various visualization techniques, which have the goal of identifying unwanted curvature regions (inflection points, dents, ...) interactively on screen.	IEEE Visualizat	visu
607	IEEE Visualization	Techniques for Visualizing Fermat's Last Theorem.	Andrew J. Hanson,P. A. Heng,B. C. Kaplan	1990	Techniques for Visualizing Fermat's Last Theorem.	IEEE Visualizat	visu
608	IEEE Visualization	Interactive Visualization of Quaternion Julia Sets.	John C. Hart,Louis H. Kauffman,Daniel J. Sandin	1990	The first half of a two-step quaternion Julia set visualization system is described. This step uses a quaternion square root function to adapt the classic inverse iteration algorithm to the quaternions. The augmented version produces a 3-D Julia set defined by a point cloud that can be interactively manipulated on a graphics workstation. Several cues are assigned to the point cloud to increase depth perception. Finally, a short theorem is proven that extends the domain of the inverse iteration method to a rotational family of quadratic quaternion Julia sets.	IEEE Visualizat	visu
609	IEEE Visualization	Surface Representations of Two- and Three-Dimensional Fluid Flow Topology.	James Helman,Lambertus Hesselink	1990	We discuss our work using critical point analysis to generate representations of the vector field topology of numerical flow data sets. Critical points are located and characterized in a two-dimensional domain, which may be either a two-dimensional flow field or the tangential velocity field near a three-dimensional body. Tangent curves are then integrated out along the principal directions of certain classes of critical points. The points and curves are linked to form a skeleton representing the two-dimensional vector field topology.When generated from the tangential velocity field near a body in a three-dimensional flow, the skeleton includes the critical points and curves which provide a basis for analyzing the three-dimensional structure of the flow separation. The points along the separation curves in the skeleton are used to start tangent curve integrations to generate surfaces representing the topology of the associated flow separations.	IEEE Visualizat	visu
610	IEEE Visualization	Wide-band Relativistic Doppler Effect Visualization.	Ping-Kang Hsiung,Robert H. Thibadeau,Christopher B. Cox,Robert H. P. Dunn,M. Wu,P. A. Olbrich	1990	One of the most visible aspects of special relativity is the relativistic Doppler effect --- the dependence of observed radiation wavelengths upon the velocity of the source and the viewing conditions.In this paper, we present a flexible and efficient method to simulate the Doppler shift. This new method has the following features:&bull; Surface properties and light composition are represented by splines as functions of wavelength. The entire electromagnetic (EM) spectrum can therefore be represented efficiently.&bull; Doppler shift and shading operations are performed through the manipulation of spline coefficients. The evaluation of the spline functions is carried out at the end of each shading loop to generate the display R, G, B values.This method simplifies the management of the shift and reduces the calculations necessary to maintain a spectral description of lights and surfaces.The study of astrophysical phenomenon, which are being color-shifted by individual recession velocity and by the expansion of the universe, requires the use of knowledge about the Doppler effect. Our simulations may contribute visual insight and understanding that enhances such knowledge.	IEEE Visualizat	visu
611	IEEE Visualization	Visualization of the Information Age.	L. Herr	1990	Visualization of the Information Age.	IEEE Visualizat	visu
612	IEEE Visualization	Superposing Images with Shadow Casting.	P. C. Hsu,John Staudhamer	1990	Algorithms are presented to render dynamic foreground images with shadows cast on static background scenes. The algorithms are based on the ray-tracing technique. We can produce complex and shaded animation with a lower cost. The target display device for these algorithms is a two-channel display in which one is for the background and the other is for the foreground.	IEEE Visualizat	visu
613	IEEE Visualization	The VIS-5D System for Easy Interactive Visualization.	William L. Hibbard,David A. Santek	1990	The VIS-5D System for Easy Interactive Visualization.	IEEE Visualizat	visu
614	IEEE Visualization	Parallel Coordinates: A Tool for Visualizing Multi-dimensional Geometry.	Alfred Inselberg,B. Dimsdale	1990	A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a non-projective mapping between N-Dimensional and 2-Dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point &larr; &rarr; line duality when N = 2 generalizes to lines and hyperplanes enabling the representation of polyhedra in RN. The representation of a class of convex and non-convex hypersurfaces is discussed together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.	IEEE Visualizat	visu
615	IEEE Visualization	The Application of Transport Theory to Visualization of 3D Scalar Data Fields.	W. Kruger	1990	This paper describes a visualization model for 3D scalar data fields based on linear transport theory. The concept of virtual particles for the extraction of information from data fields is introduced. The role of different types of interaction of the data field with those particles such as absorption, scattering, source and color shift are discussed and demonstrated.Special attention is given to possible tools for the enhancement of interesting data features. Random texturing can provide visual insights as to the magnitude and distribution of deviations of related data fields, e.g., originating from analytic models and measurements, or in the noise content of a given data field. Hidden symmetries of a data set can often be identified visually by allowing it to interact with a preselected beam of physical particles with the attendant appearance of characteristic structural effects such as channeling.	IEEE Visualizat	visu
616	IEEE Visualization	Volume Visualization in Cell Biology.	Arie E. Kaufman,Roni Yagel,Reuven Bakalash,I. Spector	1990	Living cells are 3D objects with a complex inner structural organization. Understanding this organization and its relation to biological function constitutes a major challenge for cell biologists. This paper discusses the special properties of volumetric cell data (e.g., noise, discontinuity, raggedness) and the particular difficulties encountered when trying to visualize them in 3D. We describe some of the solutions we adopted, specifically in surface discrimination and shading. These solutions have been implemented as an integral part of the BioCube system, an environment for volume visualization of cellular structures. The paper presents volume visualization results for the actin cytoskeleton of single cells.	IEEE Visualizat	visu
617	IEEE Visualization	Interpreting a 3D Object from a Rough 2D Line Drawing.	Del Lamb,Amit Bandopadhay	1990	Visualizing the third dimension while designing 3D objects is an awkward process in mechanical CAD systems, given the current state of the art. We describe a computer system that automatically constructs the shape of a 3D object from a single 2D sketch. The method makes it convenient to create and manipulate 3D objects and is thus seen as an intelligent user interface for CAD and 3D graphics applications. The proposed technique is built on well known results in image analysis. These results are applied in conjunction with some perceptual rules to determine 3D structure from a rough line drawing. The principles are illustrated by a computer implementation that works in a nontrivial object domain.	IEEE Visualizat	visu
618	IEEE Visualization	Moving Iconic Objects in Scientific Visualization.	G. David Kerlick	1990	The visualization and interpretation of multidimensional data in space can be substantially enhanced by the introduction of independently moving visual objects. These bird-oid objects or boids [1], derive from: (1) icons which are geometric objects whose shape and appearance are related to the field variables, (2) 3-dimensional cursors by which a user interactively picks a point in space, (3) particle traces, which are numerically integrated trajectories in space, (4) moving frames of vectors along space curves, and (5) actors which are programming objects which can create and destroy instances of themselves, act according to internal logic, and communicate with each other and with a user. A software prototype in the C++ language has been developed which demonstrates some of the capabilities of these objects for the visualization of scalar, vector, and tensor fields defined over finite elements or finite volumes. Visualization using boids requires fewer rendered graphical primitives, allows a higher degree of interactivity, and permits automated knowledge navigation amid data which is organized spatially.	IEEE Visualizat	visu
619	IEEE Visualization	Visualization of Free-Form Volumes.	D. Lasser	1990	An algorithm is presented which creates planar as well as arbitrarily curved sections of free form volumes. The algorithm itself can be used as a subroutine for algorithms which are able to perform more general intersections of free form volumes, e.g. boolean operations on two free form volumes.	IEEE Visualizat	visu
620	IEEE Visualization	Techniques for Visualizing 3-Dimensional Manifolds.	Michael J. Laszlo	1990	Computer graphics has long been concerned with representing and displaying surfaces in 3-dimensional space R3. We address the questions of representation and display in a higher dimensional setting, specifically, that of 3-manifolds immersed in R4. We describe techniques for visualizing the cross-section surfaces of a 3-manifold formed by a cutting hyperplane. The manifold is first triangulated, so that the cross-section may be computed on a per tetrahedron basis. The triangulated manifold is stored in a data structure which efficiently supports calculation of curvature. We expect the techniques, which we have implemented on the Personal IRIS, will support a highly-interactive system when implemented on a fine-grain parallel computer such as the Connection Machine.	IEEE Visualizat	visu
621	IEEE Visualization	Exploring N-Dimensional Databases.	J. LeBlanc,Matthew O. Ward,N. Wittels	1990	The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.	IEEE Visualizat	visu
622	IEEE Visualization	Interactive Investigations of Fluid Mechanics Data Sets.	S. M. Legensky	1990	Scientific Visualization techniques provide convenient means to graphically represent various types of experimental and computational data. Fluid mechanics data tends to be challenging to visualize. FIELDVIEW is a visual analysis tool designed to facilitate the interactive investigation of these data sets by providing an easy-to-use interface to the flow field data. Operating on NASA Plot 3D format data, FIELDVIEW computes scalar and vector flow quantities and displays them using a variety of representations including animation. An interactive viewing interface allows free motion around the data under study to allow the researcher to locate and study the interesting flow features of three-dimensional fluid dynamic data.	IEEE Visualizat	visu
623	IEEE Visualization	Classifying Visual Knowledge Representations: A Foundation for Visualization Research.	Gerald L. Lohse,Henry H. Rueter,Kevin Biolsi,Neff Walker	1990	This research is an exploratory effort to classify visual representations into homogeneous clusters. Our goal is to determine the type of knowledge conveyed by various visual representations. We collected hierarchical sorting data from twelve subjects. Five principal groups of visual representations emerged from a cluster analysis of sorting data: graphs and tables, maps, diagrams, networks, and icons. Two dimensions appear to distinguish these clusters: the amount of spatial information and cognitive processing effort. Our future research will continue to identify properties that characterize knowledge expressed with visual representations.	IEEE Visualizat	visu
624	IEEE Visualization	Animation Techniques for Chain-Coded Objects.	Anthony J. Maeder	1990	Chain coding is a common boundary representation for objects used in image analysis. When animating digital image sequences for visualization, it is often convenient to retain this representation. Methods for scaling, rotation and elastic deformation of objects based solely on chain code elements are discussed here. Quantized methods transform groups of chain code elements into other groups while incremental methods construct the transformed chain code element by element.	IEEE Visualizat	visu
625	IEEE Visualization	A Procedural Interface for Volume Rendering.	J. L. Montine	1990	This paper presents a simple, procedural interface for doing volume rendering. The interface is built upon three types of objects: volumes, which contain the data to be visualized, environments, which set up viewing and lighting, and image objects, which convert results to a user definable format. A volume is rendered against a particular environment with the results sent to an image object for conversion. By defining volume qualities such as color, opacity, and gradient in terms of user definable transfer functions, the rendering process is made independent of the data set's underlying representation.	IEEE Visualizat	visu
626	IEEE Visualization	Techniques for the Interactive Visualization of Volumetric Data.	Gregory M. Nielson,Bernd Hamann	1990	Some ideas and techniques for visualizing volumetric data are introduced. The methods presented are quite different from either volume rendering techniques or surface contour methods. All of the methods are conceptually quite simple and rather easy to implement. In addition, they are intended to be used interactively.	IEEE Visualizat	visu
627	IEEE Visualization	Ray Traced Scalar Fields with Shaded Polygonal Output.	R. J. Meyers,M. B. Stephenson	1990	An algorithm is presented for rendering scalar field data which reduces rendering times by as much as two orders of magnitude over traditional full resolution images. Less than full resolution sampling of the scalar field is performed using a fast ray tracing method. The sampling grid points are output as a set of screen based Gouraud shaded polygons which are rendered in hardware by a graphics workstation. A gradient based variable resolution algorithm is presented which further improves rendering speed. Several examples are presented.	IEEE Visualizat	visu
628	IEEE Visualization	Visualizing a Scalar Field on an N-dimensional Lattice.	Ted Mihalisin,E. Grawlinksi,John Timlin,J. Schwegler	1990	A new hierarchical method of plotting is presented which allows one to interactively view millions of data points with up to 10 independent variables.	IEEE Visualizat	visu
629	IEEE Visualization	Extracting Geometric Models Through Constraint Minimization.	James V. Miller,David E. Breen,Michael J. Wozny	1990	Geometric models that represent the features in a greyscale image allow for alternative visualizations of the features. These alternatives can lead to a greater understanding of the extents and interrelationships of the features in the image. We present a technique that extracts the geometric nature of a feature by constraining a known geometric model to conform to the characteristics of the feature. The constraints embody local properties of simple polygons and the nature of the relationship between noise and the features in the image. By minimizing these constraints we are able to deform our initial model to fit the feature.	IEEE Visualizat	visu
630	IEEE Visualization	Visualization of Scalar Data Defined on a Structured Grid: Applications to Petroleum Research.	J. L. Pajon,V. B. Tran	1990	We will describe in this article some simple visualization techniques that may be used to explore dynamic 3D scalar fields in an interactive way. Scalar data are assumed to have been already computed, and graphic manipulations are done afterwards on a graphics workstation. Structured grids (finite difference grids) are used, leading to an easy and fast exploration of the interior of a volume. Smooth animation and simultaneous visualization of two or three scalar fields are also described. We have tested our methods on various types of data issuing from different fields of petroleum engineering, i.e. oil reservoir simulation, geophysics, geology and combustion engine simulations.A demonstration videotape is available.	IEEE Visualizat	visu
631	IEEE Visualization	Spline-Based Color Sequences for Univariate, Bivariate and Trivariate Mapping.	Binh Pham	1990	Colors are often used for displaying data in order to reveal their characteristics and to facilitate the task of data analysis. Much research and experimental work has been carried out to identify principles for making effective use of color and to find good computational models for constructing color schemes for representing data values. Most existing color schemes are based on simple geometric models which facilitates the computation, but do not allow sufficient flexibility for manipulating colors in a sequence. This paper introduces alternative models which uses B-spline curves and surfaces for generating color sequences for univariate, bivariate and trivariate mapping. The models provide more flexibility for interactive modification of the range of color locally in order to obtain customized color schemes for a particular map.	IEEE Visualizat	visu
632	IEEE Visualization	An Interpersonal Multimedia Visualization System.	P. Phillips	1990	An Interpersonal Multimedia Visualization System.	IEEE Visualizat	visu
633	IEEE Visualization	Real-World Applications of Visualization Solutions.	D. A. Prawel	1990	Visual Data Analysis (VDA) methods have found application in aerospace engineering research. VDA is being used to develop new non-destructive evaluation testing techniques for graphite epoxy composites by providing new insights into stress waves propagating through them. Visual Data Analysis was used to analyze stress wave propagation, determine the origin of an unexplained wave distortion, and create a theoretical model to eliminate the distortion utilizing mathematical modeling.	IEEE Visualizat	visu
634	IEEE Visualization	A Methodology for Scientific Visualization: Choosing Representations based on Natural Scene Paradigm.	Philip K. Robertson	1990	A Methodology for Scientific Visualization: Choosing Representations based on Natural Scene Paradigm.	IEEE Visualizat	visu
635	IEEE Visualization	Accurate Display of Tensor Product Isosurfaces.	Alyn P. Rockwood	1990	A general method for rendering isosurfaces of multivariate rational and polynomial tensor products is described. The method is robust up to degree 15, handling singularities without introducing spurious rendering artifacts. It is based on finding real roots of a polynomial in Bernstein form. This makes it particularly suitable for parallel and pipelined processing.It is envisioned that the tensor products will be used as approximants or interpolants for empirical data or scalar fields. An interpolation scheme is given as an example.	IEEE Visualizat	visu
636	IEEE Visualization	ierarchical Triangulation Using Terrain Features.	Lori L. Scarlatos,Theo Pavlidis	1990	ierarchical Triangulation Using Terrain Features.	IEEE Visualizat	visu
637	IEEE Visualization	Volume Microscopy of Biological Specimens Based on Nonconfocal Imaging Techniques.	Stephen L. Senft,V. J. Argio,W. L. van Zandt	1990	Volume Microscopy of Biological Specimens Based on Nonconfocal Imaging Techniques.	IEEE Visualizat	visu
638	IEEE Visualization	Applying Space Subdivision Techniques to Volume Rendering.	Kalpathi R. Subramanian,Donald S. Fussell	1990	We present a new ray-tracing algorithm for volume rendering which is designed to work efficiently when the data of interest is distributed sparsely through the volume. A simple preprocessing step identifies the voxels representing features of interest. Frequently this set of voxels, arbitrarily distributed in three dimensional space, is a small fraction of the original voxel grid. A mediancut space partitioning scheme, combined with bounding volumes to prune void spaces in the resulting search structure, is used to store the voxels of interest in a k-d tree. The tree is then efficiently ray-traced to render the voxel data. The k-d tree is view independent and can be used for animation sequences involving changes in positions of the viewer or positions of lights. We have applied this search structure to render voxel data from MRI, CAT Scan and electron density distributions.	IEEE Visualizat	visu
639	IEEE Visualization	Scattered Data Interpolation Tools in a Microcomputer Visualization Environment.	K. Voegde	1990	Scattered Data Interpolation Tools in a Microcomputer Visualization Environment.	IEEE Visualizat	visu
640	IEEE Visualization	A Problem-oriented Classification of Visualization Techniques.	Stephen Wehrend,Clayton Lewis	1990	Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. This paper describes an approach to this problem based on a classification of visualization techniques that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representation into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods.	IEEE Visualizat	visu
641	IEEE Visualization	A System for Three-Dimensional Acoustic Visualization in a Virtual Environment Workstation.	E. M. Wenzel,S. S. Fisher,P. K. Stone,S. H. Foster	1990	This paper describes the real time acoustic display capabilities developed for the VIrtual Environment Workstation (VIEW) project at NASA-Ames Research Center. The acoustic display is capable of generating localized acoustic cues in real time over headphones. An auditory symbology, a related collection of representational auditory objects or icons, can be designed using ACE, the Auditory Cue Editor, which links both discrete and continuously-varying acoustic parameters with information or events in the display. During a given display scenario, the symbology can be dynamically co-ordinated in real time with three-dimensional visual objects, speech, and gestural displays. The types of displays feasible with the system range from simple warnings and alarms to the acoustic representation of multidimensional data or events.	IEEE Visualizat	visu
642	IEEE Visualization	Displaying Voxel-Based Objects According to Their Qualitative Shape Synthesis.	Yaser Yacoob	1990	The use of qualitative shape synthesis for the display of 3-D binary objects, is presented. Instead of the commonly used shading approaches, we propose that intrinsic shape features of the object(s) be the means for the display. The proposed approach is applicable to multi-object scenes and to outdoor scenery as well. It makes use of a new method, the diffusion process, that simulates diffusion of particles within the interior of a 3-D discrete object. Starting with initial concentrations of particles at the boundary-voxels, the diffusion procedure simulates the propagation of these particles inwards. Boundary voxels of the object are colored according to the concentration of particles obtained by suspending the diffusion process. This method assists shape characterization by providing a qualitative measure of boundary curvature and was used in achieving display of a variety of voxel-based objects. Examples of the use of this approach on synthetic, terrain, and range data, are provided.	IEEE Visualizat	visu
643	IEEE Visualization	A Three-Dimensional/Stereoscopic Display and Model Control System for Great Lakes Forecasts.	C. J. Yen,K. W. Bedford,J. L. Kempf,R. E. Marshell	1990	In a forecasting system for the Great Lakes, the data generated by the three-dimensional numerical model is visualized by a 3D/stereoscopic display module. The module consists of a control panel and a display window with the capability of interactively rendering the results. The event scheduling for scenario testing to steer the 3D numerical model is achieved by a similar panel. These panels set up the simulation and control the data flow between the graphics workstation and supercomputer. Many rendering methods, stereo imagery and animation are incorporated to display the results. Interaction between the user, the workstation and the supercomputer allows steering of the simulation and tracing of the simulation output. Distributed software for post-processing and volume rendering are also used to enhance the representation. Further enhancement will provide operational predictions of Great Lakes physics and transport features with these visualization methods and control algorithms.	IEEE Visualizat	visu
644	IEEE Visualization	Proceedings IEEE Visualization'90.	Arie E. Kaufman	1990	Proceedings IEEE Visualization'90.	IEEE Visualizat	visu
645	ICDE	Data Sharing in a Large Heterogeneous Environment.	Rafael Alonso,Daniel Barbará,Steve Chon	1991	The issues involved in sharing information among a large collection of independent databases is explored. Some of the distinguishing features that characterize such large-scale environments (such as size, autonomy, and heterogeneity) are discussed. A multistep information sharing process for those systems is outlined and an architecture supporting that exchange is presented. A detailed description of a working prototype based on this architecture and some measurements of its performance are provided	ICDE	database
646	ICDE	Performance Characteristics of Protocols With Ordered Shared Locks.	Divyakant Agrawal,Amr El Abbadi,A. E. Lang	1991	A family of locking-based protocols is analyzed that use a novel mode of locks called ordered sharing. Using a centralized database simulation model, it is demonstrated that these protocols exhibit comparable performance to that of traditional locking-based protocols when data contention is low and exhibit superior performance when data contention is high. It is shown that the performance of these protocols improves as physical resources become more plentiful. This is particularly significant since two-phase locking degrades due to data and not resource contention. Thus, introducing additional resources improves the performance of the proposed protocols while it does not benefit two-phase locking significantly	ICDE	database
647	ICDE	Object Versioning in Ode.	Rakesh Agrawal,S. Buroff,Narain H. Gehani,Dennis Shasha	1991	In designing the versioning facility in Ode, a few but semantically sound and powerful concepts are introduced that allow implementation of a wide variety of paradigms. Some of the salient features of these versioning facilities are the following: (1) object versioning is orthogonal to type; (2) reference to an object can be bound statically to a specific version of the object or dynamically to whatever is its latest version; and (3) both temporal as well as derived-from relationships between versions of an object are maintained automatically. These facilities have been incorporated seamlessly into Ode's database programming language, O++. The new language constructs are powerful enough to make O++ a suitable platform for implementing a variety of versioning paradigms and application-specific systems	ICDE	database
648	ICDE	ESQL: A Query Language for the Relation Model Supporting Image Domains.	Rafiul Ahad,Amit Basu	1991	It is shown that by simply extending the relational data model to support image domains, the model becomes rich enough for many advanced applications. Extensions to the relational algebra and the relational calculus are developed to exploit the semantics of image domains. The extended calculus is incorporated in the query language ESQL, which is a strict superset of the structured query language (SQL). A technique to implement ESQL using a preprocessor to SQL is shown. A noteworthy observation is that it is possible to incorporate multirelations without any modifications to the storage structures and data definition language of SQL. It is also possible to support queries of multirelations in ESQL without modifying the features of SQL in any way as far as traditional data manipulation is concerned	ICDE	database
649	ICDE	Title, General Co-Chairpersons' Message, Program Co-Chairpersons' Message, Committees, Reviewers, Table of Contents, Author Index.		1991	Title, General Co-Chairpersons' Message, Program Co-Chairpersons' Message, Committees, Reviewers, Table of Contents, Author Index.	ICDE	database
650	ICDE	An Indexing Technique for Object-Oriented Databases.	Elisa Bertino	1991	An Indexing Technique for Object-Oriented Databases.	ICDE	database
651	ICDE	Constraint-Based Reasoning in Deductive Databases.	Jiawei Han	1991	Constraint-based reasoning in deductive databases is studied, with the focus on set-oriented, constraint-based processing of functional linear recursions. A technique is developed which compiles a functional linear recursion into chain or bounded forms and analyzes efficient processing of the compiled chains based on different kinds of constraints. It is shown that rule constraints should be compiled together with the rectified recursions; finiteness constraints and monotonicity constraints should be used in the analysis of finite evaluability and termination; and query constraints should be pushed into the compiled chains, when possible, for efficient set-oriented evaluation. Constraint-based processing can be enhanced by dynamic constraint enforcement in query evaluation. The method is illustrated using a typical traversal recursion problem. It is concluded that the principles developed are useful for a large set of deductive database application problems	ICDE	database
652	ICDE	Divide and Conquer: A Basis for Augmenting a Conventional Query Optimizer with Multiple Query Proceesing Capabilities.	Sharma Chakravarthy	1991	Divide and Conquer: A Basis for Augmenting a Conventional Query Optimizer with Multiple Query Proceesing Capabilities.	ICDE	database
653	ICDE	Inferential Modelling Technique for Constructing Second Generation Knowledge Based Systems.	Christine W. Chan,Raymond E. Jennings,Paitoon Tontiwachwuthikul	1991	A novel inferential modeling technique (IMT) which aims to first clarify the domain ontology and inferences before proceeding onto the dynamic processing aspects of expertise is presented. The proposed model consists of the four levels of strategy, task, inference, and domain layers. The former two levels constitute the dynamic component and the latter two the static component. The static representation consists of the domain primitives and their interrelations, while the dynamic component represents a variety of tasks or activities which manipulate the domain entities in order to accomplish objectives. It is argued that the technique is useful as a tool in the elicitation and analysis phases of the development of a knowledge-based system. A preliminary application of the technique for constructing a knowledge-based system in the chemical engineering domain is described	ICDE	database
654	ICDE	Determining Beneficial Semijoins for a Join Sequence in Distributed Query Processing.	Ming-Syan Chen,Philip S. Yu	1991	The problem of combining join and semijoin reducers for distributed query processing is studied. An approach, of interleaving a join sequence with beneficial semijoins is proposed. A join sequence is mapped into a join sequence tree that provides an efficient way to identify for each semijoin its correlated semijoins as well as its reducible relations under the join sequence. In light of these properties, an algorithm is developed to determine an effective sequence of join reducers. Examples are also given to illustrate the results, which show that the approach of interleaving a join sequence with beneficial semijoins is effective in reducing the amount of data transmission to process distributed queries	ICDE	database
655	ICDE	An Efficient Hybrid Join Algorithm: A DB2 Prototype.	Josephine M. Cheng,Donald J. Haderle,Richard Hedges,Balakrishna R. Iyer,Ted Messinger,C. Mohan,Yun Wang	1991	A new join method, called hybrid join, is proposed which uses the join-index filtering and the skip sequential prefetch mechanism for efficient data access. With this method, the outer table is sorted on the join column. Then, the outer is joined with the index on the join column of the inner. The inner tuple is represented by its surrogate, equivalent of its physical disk address, which is carried in the index. The partial join result is sorted on the surrogate and then the inner table is accessed sequentially to complete the join result. Local predicate filtering can also be applied before the access of the inner relation through the index AND/ORing. Efficient methods for skip sequential access and prefetching of logically discontiguous leaf pages of B+-tree indexes are also presented	ICDE	database
656	ICDE	Using Type Inference and Induced Rules to Provide Intensional Answers.	Wesley W. Chu,Rei-Chi Lee,Qiming Chen	1991	A new approach is presented that uses knowledge induction and type inference to provide intensional answers. Machine learning techniques are used to analyze database contents and to induce a set of if-then rules. Type inference which is based on forward inference and backward inference is developed that uses database type hierarchies to derive the intensional answers for a query. It is shown that more precise intensional answers can be derived by properly merging the type inference results from multiple type hierarchies. A prototype intensional query-processing system which uses the proposed approach has been implemented. Using a ship database as a testbed, the effectiveness of the use of type interference and induced rules to derive specific intensional answers is demonstrated	ICDE	database
657	ICDE	Locking Granularity in Multiprocessor Database Systems.	Sivarama P. Dandamudi,Siu-Lun Au	1991	The effects of locking granularity in a shared-nothing multiprocessor database system are analyzed. The analysis shows that when the system is lightly loaded fine granularity (one lock per database entity) is needed when transactions access the database randomly. However, when transactions access the database sequentially, coarse granularity is desired. When the system is heavily loaded, coarse granularity is desirable. The results also indicate that horizontal partitioning results in better performance than random partitioning	ICDE	database
658	ICDE	Optimization of Generalized Transitive Closure Queries.	Shaul Dar,Rakesh Agrawal,H. V. Jagadish	1991	Two complementary techniques for optimizing generalized transitive closure queries are presented: (i) selections on paths are applied during the closure computation, so that paths that are not in the result and that are not needed to compute the result are pruned as early as possible and (ii) paths that are in the result, or needed to compute the result, are represented in a condensed form. The condensed representation holds the minimal information that is necessary for the specified label computations and selections to be performed. The combined impact of these techniques is that the number of paths generated during the closure computation and the storage required for each such path are both greatly reduced	ICDE	database
659	ICDE	Object-Centered Constraints.	Lois M. L. Delcambre,Billy B. L. Lim,Susan Darling Urban	1991	The notion of object-centered (O-C) constraints, a subset of range-restricted Horn clauses with existential variables is presented. O-C constraints correspond, intuitively, to sets of clauses that involve connected objects or objects that can be located through navigation. Other types of constraints, e.g. transition or other temporal constraints are not specifically addressed. The research philosophy adopted is that such constraints can be expressed by introducing additional constructs into the schema, e.g. old-Student or new-Student and then expressing constraints in the same manner as the O-C constraints. This approach is conceptually accurate; it provides a uniform method for expressing and enforcing constraints using generalized constraint analysis. It allows the user to precisely describe the intended semantics, e.g. when to delete the old values after an update. This philosophy basically states that database constraints necessarily constrain database objects; in order to address additional issues like old/new values, the additional structures should be brought into the purview of the database by defining them in the database schema	ICDE	database
660	ICDE	Maintaining Quasi Serializability in Multidatabase Systems.	Weimin Du,Ahmed K. Elmagarmid,Won Kim	1991	A scheduler producing quasi-serializable executions for concurrency control in multidatabase systems (MDBSs) is presented. An algorithm is proposed which ensures quasi-serializability by controlling submissions of global transactions. The algorithm groups global transactions in such a way that transactions in a group affect each other in a partial order. Transaction groups are executed separately and in a consistent order at all local sites. The algorithm differs from the others in that it does not violate local autonomy, provides a high degree of concurrency, and is globally deadlock-free	ICDE	database
661	ICDE	A Polymorphic Relational Algebra and Its Optimization.	David Eichmann,D. Alton	1991	The notion of a polymorphic database and the optimization of polymorphic queries-specifically, optimization of queries under the Morpheus data model-is addressed. The notion of query optimization through type inference, applicable both to polymorphic databases and traditional monomorphic databases, is introduced. The Morpheus data model and its type inference rules are reviewed and a polymorphic relational algebra is characterized. It is shown how the inference rules can be used for static optimization of a few sample queries. It is concluded that type inference provides a formal mechanism for optimizing a very rich extension to the relational algebra. The approach retains the basic framework that lead to the wide acceptance of the relational model, while enriching it with the structural expressiveness of the object-oriented approaches of recent years	ICDE	database
662	ICDE	Efficient Implementation Techniques For the Time Index.	Ramez Elmasri,Yeong-Joon Kim,Gene T. J. Wuu	1991	A new indexing technique, time index, for improving the performance of certain classes of temporal queries was previously described by the author (see The 16th Conference on Very Large Databases (1990)). Three variations for implementing the time index efficiently are proposed and the performance of these three variations is compared with the performance of the original time index. Various parameters such as average lifetime of a version, average number of versions per object, block size and block clustering, and query time interval length are discussed. Simulation results show how these parameters affect the performance of the various implementation variations for the time index	ICDE	database
663	ICDE	DOT: A Spatial Access Method Using Fractals.	Christos Faloutsos,Yi Rong	1991	DOT: A Spatial Access Method Using Fractals.	ICDE	database
664	ICDE	A Rule-Based Query Rewriter in an Extensible DBMS.	Béatrice Finance,Georges Gardarin	1991	An integrated approach to query rewriting in an extensible database server supporting ADTs, objects, deductive capabilities and integrity constraints is described. The approach is extensible through a uniform high level rule language used by the database implementor to specify optimization techniques. This rule language is compiled to enrich the strategy component and the knowledge base of the rewriter. Rules can be added to specify various aspects of query rewriting, including operation permutation, recursive query processing, integrity constraint addition, predicate simplification and method call simplification	ICDE	database
665	ICDE	Wait Depth Limited Concurrency Control.	Peter A. Franaszek,John T. Robinson,Alexander Thomasian	1991	A new class of wait depth limited (WDL) concurrency control (CC) methods is described. The WDL policy is shown by simulations to be effective both in systems with proportionately large I/O latencies as well as in systems with large numbers of processors. WDL is also attractive in terms of implementation. In many applications little or no system modification may be required other than the CC code. Since it is a lock-based method, unlike optimistic methods, there is no need for private copies of modified data for each transaction, nor is there any need for snapshot, timestamp, or versioning mechanisms to guarantee that transactions are always provided with a fully consistent database image	ICDE	database
666	ICDE	An Analysis Technique for Transitive Closure Algorithms: A Statistical Approach.	Sumit Ganguly,Ravi Krishnamurthy,Abraham Silberschatz	1991	A novel experimental procedure, based on a standard statistical estimation procedure, is presented to estimate the performance of transitive closure algorithms. This experimental procedure has been exemplified in three contexts: (1) comparison of a suite of algorithms: (2) analysis of one particular algorithm; and (3) analysis of the transitive closure problem itself. It is shown that the number of duplicate edges generated (by most algorithms) can be more than ten times the size of the transitive closure, even for small graphs. The majority of these duplicates are due to the existence of strongly connected components in the graph. This experimental approach can be generalized to estimate various performance metrics for a large class of database queries. It is both simple and general and provides the necessary ingredients for a guess-and-verify paradigm of testing hypotheses	ICDE	database
667	ICDE	On Serializability of Multidatabase Transactions Through Forced Local Conflicts.	Dimitrios Georgakopoulos,Marek Rusinkiewicz,Amit P. Sheth	1991	A multidatabase transaction management mechanism called the optimistic ticket method (OTM) is introduced for enforcing global serializability. It permits the commitment of multidatabase transactions only if their relative serialization order is the same in all participating local database systems (LDBSs). OTM requires the LDBSs to guarantee only local serializability. The basic idea in OTM is to create direct conflicts between multidatabase transactions at each LDBS in order to determine the relative serialization order of their subtransactions. A refinement of OTM, called the implicit ticket method (ITM), is also introduced that uses implicit tickets and eliminates ticket conflicts but works only when the participating LDBSs use rigorous transaction scheduling mechanisms. ITM uses the local commitment order of each subtransaction to determine its implicit ticket value. It achieves global serializability by controlling the commitment (execution order) and thus the serialization order of multidatabase transactions. Both OTM and ITM do not violate the autonomy of the LDBSs and can be combined in a single comprehensive mechanism	ICDE	database
668	ICDE	Real Time Retrieval and Update of Materialized Transitive Closure.	Keh-Chang Guh,Chengyu Sun,Clement T. Yu	1991	A data structure is used to store materialized transitive closure such that the evaluation of transitive closure, deletions and insertions of tuples can be performed efficiently. Experiments have been carried out on a Sun/3/180 system. It is verified experimentally and theoretically that it takes on the average O(m) to retrieve the ancestors/descendants of the given node, where m is the number of ancestors/descendants of the given node, and it takes on the average O(m*m') to perform an insertion or a deletion of a tuple (a,b), where m is the number of ancestors of a+1 and m' is the number of descendants of b+1. It is shown that, when the data types is integer, retrieval of the ancestors/descendants of a given node takes no more than 0.0001 s; insertion/deletion of a tuple and the corresponding update involving m*m=elements in the data structure takes approximately 0.07 s. When data type is a string of length 20, the corresponding retrieval time and insertion/deletion times are 0.0008 s and 1.5 s respectively	ICDE	database
669	ICDE	Query Processing Algorithms for Temporal Intersection Joins.	Himawan Gunadhi,Arie Segev	1991	Intersection join processing in temporal relational databases is investigated. An analysis is presented of the characteristics and processing requirements of three types of intersection join operators: the time-join temporal equijoin on the surrogate, and temporal equijoin on the temporal attribute. Based on the physical organization of the database and on the semantics of the operators, several algorithms were developed to process these joins efficiently. The primary cost variables were identified for each algorithm and their performance is compared to that of a conventional nested-loop join procedure. It is shown that the algorithms developed can reduce processing costs significantly	ICDE	database
670	ICDE	Spatial Database Indices for Large Extended Objects.	Oliver Günther,Hartmut Noltemeier	1991	An analytic model is given for the behavior of dynamic spatial index structures under insertions and deletions. Based on this model a new tool, called the oversize shelf to improve the performance of tree-based indices by minimizing redundancy, is optimized and evaluated. Oversize shelves are extra disk pages that are attached to the interior nodes of a tree-based spatial index structure. These pages are used to accommodate very large data objects in order to avoid their excessive fragmentation. Whenever inserting a new object into the tree, it should be decided whether to store it on an oversize shelf or to insert it into the subtrees. From the analytic model a threshold q* for the object size is obtained. If the object is larger than q*, it is more favorable to put it on the oversize shelf, otherwise the insertion into the subtrees is preferable	ICDE	database
671	ICDE	An Association Algebra For Processing Object-Oriented Databases.	Mingsen Guo,Stanley Y. W. Su,Herman Lam	1991	An association algebra (A-algebra) is presented for manipulating object-oriented (O-O) databases which is analogous to the relational algebra for relational databases. In this algebra, objects and their associations in an O-O database are uniformly represented by association patterns and are manipulated by a number of operators. These operators are defined to operate on association patterns of both heterogeneous and homogeneous structures. Very complex structures (e.g. network structures of object associations across several classes) can be directly manipulated by these operators. Therefore, the association algebra has greater expressive powers than the relational algebra which manipulates on relations of compatible structures. Some mathematical properties of these operators are described together with their application in query decomposition and optimization. The algebra has been used as the basis for the design and implementation of an O-O query language called OQL and a knowledge rule specification language	ICDE	database
672	ICDE	Modeling Transition.	Gary Hall,Ranabir Gupta	1991	It is argued that the dynamics of an application domain is best modeled as patterns of change in the entities that make up the domain. An abstraction mechanism for semantic data models is described which represents the transition of domain entities among entity classes. The model of transitions is related to a general computational formalism with well-understood properties. It is shown that the transition abstraction mechanism facilitates the accurate conceptual modeling of the static nature of the domain, assists in the design of database transactions, enables certain kinds of inference, and leads to the ability of a database to actively respond at a high level to low level updates of the data it contains	ICDE	database
673	ICDE	Preserving and Generating Objects in the LIVING IN A LATTICE Rule Language.	Andreas Heuer,Peter Sander	1991	LIVING IN A LATTICE is presented as a rule-based query language for an object-oriented database model. The model supports complex objects, object identity, and is-a-relationships. The instances are described by object relations, which are functions from a set of objects to value sets and other object sets. The rule language is based on object-terms which provide an access to objects via is-a-relationships. Rules are divided into two classes: object-preserving rules manipulating existing objects and object-generating ones creating objects with properties derived from existing objects. The derived object sets are included in a lattice of object types. Some conditions are given under which the instances of the rule's heads are consistent, i.e., where the properties of the derived objects are functionally determined by the objects	ICDE	database
674	ICDE	Unilateral Commit: A New Paradigm for Reliable Distributed Transaction Processing.	Meichun Hsu,Abraham Silberschatz	1991	An alternative approach to distributed transaction processing based on the unilateral commit paradigm (UCP) and on persistent transmission is proposed. Instead of executing a unit of work as a single distributed transaction, as in the traditional transaction execution paradigm, opportunities are looked for to execute it as a structured set or a sequence of smaller, possibly single-site atomic transactions. Each such transaction, once executed, is committed independently of other transactions in the task. A method for rigorously maintaining the linkage between the steps is provided for by a persistent transmission mechanism. It is argued that UCP is especially attractive since it relies on a site's ability to execute conventional flat local transactions and does not require additional capabilities such as the ability to execute nested transactions	ICDE	database
675	ICDE	Parallel Computation of Direct Transitive Closures.	Yan-Nong Huang,Jean-Pierre Cheiney	1991	To efficiently process recursive queries in a DBMS (database management system), a parallel, direct transitive closure algorithm is proposed. Efficiency is obtained by reorganizing the computation order of Warren's algorithm. The number of transfers among processors depends only on the number of processors and does not depend on the depth of the longest path. The evaluation shows an improvement due to the parallelism and the superiority of the proposed algorithm over recent propositions. The speed of the production of new tuples is very high and the volume of transfers between the sites is reduced	ICDE	database
676	ICDE	Navigation and Schema Transformations for Producing Nested Relations form Networks.	Mizuho Iwaihara,Tetsuya Furukawa,Yahiko Kambayashi	1991	Navigation and Schema Transformations for Producing Nested Relations form Networks.	ICDE	database
677	ICDE	Object/Behavior Diagrams.	Gerti Kappel,Michael Schrefl	1991	A novel diagram technique is presented to depict the structure as well as the behavior of objects. One of its distinguishing characteristics is its strict adherence to the object-oriented paradigm. A first prototype of an editor for object/behavior diagrams has been developed and is running on SUN-workstations. To assist the user the editor provides hypertext style facilities for navigating through different diagrams. For example, by clicking on an activity in a life cycle diagram one moves to the activity specification diagram of that activity	ICDE	database
678	ICDE	Precomputation in a Complex Object Environment.	Anant Jhingran	1991	Certain analytical results are established about precomputation in a complex object environment. The concept of `intervals' is introduced and it is shown that object-identifier caching might be beneficial provided the frequency of updates to the set of subobjects associated with an object is not too high. However, in most cases, procedures with value caching outperformed other forms of representations. Certain performance characteristics of a knapsack-based algorithm are established which can be used to optimally decide which of the precomputed results to cache. Simulation results demonstrate how well this scheme performs. In particular, a binary search strategy seems ideally suited for caching	ICDE	database
679	ICDE	A Knowledge-Based Subsystem for a Natural Language Interface to a Database that Predicts and Explains Query Failures.	Stefan W. Joseph,Romas Aleliunas	1991	A practical method is presented for eliminating unnecessary database operations that often arise from poorly posed natural language queries. This subsystem consists mainly of a knowledge-base whose rules are semantic constraints of the database. The inference procedure's actions are, unlike that of similar inference engines, strictly controlled by the structure of the query. Because of this it is easy to implement and it is relatively fast. It is believed that this subsystem represents a practical incremental improvement that can be made to any relational database front end, not just those that must cope with natural language queries. The procedure also has value as part of a practical semantic query optimizer	ICDE	database
680	ICDE	Compiling a Rule Database Program into a C/SQL Application.	Gerald Kiernan,Christophe de Maindreville	1991	The design and the implementation of a rule database language (RDL) compiler is presented. In this design, the RDL/C language supports both declarative programming based on a production rule language and C-based procedural programming. The data model is relational. This implies that all rule programs can be solved without having to download data from the database management system (DBMS) into some working memory. The language supports domain variables which can appear in rules. These variables are monitored by the inference engine and included in the semantics of rule firing. A partial ordering among rules is available to the user. The RDL/C compiler translates RDL/C source code into C code with embedded structured query language (SQL) statements. Its implementation is compared to fully integrated deductive databases and to loosely coupled systems. It is shown how the rule-based paradigm for a database can be used as a framework for a general-purpose database application generator	ICDE	database
681	ICDE	Performance Evaluation of Functional Disk System (FDS-R2).	Masaru Kitsuregawa,Miyuki Nakano,Mikio Takagi	1991	The performance of the functional disk system with relational database engine (FDS-R2) is evaluated in detail in view of two points. First, the performance evaluation of the combined hash algorithm on FDS-R2 is reported using the projection and aggregation operations in addition to the join operation and they are analyzed in order to verify the effectiveness of the proposed processing method, Second, several measured results of performance evaluations with the expanded version of the Wisconsin Benchmark are given and analyzed. FDS-R2 attained higher performance for very large relations as compared to other large database systems such as Gamma and Teradata. In this evaluation, it is also shown that the performance of the relational operations can be improved largely by using an efficient hashing strategy for large relations on FDS-R2	ICDE	database
682	ICDE	The Software Architecture of a Parallel Processing System for Advanced Database Applications.	Yasushi Kiyoki,Takahiro Kurosawa,Kazuhiko Kato,Takashi Masuda	1991	A parallel processing scheme and software architecture of SMASH, a parallel processing system for supporting a wide variety of database applications is presented. The main feature of this system is that functional programming concepts are applied to define new database operations and data types and to exploit parallelism inherent in an arbitrary set of database operations. A primitive set (SMASH primitive set) of the software architecture is presented that defines an abstract machine interface between high-level database languages and general-purpose hardware systems for parallel processing. The primitive set is used to implement functional computation systems for executing arbitrary database operations in parallel. A previously proposed stream-oriented parallel processing scheme for relational database operations is extended to support more complex database operations which deal with complex data structures. Several experimental results of parallel processing for database operations are shown to clarify feasibility of the proposed architecture	ICDE	database
683	ICDE	Semantic Query Reformulation in Deductive Databases.	Sang-goo Lee,Lawrence J. Henschen,Ghassan Z. Qadah	1991	A method is proposed for identifying relevant integrity constraints (ICs) for queries involving joins/unions of base relations and defined relations by use of graphs. The method does not rely on heavy preprocessing or redundancy. To effectively select those ICs that are relevant to a given query, the relationship between the predicates in the query is identified using an AND/OR tree where an AND mode represents a join operation and an OR node represents a union operation. Ways of collecting ICs are described that are not directly related to the query but can be useful in query optimization	ICDE	database
684	ICDE	Processing of Multiple Queries in Distributed Databases.	A. Y. Lu,Phillip C.-Y. Sheu	1991	Processing of Multiple Queries in Distributed Databases.	ICDE	database
685	ICDE	Performance Measurement of Some Main Memory Database Recovery Algorithms.	Vijay Kumar,Albert Burger	1991	The performance of two main-memory database system (MDBS) algorithms is studied. M.H. Eich's (Proc. of the Fifth Int. Workshop on Database Machines., Oct. 1987) and T.J. Lehman's (Ph. D. Thesis, Univ. of Wisconsin-Madison, Aug 1986) algorithms are selected for this study. The investigation indicates that the shadow approach, as used by Eich, has some advantages over the update in-place strategy of Lehman. The shadow approach has faster response for normal transactions even though transaction commit is slower compared to update in-place approach. It is concluded that irrespective of the recovery algorithm an efficient load balancing plays an important part in the performance of the system. It is suggested that processors should be allocated to any kind of activity on a demand basis. It is discovered that individual recovery of lockable units as used in Lehman's algorithm is a better choice since it increases the system availability after a system failure. It also allows background recovery to go in parallel to normal transaction processing	ICDE	database
686	ICDE	Incremental Restart.	Eliezer Levy	1991	Incremental Restart.	ICDE	database
687	ICDE	Natural Joins in Relational Databases with Indefinite and Maybe Information.	Ken-Chih Liu,Lu Zhang	1991	Natural Joins in Relational Databases with Indefinite and Maybe Information.	ICDE	database
688	ICDE	Interactive Manipulation of Object-oriented Views.	Jean-Claude Mamou,Claudia Bauzer Medeiros	1991	An approach to providing view support in object-oriented (O2 ) databases is presented. The approach uses what is called a hyper-view and combines results from research on database design and man-machine interfaces. A mechanism that allows interacting with databases through hyper-views and built on top of the O2 system is described. The approach is based on conciliating stored data and their visualization. Not only views corresponding to one class, but also multiclass views are considered. Hyper-views are supported by ToonMaker, a user interface generator system implemented for the O2 database management system	ICDE	database
689	ICDE	Problems Underlying the Use of Referential Integrity in Relational Database Management Systems.	Victor M. Markowitz	1991	Problems Underlying the Use of Referential Integrity in Relational Database Management Systems.	ICDE	database
690	ICDE	Conflict-driven Load Control for the Avoidance of Data-Contention Thrashing.	Axel Mönkeberg,Gerhard Weikum	1991	A conflict-driven approach to automatic load control is presented. Various definitions of conflict rate are investigated as to whether they are suitable as a control metric. Evidence is provided that there exists at least one suitable metric and a single value, called the critical conflict rate, that indicates data-contention (DC) thrashing regardless of the number or types of transactions in the system. Based on this observation, an algorithm is developed that admits new transactions and/or cancels running transactions depending on the current conflict rate. The algorithm and its various substrategies for transaction admission and transaction cancellation are evaluated under several sorts of overload situations. Simulation experiments with this algorithm have shown fairly good results, i.e. DC thrashing was prevented in overload situations without overly limiting the achievable throughput under regular conditions. Load control is fully automated, i.e., it does not require any manual tuning parameters	ICDE	database
691	ICDE	ARIES-RRH: Restricted Repeating of History in the ARIES Transaction Recovery Method.	C. Mohan,Hamid Pirahesh	1991	A method called ARIES-RRH (algorithm for recovery and isolation exploiting semantics with restricted repeating of history) is presented which is a modified version of the ARIES transaction recovery and concurrency control method implemented to varying degrees in Starburst, QuickSilver, the OS/2 Extended Edition Database Manager, DB2 V2, Workstation Data Save Facility/VM and the Gamma database machine. The repeating history paradigm of ARIES is analyzed to propose a more efficient handling of redos, especially when the smallest granularity of locking is not less than a page, by combining the paradigm of selective redo from DB2 V1. Even with fine-granularity locking, it is not always the case that all the unapplied but logged changes needed to be redone. ARIES-RRH, which incorporates these changes, still retains all the good properties of ARIES-avoiding undo of undos, single-pass media recovery, nested top actions, etc. The fundamentals behind why DB2 V1's selective redo works, in spite of failures during restart recovery, are also explained	ICDE	database
692	ICDE	Exploiting Parallelism in the Implementation of Agna, a Persistent Programming System.	Rishiyur S. Nikhil,Michael L. Heytens	1991	A design for AGNA, a persistent object system that utilizes parallelism in a fundamental way to enhance performance, is presented. The underlying thesis is that fine-grained parallelism is essential for achieving scalable performance on parallel multiple instruction/multiple data (MIMD) machines. This, in turn, implies a data-driven model of computation for efficiency. The complete design based on these principles starts with a declarative source language because such languages reveal the most fine-grained parallelism. It is described how transactions are compiled into an abstract, fine-grained parallel machine called P-RISC. The P-RISC virtual heap is implemented in the memory and disk of a parallel machine in such a way that paging is overlapped with useful computation. The current implementation status is described, some preliminary performance results are reported and the approach presented is compared to several recent parallel database system projects	ICDE	database
693	ICDE	Execution Plan Balancing.	Marguerite C. Murphy,Ming-Chien Shan	1991	A novel relational query optimization technique for use in shared memory multiprocessor database systems is described. A collection of practical algorithms for allocating computational resources to parallel select-project filter (SPJ) query execution plans is presented. The computational resources considered include disk bandwidth, memory buffers and general-purpose processors. The goal of the allocation algorithms is to produce minimum duration execution strategies with computational resource requirements that are less than the given system bounds. Preliminary experimental results indicate that the algorithms can be realized and are effective in producing good execution plans. Disk bandwidth appears to be the critical system resource. The most effective means to decrease complex query response time appears to be by reducing disk contention. This can be achieved by increasing the total number of disks and/or rearranging the placement of data on disks	ICDE	database
694	ICDE	Scheduling Batch Transactions on Shared-Nothing Parallel Database Machines: Effects of Concurrency and Parallelism.	Tadashi Ohmori,Masaru Kitsuregawa,Hidehiko Tanaka	1991	Concurrency-control scheduling of batch transactions on shared-nothing (or loosely-coupled) multiprocessor database machines is discussed. Various schedulers are tested for these batch transactions to examine how well they perform when both intertransaction parallelism and intratransaction parallelism are limited. New schedulers designed for batch transaction processing are outlined which use a new tool called a weighted transaction-precedence graph (WTPG). Simulation results show that two new schedulers (globally and locally optimized WTPG schedulers) are the best performers under various workloads	ICDE	database
695	ICDE	Atomic Commitment for Integrated Database Systems.	Peter Muth,Thomas C. Rakow	1991	A systematic discussion of atomic commitment for heterogeneous database systems is presented. An analysis is given of two alternative protocols for atomic commitment: commitment of local transaction after or before the global commit or abort decision is made. The impact of the protocols on recovery and concurrency control is shown. Atomicity, consistency, isolation, and durability properties are achieved for global transactions. It is demonstrated that commitment before fits best to multilevel transactions. In this case, the commitment protocol causes no additional overhead and a higher degree of concurrency can be achieved	ICDE	database
696	ICDE	Interval Assignment for Periodic Transactions in Real-Time Database Systems.	Hidenori Nakazato,Kwei-Jay Lin	1991	The problem of assigning execution intervals for periodic transactions in real-time databases is discussed. The object value evolution rate and the importance of the object are used as two factors for deciding transaction periods. Two different objective functions are defined to reflect different system design goals. Algorithms for optimizing each objective function are presented. The principle behind these algorithms is to allow the transactions which have higher weights to be executed more often. It is assumed that systems use the rate monotonic algorithm for scheduling transactions. Many other scheduling algorithms, like the earliest deadline first algorithm can also be used. Some examples using the proposed algorithms are given	ICDE	database
697	ICDE	A Methodology for Benchmarking Distributed Database Management Systems.	Cyril U. Orji	1991	A methodology for benchmarking distributed database management systems is proposed. A distributed environment is characterized in terms of the communication costs incurred in data movement between sites, the number of nodes that participate in processing a query and the data distribution scheme used in the network. These three major characteristics form a basis for eight query types that capture the query performance characteristics in the network. It is demonstrated that the performance characteristics of any distributed database management system can be captured by running queries based on these query types. Preliminary results obtained in applying the methodology in a single-user LAN environment are presented	ICDE	database
698	ICDE	An Efficient Semantic Query Optimization Algorithm.	HweeHwa Pang,Hongjun Lu,Beng Chin Ooi	1991	An efficient semantic query optimization algorithm is proposed, in which all possible transformations are tentatively applied to the query. Instead of physically modifying the query, the transformation process classifies the predicates into imperative, optional or redundant. At the end of the transformation process, all the imperative predicates are retained while the redundant predicates are eliminated. Optional predicates are retrained or discarded based on the estimated cost/benefit of retaining them. The issue of the grouping of semantic constraints to reduce the overhead of retrieving constraints and checking whether each constraint is relevant to the current query is also addressed. Based on the proposed algorithm, a prototype semantic query optimizer has been built and preliminary experiments show that the optimizer performs well for large databases	ICDE	database
699	ICDE	Voting with Regenerable Volatile Witnesses.	Jehan-François Pâris,Darrell D. E. Long	1991	Voting protocols ensure the consistency of replicated objects by requiring all read and write requests to collect an appropriate quorum of replicas. It is proposed to replace some of these replicas with volatile witnesses that have no data and require no stable storage, and to regenerate them instead of waiting for recovery. The small size of volatile witnesses allows them to be regenerated much easier than full replicas. Regeneration attempts are also much more likely to succeed since volatile witnesses can be stored on diskless sites. It is shown that under standard Markovian assumptions two full replicas and one regenerable volatile witness managed by a two-tier dynamic voting protocol provide a higher data availability than three full replicas managed by majority consensus voting or optimistic dynamic voting provided site failures can be detected significantly faster than they can be repaired	ICDE	database
700	ICDE	Request Order Linked List (ROLL): A Concurrency Control Object for Centralized and Distributed Database Systems.	William Perrizo	1991	A database concurrency control object called ROLL (request order linked list), which is a linked list of bit vectors, is introduced together with three simple operations available to transactions: POST, CHECK and RELEASE. POST is used to establish serialization order. CHECK is used to determine current resource availability. RELEASE is used to relinquish resources. ROLL is based on the serialization graph testing method, but no system scheduler module is involved. Using ROLL, waiting, restarting, deadlock and livelock are minimized and almost all operations can be invoked in parallel by individual transaction manager modules. The ROLL object, performance, problems and desirable extensions are discussed	ICDE	database
701	ICDE	Domain Vector Accelerator for Relational Operations.	William Perrizo,James Gustafson,Daniel Thureen,David Wenberg	1991	Domain Vector Accelerator for Relational Operations.	ICDE	database
702	ICDE	Perfect Hashing Functions for Hardware Applications.	M. V. Ramakrishna,G. A. Portice	1991	Perfect hashing functions are determined that are suitable for hardware implementations. A trial-and-error method of finding perfect hashing functions is proposed using a simple universal2 class (H3) of hashing functions. The results show that the relative frequency of perfect hashing functions within the class H3 is the same as predicted by the analysis for the set of all functions. Extensions of the basic scheme can handle dynamic key sets and large key sets. Perfect hashing functions can be found using software, and then loaded into the hardware hash address generator. Inexpensive associative memory can be used as a general memory construct offered by the system services of high-performance (super) computers. It has a potential application for storing operating system tables or internal tables for software development tools, such as compilers, assemblers and linkers. Perfect hashing in hardware may find a number of other applications, such as high speed event counting and text searching	ICDE	database
703	ICDE	Spatial Join Indices.	Doron Rotem	1991	Algorithms based on grid files as the underlying spatial index are presented for spatial joins in databases which store images, pictures, maps and drawings. For typical data distributions, it is shown that the size of the index and its maintenance cost are relatively small. The effect of diagonal distributions and different densities of the two grid files on the size of the index is also studied. It is expected that similar algorithms can be employed with other types of multidimensional data structures	ICDE	database
704	ICDE	A Semantic Integrity Framework: Set Restrictions for Semantic Groupings.	Elke A. Rundensteiner,Lubomir Bic,Jonathan P. Gilbert,Meng-Lai Yin	1991	Three of the most common fundamental groupings that are utilized in semantic database models are considered: set groupings, power set groupings, and Cartesian aggregation groupings. For each, useful restrictions that control its structure and composition are defined. This permits each grouping to capture more subtle distinctions of the concepts or situations in the application environment. The resulting set of restrictions forms a framework for integrity constraints in semantic data models. This framework is targeted towards advanced applications, such as computer-aided design, office automation, and artificial intelligence, which require the support of more sophisticated relationships among data than traditional database domains	ICDE	database
705	ICDE	Modeling Uncertainty in Databases.	Fereidoon Sadri	1991	Relational algebra operations were extended to produce, together with answers to queries, information regarding sources that contributed to the answers. The author's previous model is reviewed and the semantic interpretation is presented. It is shown that extended relational algebra operations are precise, that is, they produce exactly the same answers that are expected under the semantic interpretation. Algorithms for computing the reliability of answers to a query are also reviewed and their correctness under the semantic interpretation proposed is proved	ICDE	database
706	ICDE	Meta-reasoning: An Incremental Compilation Approach.	Abdul Sattar,Randy Goebel	1991	An incremental compilation approach to meta-reasoning is presented together with a method to update dynamically changing knowledge bases. The compilation process translates meta-level specification of facts and hypotheses into sentences of clausal logic. It then incrementally computes inconsistent sets of instances of hypotheses and records potential crucial literals. The extra information computed during compilation enables the theorem prover to avoid redundant computations and to efficiently update the compiled knowledge. Whenever a new fact is learned the effects of the fact are computed incrementally, without recompiling. A relationship between potential crucial literals and Reiter and de Kleer's prime implicants shows that this approach may be useful in incrementally computing and maintaining the prime implicants, as well	ICDE	database
707	ICDE	The Architecture of BrAID: A System for Bridging AI/DB Systems.	Amit P. Sheth,Anthony B. O'Hare	1991	The design of BrAID (a bridge between artificial intelligence and database management systems), an experimental system for the efficient integration of logic-based artificial intelligence (AI) and databases (DB) technologies, is described. Features provided by BrAID include (a) access to conventional DBMSs, (b) support for multiple inferencing strategies, (c) a powerful caching subsystem that manages views and uses subsumption to facilitate the reuse of previously cached data, (d) lazy or eager evaluation of queries submitted by the AI system, and (e) the generation of advice by the AI system to aid in cache management and query execution planning. Some of the key aspects of the BrAID architecture are discussed, focusing on the generation of advice by the AI system and its use by a cache management system to increase efficiency in accessing remote DBMSs through the selective application of such techniques as prefetching, query generalization, result caching, attribute indexing, and lazy evaluation	ICDE	database
708	ICDE	Lk: A Language for Capturing Real World Meanings of the Stored Data.	D. G. Shin	1991	A knowledge representation language Lk is introduced that is tailored for expressing the real-world meanings of stored data. Lk is developed to achieve a tight coupling between a knowledge base component and the database system. Lk offers (1) a flexible descriptive power which facilitates concepts to be expressed at different levels of granularity; (2) a versatile association mechanism which is capable of linking partially related concepts; and (3) a set of specialization and generalization operators that enable inexact reasoning in a heuristically controlled environment. Examples are provided to illustrate the language's expressive power, its associability, and the inference operations. An example of processing an inference query is given to show the application of various utilities of Lk	ICDE	database
709	ICDE	Evaluation of Rule Processing Strategies In Expert Databases.	Arie Segev,J. Leon Zhao	1991	Rule processing strategies in expert database systems which involve rules conditional on join results of base relations are studied. In particular, those rules that require very fast response time in their evaluation are considered. It is proposed to materialize the results of firing a rule in a relation, the rule relation. Performance evaluation of several strategies shows that under the clustered B-trees, strategies using pattern relations perform better than those without pattern relations. The strategy with skinny pattern relations performs poorly in comparison to that with bulky pattern relations. The selective bulky pattern strategy performs better than the bulky pattern strategy. The selective pattern strategy outperforms other strategies in terms of expected total cost. However, it always uses more storage space than the direct materialization	ICDE	database
710	ICDE	Read Optimized File System Designs: A Performance Evaluation.	Margo I. Seltzer,Michael Stonebraker	1991	A performance comparison is presented of several file system allocation policies. The file systems are designed to provide high bandwidth between disks and main memory by taking advantage of parallelism in an underlying disk array catering to large units of transfer, and minimizing the bandwidth dedicated to the transfer of metadata. All of the file systems described use a multiblock allocation strategy which allows both large and small files to be allocated efficiently. Simulation results show that these multiblock policies result in systems that are able to utilize a large percentage of the underlying disk bandwidth (more than 90% in sequential cases). As general-purpose systems are called upon to support more data intensive applications such as databases and supercomputing, these policies offer an opportunity to provide superior performance to a larger class of users	ICDE	database
711	ICDE	Query Pairs as Hypertext Links.	Katsumi Tanaka,N. Nishikawa,S. Hirayama,K. Nanba	1991	A new idea is proposed for constructing object-oriented hypertext database systems: query pairs as hypertext links, where each query is defined over a collection of document objects that are classified using a class hierarchy. With this idea, users need not modify their hypertext links against the insertions, deletions and updates of document objects. Also, when a database schema (here, a class hierarchy) evolves, a systematic method can be considered to modify user-defined query-pair links. The TextLink-III system that was developed based on this idea and that is currently running is described. The notable features of TextLink-III are the following: document objects are classified by class hierarchy and the notion of class expression is used for formulating a query for a class hierarchy; multiple viewpoint support; and less link maintenance against data updates	ICDE	database
712	ICDE	Performance Limits of Two-Phase Locking.	Alexander Thomasian	1991	A novel mean-value analysis method for two-phase locking (2PL) is presented which extends previous work to the important case of variable size transactions. The system performance expressed as the fraction of blocked transactions (&beta;) is determined by solving a cubic equation in &beta; whose coefficients are functions of a single parameter (&alpha;), which determines the degree of lock contention in the system. In fact, &alpha; is proportional to the mean number of lock requests per transaction (&eta;c) and additionally the mean waiting time (W1) for a lock held by an active transaction. For &alpha; < 0.226 the performance of the system is determined by the smallest root of the cubic and the system is thrashing otherwise, i.e. a large fraction of the transactions in the system are blocked. Validation of the analytic solution against simulation results shows that the analysis is quite accurate up to the point beyond which the system thrashes. It is shown that the variability of transaction size has a major effect on the degree of lock contention, since both &eta;c and W 1 are affected by this distribution. A theoretical justification for Tay's rule of thumb that &eta;c should be smaller than 0.7 to avoid thrashing is provided. It is shown that 2PL is susceptible to a cusp catastrophe. Sources of instability are identified, and methods for load control to avoid thrashing are suggested	ICDE	database
713	ICDE	Efficiently Maintaining Availability in the Presence of Partitionings in Distributed Systems.	Peter Triantafillou,David J. Taylor	1991	A new approach is presented for handling partitionings in replicated distributed databases. Mechanisms are developed through which transactions can access replicated data objects and observe delays similar to nonreplicated systems while enjoying the availability benefits of replication. The replication control protocol, called VELOS, achieves optimal availability, according to a well-known metric, while ensuring one-copy serializability. It is shown to provide better availability than other methods which meet the same optimality criterion. It offers these availability characteristics without relying on system transactions that must execute to restore availability, when failures and recoveries occur, but which introduce significant delays to user transactions	ICDE	database
714	ICDE	Implementation and Evaluation of a Browsing Algorithm for Design Applications.	Yosihisa Udagawa	1991	The implementation and evaluation of an extended relational database called ADAM (advanced database abstraction mechanism) are discussed. A browsing algorithm is developed for composite objects to support reuse of the objects. The algorithm takes advantage of aggregation hierarchies to select related composite objects and to order them based on the two measures, i.e. the relative difference of matching components (RDMC) and the number of nonmatching components (NNC). The algorithm has been implemented and various kinds of experiments have been carried out with a standard integrity constraint database. The results show that the CPU time roughly linearly depends on the number of selected objects. Around 90% of the CPU time is consumed in calculating RDMC and NNC. RDMC is more sensitive to retrieval conditions than NNC	ICDE	database
715	ICDE	Design Overview of the Aditi Deductive Database System.	Jayen Vaghani,Kotagiri Ramamohanarao,David B. Kemp,Zoltan Somogyi,Peter J. Stuckey	1991	An overview of the structure of Aditi, a disk-based deductive database system under continuous development at the University of Melbourne, is presented. The aim of the project is to find out what implementation methods and optimization techniques would make deductive databases competitive with current commercial relational databases. The structure of the Aditi prototype is based on a variant of the client-server model. The front end of Aditi interacts with the user exclusively in a logical language that has more expressive power than relational query languages. The back end uses relational technology for efficiency in the management of disk-based data and uses some optimization algorithms especially developed for the bottom-up evaluation of logical queries involving recursion. The system has been functional for almost two years now, and has already proven its worth as a research tool	ICDE	database
716	ICDE	How Spacey Can They Get? Space Overhead for Storage and Indexing with Object-Oriented Databases.	Mary Jane Willshire	1991	The impact of physical storage model choice on the performance of an object-oriented database is studied. It is examined how each of six physical storage models' space overhead reacts to changes in database parameters such as directed acrylic graph (DAG) shape, number of instances per class, and distribution of instances over the DAG. Home-class, leaf-overlap, and split-instance physical models consistently require the least storage, whereas repeat-classes, universal-class, and value-triple models require the most. For all models, the depth of the DAG has the strongest impact on space overhead. A set of analytic formulas is developed that allow a database designer to estimate database size for each physical model	ICDE	database
717	ICDE	An Object-Oriented Query Processor that Produces Monotonically Improving Approximate Answers.	Susan V. Vrbsky,Jane W.-S. Liu	1991	An object-oriented query processor is described that makes approximate answers available if there is not enough time to product an exact answer or if part of the database is unavailable. The accuracy of the approximate result produced improves monotonically with the amount of data retrieved to produce the result. The query-processing algorithm is based on an approximate relational data model and works within a standard relational algebra framework. The query processor maintains an object-oriented view on an underlying level and can be implemented on a relational database system with little change to the relational architecture. It is shown how a monotone query-processing strategy can be implemented, making effective use of semantic information presented by the object-oriented view	ICDE	database
718	ICDE	An Effective Algorithm for Parallelizing Hash Joins in the Presence of Data Skew.	Joel L. Wolf,Daniel M. Dias,Philip S. Yu,John Turek	1991	An Effective Algorithm for Parallelizing Hash Joins in the Presence of Data Skew.	ICDE	database
719	ICDE	Optimal Buffer Partitioning for the Nested Block Join Algorithm.	Joel L. Wolf,Balakrishna R. Iyer,Krishna R. Pattipati,John Turek	1991	An efficient, exact algorithm is developed for optimizing the performance of nested block joins. The method uses both dynamic programming and branch-and-bound. In the process of deriving the algorithm, the class of resource allocation problems for which the greedy algorithm applies has been extended. Experiments with this algorithm on extremely large problems show that it is superior to all other known algorithms by a wide margin	ICDE	database
720	ICDE	Distributed Query Optimization by One-Shot Fixed-Precision Semi-Join Execution.	Chihping Wang,Victor O. K. Li,Arbee L. P. Chen	1991	A novel semijoin execution strategy is proposed which allows parallelism and processes multiple semijoins simultaneously. In practice most of the parameters needed for query optimization, such as relation cardinality and selectivity, are of fixed-precision. Imposing this fixed-precision constraint, an efficient distributed query processing algorithm is developed. For situations where the fixed-precision constraint does not apply, a method to truncate the parameters and to use the same algorithm to find near-optimal solutions is proposed. By analyzing the truncation errors, a quantitative comparison between the near-optimal solutions and the optimal ones is provided	ICDE	database
721	ICDE	First-Order Logic Reducible Programs.	Ke Wang,Li-Yan Yuan	1991	Programs for which the least fixed point exists are considered. A program is first-order logic reducible (FOL-reducible) with respect to a set of integrity constraints if all its valid fixed points are least fixed points. For an FOL-reducible program, a logical assertion about least fixed points is reduced to a logical assertion about all first-order logic models. This makes it possible to characterize, in the first-order logic, some important `all states' properties of programs for which no proof procedures exist in general. This method is applied to the following properties: containment of programs, independence of updates with respect to queries and integrity constraints, and characterization and implication of integrity constraints in programs. It is shown that the transitive closure of a graph if FOL-reducible with respect to the constraint of acyclicity. The `all states' framework requires a modification of the standard treatment of fixed points and completed programs	ICDE	database
722	ICDE	A Framework for Schema Updates In An Object-Oriented Database System.	Roberto Zicari	1991	A `reasonable' minimal set of primitives for updating an object-oriented (O2) database schema is defined and the problems which need to be solved in order to obtain a usable schema update mechanism are shown. The distinction between structural and behavioral consistency for the O2 system is described in some detail and it is demonstrated how updates could be performed by invoking an interactive tool. Updates are classified in three categories. Each category is explained in detail	ICDE	database
723	ICDE	Optimal Buffer Allocation in A Multi-Query Environment.	Philip S. Yu,Douglas W. Cornell	1991	The concepts of memory consumption and return on consumption (ROC) are used as the basis of memory allocations. A global optimization strategy using simulated annealing is developed which minimizes the average response time over all queries under the constraint that the total memory consumption rate has to be less than the buffer size. It selects the optimal join method and memory allocation for all queries simultaneously. By analyzing the way that the optimal strategy makes memory allocations, a heuristic threshold strategy is proposed. The threshold strategy is based on the concept of ROC. As the memory consumption rate by all queries is limited by the buffer size, the strategy tries to allocate the memory so as to make sure that a certain level of ROC is achieved. A simulation model is developed to demonstrate that the heuristic strategy yields performance that is very close to the optimal strategy and is far superior to the conventional allocation strategy	ICDE	database
724	ICDE	An Evaluation Framework for Algebraic Object-Oriented Query Models.	Li Yu,Sylvia L. Osborn	1991	An evaluation framework consisting of five categories of criteria is developed for evaluating the relative merits of objects algebras, namely, object-orientedness, expressiveness, formalness, performance and database issues. Four recently proposed object algebras are evaluated against these criteria. It is shown that there exists no object algebra that satisfies all the criteria. It is argued that, since some of the criteria may not be compatible, a feasible object algebra has to make some tradeoffs to suit domain-specific needs. It is possible to identify a minimal subset of the criteria. The criterion that an object algebra should support encapsulation seems to be the most important. If an object algebra fails to support this criterion, its semantics is inconsistent with the concept of `data abstraction', which makes a language object-oriented	ICDE	database
725	SIGMOD Conference	Database Programming Languages: A Functional Approach.	Jurgen Annevelink	1991	Database Programming Languages: A Functional Approach.	SIGMOD Conferen	database
726	SIGMOD Conference	Objects and Views.	Serge Abiteboul,Anthony J. Bonner	1991	Objects and Views.	SIGMOD Conferen	database
727	SIGMOD Conference	Using Multiversion Data for Non-interfering Execution of Write-only Transactions.	Divyakant Agrawal,V. Krishnamurthy	1991	Using Multiversion Data for Non-interfering Execution of Write-only Transactions.	SIGMOD Conferen	database
728	SIGMOD Conference	Version Management of Composite Objects in CAD Databases.	Rafi Ahmed,Shamkant B. Navathe	1991	Version Management of Composite Objects in CAD Databases.	SIGMOD Conferen	database
729	SIGMOD Conference	Updating Relational Databases through Object-Based Views.	Thierry Barsalou,Arthur M. Keller,Niki Siambela,Gio Wiederhold	1991	Updating Relational Databases through Object-Based Views.	SIGMOD Conferen	database
730	SIGMOD Conference	Spatial Priority Search: An Access Technique for Scaleless Maps.	Bruno Becker,Hans-Werner Six,Peter Widmayer	1991	Spatial Priority Search: An Access Technique for Scaleless Maps.	SIGMOD Conferen	database
731	SIGMOD Conference	Data Caching Tradeoffs in Client-Server DBMS Architectures.	Michael J. Carey,Michael J. Franklin,Miron Livny,Eugene J. Shekita	1991	Data Caching Tradeoffs in Client-Server DBMS Architectures.	SIGMOD Conferen	database
732	SIGMOD Conference	Nested Relation Based Database Knowledge Representation.	Qiming Chen,Yahiko Kambayashi	1991	Nested Relation Based Database Knowledge Representation.	SIGMOD Conferen	database
733	SIGMOD Conference	Effective Clustering of Complex Objects in Object-Oriented Databases.	Jia-bing R. Cheng,Ali R. Hurson	1991	Effective Clustering of Complex Objects in Object-Oriented Databases.	SIGMOD Conferen	database
734	SIGMOD Conference	Trait: An Attribute Management System for VLSI Design Objects.	Tzi-cker Chiueh,Randy H. Katz	1991	Trait: An Attribute Management System for VLSI Design Objects.	SIGMOD Conferen	database
735	SIGMOD Conference	Extracting Concurrency from Objects: A Methodology.	Panos K. Chrysanthis,S. Raghuram,Krithi Ramamritham	1991	Extracting Concurrency from Objects: A Methodology.	SIGMOD Conferen	database
736	SIGMOD Conference	Replica Control in Distributed Systems: An Asynchronous Approach.	Calton Pu,Avraham Leff	1991	Replica Control in Distributed Systems: An Asynchronous Approach.	SIGMOD Conferen	database
737	SIGMOD Conference	Set-Oriented Constructs: From Rete Rule Bases to Database Systems.	Douglas N. Gordin,Alexander J. Pasik	1991	Set-Oriented Constructs: From Rete Rule Bases to Database Systems.	SIGMOD Conferen	database
738	SIGMOD Conference	MMDB Reload Algorithms.	Le Gruenwald,Margaret H. Eich	1991	MMDB Reload Algorithms.	SIGMOD Conferen	database
739	SIGMOD Conference	New Directions For Uncertainty Reasoning In Deductive Databases.	Ulrich Güntzer,Werner Kießling,Helmut Thöne	1991	New Directions For Uncertainty Reasoning In Deductive Databases.	SIGMOD Conferen	database
740	SIGMOD Conference	An Extended Memoryless Inference Control Method: Accounting for Dependence in Table-level Controls.	S. C. Hansen,E. A. Unger	1991	An Extended Memoryless Inference Control Method: Accounting for Dependence in Table-level Controls.	SIGMOD Conferen	database
741	SIGMOD Conference	Error-Constraint COUNT Query Evaluation in Relational Databases.	Wen-Chi Hou,Gultekin Özsoyoglu,Erdogan Dogdu	1991	Error-Constraint COUNT Query Evaluation in Relational Databases.	SIGMOD Conferen	database
742	SIGMOD Conference	Incomplete Objects - A Data Model for Design and Planning Applications.	Tomasz Imielinski,Shamim A. Naqvi,Kumar V. Vadaparty	1991	Incomplete Objects - A Data Model for Design and Planning Applications.	SIGMOD Conferen	database
743	SIGMOD Conference	On the Propagation of Errors in the Size of Join Results.	Yannis E. Ioannidis,Stavros Christodoulakis	1991	On the Propagation of Errors in the Size of Join Results.	SIGMOD Conferen	database
744	SIGMOD Conference	Left-Deep vs. Bushy Trees: An Analysis of Strategy Spaces and its Implications for Query Optimization.	Yannis E. Ioannidis,Younkyung Cha Kang	1991	Left-Deep vs. Bushy Trees: An Analysis of Strategy Spaces and its Implications for Query Optimization.	SIGMOD Conferen	database
745	SIGMOD Conference	A Retrieval Technique for Similar Shapes.	H. V. Jagadish	1991	A Retrieval Technique for Similar Shapes.	SIGMOD Conferen	database
746	SIGMOD Conference	Towards a Multilevel Secure Relational Data Model.	Sushil Jajodia,Ravi S. Sandhu	1991	Towards a Multilevel Secure Relational Data Model.	SIGMOD Conferen	database
747	SIGMOD Conference	Efficient Assembly of Complex Objects.	Thomas Keller,Goetz Graefe,David Maier	1991	Efficient Assembly of Complex Objects.	SIGMOD Conferen	database
748	SIGMOD Conference	Function Materialization in Object Bases.	Alfons Kemper,Christoph Kilger,Guido Moerkotte	1991	Function Materialization in Object Bases.	SIGMOD Conferen	database
749	SIGMOD Conference	Segment Indexes: Dynamic Indexing Techniques for Multi-Dimensional Interval Data.	Curtis P. Kolovson,Michael Stonebraker	1991	Segment Indexes: Dynamic Indexing Techniques for Multi-Dimensional Interval Data.	SIGMOD Conferen	database
750	SIGMOD Conference	Language Features for Interoperability of Databases with Schematic Discrepancies.	Ravi Krishnamurthy,Witold Litwin,William Kent	1991	Language Features for Interoperability of Databases with Schematic Discrepancies.	SIGMOD Conferen	database
751	SIGMOD Conference	Fully Persistent B+-trees.	Sitaram Lanka,Eric Mays	1991	Fully Persistent B+-trees.	SIGMOD Conferen	database
752	SIGMOD Conference	Computers versus Common Sense.	Douglas B. Lenat	1991	Computers versus Common Sense.	SIGMOD Conferen	database
753	SIGMOD Conference	Starburst II: The Extender Strikes Back!	Guy M. Lohman,George Lapis,Tobin J. Lehman,Rakesh Agrawal,Roberta Cochrane,John McPherson,C. Mohan,Hamid Pirahesh,Jennifer Widom	1991	Starburst II: The Extender Strikes Back!	SIGMOD Conferen	database
754	SIGMOD Conference	An Optimistic Commit Protocol for Distributed Transaction Management.	Eliezer Levy,Henry F. Korth,Abraham Silberschatz	1991	An Optimistic Commit Protocol for Distributed Transaction Management.	SIGMOD Conferen	database
755	SIGMOD Conference	LLO: An Object-Oriented Deductive Language with Methods and Method Inheritance.	Yanjun Lou,Z. Meral Özsoyoglu	1991	LLO: An Object-Oriented Deductive Language with Methods and Method Inheritance.	SIGMOD Conferen	database
756	SIGMOD Conference	Optimization and Evaluation of Database Queries Including Embedded Interpolation Procedures.	Leonore Neugebauer	1991	Optimization and Evaluation of Database Queries Including Embedded Interpolation Procedures.	SIGMOD Conferen	database
757	SIGMOD Conference	Flexible Buffer Allocation Based on Marginal Gains.	Raymond T. Ng,Christos Faloutsos,Timos K. Sellis	1991	Flexible Buffer Allocation Based on Marginal Gains.	SIGMOD Conferen	database
758	SIGMOD Conference	HYDRO: A Heterogeneous Distributed Database System.	William Perrizo,Joseph Rajkumar,Prabhu Ram	1991	HYDRO: A Heterogeneous Distributed Database System.	SIGMOD Conferen	database
759	SIGMOD Conference	Glue-Nail: A Deductive Database System.	Geoffrey Phipps,Marcia A. Derr,Kenneth A. Ross	1991	Glue-Nail: A Deductive Database System.	SIGMOD Conferen	database
760	SIGMOD Conference	Aspects: Extending Objects to Support Multiple, Independent Roles.	Joel E. Richardson,Peter M. Schwarz	1991	Aspects: Extending Objects to Support Multiple, Independent Roles.	SIGMOD Conferen	database
761	SIGMOD Conference	Multi-Disk B-trees.	Bernhard Seeger,Per-Åke Larson	1991	Multi-Disk B-trees.	SIGMOD Conferen	database
762	SIGMOD Conference	A Non-deterministic Deductive Database Language.	Yeh-Heng Sheng	1991	A Non-deterministic Deductive Database Language.	SIGMOD Conferen	database
763	SIGMOD Conference	K: A High-Level Knowledge Base Programming Language for Advanced Database Applications.	Yuh-Ming Shyy,Stanley Y. W. Su	1991	K: A High-Level Knowledge Base Programming Language for Advanced Database Applications.	SIGMOD Conferen	database
764	SIGMOD Conference	Performance of B-Tree Concurrency Algorithms.	V. Srinivasan,Michael J. Carey	1991	Performance of B-Tree Concurrency Algorithms.	SIGMOD Conferen	database
765	SIGMOD Conference	Are Standards the Panacea for Heterogeneous Distributed DBMSs?	Clenn Thompson	1991	Are Standards the Panacea for Heterogeneous Distributed DBMSs?	SIGMOD Conferen	database
766	SIGMOD Conference	Managing Persistent Objects in a Multi-Level Store.	Michael Stonebraker	1991	This paper presents an architecture for a persistent object store in which multi-level storage is explicitly included. Traditionally. DBMSs have assumed that all accessible data resides on magnetic disk, and recently several researchers have begun to consider the possibility that significant amounts of data will occupy space m a main memory cache. We feel that object bases in which time critical objects reside in main memory, other objects are disk resident, and the remainder occupy tertiary memory. Moreover, it is possible that more than three levels will be present, and that some of these levels will be on remote hardware. This paper contains an architectural proposal addressing these needs along with a sketch of the required query optimizer.	SIGMOD Conferen	database
767	SIGMOD Conference	Space Optimization in the Bottom-Up Evaluation of Logic Programs.	S. Sudarshan,Divesh Srivastava,Raghu Ramakrishnan,Jeffrey F. Naughton	1991	Space Optimization in the Bottom-Up Evaluation of Logic Programs.	SIGMOD Conferen	database
768	SIGMOD Conference	A Stochastic Approach for Clustering in Object Bases.	Manolis M. Tsangaris,Jeffrey F. Naughton	1991	A Stochastic Approach for Clustering in Object Bases.	SIGMOD Conferen	database
769	SIGMOD Conference	Algebraic Support for Complex Objects with Arrays, Identity, and Inheritance.	Scott L. Vandenberg,David J. DeWitt	1991	Algebraic Support for Complex Objects with Arrays, Identity, and Inheritance.	SIGMOD Conferen	database
770	SIGMOD Conference	Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture.	Yongdong Wang,Lawrence A. Rowe	1991	Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture.	SIGMOD Conferen	database
771	SIGMOD Conference	Dynamic File Allocation in Disk Arrays.	Gerhard Weikum,Peter Zabback,Peter Scheuermann	1991	Dynamic File Allocation in Disk Arrays.	SIGMOD Conferen	database
772	SIGMOD Conference	Incremental Evaluation of Rules and its Relationship to Parallelism.	Ouri Wolfson,Hasanat M. Dewan,Salvatore J. Stolfo,Yechiam Yemini	1991	Incremental Evaluation of Rules and its Relationship to Parallelism.	SIGMOD Conferen	database
773	VLDB	Management Of Schema Evolution In Databases.	José Andany,Michel Léonard,Carole Palisser	1991	Management Of Schema Evolution In Databases.	VLDB	database
774	VLDB	Optimization for Spatial Query Processing.	Walid G. Aref,Hanan Samet	1991	Optimization for Spatial Query Processing.	VLDB	database
775	VLDB	A Relationship Mechanism for a Strongly Typed Object-Oriented Database Programming Language.	Antonio Albano,Giorgio Ghelli,Renzo Orsini	1991	A Relationship Mechanism for a Strongly Typed Object-Oriented Database Programming Language.	VLDB	database
776	VLDB	On Maintaining Priorities in a Production Rule System.	Rakesh Agrawal,Roberta Cochrane,Bruce G. Lindsay	1991	On Maintaining Priorities in a Production Rule System.	VLDB	database
777	VLDB	Algebraic Properties of Bag Data Types.	Joseph Albert	1991	Algebraic Properties of Bag Data Types.	VLDB	database
778	VLDB	A Model for Active Object Oriented Databases.	Catriel Beeri,Tova Milo	1991	A Model for Active Object Oriented Databases.	VLDB	database
779	VLDB	An Iterative Method for Distributed Database Design.	Rex Blankinship,Alan R. Hevner,S. Bing Yao	1991	An Iterative Method for Distributed Database Design.	VLDB	database
780	VLDB	Logic Programming Environments for Large Knowledge Bases: A Practical Perspective (Abstract).	Jorge B. Bocca	1991	Logic Programming Environments for Large Knowledge Bases: A Practical Perspective (Abstract).	VLDB	database
781	VLDB	Semantic Modeling of Object Oriented Databases.	Mokrane Bouzeghoub,Elisabeth Métais	1991	Semantic Modeling of Object Oriented Databases.	VLDB	database
782	VLDB	Effects of Database Size on Rule System Performance: Five Case Studies.	David A. Brant,Timothy Grose,Bernie J. Lofaso,Daniel P. Miranker	1991	Effects of Database Size on Rule System Performance: Five Case Studies.	VLDB	database
783	VLDB	Interoperability In Multidatabases: Semantic and System Issues (Panel).	Yuri Breitbart,Hector Garcia-Molina,Witold Litwin,Nick Roussopoulos,Hans-Jörg Schek,Gio Wiederhold	1991	Interoperability In Multidatabases: Semantic and System Issues (Panel).	VLDB	database
784	VLDB	Deriving Production Rules for Incremental View Maintenance.	Stefano Ceri,Jennifer Widom	1991	Deriving Production Rules for Incremental View Maintenance.	VLDB	database
785	VLDB	Kaleidoscope Data Model for An English-like Query Language.	Sang Kyun Cha,Gio Wiederhold	1991	Kaleidoscope Data Model for An English-like Query Language.	VLDB	database
786	VLDB	Dynamic Constraints and Object Migration.	Jianwen Su	1991	Dynamic Constraints and Object Migration.	VLDB	database
787	VLDB	A Temporal Knowledge Representation Model OSAM*/T and Its Query Language OQL/T.	Stanley Y. W. Su,Hsin-Hsing M. Chen	1991	A Temporal Knowledge Representation Model OSAM*/T and Its Query Language OQL/T.	VLDB	database
788	VLDB	A Formalism for Extended Transaction Model.	Panos K. Chrysanthis,Krithi Ramamritham	1991	A Formalism for Extended Transaction Model.	VLDB	database
789	VLDB	Rule Management in Object Oriented Databases: A Uniform Approach.	Oscar Díaz,Norman W. Paton,Peter M. D. Gray	1991	Rule Management in Object Oriented Databases: A Uniform Approach.	VLDB	database
790	VLDB	Active Database Systems (Abstract).	Umeshwar Dayal,Klaus R. Dittrich	1991	Active Database Systems (Abstract).	VLDB	database
791	VLDB	A Transactional Model for Long-Running Activities.	Umeshwar Dayal,Meichun Hsu,Rivka Ladin	1991	A Transactional Model for Long-Running Activities.	VLDB	database
792	VLDB	A Methodology for the Design and Transformation of Conceptual Schemas.	Christoph F. Eick	1991	A Methodology for the Design and Transformation of Conceptual Schemas.	VLDB	database
793	VLDB	An Evaluation of Non-Equijoin Algorithms.	David J. DeWitt,Jeffrey F. Naughton,Donovan A. Schneider	1991	An Evaluation of Non-Equijoin Algorithms.	VLDB	database
794	VLDB	Conecptual Modeling Using and Extended E-R Model (Abstract).	Ramez Elmasri	1991	Conecptual Modeling Using and Extended E-R Model (Abstract).	VLDB	database
795	VLDB	Cooperative Access to Data and Knowledge Baes (Abstract).	Robert Demolombe	1991	Cooperative Access to Data and Knowledge Baes (Abstract).	VLDB	database
796	VLDB	The Power of Methods With Parallel Semantics.	Karl Denninghoff,Victor Vianu	1991	The Power of Methods With Parallel Semantics.	VLDB	database
797	VLDB	Predictive Load Control for Flexible Buffer Allocation.	Christos Faloutsos,Raymond T. Ng,Timos K. Sellis	1991	Predictive Load Control for Flexible Buffer Allocation.	VLDB	database
798	VLDB	Ode as an Active Database: Constraints and Triggers.	Narain H. Gehani,H. V. Jagadish	1991	Ode as an Active Database: Constraints and Triggers.	VLDB	database
799	VLDB	Optimizing Random Retrievals from CLV format Optical Disks.	Daniel Alexander Ford,Stavros Christodoulakis	1991	Optimizing Random Retrievals from CLV format Optical Disks.	VLDB	database
800	VLDB	Object Placement in Parallel Hypermedia Systems.	Shahram Ghandeharizadeh,Luis Ramos,Zubair Asad,Waheed Qureshi	1991	Object Placement in Parallel Hypermedia Systems.	VLDB	database
801	VLDB	Temporal Logic & Historical Databases.	Dov M. Gabbay,Peter McBrien	1991	Temporal Logic & Historical Databases.	VLDB	database
802	VLDB	Semantic Queries with Pictures: The VIMSYS Model.	Amarnath Gupta,Terry E. Weymouth,Ramesh Jain	1991	Semantic Queries with Pictures: The VIMSYS Model.	VLDB	database
803	VLDB	A Performance Evaluation of Multi-Level Transaction Management.	Christof Hasse,Gerhard Weikum	1991	A Performance Evaluation of Multi-Level Transaction Management.	VLDB	database
804	VLDB	Adaptive Load Control in Transaction Processing Systems.	Hans-Ulrich Heiss,Roger Wagner	1991	Adaptive Load Control in Transaction Processing Systems.	VLDB	database
805	VLDB	Handling Data Skew in Multiprocessor Database Computers Using Partition Tuning.	Kien A. Hua,Chiang Lee	1991	Handling Data Skew in Multiprocessor Database Computers Using Partition Tuning.	VLDB	database
806	VLDB	Experimental Evaluation of Real-Time Optimistic Concurrency Control Schemes.	Jiandong Huang,John A. Stankovic,Krithi Ramamritham,Donald F. Towsley	1991	Owing to its potential for a high degree of parallelism, optimistic concurrency control is expected to perform better than two-phase locking when integrated with priority-driven CPU scheduling in real-time database systems. In this paper, we examine the overall effects and the impact of the overheads involved in implementing real-time optimistic concurrency control. Using a locking mech- anism to ensure the correctness of the implementation, we develop a set of optimistic concurrency control protocols which possess the properties of deadlock freedom and a high degree of paral- lelism. Through experiments, we investigate, in depth, the effect of the locking mechanism on the performance of optimistic concurrency control protocols. We show that due to blocking, the performance of the protocols is sensitive to priority inversions but not to resource utilization. Fur- ther, in contrast to recent simulation studies, our experimental results show that with respect to meeting transaction deadlines, the optimistic approach may not always outperform the two-phase locking scheme which aborts the lower priority transaction to resolve a conflict. We also show that integrated with a weighted priority scheduling algorithm, optimistic concurrency control exhibits greater flexibility in coping with the starvation problem (for longer transactions) than two-phase locking. Our performance studies indicate that the physical implementation has a significant impact on the performance of real-time concurrency control protocols and is hence an important aspect in the study of concurrency control.	VLDB	database
807	VLDB	Language Constructs for Programming Active Databases.	Richard Hull,Dean Jacobs	1991	Language Constructs for Programming Active Databases.	VLDB	database
808	VLDB	Adaptive Locking Strategies in a Multi-node Data Sharing Environment.	Ashok M. Joshi	1991	Adaptive Locking Strategies in a Multi-node Data Sharing Environment.	VLDB	database
809	VLDB	Database Technologies for the 90's and Beyond (Panel).	Magdi N. Kamel,Umeshwar Dayal,Rakesh Agrawal,Douglas Tolbert,Gilbert Vidal	1991	Database Technologies for the 90's and Beyond (Panel).	VLDB	database
810	VLDB	Data and Knowledge Bases for Genome Mapping: What Lies Ahead? (Panel).	Nabil Kamel,M. Delobel,Thomas G. Marr,Robert Robbins,Jean Thierry-Mieg,Akira Tsugita	1991	Data and Knowledge Bases for Genome Mapping: What Lies Ahead? (Panel).	VLDB	database
811	VLDB	Solving Domain Mismatch and Schema Mismatch Problems with an Object-Oriented Database Programming Language.	William Kent	1991	Solving Domain Mismatch and Schema Mismatch Problems with an Object-Oriented Database Programming Language.	VLDB	database
812	VLDB	Extending the Search Strategy in a Query Optimizer.	Rosana S. G. Lanzelotte,Patrick Valduriez	1991	Extending the Search Strategy in a Query Optimizer.	VLDB	database
813	VLDB	Optimization of Multi-Way Join Queries for Parallel Execution.	Hongjun Lu,Ming-Chien Shan,Kian-Lee Tan	1991	Optimization of Multi-Way Join Queries for Parallel Execution.	VLDB	database
814	VLDB	Safe Referential Structures in Relational Databases.	Victor M. Markowitz	1991	Safe Referential Structures in Relational Databases.	VLDB	database
815	VLDB	Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment.	C. Mohan,Inderpal Narang	1991	Recovery and Coherency-Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment.	VLDB	database
816	VLDB	Integrity Constraints Checking In Deductive Databases.	Antoni Olivé	1991	Integrity Constraints Checking In Deductive Databases.	VLDB	database
817	VLDB	Performance Analysis of a Load Balancing Hash-Join Algorithm for a Shared Memory Multiprocessor.	Edward Omiecinski	1991	Performance Analysis of a Load Balancing Hash-Join Algorithm for a Shared Memory Multiprocessor.	VLDB	database
818	VLDB	Distributed Database Management: Current State-of-the-Art, Unsolved Problems, New Issues (Abstract).	M. Tamer Özsu	1991	Distributed Database Management: Current State-of-the-Art, Unsolved Problems, New Issues (Abstract).	VLDB	database
819	VLDB	Fido: A Cache That Learns to Fetch.	Mark Palmer,Stanley B. Zdonik	1991	Accurately fetching data objects or pages in advance of their use is a powerful means of improving performance, but this capability has been difficult to realize. Current OODBs maintain object caches that employ fetch and replacement policies derived from those used for virtual-memory demand paging. These policies usually assume no knowledge of the future. Object cache managers often employ demand fetching combined with data clustering to effect prefetching, but cluster prefetching can be ineffective when the access patterns serviced are incompatible. This paper describes FIDO, an experimental {\em predictive cache} that predicts access for individuals during a session by employing an associative memory to assimilate regularities in the access pattern of an individual over time. By dint of continual training, the associative memory adapts to changes in the database and in the user''s access pattern, enabling on-line access predictions for prefetching. We discuss two salient components of Fido: \begin{enumerate} \item MLP, a replacement policy for managing pre-fetched objects. \item Estimating Prophet, an associative memory that recognizes patterns in access sequences adaptively over time and provides on-line predictions used for prefetching. \end{enumerate} We then present some early simulation thatts which suggest that predictive caching works well, especially for sequential access patterns, and conclude that predictive caching holds great promise.	VLDB	database
820	VLDB	A Functional Programming Approach to Deductive Databases.	Alexandra Poulovassilis,Carol Small	1991	A Functional Programming Approach to Deductive Databases.	VLDB	database
821	VLDB	Real-Time Databases (Panel).	Krithi Ramamritham,Sang Hyuk Son,Alejandro P. Buchmann,Klaus R. Dittrich,C. Mohan	1991	Real-Time Databases (Panel).	VLDB	database
822	VLDB	A Framework for Automating Physical Database Design.	Steve Rozen,Dennis Shasha	1991	A Framework for Automating Physical Database Design.	VLDB	database
823	VLDB	Alert: An Architecture for Transforming a Passive DBMS into an Active DBMS.	Ulf Schreier,Hamid Pirahesh,Rakesh Agrawal,C. Mohan	1991	Alert: An Architecture for Transforming a Passive DBMS into an Active DBMS.	VLDB	database
824	VLDB	Data Management for Large Rule Systems.	Arie Segev,J. Leon Zhao	1991	Data Management for Large Rule Systems.	VLDB	database
825	VLDB	Federated Database Systems for Managing Distributed, Heterogeneous, and Autonomous Databases.	Amit P. Sheth	1991	Federated Database Systems for Managing Distributed, Heterogeneous, and Autonomous Databases.	VLDB	database
826	VLDB	A Metadata Approach to Resolving Semantic Conflicts.	Michael Siegel,Stuart E. Madnick	1991	A Metadata Approach to Resolving Semantic Conflicts.	VLDB	database
827	VLDB	Integrating Implicit Answers with Object-Oriented Queries.	Hava T. Siegelmann,B. R. Badrinath	1991	Integrating Implicit Answers with Object-Oriented Queries.	VLDB	database
828	VLDB	Cooperative Database Design (Panel).	Stefano Spaccapietra,Shamkant B. Navathe,Erich J. Neuhold,Amit P. Sheth	1991	Cooperative Database Design (Panel).	VLDB	database
829	VLDB	Aggregation and Relevance in Deductive Databases.	S. Sudarshan,Raghu Ramakrishnan	1991	Aggregation and Relevance in Deductive Databases.	VLDB	database
830	VLDB	Using Write Protected Data Structures To Improve Software Fault Tolerance in Highly Available Database Management Systems.	Mark Sullivan,Michael Stonebraker	1991	Using Write Protected Data Structures To Improve Software Fault Tolerance in Highly Available Database Management Systems.	VLDB	database
831	VLDB	A Taxonomy and Performance Model of Data Skew Effects in Parallel Joins.	Christopher B. Walton,Alfred G. Dale,Roy M. Jenevein	1991	A Taxonomy and Performance Model of Data Skew Effects in Parallel Joins.	VLDB	database
832	VLDB	Implementing Set-Oriented Production Rules as an Extension to Starburst.	Jennifer Widom,Roberta Cochrane,Bruce G. Lindsay	1991	Implementing Set-Oriented Production Rules as an Extension to Starburst.	VLDB	database
833	VLDB	Efficiency of Nested Relational Document Database Systems.	Justin Zobel,James A. Thom,Ron Sacks-Davis	1991	Efficiency of Nested Relational Document Database Systems.	VLDB	database
834	SIGMOD Record	Temporal Relations in Geographic Information Systems: A Workshop at the University of Maine.	Renato Barrera,Andrew U. Frank,Khaled K. Al-Taha	1991	A workshop on temporal relations in Geographic Information Systems (GIS) was held on October 12-13, 1990, at the University of Maine. The meeting, sponsored by the National Center for Geographic Information and Analysis (NCGIA), gathered specialists on Geography, GIS, and Computer Science to discuss users' requirements of temporal GIS and to identify the corresponding research issues.	SIGMOD Record	database
835	SIGMOD Record	A Complete Identity Set for Codd Algebras.	H. W. Buff	1991	A Complete Identity Set for Codd Algebras.	SIGMOD Record	database
836	SIGMOD Record	Data Manipulation in Heterogeneous Databases.	Abhirup Chatterjee,Arie Segev	1991	Many important information systems applications require access to data stored in multiple heterogeneous databases. This paper examines a problem in interdatabase data manipulation within a heterogeneous environment, where conventional techniques are no longer useful. To solve the problem, a broader definition for join operator is proposed. Also, a method to probabilistically estimate the accuracy of the join is discussed.	SIGMOD Record	database
837	SIGMOD Record	The Indiana Center for Database Systems.	Judith Copler	1991	The Indiana Center for Database Systems.	SIGMOD Record	database
838	SIGMOD Record	Minimal Covers Revisited: Correct and Efficient Algorithms.	Jim Diederich	1991	In [1] Nummenmaa and Tanisch show that the algorithm in [2] for computing minimal covers is incorrect even though it purports to correct the algorithms in [3-6]. As they illustrate with F = { A B &rarr; C}, the algorithm in [2] allows B to be eliminated as an extraneous attribute since the dependency AB &rarr; C is implied by A &rarr; C using augmentation. Thus F is replaced by F&prime; = [A &rarr; C], which is clearly not equivalent to F. The problematic step of the algorithm in [2] that allows this to occur is Consider each dependency X &rarr; A in some order. If Z is a subset of X such that F is contained in the closure of (F - {X &rarr; A}) &cup; {Z &rarr; A], then immediately replace X &rarr; A by Z &rarr; A in F. This step continues until no left side of any dependency in F can be reduced	SIGMOD Record	database
839	SIGMOD Record	Interoperability and Object Identity.	Frank Eliassen,Randi Karlsen	1991	Data model transparency can be achieved by providing a canonical language format for the definition and seamless manipulation of multiple autonomous information bases. In this paper we assume a canonical data and computational model combining the function and object-oriented paradigms. We investigate the concept of identity as a property of an object and the various ways this property is supported in existing databases, in relation to the object-oriented canonical data model. The canonical data model is the tool for combining and integrating preexisting syntactical homogeneous, but semantical heterogeneous data types into generalized unifying data types. We identify requirements for object identity in federated systems, and discuss problems of object identity and semantical object replication arising from this new abstraction level. We argue that a strong notion of identity at the federated level can only be acheived by weakening strict autonomy requirements of the component information bases. Finally we discuss various solutions to this problem that differ in their requirements with repect to giving up autonomy.	SIGMOD Record	database
840	SIGMOD Record	Technique for Universal Quantification in SQL.	Claudio Fratarcangeli	1991	Universal quantification is expressed in ANSI SQL with negated existential quantification because there is no direct support for universal quantification in ANSI SQL. However, the lack of explicit support for universal quantification diminishes the userfriendliness of the language because some queries are expressed more naturally using universal quantification than they are using negated existential quantification. It is the intent of this paper to describe a technique to facilitate the construction of universal quantification queries in ANSI SQL. The technique is based upon a proposed extension to ANSI SQL to incorporate explicit general support for universal quantification.	SIGMOD Record	database
841	SIGMOD Record	The Metadatabase Project at Rensselaer.	Cheng Hsu	1991	The Metadatabase project is a multi-year research effort at Rensselaer Polytechnic Institute. Sponsored by industry (ALCOA, DEC, GE, CM, IBM and other) through Rensselaer's Computer Integrated Manufacturing Program, this project seeks to develop novel concepts, methods and techniques for achieving information integration across major functional systems pertaining to computerized manufacturing enterprises. Thus, the metadatabase model emcompasses the generic tasks of heterogeneous, distributed, aand autonomous databases administration, but also includes information resources management and integration of concurrent (functional) systems. The model entails (1) an integrated data and knowledge modeling and representation method; (2) an online kernel (the metadatabase) for information modeling and management; (3) metadatabase assisted global query formulation and processing; (4) a concurrent architectural whereby global synergies are achieved through (distributed) metadata management rather than synchronization of (distributed) database processing; and (5) a theory of information requirements for integration. A metadatabase prototype was recently demonstrated to the industrial sponsors. The basic concept of the metadatabase model is discussed in this paper.	SIGMOD Record	database
842	SIGMOD Record	Semantic vs. Structural Resemblance of Classes.	Peter Fankhauser,Martin Kracker,Erich J. Neuhold	1991	We present an approach to determine the similarity of classes which utilized fuzzy and incomplete terminological knowledge together with schema knowledge. We clearly distinguish between semantic similarity determining the degree of resemblance according to real world semantics, and structural correspondence explaining how classes can actually be interrelated. To compute the semantic similarity we introduce the notion of semantic relevance and apply fuzzy set theory to reason about both terminological knowledge and schema knowledge.	SIGMOD Record	database
843	SIGMOD Record	On the Semantic Equivalence of Heterogeneous Representations in Multimodel Multidatabase Systems.	Dipayan Gangopadhyay,Thierry Barsalou	1991	On the Semantic Equivalence of Heterogeneous Representations in Multimodel Multidatabase Systems.	SIGMOD Record	database
844	SIGMOD Record	The Design of the Triton Nested Relational Database System.	Tina M. Harvey,Craig W. Schnepf,Mark A. Roth	1991	Unique database requirements of applications such as computer-aided design (CAD), computer-aided software engineering(CASE), and office information systems(OIC) have driven the development of new data models and database systems based on these new models. In particular, the goal of these new database systems is to exploit the advantages of complex data models that are more efficient (in terms of time and space) than their relational counterparts. In this paper, we describe the design and implementation of the Triton nested relational database system, a prototype system based on the nested relational data model. Triton is intended to be used as the backend storage and access component of the aforementioned applications. This paper describes the architecture of the Triton system, and compares the performance of the nested relational model versus the relational model using Triton. In addition, this paper evaluates the EXODUS extensible database toolkit used in the development of the Triton system including key features of the persistent programming language E and the EXODUS storage manager.	SIGMOD Record	database
845	SIGMOD Record	Structure and Semantics in OODB Class Specifications.	James Geller,Yehoshua Perl,Erich J. Neuhold	1991	A class specification contains both structural aspects and semantic aspects. We introduce a mathematically based distinction between structural and semantic aspects. We show how this distinction is used to identify all structural aspects of a class specification to be included in the object type of a class. The model obtained is called the Dual Model due to the separation of structure and semantics in the class specification. Advantages of the separation of structure and semantics have been discussed in previous papers and include separate hierarchies for structural and semantic aspects, refined inheritance mechanisms, support of physical database design and structural integration which is impossible in other models.	SIGMOD Record	database
846	SIGMOD Record	Handling Missing Data by Using Stored Truth Values.	G. H. Gessert	1991	This paper proposes a method for handling inapplicable and unknown missing data. The method is based on: (1) storing default values (instead of null values) in place of missing data, (2) storing truth values that describe the logical status of the default values in corresponding fields of corresponding tables. Four valued logic is used so that the logical status of the default data values can be described as, not just true or false, but also as inapplicable or unknown. This method, in contrast to the &ldquo;hidden byte&rdquo; approach, has two important advantages: (1) Because the logical status of all data is represented explicitly in tables, all 4-valued operations can be handled via a 2-valued data manipulation language, such as SQL. Language extensions for handling missing data (e.g., &ldquo;IS NULL&rdquo;) are not necessary. (2) Because data fields always contain a default value (as opposed to a null value or mark), it is possible to do arithmetic across missing data and to interpret the logical status of the result by means of logical operations on the corresponding stored truth values.	SIGMOD Record	database
847	SIGMOD Record	Database Research at the IBM Almaden Research Center.	Laura M. Haas,Patricia G. Selinger	1991	Database Research at the IBM Almaden Research Center.	SIGMOD Record	database
848	SIGMOD Record	An Anatomy of the Information Resource Semantic Abstraction.	Leonid A. Kalinichenko	1991	Semantic abstraction mapping establishing a correspondence between an information resource and an application is considered to be a basic notion providing for the study of semantic interoperability of heterogeneous information resources. The structure and necessary properties of a resource class application abstraction are considered. Intensional model-based properties of the abstraction mapping are introduced as provable conditions of a class assertion abstraction and an operation concretization	SIGMOD Record	database
849	SIGMOD Record	Continuous Media Data Manegement.	Kyoji Kawagoe	1991	Continuous Media Data Manegement.	SIGMOD Record	database
850	SIGMOD Record	The Breakdown of the Information Model in Multi-Database Systems.	William Kent	1991	The Breakdown of the Information Model in Multi-Database Systems.	SIGMOD Record	database
851	SIGMOD Record	First Order Normal Form for Relational Databases and Multidatabases.	Witold Litwin,Mohammad A. Ketabchi,Ravi Krishnamurthy	1991	First Order Normal Form for Relational Databases and Multidatabases.	SIGMOD Record	database
852	SIGMOD Record	Research Directions in Knowledge Discovery.	Ravi Krishnamurthy,Tomasz Imielinski	1991	Research Directions in Knowledge Discovery.	SIGMOD Record	database
853	SIGMOD Record	Bibliography on Temporal Databases.	Michael D. Soo	1991	Bibliography on Temporal Databases.	SIGMOD Record	database
854	SIGMOD Record	The Third-Generation/OODBMS Manifesto, Commercial version.	Frank Manola	1991	The Third-Generation/OODBMS Manifesto, Commercial version.	SIGMOD Record	database
855	SIGMOD Record	Database Research at HP Labs.	Marie-Anne Neimat,Ming-Chien Shan	1991	Database Research at HP Labs.	SIGMOD Record	database
856	SIGMOD Record	A Functional Model for Macro-Databases.	Maurizio Rafanelli,Fabrizio L. Ricci	1991	Recently there have been numerous proposals aimed at correcting the deficiency in existing database models to manipulate macro data (such as summary tables). The authors propose a new functional model, Mefisto, based on the definition of a new data structure, the &ldquo;statistical entity&rdquo;, and on a set of operations capable of manipulating this data structure by operating at metadata level.	SIGMOD Record	database
857	SIGMOD Record	Research Areas Related to Practical Problems in Automated Database Design.	David S. Reiner	1991	Research Areas Related to Practical Problems in Automated Database Design.	SIGMOD Record	database
858	SIGMOD Record	research at Altaïr.	Philippe Richard	1991	research at Altaïr.	SIGMOD Record	database
859	SIGMOD Record	Some Further Analysis of the Essential Blocking Recurrence.	John T. Robinson	1991	In previous work,1 a random graph model of concurrency control was developed, in which there are n concurrent transactions (represented as vertices of a graph), and where for each pair of transactions (vertices), a conflict (edge between the vertices) initially occurs independently with probability p. Given such a graph, a scheduling function selects a subset of transactions to complete based on the conflicts and possibly on an ordering of the transactions. At the end of each unit of time, the transactions selected by the scheduling function to complete are removed from the graph, and are replaced by new transactions from a transaction sequence. For each pair of transactions in the new graph, if the transactions were both in the previous graph then a conflict occurs between them if and only if there was a conflict in the previous graph; otherwise one or both of the transactions are new and a conflict occurs independently with probability p.	SIGMOD Record	database
860	SIGMOD Record	Modern Client-Server DBMS Architectures.	Nick Roussopoulos,Alex Delis	1991	In this paper, we describe three Client-Server DBMS architectures. We discuss their functional components and provide an overview of their performance characteristics.	SIGMOD Record	database
861	SIGMOD Record	Suitability of Data Models as Canonical Models for Federated Databases.	Fèlix Saltor,Malú Castellanos,Manuel García-Solaco	1991	Suitability of Data Models as Canonical Models for Federated Databases.	SIGMOD Record	database
862	SIGMOD Record	Spatial Database Access Methods.	Betty Salzberg,David B. Lomet	1991	In the discussion of research issues in spatial databases (SIGMOD Record vol. 19, no. 4, Dec 1990) we stated the need for a robust framework for analytical comparison of a broad range of spatial access methods. The utility of such a comparison, even of very closely related access methods, was shown in [FALO87]. A necessary precondition for a meaningful analytical comparison is the existence of strong analytical results for individual access methods. In the following paper, Salzberg and Lomet take the worst case analytical results on fan-out and average storage utilization they obtained for their hB-tree [LOME89,LOME90] and extend the analysis to another robust method, Z-order encoding [OREN84]. We think this paper is a start on the comparative assessment of access methods based on analytical results. We hope to see future work extend the framework beyond worst case analysis, and to other access methods as well.	SIGMOD Record	database
863	SIGMOD Record	Conflicts and Correspondence Assertions in Interoperable Databases.	Stefano Spaccapietra,Christine Parent	1991	Conflicts and Correspondence Assertions in Interoperable Databases.	SIGMOD Record	database
864	SIGMOD Record	Semantic Issues in Multidatabase Systems - Preface by the Special Issue Editor.	Amit P. Sheth	1991	Semantic Issues in Multidatabase Systems - Preface by the Special Issue Editor.	SIGMOD Record	database
865	SIGMOD Record	Context Interchange: Sharing the Meaning of Data.	Michael Siegel,Stuart E. Madnick	1991	Context Interchange: Sharing the Meaning of Data.	SIGMOD Record	database
866	SIGMOD Record	An Outline of MQL.	Victor J. Streeter	1991	An Outline of MQL.	SIGMOD Record	database
867	SIGMOD Record	A Note on the Strategy Space of Multiway Join Query Optimization Problem in Parallel Systems.	Kian-Lee Tan,Hongjun Lu	1991	In this short note, we estimate the search space of optimizing multiway join queries in multiprocessor computer systems, i.e. the number of possible query execution plans that need to be considered.	SIGMOD Record	database
868	SIGMOD Record	A Modular and Open Object-Oriented Database System.	Satish M. Thatte	1991	On 30 August 1990, Texas Instruments Incorporated, Dallas, TX was awarded a three year contract (Contract No. DAAB07-90-C-B920) to develop a modular and open object-oriented database system. The contract is funded by DARPA/ISTO and is being managed by the U.S. Army, CECOM, Fort Monmouth, N.J. The contract is being executed at TI's Information Technologies Laboratory, Computer Science Center, Dallas, Texas. So far, we have received an outstanding response from interested parties (database research community, OODB application developers, OODB builders) to our contract award announcement. This communication is a collection of most commonly asked questions and answers to them.	SIGMOD Record	database
869	SIGMOD Record	Practitioner Problems in Need of Database Research.	Gomer Thomas	1991	The bottlenecks between research and product development are well known. It typically takes a very long time for ideas coming out of research labs to make their way into products, and developers often face practical problems which do not seem to be addressed by currently available research results. The term &ldquo;technology transfer&rdquo; is often used to describe the process of overcoming these bottlenecks.	SIGMOD Record	database
870	SIGMOD Record	Centralized Concurrency Control Methods for High-End TP.	Alexander Thomasian	1991	Centralized Concurrency Control Methods for High-End TP.	SIGMOD Record	database
871	SIGMOD Record	Some Recent Developments in Deductive Databases.	Shalom Tsur	1991	Some Recent Developments in Deductive Databases.	SIGMOD Record	database
872	SIGMOD Record	Resolving Semantic Heterogeneity Through the Explicit Representation of Data Model Semantics.	Susan Darling Urban,Jian Wu	1991	Resolving Semantic Heterogeneity Through the Explicit Representation of Data Model Semantics.	SIGMOD Record	database
873	SIGMOD Record	Semantic Heterogeneity as a Result of Domain Evolution.	Vincent Ventrone,Sandra Heiler	1991	Semantic Heterogeneity as a Result of Domain Evolution.	SIGMOD Record	database
874	SIGMOD Record	Bibliography on Object-Oriented Database Management.	Gottfried Vossen	1991	Bibliography on Object-Oriented Database Management.	SIGMOD Record	database
875	SIGMOD Record	Data/Knowledge Packets as a Means of Supporting Semantic Heterogeneity in Multidatabase Systems.	Doyle Weishar,Larry Kerschberg	1991	Semantic heterogeneiry in heterogeneous autonomous databases poses problems in instance matches, units conversion (value interpretation), contextual and structural mismatches, etc. In this work we examine some of the research issues in semantic heterogeniety and propose a novel architecture for resolving such problems. The approach involves the use of Artifical Intelligence tools and techniques to construct &ldquo;domain models,&rdquo; that is data and knowledge representations of the constituent databases and an overall domain model of the semantic interactions among the databases. These domain models are represented as knowledge sources (KSs) in a blackboard architecture. This architecture lends itself to an opportunistic approach to query processing and goal-directed problem solving. We introduce the notion of Data/Knowledge Packets as a means of supporting both operational and structural semantic heterogeneity.	SIGMOD Record	database
876	SIGMOD Record	Funding for Small US Businesses and from DARPA and NASA.	Marianne Winslett	1991	This column is the first of a regular series describing database funding programs in the United States and abroad. I plan to include profiles of major funding agencies and programs, major efforts underway, new calls for proposals, and the outcomes of funding initiatives. I welcome submissions of relevant material; they can be sent to winslett@cs.uiuc.edu. In this issue, I describe funding in the database area for innovative research in small US businesses, and new requests for proposals from DARPA and from NASA.	SIGMOD Record	database
877	SIGMOD Record	User Surveys on Database Research Needs in Finland.	Antoni Wolski	1991	User Surveys on Database Research Needs in Finland.	SIGMOD Record	database
878	SIGMOD Record	Semantic Heterogeneity in Distributed Geographic Databases.	Michael F. Worboys,S. Misbah Deen	1991	This paper considers the special problems of semantic heterogeneity in a distributed system of databases containing spatially referenced information. Two forms of semantic heterogeneity are defined. Generic semantic heterogeneity arises when nodes are using different generic conceptual models of the spatial information. Contextual semantic heterogeneity is caused by the particular local environmental conditions at nodes. It is contextual heterogeneity which is especially the consideration with geographic databases and to which the paper devotes most attention. Two possible solutions are proposed, one founded on transforming processors between models and a second using a canonical model which is a generalization of existing generic spatial models.	SIGMOD Record	database
879	SIGMOD Record	Determining Relationships among Names in Heterogeneous Databases.	Clement T. Yu,Biao Jia,Wei Sun,Son Dao	1991	Determining Relationships among Names in Heterogeneous Databases.	SIGMOD Record	database
880	SIGMOD Record	A More General Model For Handlinh Missing Information In Relational DataBases Using A 3-Valued Logic.	Kwok-bun Yue	1991	Codd proposed the use of two interpretations of nulls to handle missing information in relational databases that may lead to a 4-valued logic [Codd86, Codd87]. In a more general model, three interpretations of nulls are necessary [Roth, Zani]. Without simplification, this may lead to a 7-valued logic, which is too complicated to be adopted in relational databases. For such a model, there is no satisfactory simplification to a 4-valued logic. However, by making a straightforward simplification and using some proposed logical functions, a 3-valued logic can handle all three interpretations.	SIGMOD Record	database
881	Artificial Intelligence in Medicine	Support of multilingual medical research.	R. F. Walters,C. Zhang	1991	Support of multilingual medical research.	Artificial Inte	medical
882	Artificial Intelligence in Medicine	Utilizing detailed anatomical knowledge for hypothesis formation and hypothesis testing in rheumatological decision support.	Werner Horn	1991	Utilizing detailed anatomical knowledge for hypothesis formation and hypothesis testing in rheumatological decision support.	Artificial Inte	medical
883	Artificial Intelligence in Medicine	Temporal query processing with indefinite information.	Peter van Beek	1991	Temporal query processing with indefinite information.	Artificial Inte	medical
884	Artificial Intelligence in Medicine	Solving quality assurance problems with object scripting languages.	Jules J. Berman	1991	Solving quality assurance problems with object scripting languages.	Artificial Inte	medical
885	Artificial Intelligence in Medicine	PROLOG. Grundlagen und anwendungen, zweite überarbeitete und erweiterte auflage: H. Kleine Büning and S. Schmitgen, (B.G. Teubner, Stuttgart, 1988) 311 pp., softcover, DM 38.00.	Christian E. Dralle	1991	PROLOG. Grundlagen und anwendungen, zweite überarbeitete und erweiterte auflage: H. Kleine Büning and S. Schmitgen, (B.G. Teubner, Stuttgart, 1988) 311 pp., softcover, DM 38.00.	Artificial Inte	medical
886	Artificial Intelligence in Medicine	Heterogeneous knowledge representation using a finite automaton and first order logic: a case study in electromyography.	Vincent Rialle,Annick Vila,Yves Besnard	1991	Heterogeneous knowledge representation using a finite automaton and first order logic: a case study in electromyography.	Artificial Inte	medical
887	Artificial Intelligence in Medicine	An expert system for the interpretation of full blood counts and blood smears in a hematology laboratory.	C. Janse Tolmie,Johan P. Du Plessis,P. N. Badenhorst	1991	An expert system for the interpretation of full blood counts and blood smears in a hematology laboratory.	Artificial Inte	medical
888	Artificial Intelligence in Medicine	Automatically analyzing a steadily beating ventricle's iterative behavior over time.	Alexander S. Yeh	1991	Automatically analyzing a steadily beating ventricle's iterative behavior over time.	Artificial Inte	medical
889	Artificial Intelligence in Medicine	Classification of electrocardiographic signals: a fuzzy pattern matching approach.	Witold Pedrycz,Giovanni Bortolan,Rosanna Degani	1991	Classification of electrocardiographic signals: a fuzzy pattern matching approach.	Artificial Inte	medical
890	Artificial Intelligence in Medicine	Programmieren in prolog: W.F. Clocksin and C.S. Mellish, (Springer-Verlag, Berlin, 1990) XIV + 331 pp., 43 figures, softcover, DM 48.00.	Christian E. Dralle	1991	Programmieren in prolog: W.F. Clocksin and C.S. Mellish, (Springer-Verlag, Berlin, 1990) XIV + 331 pp., 43 figures, softcover, DM 48.00.	Artificial Inte	medical
891	Artificial Intelligence in Medicine	An introduction to programming in prolog: Patrick Saint-Dizier, (Springer-Verlag, New York, 1990) XI + 184 pp., 44 figures, softcover, DM 48.00.	Christian E. Dralle	1991	An introduction to programming in prolog: Patrick Saint-Dizier, (Springer-Verlag, New York, 1990) XI + 184 pp., 44 figures, softcover, DM 48.00.	Artificial Inte	medical
892	Artificial Intelligence in Medicine	Flexible reasoning about patient management using multiple models.	William J. Long	1991	Flexible reasoning about patient management using multiple models.	Artificial Inte	medical
893	Artificial Intelligence in Medicine	Medical temporal reasoning.	Elpida T. Keravnou	1991	Medical temporal reasoning.	Artificial Inte	medical
894	Artificial Intelligence in Medicine	Diagnosis: Philosophical and medical perspectives : Nathaniel Laor and Joseph Agassi, (Kluwer, Dordrecht, 1990) XVIII + 262 pp., hardcover, US $ 68.00.	Luc P. Lindström	1991	Diagnosis: Philosophical and medical perspectives : Nathaniel Laor and Joseph Agassi, (Kluwer, Dordrecht, 1990) XVIII + 262 pp., hardcover, US $ 68.00.	Artificial Inte	medical
895	Artificial Intelligence in Medicine	A model of differential diagnosis in histopathology using the theory of hypergraphs and social choice.	Heather Heathfield,Deb Bose,Nigel Kirkham	1991	A model of differential diagnosis in histopathology using the theory of hypergraphs and social choice.	Artificial Inte	medical
896	Artificial Intelligence in Medicine	Transpro: natural language to Prolog translation of genealogy statements in USDVA file manager.	Wolfgang Giere,Ichiro Wakai	1991	Transpro: natural language to Prolog translation of genealogy statements in USDVA file manager.	Artificial Inte	medical
897	Artificial Intelligence in Medicine	The visual display of temporal information.	Steve B. Cousins,Michael G. Kahn	1991	The visual display of temporal information.	Artificial Inte	medical
898	Artificial Intelligence in Medicine	Medical expert system user interface.	G. William Moore	1991	Medical expert system user interface.	Artificial Inte	medical
899	Artificial Intelligence in Medicine	Precedence logic in the development of a blood bank expert system.	James M. Sorace	1991	Precedence logic in the development of a blood bank expert system.	Artificial Inte	medical
900	Artificial Intelligence in Medicine	The DeSyGNER knowledge management architecture: a building block approach based on an extensible kernel.	Robert A. Greenes,Stephan R. A. Deibel	1991	The DeSyGNER knowledge management architecture: a building block approach based on an extensible kernel.	Artificial Inte	medical
901	Artificial Intelligence in Medicine	The role of essential explanation in abduction.	Olivier Fischer,Ashok K. Goel,John R. Svirbely,Jack W. Smith	1991	The role of essential explanation in abduction.	Artificial Inte	medical
902	Artificial Intelligence in Medicine	The computer and the brain: Perspectives on human and artificial intelligence : Jean R. Brink, C. Roland Haden, eds., Chritopher Burawa, assistant ed., (North-Holland, Amsterdam, 1989) XVI + 263 pp., 38 figures, hardcover, US $ 58.00.	Luc P. Lindström	1991	The computer and the brain: Perspectives on human and artificial intelligence : Jean R. Brink, C. Roland Haden, eds., Chritopher Burawa, assistant ed., (North-Holland, Amsterdam, 1989) XVI + 263 pp., 38 figures, hardcover, US $ 58.00.	Artificial Inte	medical
903	Artificial Intelligence in Medicine	DIAGAID: a connectionist approach to determine the diagnostic value of clinical data.	Jari Forsström,Patrik Eklund,Harry Virtanen,Joakim Waxlax,Juhani Lähdevirta	1991	DIAGAID: a connectionist approach to determine the diagnostic value of clinical data.	Artificial Inte	medical
904	Artificial Intelligence in Medicine	A history of medical informatics: Bruce I. Blum and Karen Duncan, eds., (Addison-Wesley, Reading, MA, 1990) 455 pp., US $ 49.50.	Lawrence E. Widman	1991	A history of medical informatics: Bruce I. Blum and Karen Duncan, eds., (Addison-Wesley, Reading, MA, 1990) 455 pp., US $ 49.50.	Artificial Inte	medical
905	Artificial Intelligence in Medicine	Temporal logics and their applications: Antony Galton (ed.), (Academic Press, Harcourt Brace Jovanovich Publishers, London, 1987) XII + 244 pp., hardcover, £ 24.00.	Dagmar Gröppel	1991	Temporal logics and their applications: Antony Galton (ed.), (Academic Press, Harcourt Brace Jovanovich Publishers, London, 1987) XII + 244 pp., hardcover, £ 24.00.	Artificial Inte	medical
906	Artificial Intelligence in Medicine	Editorial.	Pietro Torasso	1991	Editorial.	Artificial Inte	medical
907	Artificial Intelligence in Medicine	A scheme of inference of regular grammars for the syntactic pattern recognition of saccadic eye movements.	Martti Juhola,Tapio Grönfors	1991	A scheme of inference of regular grammars for the syntactic pattern recognition of saccadic eye movements.	Artificial Inte	medical
908	Artificial Intelligence in Medicine	AIME 89: Jim Hunter, John Cookson, and Jeremy Wyatt (eds.), (Springer-Verlag, Berlin, 1989) X + 330 pp., softcover, DM 81.00.	Dagmar Gröppel	1991	AIME 89: Jim Hunter, John Cookson, and Jeremy Wyatt (eds.), (Springer-Verlag, Berlin, 1989) X + 330 pp., softcover, DM 81.00.	Artificial Inte	medical
909	Artificial Intelligence in Medicine	Using quantitative and qualitative constraints in models of cardiac electrophysiology.	Jim Hunter,Ian Kirby,Nick Gotts	1991	Using quantitative and qualitative constraints in models of cardiac electrophysiology.	Artificial Inte	medical
910	Artificial Intelligence in Medicine	Logische grundlagen der künstlichen intelligenz: Michael R. Genesereth and Nils J. Nilsson, (Vieweg & Sohn, Braunschweig, 1989) XXIV + 576 pp., softcover, DM 78.00.	Christian E. Dralle	1991	Logische grundlagen der künstlichen intelligenz: Michael R. Genesereth and Nils J. Nilsson, (Vieweg & Sohn, Braunschweig, 1989) XXIV + 576 pp., softcover, DM 78.00.	Artificial Inte	medical
911	Artificial Intelligence in Medicine	Wörterbuch der medizinischen informatik: Hans Jürgen Seelos (ed.), (Walter de Gruyter, Berlin, 1990) XXII + 550 pp., 34 figures, hardcover, DM 148.00.	Uwe C. Limbach	1991	Wörterbuch der medizinischen informatik: Hans Jürgen Seelos (ed.), (Walter de Gruyter, Berlin, 1990) XXII + 550 pp., 34 figures, hardcover, DM 148.00.	Artificial Inte	medical
912	Artificial Intelligence in Medicine	On the co-operation between abductive and temporal reasoning in medical diagnosis.	Luca Console,Pietro Torasso	1991	On the co-operation between abductive and temporal reasoning in medical diagnosis.	Artificial Inte	medical
913	Artificial Intelligence in Medicine	Methodological principles in medical knowledge programming: part I.	Peter Hucklenbroich	1991	Methodological principles in medical knowledge programming: part I.	Artificial Inte	medical
914	Artificial Intelligence in Medicine	Abductive localization of brain damage: incorporating spatial adjacency relations.	Stanley Tuhrim,Deborah R. Horowitz,James A. Reggia,Sharon Goodall	1991	Abductive localization of brain damage: incorporating spatial adjacency relations.	Artificial Inte	medical
915	Artificial Intelligence in Medicine	Teaching medicine using hypertexts: three years of experience at the Ancona Medical School.	Angelo Corvetta,Giovanni Pomponio,Aldo Salvi,Michele M. Luchetti	1991	Teaching medicine using hypertexts: three years of experience at the Ancona Medical School.	Artificial Inte	medical
916	Artificial Intelligence in Medicine	PROLOG. Fortgeschrittene programmiertechniken: Leon Sterling and Ehud Shapiro, (Addison-Wesley Publishing Company, Bonn, 1988) XXVII + 468 pp., 70 figures, hardcover, DM 78.00.	Christian E. Dralle	1991	PROLOG. Fortgeschrittene programmiertechniken: Leon Sterling and Ehud Shapiro, (Addison-Wesley Publishing Company, Bonn, 1988) XXVII + 468 pp., 70 figures, hardcover, DM 78.00.	Artificial Inte	medical
917	Artificial Intelligence in Medicine	Foundations of neural networks : Tarun Khanna, (Addison-Wesley, Reading, MA, 1990) XII + 196 pp., numerous figures, softcover, price not listed.	Luc P. Lindström	1991	Foundations of neural networks : Tarun Khanna, (Addison-Wesley, Reading, MA, 1990) XII + 196 pp., numerous figures, softcover, price not listed.	Artificial Inte	medical
918	Artificial Intelligence in Medicine	A Bayesian expert system for the analysis of an adverse drug reaction.	Robert G. Cowell,A. Philip Dawid,T. Hutchinson,David J. Spiegelhalter	1991	A Bayesian expert system for the analysis of an adverse drug reaction.	Artificial Inte	medical
919	FOCS	Polynomial Algorithms for LP over a Subring of the Algebraic Integers with Applications to LP with Circulant Matrices	Ilan Adler,Peter A. Beling	1991	It is shown that a modified variant of the interior point method can solve linear programs (LPs) whose coefficients are real numbers from a subring of the algebraic integers. By defining the encoding size of such numbers to be the bit size of the integers that represent them in the subring, it is proved that the modified algorithm runs in time polynomial in the encoding size of the input coefficients, the dimension of the problem, and the order of the subring. The Tardos scheme is then extended to this case, yielding a running time that is independent of the objective and right-hand side data. As a consequence of these results, it is shown that LPs with real circulant coefficient matrices can be solved in strongly polynomial time. It is also shown how the algorithm can be applied to LPs whose coefficients belong to the extension of the integers by a fixed set of square roots.	FOCS	theory
920	FOCS	A parallel algorithmic version of the Local Lemma	Noga Alon	1991	The Lovasz local lemma (1975) is a tool that enables one to show that certain events hold with positive, though very small probability. It often yields existence proofs of results without supplying any efficient way of solving the corresponding algorithmic problems. J. Beck has recently found a method for converting some of these existence proofs into efficient algorithmic procedures, at the cost of losing a little in the estimates, but his method does not seem to be parallelizable. His technique is modified to achieve an algorithmic version that can be parallelized, thus providing deterministic NC/sup 1/ algorithms for various interesting algorithmic search problems.	FOCS	theory
921	FOCS	On the Exponent of the All Pairs Shortest Path Problem	Noga Alon,Zvi Galil,Oded Margalit	1991	On the Exponent of the All Pairs Shortest Path Problem	FOCS	theory
922	FOCS	Exact Learning of Read-Twice DNF Formulas (Extended Abstract)	Howard Aizenstein,Leonard Pitt	1991	A polynomial-time algorithm is presented for exactly learning the class of read-twice DNF formulas, i.e. Boolean formulas in disjunctive normal form where each variable appears at most twice. The (standard) protocol used allows the learning algorithm to query whether a given assignment of Boolean variables satisfies the DNF formula to be learned (membership queries), as well as to obtain counterexamples to the correctness of its current hypothesis which can be any arbitrary DNF formula (equivalence queries). The formula output by the learning algorithm is logically equivalent to the formula to be learned.	FOCS	theory
923	FOCS	Adaptive Dictionary Matching	Amihood Amir,Martin Farach	1991	Semiadaptive and fully adaptive dictionary matching algorithms are presented. In the fully adaptive algorithm, the dictionary is processed in time O( mod D mod log mod D mod ). Inserting a new pattern P/sub k+1/ into the dictionary can be done in time O mod P/sub K+1/ mod log mod D mod ). A dictionary pattern can be deleted in time O(log mod D mod ). Text scanning is accomplished in time O( mod T mod log mod D mod ). Also presented is a parallel version of the algorithm with optimal speedup for the dictionary construction and pattern addition phase and a logarithmic overhead in the text scan phase. The method used incorporates a new way of using suffix trees as well as a new data structure in which the suffix tree is embedded for the sequential algorithm.	FOCS	theory
924	FOCS	Faster Uniquely Represented Dictionaries	Arne Andersson,Thomas Ottmann	1991	The authors present a solution to the dictionary problem where each subset of size n of an ordered universe is represented by a unique structure, containing a (unique) binary search tree. The structure permits the execution of search, insert, and delete operations in O(n/sup 1/3/) time in the worst case. They also give a general lower bound, stating that for any unique representation of a set in a graph of, bounded outdegree, one of the operations search or update must require a cost of Omega (n/sup 1/3/) Therefore, the result sheds new light on previously claimed lower bounds for unique binary search tree representations.	FOCS	theory
925	FOCS	Asymptotically Optimal PRAM Emulation on Faulty Hypercubes (Extended Abstract)	Yonatan Aumann,Michael Ben-Or	1991	A scheme for emulating the parallel random access machine (PRAM) on a faulty hypercube is presented. All components of the hypercube, including the memory modules, are assumed to be subject to failure. The faults may occur at any time during the emulation and the system readjusts dynamically. The scheme, which rests on L.G. Valiant's BSP model (1990), is the first to achieve optimal and work-preserving PRAM emulation on a dynamically faulty network.	FOCS	theory
926	FOCS	Self-Stabilization By Local Checking and Correction (Extended Abstract)	Baruch Awerbuch,Boaz Patt-Shamir,George Varghese	1991	The first self-stabilizing end-to-end communication protocol and the most efficient known self-stabilizing network reset protocol are introduced. A simple method of local checking and correction, by which distributed protocols can be made self-stabilizing without the use of unbounded counters, is used. The self-stabilization model distinguishes between catastrophic faults that abstract arbitrary corruption of global state, and other restricted kinds of anticipated faults. It is assumed that after the execution starts there are no further catastrophic faults, but the anticipated faults may continue to occur.	FOCS	theory
927	FOCS	The Maintenance of Common Data in a Distributed System	Baruch Awerbuch,Leonard J. Schulman	1991	A basic task in distributed computation is the maintenance at each processor of the network, of a current and accurate copy of a common database. Such a database must be updated in the wake of locally generated changes to its contents. Due to previous disconnections of parts of the network, a maintenance protocol may need to update processors holding widely varying versions of the database. A deterministic protocol, which has only polylogarithmic overhead in its time and communication complexities, is provided for this problem. Previous deterministic solutions required polynomial overhead in at least one of these measures.	FOCS	theory
928	FOCS	Distributed Program Checking: a Paradigm for Building Self-stabilizing Distributed Protocols (Extended Abstract)	Baruch Awerbuch,George Varghese	1991	The notion of distributed program checking as a means of making a distributed algorithm self-stabilizing is explored. A compiler that converts a deterministic synchronous protocol pi for static networks into a self-stabilizing version of pi for dynamic networks is described. If T/sub pi / is the time complexity of pi and D is a bound on the diameter of the final network, the compiled version of pi stabilizes in time O(D+T/sub pi /) and has the same space complexity as pi . The general method achieves efficient results for many specific noninteractive tasks. For instance, solutions for the shortest paths and spanning tree problems take O(D) to stabilize, an improvement over the previous best time of O(D/sup 2/).	FOCS	theory
929	FOCS	Approximate Representation Theory of Finite Groups	László Babai,Katalin Friedl	1991	The asymptotic stability and complexity of floating point manipulation of representations of a finite group G are considered, especially splitting them into irreducible constituents and deciding their equivalence. Using rapid mixing estimates for random walks, the authors analyze a classical algorithm by J. Dixon (1970). They find that both its stability and complexity critically depend on the diameter d=diam(G,S) (S is the set that generates G). They propose a worst-case speedup by using Erdos-Renyi generators and modifying the Dixon averaging method. The overall effect in asymptotic complexity is a guaranteed (n log mod G mod )/sup O(1)/ running time.	FOCS	theory
930	FOCS	On-line Scheduling in the Presence of Overload	Sanjoy K. Baruah,Gilad Koren,Bhubaneswar Mishra,Arvind Raghunathan,Louis E. Rosier,Dennis Shasha	1991	The preemptive scheduling of sporadic tasks on a uniprocessor is considered. A task may arrive at any time, and is characterized by a value that reflects its importance, an execution time that is the amount of processor time needed to completely execute the task, and a deadline by which the task is to complete execution. The goal is to maximize the sum of the values of the completed tasks. An online scheduling algorithm that achieves optimal performance when the system is underloaded and provides a nontrivial performance guarantee when the system is overloaded is designed. The algorithm is implemented using simple data structures to run at a cost of O(log n) time per task, where n bounds the number of tasks in the system at any instant. Upper bounds on the best performance guarantee obtainable by an online algorithm in a variety of settings are derived.	FOCS	theory
931	FOCS	Languages that Are Easier than their Proofs	Richard Beigel,Mihir Bellare,Joan Feigenbaum,Shafi Goldwasser	1991	Languages in NP are presented for which it is harder to prove membership interactively than it is to decide this membership. Similarly, languages where checking is harder than computing membership are presented. Under assumptions about triple-exponential time, incoherent sets in NP are constructed. Without any assumptions, incoherent sets are constructed in DSPACE (n to the log n), yielding the first uncheckable and non-random-self-reducible sets in that space.	FOCS	theory
932	FOCS	On ACC	Richard Beigel,Jun Tarui	1991	It has been shown by A. Yao (1990) that every language in ACC is recognized by a sequence of depth-2 probabilistic circuits with a symmetric gate at the root and n/sup polylog/(n) AND gates of fan-in polylog (n) at the leaves. The authors simplify Yao's proof and strengthen his results: every language in ACC is recognized by a sequence of depth-2 deterministic circuits with a symmetric gate at the root and n/sup polylog/(n) AND gates of fan-in polylog(n) at the leaves. They also analyze and improve modulus-amplifying polynomials constructed by S. Toda (1989) and Yao: this yields smaller circuits in Yao's and the present results on ACC.	FOCS	theory
933	FOCS	Lower Bounds for Data Structure Problems on RAMs (Extended Abstract)	Amir M. Ben-Amram,Zvi Galil	1991	A technique is described for deriving lower bounds and tradeoffs for data structure problems. Two quantities are defined. The output variability depends only on the model of computation. It characterizes in some sense the power of a model. The problem variability depends only on the problem under consideration. It characterizes in some sense the difficulty of the problem. The first theorem states that if a model's output variability is smaller than the problem variability, a lower bound on the worst case (average case) time for the problem follows. A RAM that can add, subtract and compare unbounded integers is considered. The second theorem gives an upper bound on the output variability of this model. The two theorems are used to derive lower bounds for the union-find problem in this RAM.	FOCS	theory
934	FOCS	Computing Sums of Radicals in Polynomial Time	Johannes Blömer	1991	For a certain sum of radicals the author presents a Monte Carlo algorithm that runs in polynomial time to decide whether the sum is contained in some number field Q( alpha ), and, if so, its coefficient representation in Q( alpha ) is computed. As a special case the algorithm decides whether the sum is zero. The main algorithm is based on a subalgorithm which is of interest in its own right. This algorithm uses probabilistic methods to check for an element beta of an arbitrary (not necessarily) real algebraic number field Q( alpha ) and some positive rational integer r whether there exists an rth root of beta in Q( alpha ).	FOCS	theory
935	FOCS	Checking the Correctness of Memories	Manuel Blum,William S. Evans,Peter Gemmell,Sampath Kannan,Moni Naor	1991	The notion of program checking is extended to include programs that alter their environment, in particular, programs that store and retrieve data from memory. The model considered allows the checker a small amount of reliable memory. The checker is presented with a sequence of requests (online) to a data structure which must reside in a large but unreliable memory. The data structure is viewed as being controlled by an adversary. The checker is to perform each operation in the input sequence using its reliable memory and the unreliable data structure so that any error in the operation of the structure will be detected by the checker with high probability. Checkers for various data structures are presented. Lower bounds of log n on the amount of reliable memory needed by these checkers, where n is the size of the structure, are proved.	FOCS	theory
936	FOCS	Subquadratic Zero-Knowledge	Joan Boyar,Gilles Brassard,René Peralta	1991	The communication complexity of zero-knowledge proof systems is improved. Let C be a Boolean circuit of size n. Previous zero-knowledge proof systems for the satisfiability of C require the use of Omega (kn) bit commitments in order to achieve a probability of undetected cheating not greater than 2/sup -k/. In the case k=n, the communication complexity of these protocols is therefore Omega (n/sup 2/) bit commitments. A zero-knowledge proof is given for achieving the same goal with only O(n/sup m/+k square root n/sup m/) bit commitments, where m=1+ epsilon /sub n/ and epsilon /sub n/ goes to zero as n goes to infinity. In the case k=n, this is O(n square root n/sup m/). Moreover, only O(k) commitments need ever be opened, which is interesting if committing to a bit is significantly less expensive than opening a commitment.	FOCS	theory
937	FOCS	Size-Depth Tradeoffs for Algebraic Formulae	Nader H. Bshouty,Richard Cleve,Wayne Eberly	1991	Some tradeoffs between the size and depth of algebraic formulas are proved. It is shown that, for any fixed in >0, any algebraic formula of size S can be converted into an equivalent formula of depth O(log S) and size O(S/sup 1+ in /). This result is an improvement over previously known results where, to obtain the same depth bound, the formula size is Omega (S/sup alpha /), with alpha >or=2.	FOCS	theory
938	FOCS	An Optimal Convex Hull Algorithm and New Results on Cuttings (Extended Abstract)	Bernard Chazelle	1991	An optimal algorithm for computing hyperplane cuttings is given. It results in a new kind of cutting, which enjoys all the properties of the previous ones and, in addition, can be refined by composition. An optimal algorithm for computing the convex hull of a finite point set in any fixed dimension is also given.	FOCS	theory
939	FOCS	How to Learn an Unknown Environment (Extended Abstract)	Xiaotie Deng,Tiko Kameda,Christos H. Papadimitriou	1991	The authors consider the problem faced by a newborn that must explore and learn an unknown room with obstacles in it. They seek algorithms that achieve a bounded ratio of the worst-case distance traversed in order to see all visible points of the environment (thus creating a map), divided by the optimum distance needed to verify the map. The situation is complicated by the fact that the latter offline problem (optimally verifying a map) is NP-hard and thus must be solved approximately. Although the authors show that there is no such competitive algorithm for general obstacle courses, they give a competitive algorithm for the case of a polygonal room with a bounded number of obstacles in it.	FOCS	theory
940	FOCS	On the Complexity of Computing the Homology Type of a Triangulation	Bruce Randall Donald,Davied Renpan Chang	1991	An algorithm for computing the homology type of a triangulation is analyzed. By triangulation is meant a finite simplicial complex; its homology type is given by its homology groups (with integer coefficients). The algorithm could be used in computer-aided design to tell whether two finite-element meshes or Bezier-spline surfaces are of the same topological type, and whether they can be embedded in R/sup 3/. Homology computation is a pure combinatorial problem of considerable intrinsic interest. While the worst-case bounds obtained for this algorithm are poor, it is argued that many triangulations (in general) and virtually all triangulations in design are very sparse in a particular sense. This sparseness measure is formalized, and a probabilistic analysis of the sparse case is performed to show that the expected running time, of the algorithm is roughly quadratic in the geometric complexity (number of simplices) and linear in the dimension.	FOCS	theory
941	FOCS	On Better Heuristic for Euclidean Steiner Minimum Trees (Extended Abstract)	Ding-Zhu Du,Yanjun Zhang,Qing Feng	1991	Finding a shortest network interconnecting a given set of points in the Euclidean plane (a Steiner minimum tree) is known to be NP-hard. It is shown that there exists a polynomial-time heuristic with a performance ratio bigger than square root 3/2.	FOCS	theory
942	FOCS	A Quadratic Time Algorithm for The MinMax Length Triangulation (Extended Abstract)	Herbert Edelsbrunner,Tiow Seng Tan	1991	A Quadratic Time Algorithm for The MinMax Length Triangulation (Extended Abstract)	FOCS	theory
943	FOCS	Communication Complexity Towards Lower Bounds on Circuit Depth	Jeff Edmonds,Steven Rudich,Russell Impagliazzo,Jiri Sgall	1991	Communication Complexity Towards Lower Bounds on Circuit Depth	FOCS	theory
944	FOCS	Tree Automata, Mu-Calculus and Determinacy (Extended Abstract)	E. Allen Emerson,Charanjit S. Jutla	1991	Tree Automata, Mu-Calculus and Determinacy (Extended Abstract)	FOCS	theory
945	FOCS	A General Approach to Removing Degeneracies	Ioannis Z. Emiris,John F. Canny	1991	Algorithms modeled as algebraic branching programs, with inputs from an infinite ordered field, are studied. Direct perturbations on the input, so that an algorithm designed under the assumption of nondegeneracy can be applied to all inputs, are described. A deterministic method for algorithms with determinant tests and a randomized one for arbitrary test expressions are defined. They both incur extra complexity factors that are constant in several cases. Moreover, polynomial and exponential time algorithms always remain in the same complexity class while being enhanced with the power to execute on arbitrary inputs. Both methods are distinguished by their conceptual elegance and are significantly faster than previous ones.	FOCS	theory
946	FOCS	Dynamic Three-Dimensional Linear Programming	David Eppstein	1991	Linear programming optimizations on the intersection of k polyhedra in R/sup 3/, represented by their outer recursive decompositions, are performed in expected time O(k log k log n+ square root k log k log/sup 3/ n). This result is used to derive efficient algorithms for dynamic linear programming problems ill which constraints are inserted and deleted, and queries must optimize specified objective functions. As an application, an improved solution to the planar 2-center problem, is described.	FOCS	theory
947	FOCS	Amortized Communication Complexity (Preliminary Version)	Tomás Feder,Eyal Kushilevitz,Moni Naor	1991	The authors study the direct sum problem with respect to communication complexity: Consider a function f: D to (0, 1), where D contained in (0, 1)/sup n/*(0, 1)/sup n/. The amortized communication complexity of f, i.e. the communication complexity of simultaneously computing f on l instances, divided by l is studied. The authors present, both in the deterministic and the randomized model, functions with communication complexity Theta (log n) and amortized communication complexity O(1). They also give a general lower bound on the amortized communication complexity of any function f in terms of its communication complexity C(f).	FOCS	theory
948	FOCS	Approximating Clique is Almost NP-Complete (Preliminary Version)	Uriel Feige,Shafi Goldwasser,László Lovász,Shmuel Safra,Mario Szegedy	1991	The computational complexity of approximating omega (G), the size of the largest clique in a graph G, within a given factor is considered. It is shown that if certain approximation procedures exist, then EXPTIME=NEXPTIME and NP=P.	FOCS	theory
949	FOCS	Dynamic Scheduling on Parallel Machines	Anja Feldmann,Jiri Sgall,Shang-Hua Teng	1991	The problem of online job scheduling on various parallel architectures is studied. An O((log log n)/sup 1/2/)-competitive algorithm for online dynamic scheduling on an n*n mesh is given. It is proved that this algorithm is optimal up to a constant factor. The algorithm is not greedy, and the lower bound proof shows that no greedy-like algorithm can be very good. The upper bound result can be generalized to any fixed-dimensional meshes. Competitive scheduling algorithms for other architectures are given.	FOCS	theory
950	FOCS	Competitive Algorithms for Layered Graph Traversal	Amos Fiat,Dean P. Foster,Howard J. Karloff,Yuval Rabani,Yiftach Ravid,Sundar Vishwanathan	1991	A layered graph is a connected, weighted graph whose vertices are partitioned into sets L/sub 0/=(s), L/sub 1/, L/sub 2/, . . ., and whose edges run between consecutive layers. Its width is max( mod L/sub i/ mod ). In the online layered graph traversal problem, a searcher starts at s in a layered graph of unknown width and tries to reach a target vertex t; however, the vertices in layer i and the edges between layers i-1 and i are only revealed when the searcher reaches layer i-1. The authors give upper and lower bounds on the competitive ratio of layered graph traversal algorithms. They give a deterministic online algorithm that is O(9w)-competitive on width-w graphs and prove that for no w can a deterministic online algorithm have a competitive ratio better than 2w/sup -2/ on width-w graphs. They prove that for all w, w/2 is a lower bound on the competitive ratio of any randomized online layered graph traversal algorithm. For traversing layered graphs consisting of w disjoint paths tied together at a common source, they give a randomized online algorithm with a competitive ratio of O(log w) and prove that this is optimal up to a constant factor.	FOCS	theory
951	FOCS	Ambivalent Data Structures for Dynamic 2-Edge-Connectivity and k Smallest Spanning Trees	Greg N. Frederickson	1991	Ambivalent data structures are presented for several problems on undirected graphs. They are used in finding the k smallest spanning trees of a weighted undirected graph in O(m log beta (m,n)+min(k/sup 3/2/, km/sup 1/2/)) time, where m is the number of edges and n the number of vertices in the graph. The techniques are extended to find the k smallest spanning trees in an embedded planar graph in O(n+k(log n)/sup 3/) time. Ambivalent data structures are also used to maintain dynamically 2-edge-connectivity information. Edges and vertices can be inserted or deleted in O(m/sup 1/2/) time, and a query as to whether two vertices are in the same 2-edge-connected component can be answered in O(log n) time, where m and n are understood to be the current number of edges and vertices, respectively. Again, the techniques are extended to maintain an embedded planar graph so that edges and vertices can be inserted or deleted in O((log n)/sup 3/) time, and a query answered in O(log n) time.	FOCS	theory
952	FOCS	Lower Bounds for the Complexity of Reliable Boolean Circuits with Noisy Gates	Anna Gál	1991	It is proved that the reliable computation of any Boolean function with, sensitivity s requires Omega (s log s) gates if the gates of the circuit fail independently with a fixed positive probability. The Omega (s log s) bound holds even if s is the block sensitivity instead of the sensitivity of the Boolean function. Some open problems are mentioned.	FOCS	theory
953	FOCS	Applications of a Poset Representation to Edge Connectivity and Graph Rigidity	Harold N. Gabow	1991	A poset representation for a family of sets defined by a labeling algorithm is investigated. Poset representations are given for the family of minimum cuts of a graph, and it is shown how to compute them quickly. The representations are the starting point for algorithms that increase the edge connectivity of a graph, from lambda to a given target tau = lambda + delta , adding the fewest edges possible. For undirected graphs the time bound is essentially the best-known bound to test tau -edge connectivity; for directed graphs the time bound is roughly a factor delta more. Also constructed are poset representations for the family of rigid subgraphs of a graph, when graphs model structures constructed from rigid bars. The link between these problems is that they all deal with graphic matroids.	FOCS	theory
954	FOCS	Fault-tolerant Computation in the Full Information Model (Extended Abstract)	Oded Goldreich,Shafi Goldwasser,Nathan Linial	1991	Efficient two-party protocols for fault-tolerant computation of any two-argument function are presented. It is proved that the influence of a dishonest player in these protocols is the minimum one possible (up to polylogarithmic factors). Also presented are efficient m-party fault-tolerant protocols for sampling a general distribution (m>or=2). Efficient m-party protocols for computation of any m-argument function are given, and it is proved for these protocols that for most functions, the influence of any t dishonest players on the outcome of the protocol is the minimum one possible (up to polylogarithmic factors).	FOCS	theory
955	FOCS	Efficient Exponentiation in Finite Fields (Extended Abstract)	Joachim von zur Gathen	1991	Optimal sequential and parallel algorithms for exponentiation in a finite field extension are presented, assuming that a normal basis over the ground field is given.	FOCS	theory
956	FOCS	Quantifying Knowledge Complexity	Oded Goldreich,Erez Petrank	1991	One of the many contributions of the paper of Goldwasser, Micali and Rackoff is the introduction of the notion of knowledge complexity. Knowledge complexity zero (also known as zero-knowledge) seems to have received most of the attention of the authors and all the attention of their followers. Unfortunately, the formulation of knowledge complexity (greater than zero) as appearing in that pioneering paper seems to be inadequate. In this paper, we present several alternative definitions of knowledge complexity and investigate the relations between them.	FOCS	theory
957	FOCS	A Deterministic Parallel Algorithm for Planar Graphs Isomorphism	Hillel Gazit	1991	A deterministic parallel algorithm for determining whether two planar graphs are isomorphic is presented. The algorithm needs O(log n) separators that have to be computed one after the other. The running time is T=O(log/sup 3/ n) time for finding separators, and the processors count is n/sup 1.5/ log n/T. It is also shown that every planar graph has a separator, and a parallel algorithm for finding the separator is given.	FOCS	theory
958	FOCS	Towards a Theory of Nearly Constant Time Parallel Algorithms	Joseph Gil,Yossi Matias,Uzi Vishkin	1991	It is demonstrated that randomization is an extremely powerful tool for designing very fast and efficient parallel algorithms. Specifically, a running time of O(lg* n) (nearly-constant), with high probability, is achieved using n/lg* n (optimal speedup) processors for a wide range of fundamental problems. Also given is a constant time algorithm which, using n processors, approximates the sum of n positive numbers to within an error which is smaller than the sum by an order of magnitude. A variety of known and new techniques are used. New techniques, which are of independent interest, include estimation of the size of a set in constant time for several settings, and ways for deriving superfast optimal algorithms from superfast nonoptimal ones.	FOCS	theory
959	FOCS	Using Approximation Algorithms to Design Parallel Algorithms that May Ignore Processor Allocation (Preliminary Version)	Michael T. Goodrich	1991	A framework is presented for designing parallel algorithms that may ignore processor allocation. A number of fast approximation algorithms are developed, and it is shown how to use these algorithms to simulate any algorithm that fits this framework in a work-preserving fashion on a randomized CRCW PRAM. Several applications of the approach to parallel computational geometry are given.	FOCS	theory
960	FOCS	An Approximation Algorithm for the Number of Zeros of Arbitrary Polynomials over GF[q]	Dima Grigoriev,Marek Karpinski	1991	The authors design the first polynomial time (for an arbitrary and fixed field GF(q)) ( in , delta )-approximation algorithm for the number of zeros of arbitrary polynomial f(x/sub 1/. . . x/sub n/) over GF(q). It gives the first efficient method for estimating the number of zeros and nonzeros of multivariate polynomials over small finite fields other than GF(2) (like GF(3)), the case important for various circuit approximation techniques. The algorithm is based on the estimation of the number of zeros of an arbitrary polynomial f(x/sub 1/. . .,x/sub n/) over GF(q) in the function of the number m of its terms. The bounding ratio is proved to be m/sup (q-1)/log/sup q/.	FOCS	theory
961	FOCS	Computing Planar Intertwines	Arvind Gupta,Russell Impagliazzo	1991	The proof of Wagner's conjecture by N. Robertson and P. Seymour gives a finite description of any family of graphs which is closed under the minor ordering, called the obstructions of the family. Since the intersection and the union of two minor closed graph families are again a minor closed graph family, an interesting question is that of computing the obstructions of the new family given the obstructions for the original two families. It is easy to compute the obstructions of the intersection, but, until very recently, it was an open problem to compute the obstructions of the union. It is shown that if the original families are planar, then the obstructions of the union are no larger than n to the O(n/sup 2/) power, where n is the size of the largest obstruction of the original family.	FOCS	theory
962	FOCS	Low Contention Linearizable Counting	Maurice Herlihy,Nir Shavit,Orli Waarts	1991	The linearizable counting problem requires asynchronous concurrent processes to assign themselves successive values so that the order of the values assigned reflects the real-time order in which they were requested. It is shown that the problem can be solved without funneling all processes through a common memory location. Two new constructions for linearizable counting networks, data structures that solve the linearizable counting problem, are given. The first construction is nonblocking: some process takes a value after O(n) network gates have been traversed. The second construction is wait-free: it guarantees that each process takes a value after it traverses O(wn) gates, where w is a parameter affecting contention. It is shown that in any nonblocking or wait-free linearizable counting network, processes must traverse an average of Omega (n) gates, and so the constructions are close to optimal. A simpler and more efficient network is constructed by giving up the robustness requirements and allowing processes to wait for one another.	FOCS	theory
963	FOCS	The Art Gallery Theorem for Polygons With Holes	Frank Hoffmann,Michael Kaufmann,Klaus Kriegel	1991	Art gallery problems which have been extensively studied over the last decade ask how to station a small (minimum) set of guards in a polygon such that every point of the polygon is watched by at least one guard. The graph-theoretic formulation and solution to the gallery problem for polygons in standard form is given. A complexity analysis is carried out, and open problems are discussed.	FOCS	theory
964	FOCS	A Linear Time Algorithm for Triconnectivity Augmentation (Extended Abstract)	Tsan-sheng Hsu,Vijaya Ramachandran	1991	The problem of finding the smallest set of edges whose addition triconnects an undirected graph is considered. This is a fundamental graph-theoretic problem that has applications in designing reliable networks and fault-tolerant computing. A linear time sequential algorithm is given for the problem. This is a substantial improvement over the best previous algorithm for this problem, which runs in O(n(n+m)/sup 2/) time on a graph with n vertices and m edges.	FOCS	theory
965	FOCS	Efficient Algorithms for the Riemann-Roch Problem and for Addition in the Jacobian of a Curve (Extended Abstract)	Ming-Deh A. Huang,Doug Ierardi	1991	Several computational problems concerning the construction of rational functions and intersecting curves over a given curve are studied. The first problem is to construct a rational function with prescribed zeros and poles over a given curve. More precisely, let C be a smooth projective curve and assume as given an affine plane model F(x,y)=0 for C, a finite set of points P/sub i/=(X/sub i/, Y/sub i/) with F (X/sub i/, Y/sub i/)=0 and natural numbers n/sub i/, and a finite set of points Q/sub i/=(X/sub j/, Y/sub j/) with F(X/sub j/, Y/sub j/)=0 and natural numbers m/sub j/. The problem is to decide whether there is a rational function which has zeros at each point P/sub i/ of order n/sub i/, poles at each Q/sub j/ of order m/sub j/, and no zeros or poles anywhere else on C. One would also like to construct such a rational function if one exists. An efficient algorithm for solving this problem when the given plane curve has only ordinary multiple points is given.	FOCS	theory
966	FOCS	Connected Components in O(\lg^3/2 |V|) Parallel Time for the CREW PRAM	Donald B. Johnson,Panagiotis Takis Metaxas	1991	Connected Components in O(\lg^3/2 |V|) Parallel Time for the CREW PRAM	FOCS	theory
967	FOCS	Better Expansion for Ramanujan Graphs	Nabil Kahale	1991	The expansion properties of regular graphs are investigated. The best previously known expansion of subsets of linear size of explicit k-regular graphs is k/4. This bound is achieved by nonbipartite Ramanujan graphs of degree k=p+1, which have the property that all but the largest eigenvalue have absolute value at most 2 square root p. The expansion coefficient for linear subsets for nonbipartite Ramanujan graphs is improved to 3(k-2)/8. Other results are established, including improved results about random walks on expanders.	FOCS	theory
968	FOCS	On-Line Maintenance of the Four-Connected Components of a Graph (Extended Abstract)	Arkady Kanevsky,Roberto Tamassia,Giuseppe Di Battista,Jianer Chen	1991	On-Line Maintenance of the Four-Connected Components of a Graph (Extended Abstract)	FOCS	theory
969	FOCS	A New Characterization of Mehlhorn's Polynomial Time Functionals (Extended Abstract)	Bruce M. Kapron,Stephen A. Cook	1991	A. Cobham (1964) presented a machine-independent characterization of computational feasibility, via inductive definition. R. Constable (1973) was apparently the first to consider the notion of feasibility for type 2 functionals. K. Mehlhorn's (1976) study of feasible reducibilities proceeds from Constable's work. Here, a class of polytime operators is defined, using a generalization of Cobham's definition. The authors provide an affirmative answer to the question of whether there is a natural machine based definition of Mehlhorn's class.	FOCS	theory
970	FOCS	Finding the Hidden Path: Time Bounds for All-Pairs Shortest Paths	David R. Karger,Daphne Koller,Steven J. Phillips	1991	The all-pairs shortest paths problem in weighted graphs is investigated. An algorithm called the hidden paths algorithm, which finds these paths in time O(m*+n n/sup 2/ log n), where m* is the number of edges participating in shortest paths, is presented. It is argued that m* is likely to be small in practice, since m*=O(n log n) with high probability for many probability distributions on edge weights. An Omega (mn) lower bound on the running time of any path-comparison-based algorithm for the all-pairs shortest paths problem is proved.	FOCS	theory
971	FOCS	Progress Measures for Complementation of omega-Automata with Applications to Temporal Logic	Nils Klarlund	1991	A new approach to complementing omega -automata, which are finite-state automata defining languages of infinite words, is given. Instead of using usual combinatorial or algebraic properties of transition relations, it is shown that a graph-theoretic approach based on the notion of progress measures is a potent tool for complementing omega -automata. Progress measures are applied to the classical problem of complementing Buchi automata, and a simple method is obtained. The technique applies to Streett automata, for which an optimal complementation method is also obtained. As a consequence, it is seen that the powerful temporal logic ETLs is much more tractable than previously thought.	FOCS	theory
972	FOCS	Walking an Unknown Street with Bounded Detour	Rolf Klein	1991	A polygon with two distinguished vertices, s and g, is called a street if the two boundary chains from s to g are mutually weakly visible. For a mobile robot with onboard vision, a strategy for finding a short path from s to g in a street not known in advance is described, and it is proved that the length of the path created does not exceed 1+3 pi /2 times the length of the shortest path from s to g. Experiments suggest that the strategy is much better than this, as no ratio bigger than 1.8 has yet been observed. This is complemented by a lower bound of 1.41 for the relative detour each strategy can be forced to generate.	FOCS	theory
973	FOCS	Concentrated Regular Data Streams on Grids: Sorting and Routing Near to the Bisection Bound	Manfred Kunde	1991	Sorting and routing on r-dimensional n*. . .*n grids of processors is studied. Deterministic algorithms are presented for h-h problems, h>or=1, where each processor initially and finally contains h elements. It is shown that the classical 1-1 sorting can be solved with (2r-1.5)n+o(n) transport steps, i.e. in about 2.5n steps for r=2. The general h-h sorting problem, h>or=4r-4 can be solved within a number of transport steps that asymptotically differs by a factor of at most 3 from the trivial bisection bound. Furthermore, the bisection bound is asymptotically tight for sequences of h permutation routing problems, h=4cr, c>or=1, and for so-called offline routing.	FOCS	theory
974	FOCS	Fully Parallelized Multi Prover Protocols for NEXP-Time (Extended Abstract)	Dror Lapidot,Adi Shamir	1991	A major open problem in the theory of multiprover protocols is to characterize the languages which can be accepted by fully parallelized protocols which achieve an exponentially low probability of cheating in a single round. The problem was motivated by the observation that the probability of cheating the n parallel executions of a multiprover protocol can be exponentially higher than the probability of cheating in n sequential executions of the same protocol. The problem is solved by proving that any language in NEXP-time has a fully parallelized multiprover protocol. By combining this result with a fully parallelized version of the protocol of M. Ben-Or et al. (ACM Symp. on Theory of Computing, 1988), a one-round perfect zero-knowledge protocol (under no cryptographic assumptions) can be obtained for every NEXPTIME language.	FOCS	theory
975	FOCS	Variation Ranks of Communication Matrices and Lower Bounds for Depth Two Circuits Having Symmetric Gates with Unbounded Fan-In	Matthias Krause,Stephan Waack	1991	An exponential lower bound for depth two circuits with arbitrary symmetric gates in the bottom level and with a MOD/sub m/-gate in the top level is proved. This solves a problem posed by R. Smolensky (1990). The method uses the variation rank of communication matrices. A variant of this method is used for deriving lower bounds for the size of depth-two circuits having a threshold gate at the top.	FOCS	theory
976	FOCS	Highly Fault-Tolerant Sorting Circuits	Frank Thomson Leighton,Yuan Ma,C. Greg Plaxton	1991	The problem of constructing a sorting circuit that will work well even if a constant fraction of its comparators fail at random is addressed. Two types of comparator failure are considered: passive failures, which result in no comparison being made (i.e., the items being compared are output in the same order that they are input), and destructive failures, which result in the items being output in the reverse of the correct order. In either scenario, it is assumed that each comparator is faulty with some constant probability rho , and a circuit is said to be fault-tolerant if it performs some desired function with high probability given that each comparator fails with probability rho . One passive and two destructive circuits are constructed.	FOCS	theory
977	FOCS	Efficient Algorithms for Dynamic Allocation of Distributed Memory	Frank Thomson Leighton,Eric J. Schwabe	1991	Efficient Algorithms for Dynamic Allocation of Distributed Memory	FOCS	theory
978	FOCS	Reporting Points in Halfspaces	Jirí Matousek	1991	The author considers the halfspace range reporting problem: Given a finite set P of points in E/sup d/, preprocess it so that given a query halfspace gamma , the points of p intersection gamma can be reported efficiently. It is shown that, with almost linear storage, this problem can be solved substantially more efficiently than the more general simplex range searching problem. A data structure for halfspace range reporting in dimensions d>or=4 is given. It uses O(n log log n) space and O (n log n) deterministic preprocessing time. The query time is also given. Results for the halfspace emptiness problem, where one only wants to know whether P intersection gamma is empty, are also presented.	FOCS	theory
979	FOCS	Discrepancy and epsilon-approximations for bounded VC-dimension	Jirí Matousek,Emo Welzl,Lorenz Wernisch	1991	Let (X, R) be a set system on an n-point set X. For a two-coloring on X, its discrepancy is defined as the maximum number by which the occurrences of the two colors differ in any set in R. It is shown that if for any m-point subset Y contained in X the number of distinct subsets induced by R on Y is bounded by O(m/sup d/) for a fixed integer d is a coloring with discrepancy bounded by O(n/sup 1/2-1/2d/ (log n)/sup 1+1/2d/). Also, if any subcollection of m sets of R partitions the points into at most O(m/sup d/) classes, then there is a coloring with discrepancy at most O(n/sup 1/2-1/2d/ n). These bounds imply improved upper bounds on the size of in -approximations for (X, R). All of the bounds are tight up to polylogarithmic factors in the worst case. The results allow the generalization of several results of J. Beck (1984) bounding the discrepancy in certain geometric settings to the case when the discrepancy is taken relative to an arbitrary measure.	FOCS	theory
980	FOCS	Fat Triangles Determine Linearly Many Holes	Jirí Matousek,Nathaly Miller,János Pach,Micha Sharir,Shmuel Sifrony,Emo Welzl	1991	Fat Triangles Determine Linearly Many Holes	FOCS	theory
981	FOCS	Search Problems in the Decision Tree Model (Preliminary Version)	László Lovász,Moni Naor,Ilan Newman,Avi Wigderson	1991	The relative power of determinism, randomness, and nondeterminism for search problems in the Boolean decision tree model is studied. It is shown that the CNF search problem is complete for all the variants of decision trees. It is then shown that the gaps between the nondeterministic, the randomized, and the deterministic complexities can be arbitrarily large for search problems. The special case of nondeterministic complexity is discussed.	FOCS	theory
982	FOCS	On the Computational Power of Sigmoid versus Boolean Threshold Circuits	Wolfgang Maass,Georg Schnitger,Eduardo D. Sontag	1991	On the Computational Power of Sigmoid versus Boolean Threshold Circuits	FOCS	theory
983	FOCS	A Unified Geometric Approach to Graph Separators	Gary L. Miller,Shang-Hua Teng,Stephen A. Vavasis	1991	A class of graphs called k-overlap graphs is proposed. Special cases of k-overlap graphs include planar graphs, k-nearest neighbor graphs, and earlier classes of graphs associated with finite element methods. A separator bound is proved for k-overlap graphs embedded in d dimensions. The result unifies several earlier separator results. All the arguments are based on geometric properties of embedding. The separator bounds come with randomized linear-time and randomized NC algorithms. Moreover, the bounds are the best possible up to the leading term.	FOCS	theory
984	FOCS	Explicit Construction of Natural Bounded Concentrators	Moshe Morgenstern	1991	The first known direct construction for linear families of bounded concentrators is given. The construction is explicit, and the results are simple natural bounded concentrators.	FOCS	theory
985	FOCS	Interactive Communication: Balanced Distributions, Correlated Files, and Average-Case Complexity	Alon Orlitsky	1991	Suppose (X,Y) is a pair of random variables distributed over a support set S. Person P/sub x/ knows X, person P/sub y/ knows Y, and both know S. Using a predetermined protocol, they exchange binary messages in order for P/sub y/ to learn X. P/sub x/ may or may not learn Y. Bounds on communication complexity are obtained and used to obtain efficient protocols for the correlated files problem where X and Y are binary strings (files) within a small edit distance from each other. The average number of bits required for P/sub y/ to learn X when at most m messages are permitted is also determined.	FOCS	theory
986	FOCS	Randomized Multidimensional Search Trees: Lazy Balancing and Dynamic Shuffling (Extended Abstract)	Ketan Mulmuley	1991	A randomized technique, called dynamic shuffling, is given for multidimensional dynamic search. This technique, when specialized to the problem of searching in sorted lists, yields the previously known randomized binary trees (treaps). The crux of the technique is a multidimensional generalization of the rotation operation on binary search trees. Simultaneously, it is shown how to dynamize the randomized incremental algorithms so as to allow additions as well as deletions of objects. The techniques are based on remembering the history of the actual or imaginary sequence of updates. The techniques are applied to several problems in computational geometry.	FOCS	theory
987	FOCS	Randomized Multidimensional Search Trees: Further Results in Dynamic Sampling (Extended Abstract)	Ketan Mulmuley	1991	The use of randomization in dynamic search structures by means of a technique called dynamic sampling is investigated. In particular, an efficient algorithm for dynamic (logarithmic time) point location in 3-D partitions induced by a set of possibly interesting polygons in R/sup 3/ is given. The expected running time of the algorithm on a random sequence of updates is close to optimal. Efficient algorithms for dynamic nearest-k-neighbor queries and half space range queries in R/sup d/ are also given.	FOCS	theory
988	FOCS	On Selecting a Satisfying Truth Assignment (Extended Abstract)	Christos H. Papadimitriou	1991	The complexity of certain natural generalizations of satisfiability, in which one of the possibly exponentially many satisfying truth assignments must be selected, is studied. Two natural selection criteria, default preference and minimality (circumscription), are considered. The thrust of the complexity results seems to be that hard problems become harder, while easy problems remain easy. This consideration yields as a byproduct a new and very natural polynomial-time randomized algorithm for 2SAT.	FOCS	theory
989	FOCS	Optimal File Sharing in Distributed Networks (Preliminary Version)	Moni Naor,Ron M. Roth	1991	Given a distributed network of processors represented by an undirected graph G=(V, E) and a file size k, the problem of distributing an arbitrary file w of k bits among all nodes of the network G is considered. Memory devices are to be assigned to the node of G such that, by accessing the memory of its own and of its adjacent nodes, each node can reconstruct the contents of w. The objective is to minimize the total size memory in the network. A file distribution scheme that realizes this objective for k>>log Delta /sub G/, where Delta /sub G/, stands for the maximum degree in G, is presented. For this range of k, the total size of memory required by the suggested scheme approaches an integer programming lower bound on that size.	FOCS	theory
990	FOCS	Shrinkage of de~Morgan formulae under restriction	Mike Paterson,Uri Zwick	1991	It is shown that a random restriction leaving only a fraction epsilon of the input variables unassigned reduces the expected de Morgan formula size of the induced function by at least a factor of epsilon^((5-sqrt(3))/2)~=epsilon^1.63. (A de Morgan formula is a formula over the basis {/\, \/, ~}.) This improves a long-standing result of epsilon^1.5 by Subbotovskaya and a recent improvement to epsilon^((21-sqrt(73))/8)~=epsilon^1.55 by Nisan and Impagliazzo. The new exponent yields an increased lower bound of omega(n^((7-sqrt(3))/2-O(1)) for the de Morgan formula size of a function defined by Andreev. This is the largest lower bound known for a function in NP.	FOCS	theory
991	FOCS	Fast Approximation Algorithms for Fractional Packing and Covering Problems	Serge A. Plotkin,David B. Shmoys,Éva Tardos	1991	Fast algorithms that find approximate solutions for a general class of problems, which are called fractional packing and covering problems, are presented. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. The algorithms are based on a Lagrangian relaxation technique, and an important result is a theoretical analysis of the running time of a Lagrangian relaxation based algorithm. Several applications of the algorithms are presented.	FOCS	theory
992	FOCS	Communication Complexity for Parallel Divide-and-Conquer	I-Chen Wu,H. T. Kung	1991	The relationship between parallel computation cost and communication cost for performing divide-and-conquer (D&C) computations on a parallel system of p processors is studied. The parallel computation cost is the maximal number of the D&C nodes that any processor in the parallel system may expand, whereas the communication cost is the total number of cross nodes (nodes generated by one processor but expanded by another processor). A scheduling algorithm is proposed, and lower bounds on the communication cost are derived. The proposed scheduling algorithm is optimal with respect to the communication cost, since the parallel computation cost of the algorithm is near optimal.	FOCS	theory
993	FOCS	Better Bounds for Threshold Formulas	Jaikumar Radhakrishnan	1991	The computation of threshold functions using formulas over the basis (AND, OR, NOT) is considered. It is shown that every monotone formula that computes the threshold function T/sub k//sup n/2	FOCS	theory
994	FOCS	Reliable Computation with Noisy Circuits and Decision Trees-A General n log n Lower Bound	Rüdiger Reischuk,Bernd Schmeltz	1991	Reliable Computation with Noisy Circuits and Decision Trees-A General n log n Lower Bound	FOCS	theory
995	FOCS	Finding k-cuts within Twice the Optimal	Huzur Saran,Vijay V. Vazirani	1991	Two simple approximation algorithms are presented for the minimum k-cut problem. Each algorithm finds a k-cut having weight within a factor of (2-2/k) of the optimal. One of the algorithms is particularly efficient, requiring a total of only n-1 maximum flow computations for finding a set of near-optimal k-cuts, one for each value of k between 2 and n.	FOCS	theory
996	FOCS	Dynamic Maintenance of Geometric Structures Made Easy	Otfried Schwarzkopf	1991	The problem of dynamically maintaining geometric structures is considered. A technique is proposed that uses randomized incremental algorithms which are augmented to allow deletions of objects. A model for distributions on the possible input sequences of insertions and deletions is developed and analyzed using R. Seidel's backwards analysis. It is further shown how to apply this to maintain Voronoi diagrams, convex hulls, and planar subdivisions. A strikingly simple algorithm for the maintenance of convex hulls in any dimension is given. The expected running time is determined.	FOCS	theory
997	FOCS	Scheduling Parallel Machines On-Line	David B. Shmoys,Joel Wein,David P. Williamson	1991	The authors study the problem of scheduling jobs on parallel machines when the existence of a job is not known until an unknown release date and the processing requirement of a job is not known until the job is processed to completion. They demonstrate two general algorithmic techniques for converting existing polynomial-time algorithms that require complete knowledge about the input data into algorithms that need less advance knowledge. They prove information-theoretic lower bounds on the lengths of online schedules for several basic parallel machine models and then show that the algorithms construct schedules with lengths that either match or come within a constant factor of the lower bounds.	FOCS	theory
998	FOCS	How to Pack Better than Best Fit: Tight Bounds for Average-Case On-Line Bin Packing	Peter W. Shor	1991	An O(n log n)-time online algorithm is given for packing items i.i.d. uniform on (0, 1) into bins of size 1 with expected wasted space Theta (n/sup 1/2/ log /sup 1/2/n). This matches the lowest bound that no online algorithm can achieve O(n/sup 1/2/ log /sup 1/2/ n) wasted space. It is done by analyzing another algorithm which involves putting balls into buckets online. The analysis of this second algorithm also gives bound on the stochastic rightward matching problem, which arises in analyzing not only the above online bin packing problem, but also a 2-D problem of packing rectangles into a half-infinite strip. The bounds on rightward matching thus give good bounds for the 2-D strip packing problem.	FOCS	theory
999	FOCS	Lower Bounds for Polynomial Evaluation and Interpolation Problems	Victor Shoup,Roman Smolensky	1991	It is shown that there is a set of points p/sub 1/, p/sub 2/,. . .,p/sub n/ such that any algebraic program of depth d for polynomial evaluation (or interpolation) at these points has size Omega (n log n/log d). Moreover, if d is a constant, then a lower bound of Omega (n/sup 1+1/d/) is obtained.	FOCS	theory
1000	FOCS	A Lower Bound for the Dictionary Problem under a Hashing Model	Rajamani Sundar	1991	A fundamental open question in data structures concerns the existence of a dictionary data structure that processes the operations in constant amortized time and uses space polynomial in the dictionary size. The complexity of the dictionary problem is studied under a multilevel hashing model that is based on A.C. Yao's (1981) cell probe model, and it is proved that dictionary operations require log-algorithmic amortized time jn this model. The model encompasses many known solutions to the dictionary problem, and the result is the first nontrivial lower bound for the problem in a reasonably general model that takes into account the limited wordsize of memory locations and realistically measures the cost of update operations. This lower bound separates the deterministic and randomized complexities of the problem under this model.	FOCS	theory
1001	FOCS	A Theory of Using History for Equational Systems with Applications (Extended Abstract)	Rakesh M. Verma	1991	A Theory of Using History for Equational Systems with Applications (Extended Abstract)	FOCS	theory
1002	FOCS	Optimal Prefetching via Data Compression (Extended Abstract)	Jeffrey Scott Vitter,P. Krishnan	1991	A form of the competitive philosophy is applied to the problem of prefetching to develop an optimal universal prefetcher in terms of fault ratio, with particular applications to large-scale databases and hypertext systems. The algorithms are novel in that they are based on data compression techniques that are both theoretically optimal and good in practice. Intuitively, in order to compress data effectively, one has to be able to predict feature data well, and thus good data compressors should be able to predict well for purposes of prefetching. It is shown for powerful models such as Markov sources and mth order Markov sources that the page fault rates incurred by the prefetching algorithms presented are optimal in the limit for almost all sequences of page accesses.	FOCS	theory
1003	FOCS	An Asynchronous Two-Dimensional Self-Correcting Cellular Automaton	Weiguo Wang	1991	Earlier work of P. Gacs and J. Reif (see J. Comput. Syst. Sci., vol.36, no.2, p.125-147 (1988)) on reliable computation using cellular automata is extended to asynchronous cellular automata. The goal is to find ways to implement computations of arbitrary size by a homogeneous asynchronous array of unreliable elementary components. An asynchronous two-dimensional cellular automaton is constructed so that given any computation and reliability requirement, a program can be found for such an automaton that performs the computation with probability that meets the reliability requirement. This is the strongest among the published results on reliable computation in an asynchronous environment. It is stronger than its asynchronous counterpart in the sense that it removes the assumption of a fault-free global synchronization clock underlying a synchronous system.	FOCS	theory
1004	FOCS	Simulating BPP Using a General Weak Random Source	David Zuckerman	1991	It is shown how to simulate BPP and approximation algorithms in polynomial time using the output from a delta -source. A delta -source is a weak random source that is asked only once for R bits, and must output an R-bit string according to some distribution that places probability no more than 2/sup - delta R/ on any particular string. Also given are two applications: one to show the difficulty of approximating the size of the maximum clique, and the other to the problem of implicit O(1) probe search.	FOCS	theory
1005	FOCS	32nd Annual Symposium on Foundations of Computer Science, 1-4 October 1991, San Juan, Puerto Rico		1991	32nd Annual Symposium on Foundations of Computer Science, 1-4 October 1991, San Juan, Puerto Rico	FOCS	theory
1006	SODA	A Sublinear-Time Randomized Parallel Algorithm for the Maximum Clique Problem in Perfect Graphs.	Farid Alizadeh	1991	A Sublinear-Time Randomized Parallel Algorithm for the Maximum Clique Problem in Perfect Graphs.	SODA	theory
1007	SODA	Planar Geometric Location Problems and Maintaining the Width of a Planar Set.	Pankaj K. Agarwal,Micha Sharir	1991	Planar Geometric Location Problems and Maintaining the Width of a Planar Set.	SODA	theory
1008	SODA	Efficient 2-dimensional Approximate Matching of Non-Rectangular Figures.	Amihood Amir,Martin Farach	1991	Efficient 2-dimensional Approximate Matching of Non-Rectangular Figures.	SODA	theory
1009	SODA	Learning the Fourier Spectrum of Probabilistic Lists and Trees.	William Aiello,Milena Mihail	1991	Learning the Fourier Spectrum of Probabilistic Lists and Trees.	SODA	theory
1010	SODA	Matching Points into Noise Regions: Combinatorial Bounds and Algorithms.	Esther M. Arkin,Klara Kedem,Joseph S. B. Mitchell,Josef Sprinzak,Michael Werman	1991	Matching Points into Noise Regions: Combinatorial Bounds and Algorithms.	SODA	theory
1011	SODA	An Efficient Parallel Algorithm for the Row Minima of a Totally Monotone Matrix.	Mikhail J. Atallah,S. Rao Kosaraju	1991	An Efficient Parallel Algorithm for the Row Minima of a Totally Monotone Matrix.	SODA	theory
1012	SODA	The Canadian Traveller Problem.	Amotz Bar-Noy,Baruch Schieber	1991	The Canadian Traveller Problem.	SODA	theory
1013	SODA	The Fourth Moment Method.	Bonnie Berger	1991	Higher moment analysis has typically been used to upper bound certain functions. In this paper, we introduce a new combinatorial method to lower bound the expectation of the absolute value of a random variable X by the expectation of a quartic in X. In the special case where we are looking at the absolute value of a (weighted) sum of {-1,+1} unbiased random variables, we achieve tight bounds, using only a fourth moment, for the total discrepancy of a set system. Because the fourth moment depends only on 4-wise independence, our bounds will hold over polynomially sized distributions, and so these bounds will be directly applicable in removing randomness to obtain NC algorithms. We obtain the first NC algorithms for the problems of total discrepancy, maximum acyclic subgraph, tournament ranking, the Gale--Berlekamp switching game, and edge discrepancy. We show that for most of these applications it is truly necessary to consider a fourth moment by exhibiting a 3-wise independent distribution which does not achieve the required bounds. Our method is strong enough to give a new combinatorial bound on tournament ranking.	SODA	theory
1014	SODA	Complexity Results and Algorithms for { <, <=, = }-Constrained Scheduling.	Bonnie Berger,Lenore Cowen	1991	Complexity Results and Algorithms for { <, <=, = }-Constrained Scheduling.	SODA	theory
1015	SODA	Tight Bounds for On-Line Tree Embeddings.	Sandeep N. Bhatt,David S. Greenberg,Frank Thomson Leighton,Pangfeng Liu	1991	Tree-structured computations are relatively easy to process in parallel. As leaf processes are recursively spawned they can be assigned to independent processors in a multicomputer network. However, to achieve good performance the on-line mapping algorithm must maintain load balance, i.e., distribute processes equitably among processors. Additionally, the algorithm itself must be distributed in nature, and process allocation must be completed via message-passing with minimal communication overhead.This paper investigates bounds on the performance of deterministic and randomized algorithms for on-line tree embeddings. In particular, we study trade-offs between computation overhead (load imbalance) and communication overhead (message congestion). We give a simple technique to derive lower bounds on the congestion that any on-line allocation algorithm must incur in order to guarantee load balance. This technique works for both randomized and deterministic algorithms. We prove that the advantage of randomization is limited. Optimal bounds are achieved for several networks, including multidimensional grids and butterflies.	SODA	theory
1016	SODA	Parallel Complexity of Tridiagonal Symmetric Eigenvalue Problem.	Dario Bini,Victor Y. Pan	1991	Parallel Complexity of Tridiagonal Symmetric Eigenvalue Problem.	SODA	theory
1017	SODA	A Fast Algorithm for Connecting Grid Points to the Boundary with Nonintersecting Straight Lines.	Yitzhak Birk,Jeffrey B. Lotspiech	1991	A Fast Algorithm for Connecting Grid Points to the Boundary with Nonintersecting Straight Lines.	SODA	theory
1018	SODA	On the Parallel Complexity of Evaluating Game Trees.	Andrei Z. Broder,Anna R. Karlin,Prabhakar Raghavan,Eli Upfal	1991	On the Parallel Complexity of Evaluating Game Trees.	SODA	theory
1019	SODA	Circular Hulls and Orbiforms of Simple Polygons.	V. Chandru,R. Venkataraman	1991	Circular Hulls and Orbiforms of Simple Polygons.	SODA	theory
1020	SODA	Computing a Face in an Arrangement of Line Segments.	Bernard Chazelle,Herbert Edelsbrunner,Leonidas J. Guibas,Micha Sharir,Jack Snoeyink	1991	Computing a Face in an Arrangement of Line Segments.	SODA	theory
1021	SODA	On Partitions and Presortedness of Sequences.	Jingsen Chen,Svante Carlsson	1991	On Partitions and Presortedness of Sequences.	SODA	theory
1022	SODA	Space-efficient Ray-shooting and Intersection Searching: Algorithms, Dynamization, and Applications.	Siu-Wing Cheng,Ravi Janardan	1991	Space-efficient Ray-shooting and Intersection Searching: Algorithms, Dynamization, and Applications.	SODA	theory
1023	SODA	Efficient Sequential and Parallel Algorithms for Computing Recovery Points in Trees and Paths.	Marek Chrobak,David Eppstein,Giuseppe F. Italiano,Moti Yung	1991	Efficient Sequential and Parallel Algorithms for Computing Recovery Points in Trees and Paths.	SODA	theory
1024	SODA	Approximation Algorithms for Planar Traveling Salesman Tours and Minimum-Length Triangulations.	Kenneth L. Clarkson	1991	Approximation Algorithms for Planar Traveling Salesman Tours and Minimum-Length Triangulations.	SODA	theory
1025	SODA	Algorithms and Complexity Analysis for Some Flow Problems.	Edith Cohen,Nimrod Megiddo	1991	Algorithms and Complexity Analysis for Some Flow Problems.	SODA	theory
1026	SODA	Dynamic Expression Trees and their Applications (Extended Abstract).	Robert F. Cohen,Roberto Tamassia	1991	Dynamic Expression Trees and their Applications (Extended Abstract).	SODA	theory
1027	SODA	Tight Bounds on the Complexity of the Boyer-Moore String Matching Algorithm.	Richard Cole	1991	The problem of finding all occurrences of a pattern of length $m$ in a text of length $n$ is considered. It is shown that the Boyer--Moore string matching algorithm performs roughly $3n$ comparisons and that this bound is tight up to $O(n/m)$; more precisely, an upper bound of $3n - 3(n-m+1)/(m+2)$ comparisons is shown, as is a lower bound of $3n(1-o(1))$ comparisons, as $\frac{n}{m}\rightarrow\infty$ and $m\rightarrow\infty$. While the upper bound is somewhat involved, its main elements provide a simple proof of a $4n$ upper bound for the same algorithm.	SODA	theory
1028	SODA	Bounded Space On-Line Bin Packing: Best is Better than First.	János Csirik,David S. Johnson	1991	Bounded Space On-Line Bin Packing: Best is Better than First.	SODA	theory
1029	SODA	The Aquarium Keeper's Problem.	Jirel Czyzowicz,Peter Egyed,Hazel Everett,David Rappaport,Thomas C. Shermer,Diane L. Souvaine,Godfried T. Toussaint,Jorge Urrutia	1991	The Aquarium Keeper's Problem.	SODA	theory
1030	SODA	Persistence, Amortization and Randomization.	Paul F. Dietz,Rajeev Raman	1991	Persistence, Amortization and Randomization.	SODA	theory
1031	SODA	Fully Persistent Lists with Catenation.	James R. Driscoll,Daniel Dominic Sleator,Robert Endre Tarjan	1991	This paper considers the problem of representing stacks with catenation so that any stack, old or new, is available for access or update operations. This problem arises in the implementation of list-based and functional programming languages. A solution is proposed requiring constant time and space for each stack operation except catenation, which requires O(log log k) time and space. Here k is the number of stack operations done before the catenation. All the resource bounds are amortized over the sequence of operations.	SODA	theory
1032	SODA	The Analysis of Multidimensional Searching in Quad-Trees.	Philippe Flajolet,Gaston H. Gonnet,Claude Puech,J. M. Robson	1991	The Analysis of Multidimensional Searching in Quad-Trees.	SODA	theory
1033	SODA	Routing through a Dense Channel with Minimum Total Wire Length.	Michael Formann,Dorothea Wagner,Frank Wagner	1991	Routing through a Dense Channel with Minimum Total Wire Length.	SODA	theory
1034	SODA	Optimal Algorithms for Tree Partitioning.	Greg N. Frederickson	1991	Optimal Algorithms for Tree Partitioning.	SODA	theory
1035	SODA	Fast Hashing on a PRAM - Designing by Expectation.	Joseph Gil,Yossi Matias	1991	Fast Hashing on a PRAM - Designing by Expectation.	SODA	theory
1036	SODA	Edge Coloring Planar Graphs with Two Outerplanar Subgraphs.	Lenwood S. Heath	1991	The standard problem of edge coloring a graph with k colors is equivalent to partitioning the edge set of the graph into k matchings. Here edge coloring is generalized by replacing matchings with outerplanar graphs. We give a polynomial-time algorithm that edge colors any planar graph with two outerplanar subgraphs. Two is clearly minimal for the class of planar graphs. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player	SODA	theory
1037	SODA	Offline Maintenance of Planar Configurations.	John Hershberger,Subhash Suri	1991	Offline Maintenance of Planar Configurations.	SODA	theory
1038	SODA	Upward Planar Drawing of Single Source Acyclic Digraphs.	Michael D. Hutton,Anna Lubiw	1991	Upward Planar Drawing of Single Source Acyclic Digraphs.	SODA	theory
1039	SODA	Randomized Competitive Algorithms for the List Update Problem.	Sandy Irani,Nick Reingold,Jeffery Westbrook,Daniel Dominic Sleator	1991	Randomized Competitive Algorithms for the List Update Problem.	SODA	theory
1040	SODA	On-Line Weighted Matching.	Bala Kalyanasundaram,Kirk Pruhs	1991	On-Line Weighted Matching.	SODA	theory
1041	SODA	Triangulating Three-Colored Graphs.	Sampath Kannan,Tandy Warnow	1991	Triangulating Three-Colored Graphs.	SODA	theory
1042	SODA	Approximating the Number of Zeroes of a GF[2] Polynomial.	Marek Karpinski,Michael Luby	1991	Approximating the Number of Zeroes of a GF[2] Polynomial.	SODA	theory
1043	SODA	On Finding Minimal 2-Connected Subgraphs.	Pierre Kelsen,Vijaya Ramachandran	1991	We present efficient parallel algorithms for the problems of finding a minimal 2-edge-connected spanning subgraph of a 2-edge-connected graph and finding a minimal biconnected spanning subgraph of a biconnected graph. The parallel algorithms for both problems run in polylog time using a linear number of PRAM processors. We also give sequential algorithms for these problems that run in time O(m+n log n) where n and m denote the number of vertices and edges, respectively, in the input graph.	SODA	theory
1044	SODA	Adaptive Heuristics for Binary Search Trees and Constant Linkage Cost.	Tony W. Lai,Derick Wood	1991	We present lower and upper bounds on adaptive heuristics for maintaining binary search trees using a constant number of link or pointer changes for each operation (constant linkage cost (CLC)). We show that no adaptive heuristic with an amortized linkage cost of o(log n) can be competitive. In particular, we show that any heuristic that performs f(n)=o(log n) promotions (rotations) amortized over each access has a competitive ratio of at least $\Omega(\log n/f(n))$ against an oblivious adversary, and any heuristic that performs f(n)=o(log n) pointer changes amortized over each access has a competitive ratio of at least $\Omega(\frac{\log n}{f(n)\log(\log n/f(n))})$ against an adaptive online adversary.In our investigation of upper bounds we present four adaptive heuristics: a randomized, worst-case-CLC heuristic randomized two-promotion (R2P) whose expected search time is within a constant factor of the search time using an optimal tree; that is, it is statically competitive against an oblivious adversary; a randomized, expected-CLC heuristic (locally optimized randomized partial splay (LORPS)) that has O(log n) expected-amortized update time and is statically competitive against an oblivious adversary; a deterministic, amortized-CLC heuristic (locally optimized partial splay (LOPS)) that has O(log n) amortized update time and is statically competitive against an adaptive adversary; a practical, randomized heuristic (randomized partial splay (RPS)) that is not CLC but has performance bounds comparable with those of the splay heuristic of Sleator and Tarjan; it is statically competitive against an adaptive adversary. The randomized heuristics use only constant extra space, whereas the deterministic heuristic uses O(n) extra space.	SODA	theory
1045	SODA	Recognizing Strong Connectivity in (Dynamic) Periodic Graphs and its Relation to Integer Programming.	Murali S. Kodialam,James B. Orlin	1991	Recognizing Strong Connectivity in (Dynamic) Periodic Graphs and its Relation to Integer Programming.	SODA	theory
1046	SODA	Density Graphs and Separators.	Gary L. Miller,Stephen A. Vavasis	1991	We propose a class of graphs that would occur naturally in finite-element problems, and we prove a bound on separators for this class of graphs. For three-dimensional graphs, our separator bound is $O(N^{2/3})$. We also propose a simple randomized algorithm to find this separator in $O(N)$ time. Such an algorithm would be used as a preprocessing step for the domain decomposition method of efficiently solving a finite-element problem on a parallel computer. This paper generalizes ``local graphs'''' of Vavasis [1990] to the case of graphs with varying densities of nodes. It also generalizes aspects of Miller and Thurston''s [1990] ``stable graphs.''''	SODA	theory
1047	SODA	Decomposing Graphs into Regions of Small Diameter.	Nathan Linial,Michael E. Saks	1991	Decomposing Graphs into Regions of Small Diameter.	SODA	theory
1048	SODA	An O(n) Time Algorithm for the 2-Chain Cover Problem and Related Problems.	Tze-Heng Ma,Jeremy Spinrad	1991	An O(n) Time Algorithm for the 2-Chain Cover Problem and Related Problems.	SODA	theory
1049	SODA	Ultra-Fast Expected Time Parallel Algorithms.	Philip D. MacKenzie,Quentin F. Stout	1991	Ultra-Fast Expected Time Parallel Algorithms.	SODA	theory
1050	SODA	The First Classical Ramsey Number for Hypergraphs is Computed.	Brendan D. McKay,Stanislaw P. Radziszowski	1991	The First Classical Ramsey Number for Hypergraphs is Computed.	SODA	theory
1051	SODA	Optimal Time Randomized Consensus - Making Resilient Algorithms Fast in Practice.	Michael E. Saks,Nir Shavit,Heather Woll	1991	Optimal Time Randomized Consensus - Making Resilient Algorithms Fast in Practice.	SODA	theory
1052	SODA	Finding Stabbing Lines in 3-Dimensional Space.	Marco Pellegrini,Peter W. Shor	1991	Finding Stabbing Lines in 3-Dimensional Space.	SODA	theory
1053	SODA	Tight Bounds on the Number of Minimum-Mean Cycle Cancellations and Related Results.	Tomasz Radzik,Andrew V. Goldberg	1991	Tight Bounds on the Number of Minimum-Mean Cycle Cancellations and Related Results.	SODA	theory
1054	SODA	Improved Approximation Algorithms for Shop Scheduling Problems.	David B. Shmoys,Clifford Stein,Joel Wein	1991	In the job shop scheduling problem, there are $m$ machines and $n$ jobs. A job consists of a sequence of operations, each of which must be processed on a specified machine, and the aim is to complete all jobs as quickly as possible. This problem is strongly ${\cal NP}$-hard even for very restrictive special cases. The authors give the first randomized and deterministic polynomial-time algorithms that yield polylogarithmic approximations to the optimal length schedule. These algorithms also extend to the more general case where a job is given not by a linear ordering of the machines on which it must be processed but by an arbitrary partial order. Comparable bounds can also be obtained when there are $m'$ types of machines, a specified number of machines of each type, and each operation must be processed on one of the machines of a specified type, as well as for the problem of scheduling unrelated parallel machines subject to chain precedence constraints.	SODA	theory
1055	SODA	A New Lower Bound Technique and Its Application: Tight Lower Bound for a Polygon Triangulation Problem.	Prakash V. Ramanan	1991	A New Lower Bound Technique and Its Application: Tight Lower Bound for a Polygon Triangulation Problem.	SODA	theory
1056	SODA	Maintaining the Minimal Distance of a Point Set in Polylogarithmic Time.	Michiel H. M. Smid	1991	Maintaining the Minimal Distance of a Point Set in Polylogarithmic Time.	SODA	theory
1057	SODA	Time-Work Tradeoffs for Parallel Graph Algorithms.	Thomas H. Spencer	1991	Time-Work Tradeoffs for Parallel Graph Algorithms.	SODA	theory
1058	SODA	On-Line Caching as Cache Size Varies.	Neal E. Young	1991	On-Line Caching as Cache Size Varies.	SODA	theory
1059	SODA	Proceedings of the Second Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 28-30 January 1991, San Francisco, California.	Alok Aggarwal	1991	Proceedings of the Second Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 28-30 January 1991, San Francisco, California.	SODA	theory
1060	STOC	Generic Computation and Its Complexity	Serge Abiteboul,Victor Vianu	1991	Generic Computation and Its Complexity	STOC	theory
1061	STOC	Factoring Numbers Using Singular Integers	Leonard M. Adleman	1991	Factoring Numbers Using Singular Integers	STOC	theory
1062	STOC	When Trees Collide: An Approximation Algorithm for the Generalized Steiner Problem on Networks	Ajit Agrawal,Philip N. Klein,R. Ravi	1991	We give the first approximation algorithm for the {\em generalized network Steiner tree problem}, a problem in network design. An instance consists of a network with link-costs and, for each pair ${i,j}$ of nodes, an edge-connectivity requirement. The goal is to find a minimum-cost network using the available links and satisfying the requirements. Our algorithm outputs a solution whose cost is within $ 2 \log R $ of optimal, where $R$ is the highest requirement value. In the course of proving the performance guarantee, we prove a combinatorial min-max approximate equality relating minimum-cost networks to maximum packings of certain kinds of cuts. As a consequence of the proof of this theorem, we obtain an approximation algorithm for optimally packing these cuts; we show that this algorithm has application to estimating the reliability of a probabilistic network.	STOC	theory
1063	STOC	Wait-free Parallel Algorithms for the Union-Find Problem	Richard J. Anderson,Heather Woll	1991	Wait-free Parallel Algorithms for the Union-Find Problem	STOC	theory
1064	STOC	When Won't Membership Queries Help? (Extended Abstract)	Dana Angluin,Michael Kharitonov	1991	When Won't Membership Queries Help? (Extended Abstract)	STOC	theory
1065	STOC	Sampling and Integration of Near Log-Concave functions	David Applegate,Ravi Kannan	1991	Sampling and Integration of Near Log-Concave functions	STOC	theory
1066	STOC	Searching in the Presence of Linearly Bounded Errors (Extended Abstract)	Javed A. Aslam,Aditi Dhagat	1991	Searching in the Presence of Linearly Bounded Errors (Extended Abstract)	STOC	theory
1067	STOC	The Expressive Power of Voting Polynomials	James Aspnes,Richard Beigel,Merrick L. Furst,Steven Rudich	1991	The Expressive Power of Voting Polynomials	STOC	theory
1068	STOC	Counting Networks and Multi-Processor Coordination	James Aspnes,Maurice Herlihy,Nir Shavit	1991	Counting Networks and Multi-Processor Coordination	STOC	theory
1069	STOC	Bounds on the Time to Reach Agreement in the Presence of Timing Uncertainty	Hagit Attiya,Cynthia Dwork,Nancy A. Lynch,Larry J. Stockmeyer	1991	Bounds on the Time to Reach Agreement in the Presence of Timing Uncertainty	STOC	theory
1070	STOC	Local Expansion of Vertex-Transitive Graphs and Random Generation in Finite Groups	László Babai	1991	Local Expansion of Vertex-Transitive Graphs and Random Generation in Finite Groups	STOC	theory
1071	STOC	Fast Monte Carlo Algorithms for Permutation Groups	László Babai,Gene Cooperman,Larry Finkelstein,Eugene M. Luks,Ákos Seress	1991	Fast Monte Carlo Algorithms for Permutation Groups	STOC	theory
1072	STOC	Checking Computations in Polylogarithmic Time	László Babai,Lance Fortnow,Leonid A. Levin,Mario Szegedy	1991	Checking Computations in Polylogarithmic Time	STOC	theory
1073	STOC	Deterministic Algorithms for Undirected s-t Connectivity Using Polynomial Time and Sublinear Space (Extended Abstract)	Greg Barnes,Walter L. Ruzzo	1991	Deterministic Algorithms for Undirected s-t Connectivity Using Polynomial Time and Sublinear Space (Extended Abstract)	STOC	theory
1074	STOC	PP Is Closed Under Intersection (Extended Abstract)	Richard Beigel,Nick Reingold,Daniel A. Spielman	1991	PP Is Closed Under Intersection (Extended Abstract)	STOC	theory
1075	STOC	Linear Approximation of Shortest Superstrings	Avrim Blum,Tao Jiang,Ming Li,John Tromp,Mihalis Yannakakis	1991	We consider the following problem: given a collection of strings s1,&hellip;, sm, find the shortest string s such that each si appears as a substring (a consecutive block) of s. Although this problem is known to be NP-hard, a simple greedy procedure appears to do quite well and is routinely used in DNA sequencing and data compression practice, namely: repeatedly merge the pair of (distinct) strings with maximum overlap until only one string remains. Let n denote the length of the optimal superstring. A common conjecture states that the above greedy procedure produces a superstring of length O(n) (in fact, 2n), yet the only previous nontrivial bound known for any polynomial-time algorithm is a recent O(n log n) result. We show that the greedy algorithm does in fact achieve a constant factor approximation, proving an upper bound of 4n. Furthermore, we present a simple modified version of the greedy algorithm that we show produces a superstring of length at most 3n. We also show the superstring problem to be MAXSNP-hard, which implies that a polynomial-time approximation scheme for this problem is unlikely.	STOC	theory
1076	STOC	Integral Equations, Systems of Quadratic Equations, and Exponential-Time Completeness (Extended Abstract)	Ker-I Ko	1991	Integral Equations, Systems of Quadratic Equations, and Exponential-Time Completeness (Extended Abstract)	STOC	theory
1077	STOC	Navigating in Unfamiliar Geometric Terrain (Preliminary Version)	Avrim Blum,Prabhakar Raghavan,Baruch Schieber	1991	Navigating in Unfamiliar Geometric Terrain (Preliminary Version)	STOC	theory
1078	STOC	Competitive Paging with Locality of Reference (Preliminary Version)	Allan Borodin,Sandy Irani,Prabhakar Raghavan,Baruch Schieber	1991	Competitive Paging with Locality of Reference (Preliminary Version)	STOC	theory
1079	STOC	A Lower Bound for Parallel String Matching	Dany Breslauer,Zvi Galil	1991	A Lower Bound for Parallel String Matching	STOC	theory
1080	STOC	Counting Linear Extensions is NP-Complete	Graham Brightwell,Peter Winkler	1991	Counting Linear Extensions is P-Complete	STOC	theory
1081	STOC	Finding Hidden Hamiltonian Cycles (Extended Abstract)	Andrei Z. Broder,Alan M. Frieze,Eli Shamir	1991	Finding Hidden Hamiltonian Cycles (Extended Abstract)	STOC	theory
1082	STOC	Constructing Nonresidues in Finite Fields and the Extended Riemann Hypothesis	Johannes Buchmann,Victor Shoup	1991	Constructing Nonresidues in Finite Fields and the Extended Riemann Hypothesis	STOC	theory
1083	STOC	Algorithms for Parallel k-Vertex Connectivity and Sparse Certificates (Extended Abstract)	Joseph Cheriyan,Ramakrishna Thurimella	1991	Algorithms for Parallel k-Vertex Connectivity and Sparse Certificates (Extended Abstract)	STOC	theory
1084	STOC	Fundamental Discrepancies between Average-Case Analyses under Discrete and Continuous Distributions: A Bin Packing Case Study	Edward G. Coffman Jr.,Costas Courcoubetis,M. R. Garey,David S. Johnson,Lyle A. McGeoch,Peter W. Shor,Richard R. Weber,Mihalis Yannakakis	1991	Fundamental Discrepancies between Average-Case Analyses under Discrete and Continuous Distributions: A Bin Packing Case Study	STOC	theory
1085	STOC	Proof of the 4/3 Conjecture for Preemptive vs. Nonpreemptive Two-Processor Scheduling	Edward G. Coffman Jr.,M. R. Garey	1991	Proof of the 4/3 Conjecture for Preemptive vs. Nonpreemptive Two-Processor Scheduling	STOC	theory
1086	STOC	Improved Algorithms for Linear Inequalities with Two Variables per Inequality (Extended Abstract)	Edith Cohen,Nimrod Megiddo	1991	Improved Algorithms for Linear Inequalities with Two Variables per Inequality (Extended Abstract)	STOC	theory
1087	STOC	Infinite Games, Randomization, Computability, and Applications to Online Problems (Preliminary Version)	Xiaotie Deng,Sanjeev Mahajan	1991	Infinite Games, Randomization, Computability, and Applications to Online Problems (Preliminary Version)	STOC	theory
1088	STOC	An Efficient Algorithm for the Genus Problem with Explicit Construction of Forbidden Subgraphs	Hristo Djidjev,John H. Reif	1991	An Efficient Algorithm for the Genus Problem with Explicit Construction of Forbidden Subgraphs	STOC	theory
1089	STOC	Non-Malleable Cryptography (Extended Abstract)	Danny Dolev,Cynthia Dwork,Moni Naor	1991	Non-Malleable Cryptography (Extended Abstract)	STOC	theory
1090	STOC	Clique Partitions, Graph Compression, and Speeding-Up Algorithms	Tomás Feder,Rajeev Motwani	1991	Clique Partitions, Graph Compression, and Speeding-Up Algorithms	STOC	theory
1091	STOC	Rigorous Time/Space Tradeoffs for Inverting Functions	Amos Fiat,Moni Naor	1991	We provide rigorous time-space tradeoffs for inverting any function. Given a function f, we give a time space tradeoff of TS2 = N3q(f), where q(f) is the probability that two random elements are mapped to the same image under f. We also give a more general tradeoff, TS3 = N3, that can invert any function at any point.	STOC	theory
1092	STOC	A Matroid Approach to Finding Edge Connectivity and Packing Arborescences	Harold N. Gabow	1991	A Matroid Approach to Finding Edge Connectivity and Packing Arborescences	STOC	theory
1093	STOC	Fully Dynamic Algorithms for Edge-Connectivity Problems (Extended Abstract)	Zvi Galil,Giuseppe F. Italiano	1991	Fully Dynamic Algorithms for Edge-Connectivity Problems (Extended Abstract)	STOC	theory
1094	STOC	Self-Testing/Correcting for Polynomials and for Approximate Functions	Peter Gemmell,Richard J. Lipton,Ronitt Rubinfeld,Madhu Sudan,Avi Wigderson	1991	Self-Testing/Correcting for Polynomials and for Approximate Functions	STOC	theory
1095	STOC	Dynamic Trees and Dynamic Point Location (Preliminary Version)	Michael T. Goodrich,Roberto Tamassia	1991	Dynamic Trees and Dynamic Point Location (Preliminary Version)	STOC	theory
1096	STOC	The Harmonic Online K-Server Algorithm Is Competitive	Edward F. Grove	1991	The Harmonic Online K-Server Algorithm Is Competitive	STOC	theory
1097	STOC	Constant-Time Parallel Integer Sorting (Extended Abstract)	Torben Hagerup	1991	Constant-Time Parallel Integer Sorting (Extended Abstract)	STOC	theory
1098	STOC	Hamiltonian Paths in Infinite Graphs	David Harel	1991	Hamiltonian Paths in Infinite Graphs	STOC	theory
1099	STOC	A Model for Data in Motion	Simon Kahan	1991	A Model for Data in Motion	STOC	theory
1100	STOC	Effective Noether Irreducibility Forms and Applications (Extended Abstract)	Erich Kaltofen	1991	Effective Noether Irreducibility Forms and Applications (Extended Abstract)	STOC	theory
1101	STOC	Lower Bounds for Randomized k-Server and Motion Planning Algorithms	Howard J. Karloff,Yuval Rabani,Yiftach Ravid	1991	Lower Bounds for Randomized k-Server and Motion Planning Algorithms	STOC	theory
1102	STOC	Probabilistic Recurrence Relations	Richard M. Karp	1991	Probabilistic Recurrence Relations	STOC	theory
1103	STOC	Combining Tentative and Definite Executions for Very Fast Dependable Parallel Computing (Extended Abstract)	Zvi M. Kedem,Krishna V. Palem,A. Raghunathan,Paul G. Spirakis	1991	Combining Tentative and Definite Executions for Very Fast Dependable Parallel Computing (Extended Abstract)	STOC	theory
1104	STOC	A General Completeness Theorem for Two-Party Games	Joe Kilian	1991	A General Completeness Theorem for Two-Party Games	STOC	theory
1105	STOC	Learning Decision Trees Using the Fourier Sprectrum (Extended Abstract)	Eyal Kushilevitz,Yishay Mansour	1991	Learning Decision Trees Using the Fourier Sprectrum (Extended Abstract)	STOC	theory
1106	STOC	Fast Approximation Algorithms for Multicommodity Flow Problems	Frank Thomson Leighton,Fillia Makedon,Serge A. Plotkin,Clifford Stein,Éva Tardos,Spyros Tragoudas	1991	In this paper, we describe the first polynomial-time combinatorial algorithms for approximately solving the multicommodity flow problem. Our algorithms are significantly faster than the best previously known algorithms, that were based on linear programming. For a k-commodity multicommodity flow problem, the running time of our randomized algorithm is (up to log factors) the same as the time needed to solve k single-commodity flow problems, thus giving the surprising result that approximately computing a k-commodity maximum-flow is not much harder than computing about k single-commodity maximum-flows in isolation. Given any multicommodity flow problem as input, our algorithm is guaranteed to provide a feasible solution to a modified flow problem in which all capacities are increased by a (1 + epsilon)-factor, or to provide a proof that there is no feasible solution to the original problem. We also describe faster approximation algorithms for multicommodity flow problems with a special structure, such as those that arise in the sparsest cut problems and the uniform concurrent flow problems if k >= the square root of m.	STOC	theory
1107	STOC	On-Line Learning of Linear Functions	Nick Littlestone,Philip M. Long,Manfred K. Warmuth	1991	We present an algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials. The bounds are logarithmic in the number of variables. Furthermore, the algorithm is shown to be optimally robust with respect to noise in the data (again to within a constant factor). We also discuss an application of our methods to the iterative solution of sparse systems of linear equations.	STOC	theory
1108	STOC	On Deterministic Approximation of DNF	Michael Luby,Boban Velickovic	1991	On Deterministic Approximation of DNF	STOC	theory
1109	STOC	Converting High Probability into Nearly-Constant Time-with Applications to Parallel Hashing (Extended Abstract)	Yossi Matias,Uzi Vishkin	1991	Converting High Probability into Nearly-Constant Time-with Applications to Parallel Hashing (Extended Abstract)	STOC	theory
1110	STOC	Approximations and Optimal Geometric Divide-And-Conquer	Jirí Matousek	1991	Approximations and Optimal Geometric Divide-And-Conquer	STOC	theory
1111	STOC	Perfect Cryptographic Security from Partially Independent Channels	Ueli M. Maurer	1991	Perfect Cryptographic Security from Partially Independent Channels	STOC	theory
1112	STOC	Reducing Elliptic Curve Logarithms to Logarithms in a Finite Field	Alfred Menezes,Scott A. Vanstone,Tatsuaki Okamoto	1991	Reducing Elliptic Curve Logarithms to Logarithms in a Finite Field	STOC	theory
1113	STOC	Hidden Surface Removal with Respect to a Moving View Point	Ketan Mulmuley	1991	Hidden Surface Removal with Respect to a Moving View Point	STOC	theory
1114	STOC	Lower Bounds for Non-Commutative Computation (Extended Abstract)	Noam Nisan	1991	Lower Bounds for Non-Commutative Computation (Extended Abstract)	STOC	theory
1115	STOC	Rounds in Communication Complexity Revisited	Noam Nisan,Avi Wigderson	1991	Rounds in Communication Complexity Revisited	STOC	theory
1116	STOC	Separating Concurrent Languages with Categories of Language Embeddings (Extended Abstract)	Ehud Y. Shapiro	1991	Separating Concurrent Languages with Categories of Language Embeddings (Extended Abstract)	STOC	theory
1117	STOC	Testing Finite State Machines (Extended Abstract)	Mihalis Yannakakis,David Lee	1991	Testing Finite State Machines (Extended Abstract)	STOC	theory
1118	STOC	Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, 6-8 May 1991, New Orleans, Louisiana, USA		1991	Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, 6-8 May 1991, New Orleans, Louisiana, USA	STOC	theory
1119	IEEE Visualization	The Hyperbox.	Bowen Alpern,Larry Carter	1991	A hyperbox is a 2-dimensional depiction of an N-dimensional box (rectangular parallelepiped). This paper defines the visual syntax of hyperboxes, states some properties, and sketches two applications. Hyperboxes can be evocative visual names for tensors or multidimensional arrays in visual programming languages. They can also be used to simultaneously display all pairwise relationships in an N-dimensional dataset. We show that this can be helpful in choosing a sequence of dimension-reducing transformations that preserve interesting properties of the dataset.	IEEE Visualizat	visu
1120	IEEE Visualization	The Virtual Windtunnel: An Environment for the Exploration of Three-Dimensional Unsteady Flows.	Steve Bryson,C. Levit	1991	We describe a recently completed implementation of a virtual environment for exploring numerically-generated three-dimensional unsteady flowfields. A boom-mounted six degree of freedom head-position-sensitive stereo CRT system is used for viewing. A hand position sensitive glove controller is used for injecting various tracers (e.g., smoke) into the virtual flowfield. A mutiprocessor graphics workstation is used for computation and rendering. We describe our techniques for visualizing unsteady flows and discuss the computer requirements for a variety of visualization techniques. These techniques generalize to visualization of other three-dimensional vector fields.	IEEE Visualizat	visu
1121	IEEE Visualization	Interactive Data Visualization Using Focusing and Linking.	Andreas Buja,John Alan McDonald,J. Michalak,Werner Stuetzle	1991	This paper discusses two basic principles for interactive visualization of high dimensional data: focusing and linking. The paper and the accompanying video give examples of how graphical data analysis methods based on focusing and linking are used in applications including linguistics, geographic information systems, time series analysis, of multi-channel images arising in radiology and remote sensing.	IEEE Visualizat	visu
1122	IEEE Visualization	Visualizing Environmental Data for Program Decision Support.	J. Burnetti,R. Manley,W. Mitchell,D. Varnadore	1991	The McClellan Air Force Base Installation Restoration Program (IRP) is responsible for identifying and remediating environmental contamination from past operations and disposal practices. Since 1979, the IRP has generated over 200 volumes of technical reports regarding the degree and extent of contamination at the base. The base is in the process of automating the storage, retrieval, and analysis of the technical data generated by the cleanup program. This paper discusses the requirements for the IRP technical information system, presents the development approach taken, illustrates visualization results from the system prototype, and outlines future plans for development of the system.	IEEE Visualizat	visu
1123	IEEE Visualization	A Scientific Visualization Synthesizer.	Roger Crawfis,M. J. Allison	1991	We describe methods for displaying scientific data using textures and raster operations rather than geometric techniques. The flexibility and simplicity of raster operations allow a greater choice of visualization techniques with only a small set of basic operations. In addition, texture mapping techniques will be shown that allow the representation of several variables simultaneously, without a high degree of clutter. The combination of traditional geometric techniques, image composition techniques and image rendering techniques can be integrated into a single framework for the display of scientific data. This paper presents a system for generating and operating on textures and images for the purposes of scientific visualization. The advantages of using such a system are demonstrated through the use of examples. In particular, the development of bump maps for vector filters and contour lines is demonstrated.	IEEE Visualizat	visu
1124	IEEE Visualization	NetV: An Experimental Network-Based Volume Visualization System.	T. Todd Elvins,David R. Nadeau	1991	Volume data imaging is a computationally expensive process. Imaging small volume data sets is slow when executed on typical workstation-class machines and imaging large volume data sets on such machines is nearly impossible. Executing the same tasks on mini-supercomputer class systems can significantly reduce imaging times and job-size restrictions, but at the cost of increased user-interface and accessibility problems. In a well-integrated system, computational tasks should be handled by high-powered compute engines, while user-interface tasks are left to graphics workstations.At the San Diego Supercomputer Center (SDSC), an experimental volume visualization system is being tested that distributes volume imaging tasks to appropriate network resources. Remote high-powered compute engines process rendering tasks, while local workstations run the user-interface.	IEEE Visualizat	visu
1125	IEEE Visualization	Gray Scale Diagrams as Business Charts.	W. R. Feeney	1991	The flood of numeric data in science and technology has prompted new graphic representations called visualization. Business also has a serious need for new graphic representations. One candidate comes from the unlikely gray scale. Gray scale diagrams can present large amounts of quantitative information in a compact format. Hundreds of data points can easily be represented in one diagram, using small gray scale squares (or tiles), without visually overloading a viewer. An experiment was done to compare subjects' responses to answer questions from three types of charts, traditional column and line charts and gray scale tile charts. The results showed that questions were answered more correctly and more quickly using gray scale tile charts than using traditional charts. However, subjects reported they experienced more strain using gray scale tile charts.	IEEE Visualizat	visu
1126	IEEE Visualization	Multidimensional Real-Time Visualization on Personal Computers.	Q. E. Dolocek	1991	This case study describes a low-cost, high-performance visualization tool based on the IBM PC. Characteristics of scientific and engineering visualization and requirements for real time analysis are discussed. Application programming without coding by use of flowgraphs is also presented.	IEEE Visualizat	visu
1127	IEEE Visualization	Multi-Valued Volumetric Visualization.	Thomas A. Foley,David A. Lane	1991	Effective methods for visualizing several sets of volumetric data simultaneously are presented which involve the composition of multiple volumetric rendering techniques. Although there are many methods for visualizing volumetric data, most of these methods can only render one set of volumetric data at a time. By rendering several volumetric data sets simultaneously, relationships among the data sets can be visualized, which may be difficult or impossible to visualize when the data sets are rendered individually.	IEEE Visualizat	visu
1128	IEEE Visualization	Span Filering: An Optimization Scheme for Volume Visualization of Large Finite Element Methods.	R. S. Gallangher	1991	Techniques for displaying 3D isovalues of scalar fields such as stress within a solid finite element model generally involve examining each element for values of interest. An inexpensive, straightforward method is discussed to reduce the number of elements searched for such isovalues. It takes advantage of one traversal of the element data to yield a compact classification of the model by result values and ranges, with no sorting required. This data structure can then relate any scalar isovalue to a set of element groups which are closely inclusive of the isovalue.This method is intended for applications requiring repeated access to the analysis data, such as animation and interactive rendering of isosurfaces and scalar fields. While applicable to general volume visualization problems, it is particularly well suited to optimizing real-valued continuum field result such those found in finite element result data.	IEEE Visualizat	visu
1129	IEEE Visualization	Enhanced Visualization of Multi-dimensional Structures: Applications in Positron Emission Tomography and Cimate Data.	Nahum D. Gershon	1991	In this work, we have developed an algorithm based on mathematical morphology, image processing, and volume rendering to enhance the visual perception of definite and abstract structures embedded in multidimensional data undergoing visualization. This erosion procedure enhances the depth and shape perception of structures present in the data beyond the perception facilitated by shading and contrasty colors alone [Gershon, 1990]. The utility of this algorithm is demonstrated in medical imaging (Positron Emission Tomography) and climate (sea surface temperature) data. The resulting information is displayed in stereo.	IEEE Visualizat	visu
1130	IEEE Visualization	A Tool for Visualizing the Topology of Three-Dimensional Vector Fields.	Al Globus,C. Levit,T. Lasinski	1991	We describe a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three dimensional vector field, v, to produce a single relatively simple picture that characterizes v. The topology of v that we consider consists of its critical points (where v = 0), their invariant manifolds, and the integral curves connecting these invariant manifolds. Many of the interesting features of v are associated with its critical points. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first non-zero term of the Taylor expansion around a critical point are the 3x3 matrix &dtri;v. Critical points are classified by examining &dtri;v's eigenvalues. The eigenvectors of &dtri;v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. In addition, one class of critical surfaces important in computational fluid dynamics is analyzed.TOPO is implemented as a module in the FAST [1] visualization environment. FAST is general purpose visualization software with modules for isosurface generation, particle tracing, etc. TOPO operates on curvilinear, structured grids, including large multi-zone grids. We have used TOPO to visualize a number of computational fluid dynamics (CFD) data sets. The results agree well with other topology software and hand generated topologies. TOPO has proved useful in finding surface topology, flow attachment and separation points, vortex cores, scalar field local extrema, and generally interesting regions of v. We believe there may be other interesting applications yet to be discovered. This paper, along with the references, contains most of the information needed for a scientific programmer to code a topology module in another environment.	IEEE Visualizat	visu
1131	IEEE Visualization	How Shall We Connect Our Software Tools?	Eric Grosse	1991	Traditionally we connect our software tools using human-readable files. This is a conscious decision to buy flexibility and understandability at some cost in performance relative to binary file formats. This note explores the possibility of using shared memory functions to retain most of the existing style while leapfrogging the speed of reading binary files, at least in some environments and for some applications.	IEEE Visualizat	visu
1132	IEEE Visualization	Data Model for Scientific Visualization with Provisions for Regular and Irregular Grids.	Robert B. Haber,Bruce Lucas,Nancy S. Collins	1991	Data Model for Scientific Visualization with Provisions for Regular and Irregular Grids.	IEEE Visualizat	visu
1133	IEEE Visualization	Visualization in Computational Fluid Dynamics: A Case Study.	Robert Haimes,D. Darmofal	1991	VISUAL3 is a highly-interactive environment for the visualization of 3D volumetric scientific data. The volume may be broken up in a structured or unstructured manner. Also, the problem may be static or unsteady in time. Because the data is volumetric (not just surfaces), and all the information can be changing, traditional CAD techniques are not appropriate. Therefore VISUAL3 was developed using immediate mode rendering methods.A unique aspect of VISUAL3 is the dimensional windowing approach coupled with cursor mapping which allows efficient pointing in 3D space.VISUAL3 is composed of a large number of visualization tools that can be generally classified into identification, scanning and probing techniques.	IEEE Visualizat	visu
1134	IEEE Visualization	Visualizing the Fourth Dimension Using Geometry and Light.	Andrew J. Hanson,P. A. Peng	1991	Visualizing the Fourth Dimension Using Geometry and Light.	IEEE Visualizat	visu
1135	IEEE Visualization	Deixis and the Future of Visualization Excellence.	William C. Hill,James D. Hollan	1991	The nature of visualizations and the social uses to which they are put rely heavily on pointing, or to use the linguistic term, deixis. Of particular importance for visualization excellence is an understanding of effective deictic facilities, especially new techniques enabled by computation. In this paper, we (1) explain what deixis is, (2) say why it is fundamental to visualization, (3) analyze some of what is required for effective deixis in the context of emergent visualization technology, and (4) provide an accompanying video demonstration of deictic techniques for visualization.	IEEE Visualizat	visu
1136	IEEE Visualization	The Visual Comparison of Three Sequences.	K. P. Hinkley,Matthew O. Ward	1991	Scientists (particularly biologists) currently lack effective tools for comparing multiple sequences of numbers or symbols. This paper describes a method of visual comparison which provides the scientist with a new and unique tool to study the qualitative relationships between three such sequences. The program displays a three-dimensional shape containing the sequence similarities and differences, which manifest themselves as simple geometric shapes and colors that a human observer can easily detect and classify. The method presents all possible correlations to the user, giving it a considerable advantage over existing sequence comparison tools which only search for a programmed subset of all possible correlations. Thus, using this technique, researchers may detect sequence similarities which available analytic methods might completely overlook. The program can also filter out undesirable or insignificant correlations, letting the user focus full attention on the more interesting sequence relationships. The technique enjoys facile adaptation to a wide range of applications, including DNA and protein sequence analysis, speech analysis, signal processing, text comparison, and image analysis.	IEEE Visualizat	visu
1137	IEEE Visualization	Visualizing Chemical Kinetics in Fractal Domains.	N. E. Hurlburt,L. W. Anacker,R. Kopelman	1991	Chemical reactions occurring within complex domains, such as fractals, can display behavior which differs radically from the expectations of classical chemical kinetics. Rather than relaxing to a uniform distribution at the steady state, these non-classical systems display large-scale order on many scales. Such self-organization is difficult to measure using the usual statistical techniques, but is visually apparent. Hence visualization is essential to the understanding of these chemical systems. We discuss some of the problems of visualizing chemical kinetics in fractal domains and describe evolution of the visualization as the chemist and visualization scientist collaborated.	IEEE Visualizat	visu
1138	IEEE Visualization	Tree maps: A Space-Filling Approach to the Visualization of Hierarchical Information Structures.	B. Johnson,Ben Shneiderman	1991	This paper describes a novel method for the visualization of hierarchically structured information. The Tree-Map visualization technique makes 100% use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information.	IEEE Visualizat	visu
1139	IEEE Visualization	Integration of Visualization and Scientific Calculation in a Software System.	Ulrich Lang,R. Lang,R. Rule	1991	This paper presents the problems and advantages of the integration of scientific computations and visualization into one common program system. An important point is the direct feedback of information from the visualization into an ongoing simulation. Some strong and weak points of the varying approaches in different software packages are shown. The visualization component of the program system developed at our computer center and the advantages of its integration into the overal system is explained. Finaly the weak points in our system and the open work items to deal with them are described.	IEEE Visualizat	visu
1140	IEEE Visualization	Topographical Mapping of Brain Electrical Activity.	S. K. Law,P. L. Nunez,A. F. Westdorp,A. V. Nelson,K. L. Pilgreen	1991	An interdisciplinary approach is applied toward the development of methods to improve spatial resolution of brain electrical activity. Methods to interpolate the potential distribution and to estimate the surface Laplacian from multi-channel data are presented and applied to human evoked potential data. Although developed for electroencephalographic (EEG) data, these spline algorithms can be applied to a variety of fields where visualization of spatial information is desired.	IEEE Visualizat	visu
1141	IEEE Visualization	Shadowed Hedgehogs: A Technique for Visualizing 2D Slices of 3D Vector Fields.	R. Victor Klassen,Steven J. Harrington	1991	The technique of placing directed line segments at grid points, known as hedgehogging, has been used for some time as a tool for visualizing two dimensional vector fields. We provide a means of rapidly rendering a slice of a three dimensional field, suitable for a bilevel display. Shape and shadowing are used to disambiguate orientation. Liberal use of lookup tables makes the technique very fast.	IEEE Visualizat	visu
1142	IEEE Visualization	Cooperative, Computer-Aided Design of Scientific Visualizations.	Sandeep Kochhar,Mark Friedell,Mark Vincent LaPolla	1991	While the field of scientific visualization has grown rapidly over the last decade, the task of designing graphical displays that effectively depict the data to be visualized is still a time-consuming, difficult, and essentially manual process. This paper proposes an approach to partially automating the process through cooperative computer-aided design (CCAD)--a paradigm that combines the strengths of manual and automated design by interspersing guiding design operations by the human user with the exploration of design alternatives by the computer. We demonstrate this approach in the context of the IVE design system--a CCAD environment for the design of scientific visualizations. Given a set of design requirements, the system is able to generate several alternative visualizations using a set of design rules that combine primitive visualization components in different ways. These alternatives are presented graphically to the user, who can browse through them, select the most promising visualization and refine it manually.	IEEE Visualizat	visu
1143	IEEE Visualization	Computer Assisted Sphere Packing in Higher Dimensions.	Nelson L. Max	1991	A computer was used to help study the packing of equal spheres in dimension four and higher. A candidate for the densest packing in 4-space is described. The configuration of 24 spheres touching a central sphere in this packing is shown to be rigid, unlike the analogue in 3-space, in which the spheres can slide past each other. A system for interactively manipulating and visualizing such configurations is described.The Voronoi cell for a sphere is the set of points closer to its center than to any other sphere center in the packing. The packing density is the ratio of a sphere's volume to the average of the volumes of the Voronoi cells. A method of constructing Voronoi cells and computing their volumes is presented, which works in any dimension. Examples of Voronoi cell volumes are given.	IEEE Visualizat	visu
1144	IEEE Visualization	Advanced Visualization on Desktop Workstations.	S. M. Legensky	1991	Computer graphics and visualization play a central role in software tools for Computer-Aided Engineering (CAE) and scientific research. As capabilities of low-cost workstations are enhanced both through price/performance breakthroughs and distributed computing, more sophisticated interactive techniques become locally available to a wider range of users.This paper explores some of the primary challenges that face designers of hardware and software for visualization who are attempting to create tools that will be used and widely accepted. Possible solutions to some of these challenges have been incorporated into FIELDVIEW, a commercial tool for increasing engineering productivity in Computational Fluid Dynamics (CFD).	IEEE Visualizat	visu
1145	IEEE Visualization	Color Icons: Merging Color and Texture Perception for Integrated Visualization of Multiple Parameters.	Haim Levkowitz	1991	Multiparameter data collection is becoming increasingly common in many scientific disciplines. The need exists for integrated displays to enable the scientist to see the combined information, some of which may not be adequately perceived or may not be perceived at all when viewed individually. In order for such displays to succeed, they must exploit the visual perceptual capabilities as much as possible. We present a new technique that harnesses color and texture perception to create integrated displays of two-dimensional imagelike multiparameter distributions. The power of the new technique is demonstrated by an example of a synthesized dataset comparing it with several other proposed techniques. We discuss the nature of studies required to measure objectively and accurately the effectiveness of such displays.	IEEE Visualizat	visu
1146	IEEE Visualization	Golf Green Visualization.	William E. Lorensen,B. Yamron	1991	Television coverage of golf fails to bring the viewer an appreciation of the complex topography of a golf green and how that topography affects the putting of golf balls, We present a computer graphics simulation that enhances the viewer perception of these features using shaded polygonal models of the actual golf greens used in tournaments. Mathematical modeling of the golf ball's trajectory on its way towards the hole further enhances viewer understanding. A putting from each location on the green to a given pin position. The object-oriented system is written in C and runs on a variety of 3D graphics workstations, As an experiment, the system was used at a professional golf tournament and correctly simulated all putts during the final round.	IEEE Visualizat	visu
1147	IEEE Visualization	Image Handling in a Multi-Vendor Environment.	David R. Nadeau,T. Todd Elvins,Michael J. Bailey	1991	In an ideal world every hardware and software vendor stores the same type of data in the same file format. Software packages transparently exchange their data and results. Different vendor's hardware platforms read and write each other's files without a hitch. And the skies are not cloudy all day.This paper discusses software developed by the San Diego Supercomputer Center (SDSC) to deal with the real world of differing image file formats, mismatched byte orders and word sizes, and confusing hardcopy device interfaces.	IEEE Visualizat	visu
1148	IEEE Visualization	Achieving Direct Volume Visualization with Interactive Semantic Region Selection.	Terry S. Yoo,Ulrich Neumann,Henry Fuchs,Stephen M. Pizer,Tim J. Cullip,John Rhoades,Ross T. Whitaker	1991	Interactive direct visualization of 3D data requires fast update rates and the ability to extract regions of interest from the surrounding data. Parallel volume rendering yields rates that make interactive control of image viewing possible for the first time. We have achieved rates as high as 15 frames per second by trading some function for speed. while volume rendering with a full complement of ramp classification capabilities is performed at 1.4 frames per second. These speeds have made the combination of region selection with volume rendering practical for the first time. Semantic driven selection, rather than geometric clipping, has proven to be a natural means of interacting with 3d data. Internal organs in medical data or other regions of interest can be built from preprocessed region primitives. We have applied the resulting combined system to real 3D medical data with encouraging results. The ideas presented are not just limited to our platform, but can be generalized to include most parallel architectures. We present lessons learned from writing fast volume renderers and from applying image processing techniques to viewing volumetric data.	IEEE Visualizat	visu
1149	IEEE Visualization	The Asymptotic Decider: Resolving the Ambiguity in Marching Cubes.	Gregory M. Nielson,Bernd Hamann	1991	A method for computing isovalue or contour surfaces of a trivariate function is discussed. The input data are values of the trivariate function, Fijk, at the cuberille grid points (Xi, yj, zk) and the output is a collection of triangles representing the surface consisting of all points where F(x, y, z) is a constant value. The method described here is a modification that is intended to correct a problem with a previous method.	IEEE Visualizat	visu
1150	IEEE Visualization	Visualization and Analysis of Multivariate Data: A Technique for all Fields.	Ted Mihalisin,John Timlin,J. Schwegler	1991	Visualization and Analysis of Multivariate Data: A Technique for all Fields.	IEEE Visualizat	visu
1151	IEEE Visualization	Two Widely Different Architectural Approaches to Computer Image Generation.	H. W. Park,K. S. Eo,D. L. Kim,B. K. Choi,Y. Kim,T. Alexander	1991	Among several systems from the UWGSP (University of Washington Graphics System Processor) series, two recent architectures were designed for imaging and graphics, One of them, UWGSP3, has already been completed and is being used for selected applications, while the other one, UWGSP4, is being implemented now.These two systems use parallel and pipelined architectures for high performance graphics operations. UWGSP3 uses only commercially available of-the-shelf chips, and consists of a TMS34082 graphics system processor and four TMS34082 floating point coprocessor that can be configured into pipelined or SIMD modes depending on the algorithm. UWGSP4, however, uses dedicated ASIC (Application Specific IC) chips for higher performance, and consists of two main computational parts: a parallel vector processor with 16 vector processing units, used mainly for image processing, and a graphics subsystem which utilizes a parallel pipelined architecture for image synthesis.IN this paper, the computer graphics aspects of both UWGSP3 and UWGSP4 will be described.	IEEE Visualizat	visu
1152	IEEE Visualization	Distributed Visualization using Workstations, SuperJacques Lévy-Vehelcomputers and High Speed Networks.	David W. Robertson,V. L. Jacobson,William E. Johnston,S. C. Loken,E. H. Theil,B. L. Tieney	1991	Distributed Visualization using Workstations, SuperJacques Lévy-Vehelcomputers and High Speed Networks.	IEEE Visualizat	visu
1153	IEEE Visualization	Acoustic Imaging: The Reconstruction of Underwater Objects.	Lawrence J. Rosenblum,Behzad Kamgar-Parsi,Edward O. Belcher,O. Engelsen	1991	While many sensors now produce a plethora of data, some still produce an insufficient number of samples. This is true for the marine scientific community, because the theory of wave propagation in water dictates the use of acoustic frequencies for underwater imaging. In this paper we discuss reconstruction of 3D scenes using data from an acoustic imaging sonar. Two methods for visualizing objects in an acoustic snapshot of the ocean are discussed: mathematical morphology and a synthesis of 3D digital imaging with volume rendering.	IEEE Visualizat	visu
1154	IEEE Visualization	Experiments with Interdisciplinary Projects and Scientific Visualization Applications at the Undergraduate Level.	Nan C. Schaller	1991	This paper describes the interaction between computer graphics students from the computer science department at Rochester Institute of Technology and faculty from various disciplines, in their attempts to utilize state-of-the-art computer graphics techniques for the visualization of physical systems. The structure of a computer graphics course designed to act as the vehicle for this interaction is also described.	IEEE Visualizat	visu
1155	IEEE Visualization	Fast Rotation of Volume Data on Data Parallel Architectures.	P. Schroder,J. B. Salem	1991	Data parallel computer architectures hold great promises for high performance computing. Volume visualization (raytracing) is an application that can greatly benefit from these architectures. We describe an algorithm for rendering of orthographic views of volume data on such architectures. In particular the problem of rotating the volume in regard to the communication overhead associated with finely distributed memory is analyzed. We extend an earlier technique (shear decomposition) to 3D and show how this can be mapped onto a data parallel architecture using only grid communication during the resampling associated with the rotation. The rendering uses efficient parallel computation constructs that allow us to use sophisticated shading models and still maintain high speed throughout. This algorithm has been implemented on the Connection MachineR parallel supercomputer and is used in an interactive volume rendering application, with multiple frames per second performance.	IEEE Visualizat	visu
1156	IEEE Visualization	The Stream Polygon: A Technique for 3D Vector Field Visualization.	William J. Schroeder,Christopher R. Volpe,William E. Lorensen	1991	We present a new method for the visualization of 3D vector fields called the Stream polygon: a regular, n-sided polygon, oriented normal to the local vector, The polygon can represent local deformation due to rigid body rotation and both normal and shear strain. In addition, the effects of translation and scalar functions may be represented by sweeping the stream polygon along the streamline, and by appropriately varying the radius and shading the surface of the resulting streamtube. In this paper we develop a mathematical foundation for the stream polygon, and provide examples with application to velocity field visualization.	IEEE Visualizat	visu
1157	IEEE Visualization	A Fast Ray Casting Algorithm Using Adaptive Isotriangular Subdivision.	R. Shu,A. Lui	1991	Ray casting is a popular method of rendering high quality images from volume data. Its main shortcoming has been the high computational expense. This paper proposes a method of subdividing the image plane with isosceles triangles instead of quadrants as is usually done, resulting in fewer rays being fired without sacrificing image quality. A brief theoretical analysis of the algorithm in comparison with other methods is given.	IEEE Visualizat	visu
1158	IEEE Visualization	Visualizing Causal Effects in 4D Space-Time Vector Fields.	Deborah Silver,M. Gao,Norman Zabusky	1991	In this paper, we present a method to juxtapose 4D space-time vector fields in which one contains a source variable and the other the response field. The technique helps highlight the topological relationship between the two in an effort to understand the causal connection. These concepts are applied to ongoing research in evolving fluid dynamical problems.	IEEE Visualizat	visu
1159	IEEE Visualization	Designing a Distributed Scientific Visualization Tool.	L. van der Sluis	1991	Technology Applications, Inc. (TAI) provides supercomputing services for the Naval Underwater Systems Center (NUSC) in New London, Connecticut and Newport, Rhode Island. Many NUSC engineers and scientists use the CRAY X-MP/28 to accomplish their work in such diverse areas as acoustic modeling, finite element analysis, and computational fluid dynamics. This paper focuses on the benefits of using a distributed scientific visualization tool in the field of acoustic modeling.	IEEE Visualizat	visu
1160	IEEE Visualization	Interactive Data Exploration with a Supercomputer.	Stuart Smith,Georges G. Grinstein,R. Daniel Bergeron	1991	Scientific data of high-dimensionality is particularly difficult to understand if there are complex (and perhaps unknown) interactions among parameters. In such situations, the scientist can turn to a process Tukey has called exploratory data visualization. In exploratory data visualisation, we typically do not know exactly what we are looking for; instead, we explore the data with a variety of visualization techniques that can help us understand the nature of the data by demonstrating patterns in it. Given the complexity of the data and the large number of ways to map the data to a display, exploratory visualization can be truly effective only if it can also be interactive. In this paper we describe an experiment in exploratory data visualization using a massively parallel processor. With this approach we were able to find new features in some of our oldest datasets and to create more vivid presentations of familiar features in these datasets. Our experience has also led us to a better understanding of the nature of exploratory visualization and has resulted in some formal representations of the interaction process in this environment.	IEEE Visualizat	visu
1161	IEEE Visualization	Visualization Tools for Semi-Conductor Modeling Software.	Duncan Stevenson	1991	This case study looks at the issues involved in using a visualisation software package to extend the scope of an existing suite of semi-conductor modelling software.The visualisation software and its hardware platform represent the state of the art in powerful interactive workstation visualisation systems. The semi-conductor modelling software is the result of joint development between research groups and industry, and is at the leading edge in terms of the underlying models used and the solution techniques employed.The result of this case study is the identification of a range of important issues to be considered when applying off the shelf visualisation software to a real-world scientific problem.	IEEE Visualizat	visu
1162	IEEE Visualization	Volume Rendering of Flow-Visualization Point Data.	P. G. Swann,Sudhanshu Kumar Semwal	1991	A survey of two and three-dimensional flow-visualization techniques is provided. Our approach is base on applying volume rendering to flow-visualization data. Linear interpolation and B-Spline approximation is used. Several views are given for linear interpolation and B-spline approximation. Our aim is to offer researchers to see three-dimensional (3-D) views of multiple slices. Thus, relieving them from mental visualization of two-dimensional (2-D) slices. We conclude by providing suggestions for efficient volume rendering.	IEEE Visualizat	visu
1163	IEEE Visualization	Visualizing 4-D Medical Ultrasound Data.	Nils Thune,Bjørn Olstad	1991	There is an increasing interest in visualizing 4-D ultrasound data for use in medical diagnosis. This paper discusses different standard rendering methods applied to 4-D medical ultrasound data. In particular we have tested maximum value projection, sum of values projection, transparent gray level gradient shading, and surface shading. Due to the fact that ultrasound data suffer from a low signal to noise ratio issues such as image processing and image analysis are used with the purpose to enhance and classify the volumetric data set.	IEEE Visualizat	visu
1164	IEEE Visualization	Run-Time Visualization of Program Data.	Allan Tuchman,David Jablonowski,George Cybenko	1991	An important improvement to visualization systems will provide a graphics window into an application displaying program data at run-time through an easy-to-use graphical interface. With little or no instrumentation of the application the user will be able to dynamically select data for graphical display as the program executes on a remote computer system. The data to be displayed and the type of display to be used are chosen interactively while the application is executing. Any data display can be enabled or disabled at any time; it is not necessary to specify the data or graphics technique before compilation as with conventional graphics tools. We propose an architecture for such a remote visualization system, and describe Vista, our implementation. Designed primarily for scientific visualization, Vista also offers an environment for more effective debugging and program development.	IEEE Visualizat	visu
1165	IEEE Visualization	Visualization of Equations in an Interactive Environment.	David Watson,Jakub Wejchert,David W. Williams,Bri M. Collins	1991	The interactive visualization of equations in 3D is potentially an important tool for both research and education. We describe a method of visualizing equations in their explicit form using 3D fields. Equations are written algebraically, interpreted by an equation parser and then expressed as scalar fields. Fields are represented as isosurfaces making use of an algorithm similar to the method of marching cubes. The implementation allows the real time interaction of equation parameters, isosurface and colouring. A variety of applications from mathematics and physics are given together with examples of the construction of data probes using equations.	IEEE Visualizat	visu
1166	IEEE Visualization	The Electronic Structure of Oxygen in Silicon as Revealed by Volume Visualization of Ab Initio Calculations.	R. H. Wolfe,M. Needels,J. D. Jaonnopoulos	1991	We apply volumetric rendering to the interpretation of atomic-scale data generated from quantum molecular dynamics computations. In particular, we examine silicon computations, and we discover that volumetric visualization of the computed 3D electronic charge density is a valuable tool for identifying defect states in silicon lattices in which oxygen atoms occur as impurities. Rendering of several judiciously selected ranges of charge density in translucent colors provides an effective means of identifying broken or altered molecular bonds and induced charge excesses in the lattice. The resulting 3D images reveal important features missed previously in 2D charge density contour maps. We find that stereoscopic blink comparison of image pairs is an extremely valuable way to study the structural differences among various configurations and that time animation provides significant in sight into the molecular dynamics. We conclude that our success with silicon implies that the technique has the potential to provide a significant benefit to other problems in computational condensed matter physics.	IEEE Visualizat	visu
1167	IEEE Visualization	Realistic Volumetric Imaging.	Roni Yagel,Arie E. Kaufman,Q. Zhang	1991	We present a set of volume visualization tools that are based on the use of recursive ray tracing as the primary vehicle for realistic volume imaging. The visualization tools include shadows, mirrors, specularity, and constructive solid geometry. The underlying representation for the ray tracer is a 3D raster of voxels that holds the discrete form of the scene. Unlike traditional volume rendering techniques, our discrete recursive ray tracer models many illumination phenomena by traversing discrete rays in voxel space. Our approach provides true ray tracing of sampled or computed datasets, as well as ray tracing of hybrid scenes where sampled or computed datasets, as well as ray tracing of hybrid scenes where sampled or computed data are intermixed with geometric models. We demonstrate that our techniques enhance the understanding of complex biomedical datasets.	IEEE Visualizat	visu
1168	IEEE Visualization	In Vivo Blood Flow Visualization with Magnetic Resonance Imaging.	Guang-Zhong Yang,Peter Burger,Philip J. Kilner,Raad Mohiaddin	1991	Blood movement investigated by magnetic resonance (MR) velocity mapping is generally presented in the form of velocity components in one or more chosen velocity encoding directions. By viewing these components separately, it is difficult for MR practitioners to conceptualize and comprehend the underlying flow structures, especially when the image data has strong background noise. The flow visualization technique presented in this paper adapts the idea of particle tracing used in classical fluid dynamics for visualizing flow. By rendering and animating the processed flow signal, clear flow structures can be revealed.	IEEE Visualizat	visu
1169	IEEE Visualization	Proceedings IEEE Visualization'91.	Gregory M. Nielson,Lawrence J. Rosenblum	1991	Proceedings IEEE Visualization'91.	IEEE Visualizat	visu
1170	ICDE	Knowledge Mining by Imprecise Querying: A Classification-Based Approach.	Tarek M. Anwar,Howard W. Beck,Shamkant B. Navathe	1992	Knowledge mining is the process of discovering knowledge that is hitherto unknown. An approach to knowledge mining by imprecise querying that utilizes conceptual clustering techniques is presented. The query processor has both a deductive and an inductive component. The deductive component finds precise matches in the traditional sense, and the inductive component identifies ways in which imprecise matches may be considered similar. Ranking on similarity is done by using the database taxonomy, by which similar instances become members of the same class. Relative similarity is determined by depth in the taxonomy. The conceptual clustering algorithm, its use in query processing, and an example are presented	ICDE	database
1171	ICDE	Fast Read-Only Transactions in Replicated Databases.	P. C. Aristides,Amr El Abbadi	1992	The authors present a propagation mechanism, called the commit propagation mechanism (CPM), which increases the availability of data for read-only transactions. The proposed mechanism is piggy-backed on the messages used in the two-phase commit protocol. The CPM was combined with the standard quorum protocol in two different replicated database systems. In a fully replicated database, CPM allows any read-only transaction to execute locally at a single site without the need for any communication overhead. In a partially replicated database, CPM either ensures that the set of copies residing at a site are mutually consistent, or indicates which copies violate such consistency	ICDE	database
1172	ICDE	M(DM): An Open Framework for Interoperation of Multimodel Multidatabase Systems.	Thierry Barsalou,Dipayan Gangopadhyay	1992	The authors present M(DM), an extensible metalevel system in which the syntax and the semantics of data models, schemas, and databases can be uniformly represented. M(DM) consists primarily of a set of metatypes that capture and express data-model constructs in second-order logic: a data model is represented as a collection of M(DM) metatypes. To achieve extensibility, M(DM)'s metatypes are organized into an inheritance lattice. The robustness and openness of the approach are demonstrated by expressing a variety of data models in M(DM), and the authors show how to exploit M(DM)'s metalevel capabilities for hiding representational heterogeneities in multimodel multidatabase systems	ICDE	database
1173	ICDE	On Mixing Queries and Transactions via Multiversion Locking.	Paul M. Bober,Michael J. Carey	1992	The authors discuss a novel approach to multiversion concurrency control that allows high-performance transaction systems to support long-running queries. The approach extends the multiversion locking algorithm developed by Computer Corporation of America by using record-level versioning and reserving a portion of each data page for caching prior versions that are potentially needed for the serializable execution of queries; on-page caching also enables an efficient approach to garbage collection of old versions. In addition, view sharing is introduced, which has the potential for reducing the cost of versioning by grouping together queries to run against the same transaction-consistent view of the database. Results from a simulation study that indicate that the approach is a viable alternative to level-one and level-two consistency locking when the portion of each data reserved for prior versions is chosen appropriately are presented	ICDE	database
1174	ICDE	Transactions in Distributed Shared Memory Systems.	Peter Bodorik,F. I. Smith,D. J-Lewis	1992	The authors propose a distributed shared memory model based on a paged segmented two-level address space and an extended set of memory operations. In addition to the traditional read and write operations, the memory model includes operations which support mapping between local and global address spaces and mapping of processes to transactions. An architecture and associated algorithm are outlined for a virtual memory management unit to provide concurrency control for transactions. Although the traditional concept of the transaction is assumed, only the aspects of concurrency control and coherence are addressed	ICDE	database
1175	ICDE	An Exploratory Study of Ad Hoc Query Languages to Databases.	John E. Bell,Lawrence A. Rowe	1992	The authors describe an exploratory study performed to compare three different interface styles for ad hoc query to a database. Subjects with wide-ranging computer experience performed queries of varying difficulty using either an artificial, a graphical, or a natural language interface. All three interfaces were commercial products. The study revealed strengths and weaknesses of each interface and showed that interaction with the natural language interface was qualitatively different than interaction with either the graphical or artificial language systems	ICDE	database
1176	ICDE	Title, Message from the General Chairperson, Message from the Program Chairperson, Committees, Referees, Table of Contents, Author Index.		1992	Title, Message from the General Chairperson, Message from the Program Chairperson, Committees, Referees, Table of Contents, Author Index.	ICDE	database
1177	ICDE	On Interoperability for KBMS Applications - The Horizontal Integration Task.	Wolfgang Benn,Christian Kortenbreer,Gunter Schlageter,Xinglin Wu	1992	On Interoperability for KBMS Applications - The Horizontal Integration Task.	ICDE	database
1178	ICDE	An Efficient Database Storage Structure for Large Dynamic Objects.	Alexandros Biliris	1992	The author presents storage structures and algorithms for the efficient manipulation of general-purpose large unstructured objects in a database system. The large object is stored in a sequence of variable-size segments, each of which consists of a large number of physically contiguous disk blocks. A tree structure indexes byte positions within the object. Disk space management is based on the binary buddy system. The scheme supports operations that replace, insert, delete bytes at arbitrary positions within the object, and append bytes at the end of the object	ICDE	database
1179	ICDE	Data Hiding and Security in Object-Oriented Databases.	Elisa Bertino	1992	Data Hiding and Security in Object-Oriented Databases.	ICDE	database
1180	ICDE	Performance Comparisons of Distributed Deadlock Detection Algorithms.	Omran A. Bukhres	1992	Performance Comparisons of Distributed Deadlock Detection Algorithms.	ICDE	database
1181	ICDE	A Model for Optimizing Deductive and Object-Oriented DB Requests.	Jean-Pierre Cheiney,Rosana S. G. Lanzelotte	1992	A Model for Optimizing Deductive and Object-Oriented DB Requests.	ICDE	database
1182	ICDE	A Declarative Approach to Active Databases.	Stefano Ceri	1992	A Declarative Approach to Active Databases.	ICDE	database
1183	ICDE	Chain-Split Evaluation in Deductive Databases.	Jiawei Han	1992	Many popularly studied recursions in deductive databases can be compiled into one or a set of highly regular chain generating paths, each of which consists of one or a set of connected predicates. Previous studies on chain-based query evaluation in deductive databases take a chain generating path as an inseparable unit in the evaluation. However, some recursions, especially many functional recursions whose compiled chain consists of infinitely evaluable function(s), should be evaluated by chain-split evaluation, which splits a chain generating path into two portions in the evaluation: an immediately evaluable portion and a delayed-evaluation portion. In this paper, the necessity of chain-split evaluation is examined from the points of view of both efficiency and finite evaluation, and three chain-split evaluation techniques: magic sets, buffered evaluation, and partial evaluation are developed. Our study shows that chain-split evaluation is a primitive recursive query evaluation technique for different kinds of recursions, and it can be implemented efficiently in deductive databases by extensions to the existing recursive query evaluation methods.	ICDE	database
1184	ICDE	Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries.	Ming-Syan Chen,Philip S. Yu,Kun-Lung Wu	1992	Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries.	ICDE	database
1185	ICDE	History-less Checking of Dynamic Integrity Constraints.	Jan Chomicki	1992	An efficient implementation method is described for dynamic integrity constraints formulated in past temporal logic. Although the constraints can refer to past states of the database, their checking does not require that the entire database history be stored. Instead, every database state is extended with auxiliary relations that contain the historical information necessary for checking constraints. Auxiliary relations can be implemented as materialized relational views. The author analyzes the computational cost of the method and outlines how it can be implemented by using existing database technology. Related work on dynamic integrity constraints is surveyed	ICDE	database
1186	ICDE	Object Allocation in Distributed Systems with Virtual Replication.	Wesley W. Chu,Berthier A. Ribeiro-Neto,Patrick H. Ngai	1992	Object Allocation in Distributed Systems with Virtual Replication.	ICDE	database
1187	ICDE	A Spanning Tree Transitive Closure Algorithm.	Shaul Dar,H. V. Jagadish	1992	The authors present a transitive closure algorithm that maintains a spanning tree of successors for each node rather than a simple successor list. This spanning tree structure promotes sharing of information across multiple nodes and leads to more efficient algorithms. An effective relational implementation of the spanning tree storage structure is suggested, and it is shown how blocking can be applied to reduce the input/output cost of the algorithm. The algorithm can handle path problems also. Analytical and experimental evidence is presented that demonstrates the utility of the algorithm, especially in a graph with many alternate paths between the nodes. The spanning tree storage structure can be compressed and updated incrementally in response to changes in the underlying graph	ICDE	database
1188	ICDE	An Object-Oriented Model for Capturing Data Semantics.	G. Decorte,A. Eiger,D. Kroenke,T. Kyte	1992	An Object-Oriented Model for Capturing Data Semantics.	ICDE	database
1189	ICDE	The Design and Implementation of a Parallel Join Algorithm for Nested Relations on Shared-Memory Multiprocessors.	Vinay Deshpande,Per-Åke Larson	1992	The Design and Implementation of a Parallel Join Algorithm for Nested Relations on Shared-Memory Multiprocessors.	ICDE	database
1190	ICDE	Partitioning of Time Index for Optical Disks.	Ramez Elmasri,Muhammad Jaseemuddin,Vram Kouramajian	1992	The authors present a storage model for temporal databases that accommodates large amounts of temporal data. The model supports efficient search for object versions based on temporal conditions, using a time index. They define an access structure, the monotonic B+ -tree, that is suitable for implementing a time index for append-only temporal databases. The storage model uses a combination of magnetic disks and write-once optical disks to keep current, past, and even future states of a database online and readily accessible. It provides an automatic archiving of both object versions and time index blocks to optical disks	ICDE	database
1191	ICDE	A Time-based Distributed Optimistic Recovery and Concurrency Control Mechanism.	Anat Gafni,K. V. Bapa Rao	1992	The authors describe a time-based approach to distributed concurrency control and recovery that alleviates the high cost of optimistic methods by combining the solutions to concurrency control, recovery management, and localized control into a single flexible yet powerful and efficient mechanism. The approach adapts the object-oriented Timewarp mechanism to handle competing processes rather than the cooperating processes for which it was originally intended. The result is a completely decentralized, nonblocking concurrency and recovery protocol that supports more general features of other desirable aspects of distributed applications, such as versioning and active objects	ICDE	database
1192	ICDE	How to Extend a Conventional Optimizer to Handle One- and Two-Sided Outerjoin.	César A. Galindo-Legaria,Arnon Rosenthal	1992	The authors provide a nearly complete theory for reordering join/outerjoin queries. The theory is used to describe modular extensions that strengthen a conventional optimizer to handle nearly all select/project/join/outerjoin queries. Unlike previous work, these results are not limited to queries possessing a nice structure, or queries that are nicely represented in relational calculus. The theoretical results concern query simplification and reassociation using a generalized outerjoin	ICDE	database
1193	ICDE	ESQL2: An Object-Oriented SQL with F-Logic Semantics.	Georges Gardarin,Patrick Valduriez	1992	ESQL2: An Object-Oriented SQL with F-Logic Semantics.	ICDE	database
1194	ICDE	Quorum-oriented Multicast Protocols for Data Replication.	Richard A. Golding,Darrell D. E. Long	1992	Many wide-area distributed applications use replicated data to improve the availability of the data, and to improve access latency by locating copies of the data near to their use. This paper presents a new family of communication protocols, called *quorum multicasts*, that provide efficient communication services for widely replicated data. Quorum multicasts are similar to ordinary multicasts, which deliver a message to a set of destinations. The new protocols extend this model by allowing delivery to a subset of the destinations, selected according to distance or expected data currency. These protocols provide well-defined failure semantics, and can distinguish between communication failure and replica failure with high probability. We have evaluated their performance, which required taking several traces of the Internet to determine distributions for communication latency and failure. A simulation study of quorum multicasts, based on these measurements, shows that these protocols provide low latency and require few messages. A second study that measured a test application running at several sites confirmed these results.	ICDE	database
1195	ICDE	Research Directions in Image Database Management (Panel).	William I. Grosky,Rajiv Mehrotra	1992	Research Directions in Image Database Management (Panel).	ICDE	database
1196	ICDE	An Abstraction Mechanism for Modeling Generation.	Ranabir Gupta,Gary Hall	1992	An abstraction mechanism for modeling the generation of entities from other entities is presented. It is shown to be useful for representing a wide range of generative processes, including those which are reversible, spontaneous, and involve multiple inputs and outputs. The mechanism is related to an earlier defined abstraction mechanism which represents the transitional behavior of existing entities. The model of generation is described in terms of an operational formalism with well-understood properties	ICDE	database
1197	ICDE	A Run-Time Execution Model for Referential Integrity Maintenance.	Bruce M. Horowitz	1992	The author explores anomalous situations which can arise during the processing of database operations on schemas which include referential integrity constraints. A more declarative (as opposed to operational) approach to referential integrity is proposed. He reviews some of the contributions which ANSI Technical Committee X3H2 on Database has made in this area, and which have been reflected in the referential integrity specifications of the forthcoming SQL2 and SQL3 standards. A proposal that replaced the recent compile-time paradigm with a run-time paradigm is included. A correctness proof for this paradigm is provided	ICDE	database
1198	ICDE	Distributed Rule Processing in Active Databases.	Ing-Miin Hsu,Mukesh Singhal,Ming T. Liu	1992	Processing rules in a distributed active database involves three design issues: how to decompose rules, how to distribute rules to sites, and how to evaluate distributed rules correctly. The authors study these three issues for complicated rules, which are complex and time-consuming to evaluate. They propose a relational operator, AND, and the associated algebraic manipulations of this operator to find independent parts of a rule query, which can be distributed among sites. Due to geographical dispersion in a distributed system, correct evaluation of distributed rules is not trivial. A distributed evaluation algorithm is preferred, which guarantees the correctness of the evaluation result of the distributed rule by collecting consistent local results from sites to form a global view	ICDE	database
1199	ICDE	Semantically Consistent Schedules for Efficient and Concurrent B-Tree Restructuring.	Ragaa Ishak	1992	A concurrent B-tree algorithm can achieve more parallelism than a standard concurrency control method. The author presents a semantically based method for B-tree restructuring which allows efficient and concurrent traversals and fetches. The concurrent operations compare favorably with earlier solutions because they avoid wasted input/output (I/O). In addition, the concurrent B-tree algorithms considerably reduce the need to repeatedly traverse the tree in order to recover from the effect of in-progress restructuring. The method increases the performance of a high-volume database management system	ICDE	database
1200	ICDE	Imprecise and Uncertain Information in Databases: An Evidential Approach.	Suk Kyoon Lee	1992	A novel approach for representing imprecise and uncertain data and evaluating queries in the framework of an extended relational database model based on the Dempster-Shafer theory of evidence is proposed. Because of the ability to combine evidences from different sources, the semantics of the update operation of imprecise or uncertain data is reconsidered. By including an undefined value in a domain, three different cases of a null value are presented: unknown, inapplicable, and unknown or inapplicable. In this model, two levels of uncertainty in the database are supported: one is for the attribute value level and the other is for the tuple level	ICDE	database
1201	ICDE	Using Coding to Support Data Resiliency in Distributed Systems.	Pankaj Jalote,Gagan Agrawal	1992	A scheme for maintaining replicated files is suggested. The authors describe how the coding scheme suggested by M.O. Rabin (1987, 1989) can be used to store replicated data and how the voting algorithm and the quorum requirements change to manage this replication. It is shown that the disk storage space required to achieve a given availability is significantly lower than that for the conventional scheme with full file replication. Since coding is used, this scheme also provides a high degree of data security	ICDE	database
1202	ICDE	Mapping a Version Model to a Complex-Object Data Model.	Wolfgang Käfer,Harald Schöning	1992	The authors present a version model for CAD purposes and its implementation on the basis of a complex-object database management system. The functionality of the model is illustrated with the help of a VLSI design example. In contrast to similar solutions based on the relational data model, this approach allows for a simple and efficient implementation of the version model, allowing for powerful retrieval operations. Sharing of data, which occurs necessarily among versions, is system controlled. This prohibits redundant storage of data. It is concluded that implementing a complex-object database system supporting versions is not more complicated than implementing a complex-object database system without version support	ICDE	database
1203	ICDE	Temporal Specialization.	Christian S. Jensen,Richard T. Snodgrass	1992	The authors explore a variety of temporal relations with specialized relationships between transaction and valid time. An example is a retroactive temporal event relation, where the event must have occurred before it was stored, i.e., the valid time-stamp is restricted to be less than the transaction time-stamp. The authors discuss many useful restrictions, defining a large number of specialized types of temporal relations, and indicate some of their applications. A detailed taxonomy of specialized temporal relations is presented. This taxonomy may be used during database design to specify the particular time semantics of temporal relations	ICDE	database
1204	ICDE	I/O-Efficiency of Shortest Path Algorithms: An Analysis.	Bin Jiang	1992	To establish the behavior of algorithms in a paging environment, the author analyzes the input/output (I/O) efficiency of several representative shortest path algorithms. These algorithms include single-course, multisource, and all pairs ones. The results are also applicable for other path problems such as longest paths, most reliable paths, and bill of materials. The author introduces the notation and a model of a paging environment. The I/O efficiencies of the selected single-source, all pairs, and multisource algorithms are analyzed and discussed	ICDE	database
1205	ICDE	Exploring Semantics in Aggregation Hierarchies for Object-Oriented Databases.	Ling Liu	1992	An extended object-oriented model for exploring semantics in aggregation hierarchies is presented. The extension is mainly based on a general distinction between aggregation references and association references and a support for type inheritance in both specialization and aggregation abstractions. The author formally describes notions of aggregation reference and aggregation hierarchy and introduces the concept of aggregation inheritance as a type composition mechanism for sharing specifications among types. The similarities and differences between aggregation inheritance and subtype inheritance are analyzed. It is shown that a combination of these two types of inheritance provides a powerful mechanism for abstract implementation of behavior and for enhancing the extensibility of the object model	ICDE	database
1206	ICDE	Parallel GRACE Hash Join on Shared-Everything Multiprocessor: Implementation and Performance Evaluation on Symmetry S81.	Masaru Kitsuregawa,Shin-ichiro Tsudaka,Miyuki Nakano	1992	The authors implemented a parallel hash join algorithm on a Symmetry S81 shared-everything multiprocessor environment and evaluated the performance. They evaluated the input/output (I/O) performance on a multiple-disk environment, and showed linear performance increase of up to eight disks. The performance of the implemented join operation was examined on each phase, and the effect of parallel processing by the multiprocessor and the multiple disks was clarified. It was concluded from the experimental result that on such a shared-everything multiprocessor system parallelism could be easily exploited for the construction of high-performance relational database systems	ICDE	database
1207	ICDE	Deleted Tuples are Useful when Updating through Universal Scheme Interfaces.	Dominique Laurent,Viet Phan Luong,Nicolas Spyratos	1992	The authors present a novel approach to database updating through universal scheme interfaces. The main contribution of the approach is the elimination of non-determinism. That is, contrary to most other approaches, inserting or deleting a tuple can always be done without having to make any choice at all. Tuples that have been deleted from the database are explicitly stored and are used subsequently in order to invalidate certain derivations. Updates are performed in a monotonous manner, and updates satisfy the property of reversibility	ICDE	database
1208	ICDE	An Efficient Object-based Algorithm for Spatial Searching, Insertion and Deletion.	Jui-Tine Lee,Geneva G. Belford	1992	The authors propose an object-based index structure for manipulating spatial objects with non-zero size. They introduce the main ideas of the proposed index structure. A detailed description of the algorithms is given for searching, insertion, and deletion in a database system with a high frequency of retrievals and a low frequency of insertions and deletions. The algorithms are then described for retrievals, insertions, and deletions for a database system with a nearly equal frequency of retrievals, insertions and deletions	ICDE	database
1209	ICDE	Distance-Associated Join Indices for Spatial Range Search.	Wei Lu,Jiawei Han	1992	A distance-associated join index structure is developed to speed up spatial queries, especially for spatial range queries. Three distance-associated join indexing mechanisms: basic, ring-structured, and hierarchical, are presented and studied. The analysis and performance study shows that distance-associated spatial join indices substantially improve the performance of spatial queries, and different structures are best suited for different applications	ICDE	database
1210	ICDE	On Semantic Query Optimization in Deductive Databases.	Laks V. S. Lakshmanan,Rokia Missaoui	1992	On Semantic Query Optimization in Deductive Databases.	ICDE	database
1211	ICDE	Logical Database Design with Inclusion Dependencies.	Tok Wang Ling,Cheng Hian Goh	1992	Classical data dependencies are oblivious to important constraints which may exist between sets of attributes occurring in different relation schemes. The authors study how inclusion dependencies can be used to model these constraints, leading to the design of better database schemes. A normal form called the inclusion normal form (IN-NF) is proposed. Unlike classical normal forms, the IN-NF characterizes a database scheme as a whole rather than the individual relation schemes. It is shown that a database scheme in IN-NF is always in improved third normal form, while the converse is not true. It is demonstrated that the classical relational design framework may be extended to facilitate the design of database schemes in IN-NF	ICDE	database
1212	ICDE	A Relation Merging Technique for Relational Databases.	Victor M. Markowitz	1992	A merging technique for relational schemas consisting of relation-schemes, key dependencies, referential integrity constraints, and null constraints is presented. The author examines the conditions required for using this technique with relational database management systems that provide different mechanisms for maintaining null and referential integrity constraints. For relational schemas developed using an extended entity-relationship (EER) oriented design methodology, it is shown that a relation-scheme can be used for representing multiple object-sets not only for the standard binary many-to-one relationship-set structure, but for more complex structures as well	ICDE	database
1213	ICDE	Database Structure and Discovery Tools for Integrated Circuit Reliability Evaluation.	Paola Mauri	1992	The reliability performance of integrated circuits is described by means of a large amount of quantitative and qualitative data that require computer tools for effective management. The author describes some design solutions in the implementation of these tools, in particular stressing the integration of different points of view to model reliability performance; the structure of the failure database that, following expert reasoning features, implicitly contains as cause-effect relationships the results of the failure analysis; and the procedures designed to discover regularities and relationships among stored data, thus helping engineers in reliability evaluation and failure analysis	ICDE	database
1214	ICDE	Processing Hierarchical Queries in Heterogeneous Environment.	Weiyi Meng,Clement T. Yu,Won Kim	1992	Processing Hierarchical Queries in Heterogeneous Environment.	ICDE	database
1215	ICDE	An Extensible Object-Oriented Database Testbed.	Magdi M. A. Morsi,Shamkant B. Navathe,Hyoung-Joo Kim	1992	The authors describe the object-oriented design and implementation of an extensible schema manager for object-oriented databases. The open class hierarchy approach has been adopted to achieve the extensibility of the implementation. In this approach. the system meta information is implemented as objects of system classes. A graphical interface for an object-oriented database scheme environment, GOOSE, has been developed. GOOSE supports several advanced features which include schema evolution, schema versioning, and DAG (direct acyclic graph) rearrangement view of a class hierarchy. Schema evolution is the ability to make a variety of changes to a database scheme without reorganization. Schema versioning is the ability to define multiple scheme versions and to keep track of schema changes. A novel type of view for object-oriented databases, the DAG rearrangement view of a class hierarchy, is also supported	ICDE	database
1216	ICDE	Database Recovery Using Redundant Disk Arrays.	Antoine N. Mourad,W. Kent Fuchs,Daniel G. Saab	1992	Database Recovery Using Redundant Disk Arrays.	ICDE	database
1217	ICDE	Relational Databases with Exclusive Disjunctions.	Adegbemiga Ola	1992	The author presents a mechanism for representing exclusive disjunctive information in database tables using various tuple types and a range for the count of the number of tuples in the unknown relation denoted by a table. The relational algebra operators are extended to take the new tables as operands. Query evaluation in the extended model is sound and complete for relational algebra expressions consisting of projection, difference, Cartesian product, or selection operators. Possible storage structures for storing the base tables and algorithms for inserting tuples into a table are described	ICDE	database
1218	ICDE	Maintenance of Materialized Views of Sampling Queries.	Frank Olken,Doron Rotem	1992	The authors discuss materialized views of random sampling queries of a relational database. They show how to maintain such views in the presence of insertions, deletions, and updates of the base relations. The basic idea is to reuse the maximal portion of the original sample when constructing the updated sample. The results are based on a synthesis of view update techniques and sampling algorithms. It is demonstrated that maintenance of materialized sample views may be substantially cheaper than resampling	ICDE	database
1219	ICDE	Concurrent File Reorganization for Record Clustering: A Performance Study.	Edward Omiecinski,Liehuey Lee,Peter Scheuermann	1992	The authors presents performance analysis of a concurrent file reorganization algorithm. They examined the effect of buffer size, degree of reorganization, and write probability of transactions on system throughput. The problem of file reorganization considered involves altering the placement of records on pages on a secondary storage device. This reorganization must be done in-place. The approach is appropriate for a non-in-place reorganization. The motivation for such a physical change is to improve the database system's performance, by minimizing the number of page accesses made in answering a set of queries. It is shown through simulation that the algorithm, when run concurrently with user transactions, provides an acceptable level of overall database system performance	ICDE	database
1220	ICDE	Processing Real-Time, Non-Aggregate Queries with Time-Constraints in CASE-DB.	Gultekin Özsoyoglu,Kaizheng Du,Sujatha Guru Swamy,Wen-Chi Hou	1992	Processing Real-Time, Non-Aggregate Queries with Time-Constraints in CASE-DB.	ICDE	database
1221	ICDE	A Keying Method for a Nested Relational Database Management System.	Z. Meral Özsoyoglu,Jian Wang	1992	A Keying Method for a Nested Relational Database Management System.	ICDE	database
1222	ICDE	Prefetching with Multiple Disks for External Mergesort: Simulation and Analysis.	Vinay S. Pai,Peter J. Varman	1992	The authors present a simulation study of multiple disk systems to improve the input/output (I/O) performance of multiway merging. With the increase in the size of main memory in computer systems, multiple disks and aggressive prefetching can be used to significantly reduce I/O time. Two prefetching strategies-intra-run and inter-run-for external merging using multiple disks were studied. Their performance was evaluated, and simple analytical expressions are derived to explain their asymptotic behavior. The results indicate that a combination of the strategies can result in a significant reduction in I/O time	ICDE	database
1223	ICDE	A Periodic Deadlock Detection and Resolution Algorithm with a New Graph Model for Sequential Transaction Processing.	Young Chul Park,Peter Scheuermann,Sang Ho Lee	1992	The authors address the deadlock problem in sequential transaction processing where the strict two-phase locking and the multiple granularity locking protocol with five lock modes are used. The scheduling policy honors lock requests in a first-in-first-out basis except for lock conversions. As a basic tool, a direct graph model called the holder/wire-transaction waited-by graph (H/W-TWBG) is introduced to capture the precise status of systems in terms of deadlock. The properties of H/W-TWBG are presented. Based on H/W-TWBG, the identification principles of the victim candidates are established in a deadlock cycle, and a periodic deadlock detection and resolution algorithm which has a reasonable time and storage complexity is preserved. One important feature of the deadlock resolution scheme is that some deadlocks can be resolved without aborting any transaction	ICDE	database
1224	ICDE	Parallel Algorithms for Executing Joins on Cube-Conneced Multicomputers.	Manuel A. Penaloza,Esen A. Ozkarahan	1992	Parallel Algorithms for Executing Joins on Cube-Conneced Multicomputers.	ICDE	database
1225	ICDE	A Fault-Tolerant Algorithm for Replicated Data Management.	Sampath Rangarajan,Sanjeev Setia,Satish K. Tripathi	1992	In this paper, we examine the tradeoff between message overhead and data availability that arises in the design of fault-tolerant algorithms for replicated data management in distributed systems. We propose a property called asymptotically high resiliency which is useful for evaluating the fault-tolerance of replica control algorithms and distributed mutual exclusion algorithms. We present a new algorithm for replica control that can be tailored (through a design parameter) to achieve the desired balance between low message overhead and high data availability. Further, we show that for a message overhead of ${\bf O}(\sqrt{N{\rm log}N})$, our algorithm can achieve asymptotically high resiliency.	ICDE	database
1226	ICDE	Object-Oriented Models for Heterogeneous Multidatabase Management Systems.	Ming-Chien Shan	1992	Object-Oriented Models for Heterogeneous Multidatabase Management Systems.	ICDE	database
1227	ICDE	Probabilistic Dignosis of Hot Spots.	Kenneth Salem,Daniel Barbará,Richard J. Lipton	1992	Probabilistic Dignosis of Hot Spots.	ICDE	database
1228	ICDE	MoBiLe Files and Efficient Processing of Path Queries on Scientific Data.	Shashi Shekhar,Toneluh Andrew Yang	1992	Efforts in database design for observational scientific data concerned with path query specification and an access method design are discussed. The goal is to understand the issues related to scientific data and computations. The authors propose a representation of path queries and an access method, MoBiLe files, to capture space-time continuity. A survey on spatial indexing methods is given. The model of scientific data and computation is described. An example of scientific databases is also given. Path queries are then specified. The MoBiLe mapping functions and MoBiLe file design are described. The experiment used to verify the access methods and the data model are outlined. The experimental results and this observation and analysis are presented	ICDE	database
1229	ICDE	Object-Oriented Modeling and Design of Coupled Knowledge-base/Database Systems.	Olivia R. Liu Sheng,Chih-Ping Wei	1992	The objective is to develop a structured object-oriented modeling and design methodology for coupled knowledge-base/database (KB/DB) systems by exploring the useful principles and features of object-oriented modeling and software development techniques. The methodology uses a synthesize object-oriented entity-relationship model for representing the knowledge and the embedded data semantics involved in coupled KB/DB systems. An associated design procedure is presented. This methodology improves on existing coupled KB/DB design methods because of its well-defined constructs that deal with various forms of knowledge involved in data processing, knowledge-based problem solving and object-oriented reasoning	ICDE	database
1230	ICDE	Utilization of External Foreign Computation Services.	Hans-Jörg Schek	1992	Utilization of External Foreign Computation Services.	ICDE	database
1231	ICDE	An Integrated Real-Time Locking Protocol.	Sang Hyuk Son,Seog Park,Yi Lin	1992	The authors examine a priority-driven locking protocol called integrated real-time locking protocol. They show that this protocol is free of deadlock, and in addition, a high-priority transaction is not blocked by uncommitted lower protocol. They show that this protocol is free of deadlock, and in addition, a high-priority transaction is not blocked by uncommitted lower priority transactions. The protocol does not assume any knowledge about the data requirements or the execution time of each transaction. This makes the protocol widely applicable, since in many actual environments such information may not be readily available. Using a database prototyping environment, it was shown that the proposed protocol offers a performance improvement over the two-phase locking protocol	ICDE	database
1232	ICDE	An Index Implementation Supporting Fast Recovery for the POSTGRES Storage System.	Mark Sullivan,Michael A. Olson	1992	The authors present two algorithms for maintaining B-tree index consistency in a database management system which does not use write-ahead logging (WAL). One algorithm is similar to shadow paging, but improves performance by integrating shadow meta-data with index meta-data. The other algorithm uses a two-phase page reorganization scheme to reduce the space overhead caused by shadow paging. Although designed for the POSTGRES storage system, these algorithms should also be useful in a WAL-based storage system, as support for logical logging. Measurements and analysis of a prototype implementation suggest that the algorithms will have little impact on data manager performance	ICDE	database
1233	ICDE	Thrashing in Two-Phase Locking Revisited.	Alexander Thomasian	1992	Thrashing in Two-Phase Locking Revisited.	ICDE	database
1234	ICDE	Query Optimization for KBMSs: Temporal, Syntactic and Semantic Transformantions.	Thodoros Topaloglou,Arantza Illarramendi,Licia Sbattella	1992	Query Optimization for KBMSs: Temporal, Syntactic and Semantic Transformantions.	ICDE	database
1235	ICDE	Optimal Versioning of Objects.	Vassilis J. Tsotras,B. Gopinath	1992	The purpose of versioning is to reconstruct any past state of an object class. The authors show that access to any past version is possible in almost constant time, while the space used is only linear to the number of changes occurring in the class evolution. As a result, versioning with fast reconstruction can be supported in an object-oriented environment without using excessive space requirements. It is also proved that the solution is optimal among all approaches that use the same space limitations. A crucial characteristic of the results is that they can be easily implemented on a storage facility that uses a magnetic disk and an optical disk	ICDE	database
1236	ICDE	The Implementation and Evaluation of Integrity Maintenance Rules in an Object-Oriented Database.	Susan Darling Urban,Anton P. Karadimce,Ravi B. Nannapaneni	1992	The authors describe an approach to the declarative representation of integrity constraints in an object-oriented database and the use of integrity maintenance rules for the active maintenance of constraints. A semantic data model is used to automatically generate class definitions and state-altering database operations with constraints represented as objects in the database. Integrity maintenance production rules are automatically generated from constraints and stored as extensions to class operations, hiding the details of constraint checking and rule triggering. High-level transactions call state-altering operations and invoke the integrity maintenance process at commit time. Integrity constraints are declaratively represented in the database system, with operations encapsulating rules about how to respond to constraint violations. An analysis of problems associated with cyclic and anomalous rule behavior	ICDE	database
1237	ICDE	Prepare and Commit Certification for Decentralized Transaction Management in Rigorous Heterogeneous Multidatabases.	Jari Veijalainen,Antoni Wolski	1992	Algorithms for scheduling of distributed transactions in a heterogeneous multidatabase, in the presence of failures, are presented. The algorithms of prepare certification and commit certification protect against serialization errors called global view distortions and local view distortions. View serializable overall histories are guaranteed in the presence of most typical failures. The assumptions are, among others, that the participating database systems produce rigorous histories and that no local transaction may update the data accessed by a global transaction that is in the prepared state. The main advantage of the method, as compared to other known solutions, is that it is totally decentralized	ICDE	database
1238	ICDE	A Performance Comparison of the Rete and TREAT Algorithms for Testing Database Rule Conditions.	Yu-Wang Wang,Eric N. Hanson	1992	The authors present the results of a simulation comparing the performance of the two most widely used production rule condition testing algorithms, Rete and TREAT, in the context of a database rule system. The results show that TREAT almost always outperforms Rete. TREAT requires less storage than Rete, and is less sensitive to optimization decisions than Rete. Based on these results, it is concluded that TREAT is the preferred algorithm for testing join conditions of database rules. Since Rete does outperform TREAT in some cases, this study suggests a next step which would be to develop a hybrid version of Rete and TREAT with an optimizer that would decide which strategy to use based on the rule definition and statistics about the data and update patterns	ICDE	database
1239	ICDE	Divergence Control for Epsilon-Serializability.	Kun-Lung Wu,Philip S. Yu,Calton Pu	1992	The authors present divergence control methods for epsilon-serializability (ESR) in centralized databases. ESR alleviates the strictness of serializability (SR) in transaction processing by allowing for limited inconsistency. The bounded inconsistency is automatically maintained by divergence control (DC) methods in a way similar to the manner in which SR is maintained by concurrency control mechanisms, but DC for ESR allows more concurrency. Concrete representative instances of divergence-control methods are described based on two-phase locking, timestamp ordering, and optimistic approaches. The applicability of ESR is demonstrated by presenting the designs of DC methods using other most known inconsistency specifications, such as absolute value, age, and total number of nonserializably read data items	ICDE	database
1240	ICDE	A Uniform Model for Temporal Object-Oriented Databases.	Gene T. J. Wuu,Umeshwar Dayal	1992	A temporal object-oriented model and query language that supports the modeling and manipulation of complex temporal or versioned objects is developed. The authors show that the approach not only provides a richer model than the relational for capturing the semantics of complex temporal objects, but also requires no special constructs in the query language. Consequently, the retrieval of temporal and non-temporal information is uniformly expressed. By allowing variables and quantifiers to range over time, can be formulated that require special operators in other languages. Temporal aggregation queries, which are not easily expressed in other models, are expressed using the same aggregation operators as for nontemporal data	ICDE	database
1241	ICDE	Hot-Spot Based Compostion Algorithm.	Shu-Shang Wei,Yao-Nan Lien,Dik Lun Lee,Ten-Hwang Lai	1992	Hot-Spot Based Compostion Algorithm.	ICDE	database
1242	ICDE	Dynamic Self-Configuring Methods for Graphical Presentation of ODBMS Objects.	Randal V. Zoeller,Douglas K. Barry	1992	The authors describe a preliminary implementation of the self-configuring methods for automatic representation of time-altered ITASCA entities (SMARTIE) system. SMARTIE defines a set of visual display methods for the ITASCA distributed object database management system. These dynamic methods provide a framework that assists the user in visually browsing instance objects in the ITASCA data space. The methods also support graphic in-place editing of existing instances as well as creation of new instances. The querying and presentation of instances requires no programming by the user or the designer, and support for new classes is provided simply by inheriting the methods. To coexist with ITASCA's dynamic schema modification, the SMARTIE methods automatically reconfigure themselves to reflect the current schema definition	ICDE	database
1243	ICDE	Effect of System Dynamics on Coupling Architectures for Transaction Processing.	Philip S. Yu,Asit Dan	1992	The authors present a comparison on the resilience of the performance to system dynamics of three multinode architectures for transaction processing. They describe the different architectures considered. The issues of system dynamics are addressed. The performance model is outlined. Three specific scenarios are considered: (1) a sudden load surge in one of the transaction classes, (2) varying transaction rates for all transaction classes, and (3) failure of a single node. It was found that the different architectures require different amounts of capacity to be reserved to cope with these dynamic situations. Quantitative comparisons of the three architectures are given	ICDE	database
1244	SIGMOD Conference	Fast Search in Main Memory Databases.	Anastasia Analyti,Sakti Pramanik	1992	The objective of this paper is to develop and analyze high performance hash based search methods for main memory databases. We define optimal search in main memory databases as the search that requires at most one key comparison to locate a record. Existing hashing techniques become impractical when they are adapted to yield optimal search in main memory databases because of their large directory size. Multi-directory hashing techniques can provide significantly improved directory utilization over single-directory hashing techniques. A multi-directory hashing scheme, called fast search multi-directory hashing, and its generalization, called controlled search multi-directory hashing, are presented. Both methods achieve linearly increasing expected directory size with the number of records. Their performance is compared to existing alternatives.	SIGMOD Conferen	database
1245	SIGMOD Conference	Behavior of Database Production Rules: Termination, Confluence, and Observable Determinism.	Alexander Aiken,Jennifer Widom,Joseph M. Hellerstein	1992	Static analysis methods are given for determining whether arbitrary sets of database production rules are (1) guaranteed to terminate; (2) guaranteed to produce a unique final database state; (3) guaranteed to produce a unique stream of observable actions. When the analysis determines that one of these properties is not guaranteed, it isolates the rules responsible for the problem and determines criteria that, if satisfied, guarantee the property. The analysis methods are presented in the context of the Starburst Rule System; they will form the basis of an interactive development environment for Starburst rule programmers.	SIGMOD Conferen	database
1246	SIGMOD Conference	Using Delayed Commitment in Locking Protocols for Real-Time Databases.	Divyakant Agrawal,Amr El Abbadi,Richard Jeffers	1992	In this paper, we propose locking protocols that are useful for real-time databases. Our approach is motivated from two main observations. First, locking protocols are widely accepted and used in most database systems. Second, in real-time databases it has been shown that the blocking behavior of transactions in locking protocols results in performance degradation. We use a new relationship between locks called ordered sharing to eliminate blocking that arises in the traditional locking protocols. Ordered sharing eliminates blocking of read and write operations but may result in delayed commitment. Since in real-time databases, timeliness and not response time is the crucial factor, or protocols exploit this delay to allow transactions to execute within the slacks of delayed transactions. We compare the performance of the proposed protocols with the two phase locking protocol for real-time databases. Our experiments indicate that the propose protocols significantly reduce the percentage of missed deadlines in the system for a variety of workloads.	SIGMOD Conferen	database
1247	SIGMOD Conference	The Term Retrieval Machine.	Michael Ley	1992	The Term Retrieval Machine.	SIGMOD Conferen	database
1248	SIGMOD Conference	Using Multiversioning to Improve Performance Without Loss of Consistency.	Roger Bamford	1992	Using Multiversioning to Improve Performance Without Loss of Consistency.	SIGMOD Conferen	database
1249	SIGMOD Conference	The O2 Object-Oriented Database System.	François Bancilhon	1992	The O2 Object-Oriented Database System.	SIGMOD Conferen	database
1250	SIGMOD Conference	An Efficient Scheme for Providing High Availability.	Anupam Bhide,Ambuj Goyal,Hui-I Hsiao,Anant Jhingran	1992	Replication at the partition level is a promising approach for increasing availability in a Shared Nothing architecture. We propose an algorithm for maintaining replicas with little overhead during normal failure-free processing. Our mechanism updates the secondary replica in an asynchronous manner: entire dirty pages are sent to the secondary at some time before they are discarded from primary's buffer. A log server node (hardened against failures) maintains the log for each node. If a primary node fails, the secondary fetches the log from the log server, applied it to its replica, and brings itself to the primary's last transaction-consistent state. We study the performance of various policies for sending pages to secondary and the corresponding trade-offs between recovery time and overhead during failure-free processing.	SIGMOD Conferen	database
1251	SIGMOD Conference	Implementation of General Constraints in SIM.	Richard Bigelow	1992	Implementation of General Constraints in SIM.	SIGMOD Conferen	database
1252	SIGMOD Conference	The Performance of Three Database Storage Structures for Managing Large Objects.	Alexandros Biliris	1992	This study analyzes the performance of the storage structures and algorithms employed in three experimental database storage systems &ndash; EXODUS, Starburst, and EOS &ndash; for managing large unstructured general-purpose objects. All three mechanisms are segment-based in that the large object is stored in a sequence of segments, each consisting of physically continuous disk block. To analyze the algorithms we measured object creation time, sequential scan time, storage utilization in the presence of updates, and the I/O cost of random reads, inserts, and deletes.	SIGMOD Conferen	database
1253	SIGMOD Conference	ITASCA Distributed ODBMS.	Douglas K. Barry	1992	ITASCA Distributed ODBMS.	SIGMOD Conferen	database
1254	SIGMOD Conference	Extending Ingres with Methods and Triggers.	Fred Carter	1992	Extending Ingres with Methods and Triggers.	SIGMOD Conferen	database
1255	SIGMOD Conference	Conceptual Document Browsing and Retrieval in Kabiria.	Augusto Celentano,Maria Grazia Fugini,Silvano Pozzi	1992	Conceptual Document Browsing and Retrieval in Kabiria.	SIGMOD Conferen	database
1256	SIGMOD Conference	Distribution, Parallelism, and Availability in NonStop SQL.	Pedro Celis	1992	Distribution, Parallelism, and Availability in NonStop SQL.	SIGMOD Conferen	database
1257	SIGMOD Conference	The Design and Implementation of Persistent Transactions in an Object Database System.	Hong-Tai Chou	1992	The Design and Implementation of Persistent Transactions in an Object Database System.	SIGMOD Conferen	database
1258	SIGMOD Conference	A General Framework for the Optimization of Object-Oriented Queries.	Sophie Cluet,Claude Delobel	1992	The goal of this work is to integrate in a general framework the different query optimization techniques that have been proposed in the object-oriented context. As a first step, we focus essentially on the logical aspect of query optimization. In this paper, we propose a formalism (i) that unifies different rewriting formalisms, (ii) that allows easy and exhaustive factorization of duplicated subqueries, and (iii) that supports heuristics in order to reduce the optimization rewriting phase.	SIGMOD Conferen	database
1259	SIGMOD Conference	Scientific Data Management: Real-World Issues and Requirements.	Paula J. Cowley	1992	Scientific Data Management: Real-World Issues and Requirements.	SIGMOD Conferen	database
1260	SIGMOD Conference	DOODLE: A Visual Language for Object-Oriented Databases.	Isabel F. Cruz	1992	In this paper we introduce DOODLE, a new visual and declarative language for object-oriented databases. The main principle behind the language is that it is possible to display and query the database with arbitrary pictures. We allow the user to tailor the display of the data to suit the application at hand or her preferences. We want the user-defined visualizations to be stored in the database, and the language to express all kinds of visual manipulations. For extendibility reasons, the language is object-oriented. The semantics of the language is given by a well-known deductive query language for object-oriented databases. We hope that the formal basis of our language will contribute to the theoretical study of database visualizations and visual query languages, a subject that we believe is of great interest, but largely left unexplored.	SIGMOD Conferen	database
1261	SIGMOD Conference	Performance Analysis of Coherency Control Policies through Lock Retention.	Asit Dan,Philip S. Yu	1992	Buffer coherency control can be achieved through retaining a lock (shared, exclusive, etc.) on each page in the buffer, even after the requesting transaction has committed. Depending upon the lock mode held for retention and the compatibility of lock modes specified, different retention policies can be devised. In addition to tracking the validity of the buffered data granules, additional capabilities can be provided such as deferred writes to support no-force policy on commit, (node) location identification of valid granules to support remote memory accesses, and shared/exclusive lock retention to reduce the number of global lock requests for concurrency control. However, these can have serious implications not only on the performance but also on the recovery complexity. In this paper, five different integrated coherency policies are considered. We classify these policies into three different categories according to their recovery requirements. A performance study based on analytic models is provided to understand the trade-offs on both maximum throughputs and response times of the policies with a similar level of recovery complexity and the performance gain achievable through increasing the level of recovery complexity.	SIGMOD Conferen	database
1262	SIGMOD Conference	Parallel Index Building in Informix OnLine 6.0.	Wayne Davison	1992	Parallel Index Building in Informix OnLine 6.0.	SIGMOD Conferen	database
1263	SIGMOD Conference	A Concurrency Model for Transaction Management.	Marc Descollonges	1992	A Concurrency Model for Transaction Management.	SIGMOD Conferen	database
1264	SIGMOD Conference	Access to Data in NASA's Earth Observing System.	Jeff Dozier	1992	Access to Data in NASA's Earth Observing System.	SIGMOD Conferen	database
1265	SIGMOD Conference	Crash Recovery in Client-Server EXODUS.	Michael J. Franklin,Michael J. Zwilling,C. K. Tan,Michael J. Carey,David J. DeWitt	1992	In this paper, we address the correctness and performance issues that arise when implementing logging and crash recovery in a page-server environment. The issues result from two characteristics of page-server systems: 1) the fact that data is modified and cached in client database buffers that are not accessible by the server, and 2) the performance and cost trade-offs that are inherent in a client-server environment. We describe a recovery system that we have implemented for the client-server version of the EXODUS storage manager. The implementation supports efficient buffer management policies, allows flexibility in the interaction between clients and the server, and reduces the server load by generating log records at clients. We also present a preliminary performance analysis of the implementation.	SIGMOD Conferen	database
1266	SIGMOD Conference	Query Optimization for Parallel Execution.	Sumit Ganguly,Waqar Hasan,Ravi Krishnamurthy	1992	The decreasing cost of computing makes it economically viable to reduce the response time of decision support queries by using parallel execution to exploit inexpensive resources. This goal poses the following query optimization problem: Minimize response time subject to constraints on throughput, which we motivate as the dual of the traditional DBMS problem. We address this novel problem in the context of Select-Project-Join queries by extending the execution space, cost model and search algorithm that are widely used in commercial DBMSs. We incorporate the sources and deterrents of parallelism in the traditional execution space. We show that a cost model can predict response time while accounting for the new aspects due to parallelism. We observe that the response time optimization metric violates a fundamental assumption in the dynamic programming algorithm that is the linchpin in the optimizers of most commercial DBMSs. We extend dynamic programming and show how optimization metrics which correctly predict response time may be designed.	SIGMOD Conferen	database
1267	SIGMOD Conference	Database and Transaction Processing Benchmarks.	Jim Gray	1992	Database and Transaction Processing Benchmarks.	SIGMOD Conferen	database
1268	SIGMOD Conference	Event Specification in an Active Object-Oriented Database.	Narain H. Gehani,H. V. Jagadish,Oded Shmueli	1992	The concept of a trigger is central to any active database. Upon the occurrence of a trigger event, the trigger is &ldquo;fired&rdquo;, i.e, the trigger action is executed. We describe a model and a language for specifying basic and composite trigger events in the context of an object-oriented database. The specified events can be detected efficiently using finite automata. We integrate our model with O++, the database programming language for the ode object database being developed at AT&T Bell Labs. We propose a new Event-Action model, which folds into the event specification the condition part of the well-known Event-Condition-Action model and avoids the multiple coupling modes between the event, condition, and action trigger components.	SIGMOD Conferen	database
1269	SIGMOD Conference	PRIMA - A Database System Supporting Dynamically Defined Composite Objects.	Michael Gesmann,Andreas Grasnickel,Theo Härder,Christoph Hübel,Wolfgang Käfer,Bernhard Mitschang,Harald Schöning	1992	PRIMA - A Database System Supporting Dynamically Defined Composite Objects.	SIGMOD Conferen	database
1270	SIGMOD Conference	A Performance Analysis of Alternative Multi-Attribute Declustering Strategies.	Shahram Ghandeharizadeh,David J. DeWitt,Waheed Qureshi	1992	During the past decade, parallel database systems have gained increased popularity due to their high performance, scalability and availability characteristics. With the predicted future database sizes and the complexity of queries, the scalability of these systems to hundreds and thousands of processors is essential for satisfying the projected demand. Several studies have repeatedly demonstrated that both the performance and scalability of a paralel database system is contingent on the physical layout of data across the processors of the system. If the data is not declustered properly, the execution of an operator might waste resources, reducing the overall processing capability of the system. With earlier, single attribute declustering strategies, such as those found in Tandem, Teradata, Gamma, and Bubba parallel database systems, a selection query including a range predicate on any attribute other than the partitioning attribute must be sent to all processors containing tuples of the relation. By directing a query with minimal resource requirements to processors that contain no relevant tuples, the system wastes CPU cycles, communication bandwidth, and I/O bandwidth, reducing its overall processing capability. As a solution, several multi-attribute declustering strategies have been proposed. However, the performance of these declustering techniques have not previously been compared to one another nor with a single attribute partitioning strategy. This paper, compares the performance of Multi-Attribute GrId deClustering (MAGIC) strategy and Bubba's Extended Range Declustering (BERD) strategy with one another and with the range partitioning strategy. Our results indicate that MAGIC outperforms both range and BERD in all experiments conducted in this study.	SIGMOD Conferen	database
1271	SIGMOD Conference	Sequential Sampling Procedures for Query Size Estimation.	Peter J. Haas,Arun N. Swami	1992	We provide a procedure, based on random sampling, for estimation of the size of a query result. The procedure is sequential in that sampling terminates after a random number of steps according to a stopping rule that depends upon the observations obtained so far. Enough observations are obtained so that, with a pre-specified probability, the estimate differs from the true size of the query result by no more than a prespecified amount. Unlike previous sequential estimation procedures for queries, our procedure is asymptotically efficient and requires no ad hoc pilot sample or a a priori assumptions about data characteristics. In addition to establishing the asymptotic properties of the estimation procedure, we provide techniques for reducing undercoverage at small sample sizes and show that the sampling cost of the procedure can be reduced through stratified sampling techniques.	SIGMOD Conferen	database
1272	SIGMOD Conference	Rule Condition Testing and Action Execution in Ariel.	Eric N. Hanson	1992	This paper describes testing of rule conditions and execution of rule actions in Ariel active DBMS. The Ariel rule system is tightly coupled with query and update processing. Ariel rules can have conditions based on a mix of patterns, events, and transitions. For testing rule conditions, Ariel makes use of a discrimination network composed of a special data structure for testing single-relation selection conditions efficiently, and a modified version of the TREAT algorithm, called A-TREAT, for testing join conditions. The key modification to TREAT (which could also be used in the Rete algorithm) is the use of virtual &agr;-memory nodes which save storage since they contain only the predicate associated with the memory node instead of copies of data matching the predicate. The rule-action executor in Ariel binds the data matching a rule's condition to the action of the rule at rule fire time, and executes the rule action using the query processor.	SIGMOD Conferen	database
1273	SIGMOD Conference	A High Performance Multiversion Concurrency Control Protocol of Object Databases.	Craig Harris,Madhu Reddy,Carl Woolf	1992	A High Performance Multiversion Concurrency Control Protocol of Object Databases.	SIGMOD Conferen	database
1274	SIGMOD Conference	A Qualitative Comparison Study of Data Structures for Large Line Segment Databases.	Erik G. Hoel,Hanan Samet	1992	A qualitative comparative study is performed of the performance of three popular spatial indexing methods - the R-tree, R+-tree, and the PMR quadtree-in the context of processing spatial queries in large line segment databases. The data is drawn from the TIGER/Line files used by the Bureau of the Census to deal with the road networks in the US. The goal is not to find the best data structure as this is not generally possible. Instead, their comparability is demonstrated and an indication is given as to when and why their performance differs. Tests are conducted with a number of large datasets and performance is tabulated in terms of the complexity of the disk activity in building them, their storage requirements, and the complexity of the disk activity for a number of tasks that include point and window queries, as well as finding the nearest line segment to a given point and an enclosing polygon.	SIGMOD Conferen	database
1275	SIGMOD Conference	Exploiting Inter-Operation Parallelism in XPRS.	Wei Hong	1992	In this paper, we study the scheduling and optimization problems of parallel query processing using interoperation parallelism in a shared-memory environment and propose our solutions for XPRS. We first study the scheduling problem of a set of a continuous sequence of independent tasks that are either from a bushy tree plan of a single query or from the plans of multiple queries, and present a clean and simple scheduling algorithm. Our scheduling algorithm achieves maximum resource utilizations by running an IO-bound task and a CPU-bound task in parallel with carefully calculated degrees of parallelism and maintains the maximum resource utilizations by dynamically adjusting the degrees of parallelism of running tasks whenever necessary. Real performance figures are shown to confirm the effectiveness of our scheduling algorithm. We also revisit the optimization problem of parallel execution plans of a single query and extend our previous results to consider inter-operation parallelism by introducing a new cost estimation method to the query optimizer based on our scheduling algorithm.	SIGMOD Conferen	database
1276	SIGMOD Conference	Analysis of Recovery in a Database System Using a Write-Ahead Log Protocol.	Anant Jhingran,Pratap Khedkar	1992	In this paper we examine the recovery time in a database system using a Write-Ahead Log protocol, such as ARIES [9], under the assumption that the buffer replacement policy is strict LRU. In particular, analytical equations for log read time, data I/O, log application, and undo processing time are presented. Our initial model assumes a read/write ratio of one, and a uniform access pattern. This is later generalized to include different read/write ratios, as well as a &ldquo;hot set&rdquo; model (i.e. x% of the accesses go to y% of the data). We show that in the uniform access model, recovery is dominated by data I/O costs, but under extreme hot-set conditions, this may no longer be true. Furthermore, since we derive anaytical equations, recovery can be analyzed for any set of parameter conditions not discussed here.	SIGMOD Conferen	database
1277	SIGMOD Conference	USD - A Database Management System for Scientific Research.	Rowland R. Johnson,Mandy Goldner,Mitch Lee,Keith McKay,Robert Shectman,John Woodruff	1992	USD - A Database Management System for Scientific Research.	SIGMOD Conferen	database
1278	SIGMOD Conference	Realizing a Temporal Complex-Object Data Model.	Wolfgang Käfer,Harald Schöning	1992	Support for temporal data continues to be a requirement posed by many applications such as VLSI design and CAD, but also in conventional applications like banking and sales. Furthermore, the strong demand for complex-object support is known as an inherent fact in design applications, and also emerges for advance &ldquo;conventional&rdquo; applications. Thus, new advanced database management systems should include both features, i.e. should support temporal complex-objects. In this paper, we present such a temporal complex-object data model. The central notion of our temporal complex-object data model is a time slice, representing one state of a complex object. We explain the mapping of time slices onto the complex objects supported by the MAD model (which we use for an example of a non-temporal complex-object data model) as well as the transformation process of operations on temporal complex-objects into MAD model operations. Thereby, the basic properties of the MAD model are a prerequisite for our approach. For example, time slices can only be directly stored, if non-disjunct (i.e. over-lapping) complex objects are easily handled in the underlying complex-object data model.	SIGMOD Conferen	database
1279	SIGMOD Conference	Parallel R-trees.	Ibrahim Kamel,Christos Faloutsos	1992	We consider the problem of exploiting parallelism to accelerate the performance of spacial access methods and specifically, R-trees [11]. Our goal is to design a server for spatial data, so that to maximize the throughput of range queries. This can be achieved by (a) maximizing parallelism for large range queries, and (b) by engaging as few disks as possible on point queries [22]. We propose a simple hardware architecture consisting of one processor with several disks attached to it. On this architecture, we propose to distribute the nodes of a traditonal R-tree, with cross-disk pointers (&ldquo;Multiplexed&rdquo; R-tree). The R-tree code is identical to the one for a single-disk R-tree, with the only addition that we have to decide which disk a newly created R-tree node should be stored in. We propose and examine several criteria to choose a disk for a new node. The most successful one, termed &ldquo;proximity index&rdquo; or PI, estimates the similarity of the new node with the other R-tree nodes already on a disk, and chooses the disk with the lowest similarity. Experimental results show that our scheme consistently outperforms all the other heuristics for node-to-disk assignments, achieving up to 55% gains over the Round Robin one. Experiments also indicate that the multiplexed R-tree with PI heuristic gives better response time than the disk-stripping (=&ldquo;Super-node&rdquo;) approach, and imposes lighter load on the I/O sub-system. The speed up of our method is close to linear speed up, increasing with the size of the queries.	SIGMOD Conferen	database
1280	SIGMOD Conference	High Performance and Availability Through Data Distribution.	Jay Kasi	1992	High Performance and Availability Through Data Distribution.	SIGMOD Conferen	database
1281	SIGMOD Conference	Querying Object-Oriented Databases.	Michael Kifer,Won Kim,Yehoshua Sagiv	1992	Querying Object-Oriented Databases.	SIGMOD Conferen	database
1282	SIGMOD Conference	Optimization of Object-Oriented Recursive Queries using Cost-Controlled Strategies.	Rosana S. G. Lanzelotte,Patrick Valduriez,Mohamed Zaït	1992	Object-oriented data models are being extended with recursion to gain expressive power. This complicates the optimization problem which has to deal with recursive queries on complex objects. Because unary operations invoking methods or path expressions on objects may be costly to execute, traditional heuristics for optimizing recursive queries are no longer valid. In this paper we propose a cost-based optimization method which handles object-oriented recursive queries. In particular, it is able to delay the decision of pushing selective operations through recursion until the effect of such a transformation can be measured by a cost model. The approach integrates rewriting and increases the optimization opportunities for recursive queries on objects while allowing for efficient optimization.	SIGMOD Conferen	database
1283	SIGMOD Conference	MLR: A Recovery Method for Multi-level Systems.	David B. Lomet	1992	To achieve high concurrency in a database system has meant building a system that copes well with important special cases. Recent work on multi-level systems suggest a systematic path to high concurrency. A multi-level system using locks permits restrictive low level locks of a subtransaction to be replaced with less restrictive high level locks when sub-transactions commit, enhancing concurrency. This is possible because sub-transactions can be undone via high level compensation actions rather than by restoring a prior lower level state. We describe a recovery scheme, called Multi-Level Recovery (MLR) that logs this high level undo operation with the commit record for the subtransaction that it compensates, posting log records to only a single log. A variant of the method copes with nested transactions, and both nested and multi-level transactions can be treated in a unified fashion.	SIGMOD Conferen	database
1284	SIGMOD Conference	Access Method Concurrency with Recovery.	David B. Lomet,Betty Salzberg	1992	Providing high concurrency in B+-trees has been studied extensively. But few efforts have been documented for combining concurrency methods with a recovery scheme that preserves well-formed trees across system crashes. We describe an approach for this that works for a class of index trees that is a generalization of the Blink-tree. A major feature of our method is that it works with a range of different recovery methods. It achieves this by decomposing structure changes in an index tree into a sequence of atomic actions, each one leaving the tree well-formed and each working on a separate level of the tree. All atomic actions on levels of the tree above the leaf level are independent of database transactions, and so are of short duration.	SIGMOD Conferen	database
1285	SIGMOD Conference	A Transformation-Based Approach to Optimizing Loops in Database Programming Languages.	Daniel F. Lieuwen,David J. DeWitt	1992	Database programming languages like O2, E, and O++ include the ability to iterate through a set. Nested iterators can be used to express joins. This paper describes compile-time optimizations similar to relational transformations like join reordering for such programming constructs. This paper also shows how to use a standard transformation-based optimizer to optimize these joins. An optimizer built using the EXODUS Optimizer Generator [GRAE87] was added to the Bell Labs O++ [AGRA89] compiler. We used the resulting optimizing compiler to experimentally validate the ideas in this paper. The experiments show that this technique can significantly improve the performance of database programming languages.	SIGMOD Conferen	database
1286	SIGMOD Conference	H-trees: A Dynamic Associative Search Index for OODB.	Chee Chin Low,Beng Chin Ooi,Hongjun Lu	1992	The support of the superclass-subclass concept in object-oriented databases (OODB) makes an instance of a subclass also an instance of its superclass. As a result, the access scope of a query against a class in general includes the access scope of all its subclasses, unless specified otherwise. To support the superclass-subclass relationship efficiently, the index must achieve two objectives. First, the index must support efficient retrieval of instances from a single class. Second, it must also support efficient retrieval of instances from classes in a hierarchy of classes. In this paper, we propose a new index called the H-tree that supports efficient retrieval of instances of a single class as well as retrieval of instances of a class and its subclasses. The unique feature of H-trees is that they capture the superclass-subclass relationships. A performance analysis is conducted and both experimental and analytical results indicate that the H-tree is an efficient indexing structure for OODB.	SIGMOD Conferen	database
1287	SIGMOD Conference	The Concurrency Control Problem in Multidatabases: Characteristics and Solutions.	Sharad Mehrotra,Rajeev Rastogi,Yuri Breitbart,Henry F. Korth,Abraham Silberschatz	1992	A Multidatabase System (MDBS) is a collection of local database management systems, each of which may follow a different concurrency control protocol. This heterogeneity makes the task of ensuring global serializability in an MDBS environment difficult. In this paper, we reduce the problem of ensuring global serializability to the problem of ensuring serializability in a centralized database system. We identify characteristics of the concurrency control problem in an MDBS environment, and additional requirements on concurrency control schemes for ensuring global serializability. We then develop a range of concurrency control schemes that ensure global serializability in an MDBS environment, and at the same time meet the requirements. Finally, we study the tradeoffs between the complexities of the various schemes and the degree of concurrency provided by each of them.	SIGMOD Conferen	database
1288	SIGMOD Conference	The Sybase Open Server.	Paul Melmom	1992	The Sybase Open Server.	SIGMOD Conferen	database
1289	SIGMOD Conference	DIRECT: A Query Facility for Multiple Databases.	Ulla Merz,Roger King	1992	The subject of this research project is the architecture and design of a multidatabase query facility. These databases contain structured data, typical for business applications. Problems addressed are: presenting a uniform interface for retrieving data from multiple databases, providing autonomy for the component databases, and defining an architecture for semantic services.DIRECT is a query facility for heterogeneous databases. The databases and their definitions can differ in their data models, names, types, and encoded values. Instead of creating a global schema, descriptions of different databases are allowed to coexist. A multidatabase query language provides a uniform interface for retrieving data from different databases. DIRECT has been exercised with operational databases that are part of an automated business system.	SIGMOD Conferen	database
1290	SIGMOD Conference	ARIES/IM: An Efficient and High Concurrency Index Management Method Using Write-Ahead Logging.	C. Mohan,Frank E. Levine	1992	This paper provides a comprehensive treatment of index management in transaction systems. We present a method, called ARIESIIM (Algorithm for Recovery and Isolation Exploiting Semantics for Index Management), for concurrency control and recovery of B+-trees. ARIES/IM guarantees serializability and uses write-ahead logging for recovery. It supports very high concurrency and good performance by (1) treating as the lock of a key the same lock as the one on the corresponding record data in a data page (e.g., at the record level), (2) not acquiring, in the interest of permitting very high concurrency, commit duration locks on index pages even during index structure modification operations (SMOs) like page splits and page deletions, and (3) allowing retrievals, inserts, and deletes to go on concurrently with SMOs. During restart recovery, any necessary redos of index changes are always performed in a page-oriented fashion (i.e., without traversing the index tree) and, during normal processing and restart recovery, whenever possible undos are performed in a page-oriented fashion. ARIES/IM permits different granularities of locking to be supported in a flexible manner. A subset of ARIES/IM has been implemented in the OS/2 Extended Edition Database Manager. Since the locking ideas of ARIES/IM have general applicability, some of them have also been implemented in SQL/DS and the VM Shared File System, even though those systems use the shadow-page technique for recovery.	SIGMOD Conferen	database
1291	SIGMOD Conference	Algorithms for Creating Indexes for Very Large Tables Without Quiescing Updates.	C. Mohan,Inderpal Narang	1992	As relational DBMSs become more and more popular and as organizations grow, the sizes of individual tables are increasing dramatically. Unfortunately, current DBMSs do not allow updates to be performed on a table while an index (e.g., a B+-tree) is being built for that table, thereby decreasing the systems' availability. This paper describes two algorithms in order to relax this restriction. Our emphasis has been to maximize concurrency, minimize overheads and cover all aspects of the problem. Builds of both unique and nonunique indexes are handled correctly. We also describe techniques for making the index-build operations restartable, without loss of all work, in case a system failure were to interrupt the completion of the creation of the index. In this connection, we also present algorithms for making a long sort of operation restartable. These include algorithms for the sort and merge phases of sorting.	SIGMOD Conferen	database
1292	SIGMOD Conference	Efficient and Flexible Methods for Transient Versioning of Records to Avoid Locking by Read-Only Transactions.	C. Mohan,Hamid Pirahesh,Raymond A. Lorie	1992	We present efficient and flexible methods which permit read-only transactions that do not mind reading a possibly slightly old, but still consistent, version of the data base to execute without acquiring locks. This approach avoids the undesirable interferences between such queries and the typically shorter update transactions that cause unnecessary and costly delays. Indexed access by such queries is also supported, unlike by the earlier methods. Old versions of records are maintained only in a transient fashion. Our methods are characterized by their flexibility (number of versions maintained and the timing of version switches, supporting partial rollbacks, and different recovery and buffering methods) and their efficiency (logging, garbage collection, version selection, and incremental, record-level versioning). Distributed data base environments are also supported, including commit protocols with the read-only optimization. We also describe efficient methods for garbage collecting unneeded older versions.	SIGMOD Conferen	database
1293	SIGMOD Conference	Multi-vendor Interoperability Through SQL Access.	Scott Newmann	1992	Multi-vendor Interoperability Through SQL Access.	SIGMOD Conferen	database
1294	SIGMOD Conference	Architectures for Object Data Management.	Jack A. Orenstein	1992	Architectures for Object Data Management.	SIGMOD Conferen	database
1295	SIGMOD Conference	Query Processing in the ObjectStore Database System.	Jack A. Orenstein,Sam Haradhvala,Benson Margulies,Don Sakahara	1992	ObjectStore is an object-oriented database system supporting persistence orthogonal to type, transaction management, and associative queries. Collections are provided as objects. The data model is non-1NF, as objects may have embedded collections. Queries are integrated with the host language in the form of query operators whose operands are a collection and a predicate. The predicate may itself contain a (nested) query operating on an embedded collection. Indexes on paths may be added and removed dynamically. Collections, being treated as objects, may be referred to indirectly, e.g., through a by-reference argument. For this reason and others, multiple execution strategies are generated, and a final selection is made just prior to query execution. Nested queries can result in interleaved execution and strategy selection.	SIGMOD Conferen	database
1296	SIGMOD Conference	Improving Fault Tolerance and Supporting Partial Writes in Structured Coterie Protocols for Replicated Objects.	Michael Rabinovich,Edward D. Lazowska	1992	This paper presents a new technique for efficiently controlling replicas in distributed systems. Conventional structured coterie protocols are efficient but incur a penalty of reduced availability in exchange for the performance gain. Further, the performance advantage can only be fully realized when write operations always replace the old data item with the new value instead of updating a portion of the data item. Our new approach significantly improves availability while allowing partial write operations. After presenting our general approach, we apply it to an existing structured coterie protocol and analyze the availability of the resulting protocol. We also show that other classes of protocols can make use of our approach.	SIGMOD Conferen	database
1297	SIGMOD Conference	Performance Evaluation of Extended Storage Architectures for Transaction Processing.	Erhard Rahm	1992	The use of non-volatile semiconductor memory within an extended storage hierarchy promises significant performance improvements for transaction processing. Although page-addressable semiconductor memories like extended memory, solid-state disks and disk caches are commercially available since several years, no detailed investigation of their use for transaction processing has been performed so far. We present a comprehensive simulation study that compares the performance of these storage types and of different usage forms. The following usage forms are considered: allocation of entire log and database files in non-volatile semiconductor memory, using a so-called write buffer to perform disk writes asynchronously, and caching of database pages at intermediate storage levels (in addition to main memory caching). Simulation results will be presented for the debit-credit workload frequently used in transaction processing benchmarks.	SIGMOD Conferen	database
1298	SIGMOD Conference	Extensible/Rule Based Query Rewrite Optimization in Starburst.	Hamid Pirahesh,Joseph M. Hellerstein,Waqar Hasan	1992	This paper describes the Query Rewrite facility of the Starburst extensible database system, a novel phase of query optimization. We present a suite of rewrite rules used in Starburst to transform queries into equivalent queries for faster execution, and also describe the production rule engine which is used by Starburst to choose and execute these rules. Examples are provided demonstrating that these Query Rewrite transformations lead to query execution time improvements of orders of magnitude, suggesting that Query Rewrite in general&mdash;and these rewrite rules in particular&mdash;are an essential step in query optimization for modern database systems.	SIGMOD Conferen	database
1299	SIGMOD Conference	Evaluation of Remote Backup Algorithms for Transaction Processing Systems.	Christos A. Polyzois,Hector Garcia-Molina	1992	A remote backup is a copy of a primary database maintained at a geographically separate location and is used to increase data availability. Remote backup systems are typically log-based and can be classified into 2-safe and 1-safe, depending on whether transactions commit at both sites simultaneously or they first commit at the primary and are later propagated to the backup. We have built an experimental database system on which we evaluated the performance of the epoch algorithm, a 1-safe algorithm we have developed, and compared it with the 2-safe approach under various conditions. We also report on the use of multiple log streams to propagate information from the primary to the backup.	SIGMOD Conferen	database
1300	SIGMOD Conference	Rdb/VMS Support for Multi-media Databases.	T. K. Rengarajan	1992	Rdb/VMS Support for Multi-media Databases.	SIGMOD Conferen	database
1301	SIGMOD Conference	Administration, Availability, and Development Features of Teradata.	Bill Robertson	1992	Administration, Availability, and Development Features of Teradata.	SIGMOD Conferen	database
1302	SIGMOD Conference	What Can We Do to Strengthen the Connection Between Theory and System Builders.	Arnon Rosenthal	1992	What Can We Do to Strengthen the Connection Between Theory and System Builders.	SIGMOD Conferen	database
1303	SIGMOD Conference	Simple Rational Guidance for Chopping Up Transactions.	Dennis Shasha,Eric Simon,Patrick Valduriez	1992	Chopping transactions into pieces is good for performance but may lead to non-serializable executions. Many researchers have reacted to this fact by either inventing new concurrency control mechanisms, weakening serializability, or both. We adopt a different approach. We assume a user who &bull; has only the degree 2 and degree 3 consistency options offered by the vast majority of conventional database systems; and &bull;knows the set of transactions that may run during a certain interval (users are likely to have such knowledge for online or real-time transactional applications). Given this information, our algorithm finds the finest partitioning of a set of transactions TranSet with the following property; if the partitioned transactions execute serializably, then TranSet executes serializably. This permits users to obtain more concurrency while preserving correctness. Besides obtaining more inter-transaction concurrency, chopping transactions in this way can enhance intra-transaction parallelism. The algorithm is inexpensive, running in O(n x (e + m)) time using a naive implementation where n is the number of edges in the conflict graph among the transactions, and m is the maximum number of accesses of any transaction. This makes it feasible to add as a tuning knob to practical systems.	SIGMOD Conferen	database
1304	SIGMOD Conference	Compensation-Based On-Line Query Processing.	V. Srinivasan,Michael J. Carey	1992	It is well known that using conventional concurrency control techniques for obtaining serializable answers to long-running queries leads to an unacceptable drop in system performance. As a result, most current DBMSs execute such queries under a reduced degree of consistency, thus providing non-serializable answers. In this paper, we present a new and highly concurrent approach for processing large decision support queries in relational databases. In this new approach, called compensation-based query processing, concurrent updates to any data participating in a query are communicated to the query's on-line query processor, which then compensates for these updates so that the final answer reflects changes caused by the updates. Very high concurrency is achieved by locking data only briefly, while still delivering transaction-consistent answers to queries.	SIGMOD Conferen	database
1305	SIGMOD Conference	Continuous Queries over Append-Only Databases.	Douglas B. Terry,David Goldberg,David A. Nichols,Brian M. Oki	1992	In a database to which data is continually added, users may wish to issue a permanent query and be notified whenever data matches the query. If such continuous queries examine only single records, this can be implemented by examining each record as it arrives. This is very efficient because only the incoming record needs to be scanned. This simple approach does not work for queries involving joins or time. The Tapestry system allows users to issue such queries over a database of mail and bulletin board messages. The user issues a static query, such as &ldquo;show me all messages that have been replied to by Jones,&rdquo; as though the database were fixed and unchanging. Tapestry converts the query into an incremental query that efficiently finds new matches to the original query as new messages are added to the database. This paper describes the techniques used in Tapestry, which do not depend on triggers and thus be implemented on any commercial database that supports SQL. Although Tapestry is designed for filtering mail and news messages, its techniques are applicable to any append-only database.	SIGMOD Conferen	database
1306	SIGMOD Conference	On the Performance of Object Clustering Techniques.	Manolis M. Tsangaris,Jeffrey F. Naughton	1992	We investigate the performance of some of the best-known object clustering algorithms on four different workloads based upon the tektronix benchmark. For all four workloads, stochastic clustering gave the best performance for a variety of performance metrics. Since stochastic clustering is computationally expensive, it is interesting that for every workload there was at least one cheaper clustering algorithm that matched or almost matched stochastic clustering. Unfortunately, for each workload, the algorithm that approximated stochastic clustering was different. Our experiments also demonstrated that even when the workload and object graph are fixed, the choice of the clustering algorithm depends upon the goals of the system. For example, if the goal is to perform well on traversals of small portions of the database starting with a cold cache, the important metric is the per-traversal expansion factor, and a well-chosen placement tree will be nearly optimal; if the goal is to achieve a high steady-state performance with a reasonably large cache, the appropriate metric is the number of pages to which the clustering algorithm maps the active portion of the database. For this metric, the PRP clustering algorithm, which only uses access probabilities achieves nearly optimal performance.	SIGMOD Conferen	database
1307	SIGMOD Conference	Full Distribution in Objectivity/DB.	Andrew E. Wade	1992	Full Distribution in Objectivity/DB.	SIGMOD Conferen	database
1308	SIGMOD Conference	Experience from a Real Life Query Optimizer.	Yun Wang	1992	Experience from a Real Life Query Optimizer.	SIGMOD Conferen	database
1309	VLDB	An Interval Classifier for Database Mining Applications.	Rakesh Agrawal,Sakti P. Ghosh,Tomasz Imielinski,Balakrishna R. Iyer,Arun N. Swami	1992	An Interval Classifier for Database Mining Applications.	VLDB	database
1310	VLDB	Using Flexible Transactions to Support Multi-System Telecommunication Applications.	Mansoor Ansari,Linda Ness,Marek Rusinkiewicz,Amit P. Sheth	1992	Using Flexible Transactions to Support Multi-System Telecommunication Applications.	VLDB	database
1311	VLDB	Random Sampling from Pseudo-Ranked B+ Trees.	Gennady Antoshenkov	1992	Random Sampling from Pseudo-Ranked B+ Trees.	VLDB	database
1312	VLDB	Resilient Logical Structures for Efficient Management of Replicated Data.	Divyakant Agrawal,Amr El Abbadi	1992	Resilient Logical Structures for Efficient Management of Replicated Data.	VLDB	database
1313	VLDB	An Extended Relational Database Model for Uncertain and Imprecise Information.	Suk Kyoon Lee	1992	An Extended Relational Database Model for Uncertain and Imprecise Information.	VLDB	database
1314	VLDB	Multiversion Query Locking.	Paul M. Bober,Michael J. Carey	1992	Multiversion Query Locking.	VLDB	database
1315	VLDB	Data Management for Real-Time Systems.	Alejandro P. Buchmann	1992	Data Management for Real-Time Systems.	VLDB	database
1316	VLDB	A Conceptual Model for Dynamic Clustering in Object Databases.	Qing Li,John L. Smith	1992	A Conceptual Model for Dynamic Clustering in Object Databases.	VLDB	database
1317	VLDB	Production Rules in Parallel and Distributed Database Environments.	Stefano Ceri,Jennifer Widom	1992	Production Rules in Parallel and Distributed Database Environments.	VLDB	database
1318	VLDB	The Principle of Commitment Ordering, or Guaranteeing Serializability in a Heterogeneous Environment of Multiple Autonomous Resource Mangers Using Atomic Commitment.	Yoav Raz	1992	The Principle of Commitment Ordering, or Guaranteeing Serializability in a Heterogeneous Environment of Multiple Autonomous Resource Mangers Using Atomic Commitment.	VLDB	database
1319	VLDB	Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins.	Ming-Syan Chen,Ming-Ling Lo,Philip S. Yu,Honesty C. Young	1992	Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins.	VLDB	database
1320	VLDB	Dynamic Data Distribution (D) in a Shared-Nothing Multiprocessor Data Store.	Donald D. Chamberlin,Frank B. Schmuck	1992	Dynamic Data Distribution (D) in a Shared-Nothing Multiprocessor Data Store.	VLDB	database
1321	VLDB	Extensible Buffer Management of Indexes.	Chee Yong Chan,Beng Chin Ooi,Hongjun Lu	1992	Extensible Buffer Management of Indexes.	VLDB	database
1322	VLDB	A Temporal Evolutionary Object-Oriented Data Model and Its Query Language for Medical Image Management.	Wesley W. Chu,Ion Tim Ieong,Ricky K. Taira,Claudine M. Breant	1992	A Temporal Evolutionary Object-Oriented Data Model and Its Query Language for Medical Image Management.	VLDB	database
1323	VLDB	Query Optimization in a Heterogeneous DBMS.	Weimin Du,Ravi Krishnamurthy,Ming-Chien Shan	1992	Query Optimization in a Heterogeneous DBMS.	VLDB	database
1324	VLDB	A Uniform Approach to Processing Temporal Queries.	Umeshwar Dayal,Gene T. J. Wuu	1992	A Uniform Approach to Processing Temporal Queries.	VLDB	database
1325	VLDB	Practical Skew Handling in Parallel Joins.	David J. DeWitt,Jeffrey F. Naughton,Donovan A. Schneider,S. Seshadri	1992	Practical Skew Handling in Parallel Joins.	VLDB	database
1326	VLDB	Performance and Scalability of Client-Server Database Architectures.	Alex Delis,Nick Roussopoulos	1992	Performance and Scalability of Client-Server Database Architectures.	VLDB	database
1327	VLDB	On B-Tree Indices for Skewed Distributions.	Christos Faloutsos,H. V. Jagadish	1992	On B-Tree Indices for Skewed Distributions.	VLDB	database
1328	VLDB	Composite Event Specification in Active Databases: Model & Implementation.	Narain H. Gehani,H. V. Jagadish,Oded Shmueli	1992	Composite Event Specification in Active Databases: Model & Implementation.	VLDB	database
1329	VLDB	Global Memory Management in Client-Server Database Architectures.	Michael J. Franklin,Michael J. Carey,Miron Livny	1992	Global Memory Management in Client-Server Database Architectures.	VLDB	database
1330	VLDB	Incomplete Information in Relational Temporal Databases.	Shashi K. Gadia,Sunil S. Nair,Yiu-Cheong Poon	1992	Incomplete Information in Relational Temporal Databases.	VLDB	database
1331	VLDB	Locking and Latching in a Memory-Resident Database System.	Vibby Gottemukkala,Tobin J. Lehman	1992	Locking and Latching in a Memory-Resident Database System.	VLDB	database
1332	VLDB	Knowledge Discovery in Databases: An Attribute-Oriented Approach.	Jiawei Han,Yandong Cai,Nick Cercone	1992	Knowledge Discovery in Databases: An Attribute-Oriented Approach.	VLDB	database
1333	VLDB	Experiences With an Object Manager for a Process-Centered Environment.	Dennis Heimbigner	1992	Experiences With an Object Manager for a Process-Centered Environment.	VLDB	database
1334	VLDB	Querying in Highly Mobile Distributed Environments.	Tomasz Imielinski,B. R. Badrinath	1992	Querying in Highly Mobile Distributed Environments.	VLDB	database
1335	VLDB	Parametric Query Optimization.	Yannis E. Ioannidis,Raymond T. Ng,Kyuseok Shim,Timos K. Sellis	1992	In most database systems, the values of many important run-time parameters of the system, the data, or the query are unknown at query optimization time. Parametric query optimization attempts to identify at compile time several execution plans, each one of which is optimal for a subset of all possible values of the run-time parameters. The goal is that at run time, when the actual parameter values are known, the appropriate plan should be identifiable with essentially no overhead. We present a general formulation of this problem and study it primarily for the buffer size parameter. We adopt randomized algorithms as the main approach to this style of optimization and enhance them with a sideways information passing feature that increases their effectiveness in the new task. Experimental results of these enhanced algorithms show that they optimize queries for large numbers of buffer sizes in the same time needed by their conventional versions for a single buffer size, without much sacrifice in the output quality and with essentially zero run-time overhead.	VLDB	database
1336	VLDB	Integrity Maintenance in Object-Oriented Databases.	H. V. Jagadish,Xiaolei Qian	1992	Integrity Maintenance in Object-Oriented Databases.	VLDB	database
1337	VLDB	Proclamation-Based Model for Cooperating Transactions.	H. V. Jagadish,Oded Shmueli	1992	Proclamation-Based Model for Cooperating Transactions.	VLDB	database
1338	VLDB	Optimizing Boolean Expressions in Object-Bases.	Alfons Kemper,Guido Moerkotte,Michael Steinbrunn	1992	Optimizing Boolean Expressions in Object-Bases.	VLDB	database
1339	VLDB	Updates in a Rule-Based Language for Objects.	Michael Kramer,Georg Lausen,Gunter Saake	1992	Updates in a Rule-Based Language for Objects.	VLDB	database
1340	VLDB	High Throughput Escrow Algorithms for Replicated Databases.	Narayanan Krishnakumar,Arthur J. Bernstein	1992	High Throughput Escrow Algorithms for Replicated Databases.	VLDB	database
1341	VLDB	Temporal Query Processing and Optimization in Multiprocessor Database Machines.	T. Y. Cliff Leung,Richard R. Muntz	1992	Temporal Query Processing and Optimization in Multiprocessor Database Machines.	VLDB	database
1342	VLDB	CMD: A Multidimensional Declustering Method for Parallel Data Systems.	Jianzhong Li,Jaideep Srivastava,Doron Rotem	1992	CMD: A Multidimensional Declustering Method for Parallel Data Systems.	VLDB	database
1343	VLDB	Activity Model: A Declarative Approach for Capturing Communication Behavior in Object-Oriented Databases.	Ling Liu,Robert Meersman	1992	Activity Model: A Declarative Approach for Capturing Communication Behavior in Object-Oriented Databases.	VLDB	database
1344	VLDB	Performance Evaluation of an Adaptive and Robust Load Control Method for the Avoidance of Data-Contention Thrashing.	Axel Mönkeberg,Gerhard Weikum	1992	Performance Evaluation of an Adaptive and Robust Load Control Method for the Avoidance of Data-Contention Thrashing.	VLDB	database
1345	VLDB	Database Technology for Reliable Systems: Issues, Impact, and Approaches (Panel).	Matthew Morgenstern	1992	Database Technology for Reliable Systems: Issues, Impact, and Approaches (Panel).	VLDB	database
1346	VLDB	Improved Unnesting Algorithms for Join Aggregate SQL Queries.	M. Muralikrishna	1992	Improved Unnesting Algorithms for Join Aggregate SQL Queries.	VLDB	database
1347	VLDB	Software Repositories.	John Mylopoulos,Thomas Rose	1992	Software Repositories.	VLDB	database
1348	VLDB	Georgraphic Information Systems, A Challenge for the 90's (Panel).	Ekow J. Otoo,Ron Lake,Wo-Shun Luk,T. H. Merrett,Hanan Samet	1992	Georgraphic Information Systems, A Challenge for the 90's (Panel).	VLDB	database
1349	VLDB	SVP: A Model Capturing Sets, Lists, Streams, and Parallelism.	Douglas Stott Parker Jr.,Eric Simon,Patrick Valduriez	1992	SVP: A Model Capturing Sets, Lists, Streams, and Parallelism.	VLDB	database
1350	VLDB	An Information-Retrieval Approach for Image Databases.	Fausto Rabitti,Pasquale Savino	1992	An Information-Retrieval Approach for Image Databases.	VLDB	database
1351	VLDB	CORAL - Control, Relations and Logic.	Raghu Ramakrishnan,Divesh Srivastava,S. Sudarshan	1992	CORAL - Control, Relations and Logic.	VLDB	database
1352	VLDB	A Multi-Resolution Relational Data Model.	Robert L. Read,Donald S. Fussell,Abraham Silberschatz	1992	The use of data at different levels of information content is essential to the performance of multimedia, scientific, and other large databases because it can significantly decrease I/O and communication costs. The performance advantages of such a multi-resolution scheme can only be fully exploited by a data model that supports the convenient retrieval of data at different levels of information content. In this paper we extend the relational data model to support multi-resolution data retrieval. In particular, we introduce a new partial set construct, called the sandbag, that can support multi-resolution for the types of data used in a wide variety of next-generation database applications, as well as traditional applications. We extend the relational algebra operators to analogous operators on sandbags. The resulting extension of the relational algebra is sound and forms a foundation for future database management systems that support these types of next-generation applications.	VLDB	database
1353	VLDB	Supporting Lists in a Data Model (A Timely Approach).	Joel E. Richardson	1992	Supporting Lists in a Data Model (A Timely Approach).	VLDB	database
1354	VLDB	Multiview: A Methodology for Supporting Multiple Views in Object-Oriented Databases.	Elke A. Rundensteiner	1992	Multiview: A Methodology for Supporting Multiple Views in Object-Oriented Databases.	VLDB	database
1355	VLDB	Multidatabase Applications: Semantic and System Issues.	Marek Rusinkiewicz,Amit P. Sheth	1992	Multidatabase Applications: Semantic and System Issues.	VLDB	database
1356	VLDB	Principles of Transaction-Based On-Line Reorganization.	Betty Salzberg,Allyn Dimock	1992	Principles of Transaction-Based On-Line Reorganization.	VLDB	database
1357	VLDB	Spatial Databases.	Hanan Samet	1992	Spatial Databases.	VLDB	database
1358	VLDB	Database Tuning.	Dennis Shasha,Steve Rozen	1992	Database Tuning.	VLDB	database
1359	VLDB	Implementing High Level Active Rules on Top of a Relational DBMS.	Eric Simon,Jerry Kiernan,Christophe de Maindreville	1992	Implementing High Level Active Rules on Top of a Relational DBMS.	VLDB	database
1360	VLDB	Entity Modeling in the MLS Relational Model.	Kenneth Smith,Marianne Winslett	1992	Entity Modeling in the MLS Relational Model.	VLDB	database
1361	VLDB	Database Management in the Year 2000: Projections and Star Gazing (Panel).	Paul G. Sorenson,Felipe Cariño,Jnan R. Dash,Patricia G. Selinger	1992	Database Management in the Year 2000: Projections and Star Gazing (Panel).	VLDB	database
1362	VLDB	A Method for Change Computation in Deductive Databases.	Toni Urpí,Antoni Olivé	1992	A Method for Change Computation in Deductive Databases.	VLDB	database
1363	VLDB	Object-Oriented Database Systems.	Patrick Valduriez	1992	Object-Oriented Database Systems.	VLDB	database
1364	VLDB	A Performance Study of Alternative Object Faulting and Pointer Swizzling Strategies.	Seth J. White,David J. DeWitt	1992	A Performance Study of Alternative Object Faulting and Pointer Swizzling Strategies.	VLDB	database
1365	VLDB	Parallelism in a Main-Memory DBMS: The Performance of PRISMA/DB.	Annita N. Wilschut,Jan Flokstra,Peter M. G. Apers	1992	Parallelism in a Main-Memory DBMS: The Performance of PRISMA/DB.	VLDB	database
1366	VLDB	An Efficient Indexing Technique for Full Text Databases.	Justin Zobel,Alistair Moffat,Ron Sacks-Davis	1992	An Efficient Indexing Technique for Full Text Databases.	VLDB	database
1367	SIGMOD Record	Building User Interfaces for Database Applications: The O2 Experience.	Patrick Borras,Jean-Claude Mamou,Didier Plateau,Bruno Poyet,Didier Tallot	1992	Building User Interfaces for Database Applications: The O2 Experience.	SIGMOD Record	database
1368	SIGMOD Record	The Relational Model contra Entity Relationship?	H. W. Buff	1992	The Relational Model contra Entity Relationship?	SIGMOD Record	database
1369	SIGMOD Record	An Annotated Bibliography on Object-Orientation and Deduction.	Stefan Conrad,Martin Gogolla	1992	This note tries to briefly survey research activities and results on the integration of object-oriented concepts and deductive database languages.	SIGMOD Record	database
1370	SIGMOD Record	Visualizing Queries and Querying Visualizations.	Mariano P. Consens,Isabel F. Cruz,Alberto O. Mendelzon	1992	Visualizing Queries and Querying Visualizations.	SIGMOD Record	database
1371	SIGMOD Record	Advanced Capabilities of the Outer Join.	Michael M. David	1992	This paper demonstrates that the modeling of complex data structures can be performed easily and naturally in SQL using the direct outer join operation as defined in the proposed ISO-ANSI SQL2 standard. This paper goes on to demonstrate four advanced capabilities that can be implemented by SQL vendors utilizing the data modeling ability of the outer join. These capabilities are: powerful optimization techniques that can dynamically shorten the access path length; intelligent join view updates that utilize the semantics in the data structure being modeled; direct disparate heterogeneous database access that is transparent and efficient; and automatic conversion of multi-table structures into nested relations allowing for more powerful SQL operations.	SIGMOD Record	database
1372	SIGMOD Record	Supporting Display Generation for Complex Database Objects.	Belinda B. Flynn,David Maier	1992	Supporting Display Generation for Complex Database Objects.	SIGMOD Record	database
1373	SIGMOD Record	Locking Protocols for Concurrency Control in Real-time Database Systems.	Sheung-lun Hung,Kam-yiu Lam	1992	Concurrency Control in real-time database systems is complicated by the requirement to maintain database consistency at the same time to minimize the number of transactions missing their deadlines. The scheduling of data in Basic Two Phase Locking (2PL) completely ignores the urgency of a transaction and thus the effectiveness of the adopted real-time resource scheduling protocol is greatly reduced. In Restart based locking protocols (R2PL), same priorities are used for both data and resources scheduling and should have fewer transactions missing their deadlines. However, Restart based protocols sufferred the intrinsic weakness of high restart overhead owing to ensure atomicity of transactions. In this paper, based on their weaknesses, a hybrid concurrency control protocol (H2PL) is proposed. Through performance study, results indicate that it can perform well under different degree of deadline constraint and workload as compared with other real-time locking protocols.	SIGMOD Record	database
1374	SIGMOD Record	Advanced User Interfaces for Database Systems, Letter from the Special Issue Editor.	Yannis E. Ioannidis	1992	Advanced User Interfaces for Database Systems, Letter from the Special Issue Editor.	SIGMOD Record	database
1375	SIGMOD Record	Graphical User Interfaces for the Management of Scientific Experiments and Data.	Yannis E. Ioannidis,Miron Livny,Eben M. Haber	1992	It is often stated that the three most important factors that determine the success or failure of a database system are performance, performance, performance! The experience of the last twenty years with relational systems has shown that at least one of these three references to performance implies that of end-users when interacting with the system to access data, i.e., user productivity. Although declarative query languages like SQL and QUEL represent major improvements over procedural programming languages like COBOL, the overall consensus is that they are too complex for many users. The need for more intuitive and easier to learn and use interfaces to database systems is always current.	SIGMOD Record	database
1376	SIGMOD Record	A Glossary of Temporal Database Concepts.	Christian S. Jensen,James Clifford,Shashi K. Gadia,Arie Segev,Richard T. Snodgrass	1992	This glossary contains concepts specific to temporal databases that are well-defined, well understood, and widely used. In addition to defining and naming the concepts, the glossary also explains the decisions made. It lists competing alternatives and discusses the pros and cons of these. It also includes evaluation criteria for the naming of concepts. This paper is a structured presentation of the results of e-mail discussions initiated during the preparation of the first book on temporal databases, Temporal Databases: Theory, Design, and Implementation, published by Benjamin Cummings, to appear January 1993. Independently of the book, an initiative aimed at designing a consensus Temporal SQL is under way. The paper is a contribution towards establishing common terminology, an initial subtask of this initiative.	SIGMOD Record	database
1377	SIGMOD Record	Formal Syntax and Semantics of a Reconstructed Relational Database System.	Dan Jonsson	1992	Formal Syntax and Semantics of a Reconstructed Relational Database System.	SIGMOD Record	database
1378	SIGMOD Record	Chair's Message.	Won Kim	1992	Chair's Message.	SIGMOD Record	database
1379	SIGMOD Record	Moscow ACM SIGMOD Chapter Established.	Leonid A. Kalinichenko	1992	Moscow ACM SIGMOD Chapter Established.	SIGMOD Record	database
1380	SIGMOD Record	A Complex Benchmark for Logic Programming and Deductive Databases, or Who Can Beat the N-Queens ?	Werner Kießling	1992	The N-queens problem with its long history and inherent complexity is a challenging benchmark target. We present our solution and performance results, hoping that this will stimulate a sort of benchmark competition for tough problems.	SIGMOD Record	database
1381	SIGMOD Record	Chair's Message.	Won Kim	1992	Chair's Message.	SIGMOD Record	database
1382	SIGMOD Record	Building Data Representations with FaceKit.	Roger King,Michael Novak	1992	Building Data Representations with FaceKit.	SIGMOD Record	database
1383	SIGMOD Record	A Suppletment to Sampling-Based Methods for Query Size Estimation in a Database System.	Yibei Ling,Wei Sun	1992	Sampling-based methods for estimating relation sizes after relational operators such as selections, joins and projections have been intensively studied in recent years. Methods of this type can achieve high estimation accuracy and efficiency. Since the dominating overhead involved in a sampling-based method is the sampling cost, different variants of sampling methods are proposed so as to minimize the sampling percentage (thus reducing the sampling cost) while maintaining the estimation accuracy in terms of the confidence level and relative error (to be precisely defined later in Section 2). In order to determine the minimal sampling percentage, the overall characteristics of the data such as the mean and variance are needed. Currently, the representative sampling-based methods in literature are based on the assumption that overall characteristics of data are unavailable, and thus a significant amount of effort is dedicated to estimating these characteristics so as to approach the optimal (minimal) sampling percentage. The estimation for these characteristics incurs cost as well as suffers the estimation error. In this short essay, we point out that the exact values of these characteristics of data can be kept track of in a database system at a negligible overhead. As a result, the minimal sampling percentage while ensuring the specified relative error and confidence level can be precisely determined.	SIGMOD Record	database
1384	SIGMOD Record	Semantic Optimization: What are Disjunctive Residues Useful for?	Wolfgang L. J. Kowarschick	1992	Residues have been proved to be a very important means for doing semantic optimization. In this paper we will discuss a new kind of residues&mdash;the disjunctive residues. It will be shown that they are very useful to perform subformula elimination, if, in addition, a powerful reduction algorithm is available.	SIGMOD Record	database
1385	SIGMOD Record	The Gist of GIUKU: Graphical Interactive Intelligent Utilities for Knowledgeable Users of Data Base Systems.	Michel Kuntz	1992	Synoptic description of GIUKU: its rationale, its main functionalities, its novel features, a comparison to related work, and a discussion of its current status &mdash; a fully implemented prototype available for use.	SIGMOD Record	database
1386	SIGMOD Record	A Review of Recent Work on Multi-attribute Access Methods.	David B. Lomet	1992	Most database systems provide database designers with single attribute indexing capability via some form of B+tree. Multi-attribute search structures are rare, and are mostly found in systems specialized to some more narrow application area, e.g. geographic databases. The reason is that no multi-attirbute search structure has been demonstrated, with high confidence. Multi-attribute search is an active area of research. This paper reviews the state of this field and some of the difficult problems, and reviews some recent notable papers.	SIGMOD Record	database
1387	SIGMOD Record	On Global Multidatabase Query Optimization.	Hongjun Lu,Beng Chin Ooi,Cheng Hian Goh	1992	On Global Multidatabase Query Optimization.	SIGMOD Record	database
1388	SIGMOD Record	Functional Completeness in Object-Oriented Databases.	Priti Mishra,Margaret H. Eich	1992	A definition of completeness in the context of Object Oriented Databases (OODBs) is proposed in this paper. It takes into account the existence of various categories of functions in OODBs, each of which must be complete in itself. The functionality of an OODB can be divided into sets of related functions. For example, functions needed to perform all schema evolution operations or all version management operations belong in two distinct sets. Further, each set of functions must include all functions needed to perform all operations defined for that set. Thus, for an OODB to be functionally complete, it must support a certain number of sets (or categories) of functions and each such set must be complete in itself. The purpose of this paper is not to give a precise definition of the categories of functions but rather to define a framework within which such categories should be examined. This paper contains a working definition of functional completeness. We would welcome any feedback on our proposal.	SIGMOD Record	database
1389	SIGMOD Record	Annotating Answers with Their Properties.	Amihai Motro	1992	When responding to queries, humans often volunteer additional information about their answers. Among other things, they may qualify the answer as to its reliability, and they may provide some abstract characterization of the answer. This paper describes a user interface to relational databases that similarly annotates its answers with their properties. The process assumes that various assertions about properties of the data have been stored in the database (meta-information). These assertions are then used to infer properties of each answer provided by the system (meta-answers). Meta-answers are offered to users along with each answer issued, and help them to assess the value and meaning of the information that they receive.	SIGMOD Record	database
1390	SIGMOD Record	Database Research at IPSI.	Erich J. Neuhold,Volker Turau	1992	At the Integrated Publication and Information Systems Institute (IPSI) of the GMD (Gesellschaft f&uuml;r Mathematik und Datenverarbeitung) database research is focused towards distributed database management systems to support the integration of heterogeneous multi-media information bases needed in an integrated publishing environment. The objective is to investigate advanced object-oriented and active data modelling concepts together with the principles of distributed data stores and data management. The unifying basis for the database research is the object-oriented data model VML developed in the project VODAK over the last four years. The data model is based on recursively defined meta classes, classes and instance hierarchies paired with a strict separation of structural and operational definitions in a polymorphic type system. This report describes the highlights of the work on the VODAK database system, the research efforts in heterogeneous database integration and the research plans of the multimedia database project as well as applications of our system in different environments such as hypertext and office automation.	SIGMOD Record	database
1391	SIGMOD Record	Database Research at the Queensland University of Technology.	Mike P. Papazoglou,M. McLoughlin,E. Lindsay,Sylvia Willie	1992	Database Research at the Queensland University of Technology.	SIGMOD Record	database
1392	SIGMOD Record	An Overview of GOOD.	Jan Paredaens,Jan Van den Bussche,Marc Andries,Marc Gemis,Marc Gyssens,Inge Thyssens,Dirk Van Gucht,Vijay M. Sarathy,Lawrence V. Saxton	1992	GOOD is an acronym, standing for Graph-Oriented Object Database. GOOD is being developed as a joint research effort of Indiana University and the University of Antwerp. The main thrust behind the project is to indicate general concepts that are fundamental to any graph-oriented database user-interface. GOOD does not restrict its attention to well-considered topics such as ad-hoc query facilities, but wants to cover the full spectrum of database manipulations. The idea of graph-pattern matching as a uniform object manipulation primitive offers a uniform framework in which this can be accomplished.	SIGMOD Record	database
1393	SIGMOD Record	Bibliography on Database Security.	Günther Pernul,Gottfried Luef	1992	Bibliography on Database Security.	SIGMOD Record	database
1394	SIGMOD Record	A Process-Oriented Scientific Database Model.	J. Michael Pratt,Maxine S. Cohen	1992	A database model is proposed for organizing data that describes natural processes studied experimentally. Adapting concepts from object-oriented and temporal databases, this process-oriented scientific database model (POSDBM) identifies two data object types (independent and dependent variables) and two types of relationships (becomes-a and affects-a) between data objects. Successive versions of dependent variable objects are associated by the becomes-a relationship, while independent and dependent variable objects are associated by the affects-a relationship. Thus, a process can be viewed as a sequence of states (versions) of a dependent variable object whose attributes are affected over time by independent variable objects.	SIGMOD Record	database
1395	SIGMOD Record	Summary of Database Research Activities at The University of Massachusetts, Amherst.	Krithi Ramamritham,J. Eliot B. Moss,John A. Stankovic,David W. Stemple,W. Bruce Croft,Donald F. Towsley	1992	At the University of Massachusetts, we have been conducting research in the following database related areas: theoretical support for database system development, database programming languages, flexible concurrency control and transaction management, real-time databases, and information retrieval. The following is a summary of our research in each area.	SIGMOD Record	database
1396	SIGMOD Record	SQL/SE - A Query Language Extension for Databases Supporting Schema Evolution.	John F. Roddick	1992	The incorporation of a knowledge of time within database systems allows for temporally related information to be modelled more naturally and consistently. Adding this support to the metadatabase further enhances its semantic capability and allows elaborate interrogation of data. This paper presents SQL/SE, an SQL extension capable of handling schema evolution in relational database systems.	SIGMOD Record	database
1397	SIGMOD Record	Schema Evolution in Database Systems - An Annotated Bibliography.	John F. Roddick	1992	Schema Evolution is the ability of a database system to respond to changes in the real world by allowing the schema to evolve. In many systems this property also implies a retaining of past states of the schema. This latter property is necessary if data recorded during the lifetime of one version of the schema is not to be made obsolete as the schema changes. This annotated bibliography investigates current published research with respect to the handling of changing schemas in database systems.	SIGMOD Record	database
1398	SIGMOD Record	A Retrospective on Database Application Development Frameworks.	Lawrence A. Rowe	1992	Four application framework models developed by the author for database application development systems are described. The key feature of these systems is to provide a model for the definition of high level objects that represent interface abstraction that can be used to build an application. Structuring application code around interface objects reduces the conceptual distance between the executing program and its specification. At the same time, good programming practices must be supported (e.g., code modularity, reusable components, and information hiding).	SIGMOD Record	database
1399	SIGMOD Record	Database Research at CITRI.	Ron Sacks-Davis,Kotagiri Ramamohanarao	1992	Database Research at CITRI.	SIGMOD Record	database
1400	SIGMOD Record	Conferences on Databases / Calls for Papers.	Fèlix Saltor	1992	Conferences on Databases / Calls for Papers.	SIGMOD Record	database
1401	SIGMOD Record	Conferences on Databases / Calls for Papers.	Fèlix Saltor	1992	Conferences on Databases / Calls for Papers.	SIGMOD Record	database
1402	SIGMOD Record	Conferences on Databases / Calls for Papers.	Fèlix Saltor	1992	Conferences on Databases / Calls for Papers.	SIGMOD Record	database
1403	SIGMOD Record	Editor's Notes.	Arie Segev	1992	Editor's Notes.	SIGMOD Record	database
1404	SIGMOD Record	Editor's Notes.	Arie Segev	1992	Editor's Notes.	SIGMOD Record	database
1405	SIGMOD Record	Editor's Notes.	Arie Segev	1992	Editor's Notes.	SIGMOD Record	database
1406	SIGMOD Record	Pictures from SIGMOD Conference 1991.	Frederick N. Springsteel	1992	Pictures from SIGMOD Conference 1991.	SIGMOD Record	database
1407	SIGMOD Record	An Overview of Three Commercial Object-Oriented Database Management Systems: ONTOS, ObjectStore, and O2.	Valery Soloviev	1992	We present an analysis of three current object-oriented DBMS products: ONTOS, ObjectStore, and O2, as described by their available documentation. The most attractive feature of ONTOS and Object-Store is their use of C++ as a user interface - a widespread object-oriented language. They also provide persistent data implementation, transaction and recovery mechanisms, and modern application development tool sets following the recommendations of [Atkinson et al. 89]. O2 was chosen for a well-developed data type system and end-user interface, and for its reputation from the literature.	SIGMOD Record	database
1408	SIGMOD Record	SIGMOD Innovations Award.		1992	SIGMOD Innovations Award.	SIGMOD Record	database
1409	SIGMOD Record	Current Status of R&D in Trusted Database Management Systems.	Bhavani M. Thuraisingham	1992	Current Status of R&D in Trusted Database Management Systems.	SIGMOD Record	database
1410	SIGMOD Record	Database Research Acitivities at The University of Vienna.	A. Min Tjoa,G. Vinek	1992	Database Research Acitivities at The University of Vienna.	SIGMOD Record	database
1411	SIGMOD Record	Current Research on Real-Time Databases.	Özgür Ulusoy	1992	Current Research on Real-Time Databases.	SIGMOD Record	database
1412	SIGMOD Record	A Denotational Semantics for the Starburst Production Rule Language.	Jennifer Widom	1992	Researchers often complain that the behavior of database production rules is difficult to reason about and understand, due in part to the lack of formal declarative semantics. It has even been claimed that database production rule languages inherently cannot be given declarative semantics, in contrast to, e.g., deductive database rule languages. In this short paper we dispute this claim by giving a denotational semantics for the Starburst database production rule language.	SIGMOD Record	database
1413	SIGMOD Record	EUG'91 Meeting Notes.	Peter R. Wilson	1992	The first annual meeting of the EXPRESS Users Group was held in Houston, Texas on 17-18 October 1991. There was a good international audience at the conference, two thirds of whom were from North America with the remainder from several European countries and Japan.	SIGMOD Record	database
1414	SIGMOD Record	Opportunities from the US Department of Defense and NSF.	Marianne Winslett	1992	Opportunities from the US Department of Defense and NSF.	SIGMOD Record	database
1415	SIGMOD Record	Opportunities in the US from NSF, DARPA, and NASA.	Marianne Winslett	1992	In this issue, we begin with general information about the High Performance Computing and Communications (HPCC) Program at NSF, followed by a more focused look at HPCC work in the database area, and a close-up of the new scientific databases initiative. A NASA program for intelligent systems, DARPA programs in 3-D visualization and multiple knowledge sources, news of recent events at DARPA, and two new small business solicitations round out the funding news for this issue.	SIGMOD Record	database
1416	SIGMOD Record	The Winds of Change?	Marianne Winslett	1992	In this issue, we bring you coverage of recent events in the US that may have an impact on database funding, especially at NSF. We also announce two upcoming NSF Small Business Innovative Research Conferences and requests for proposals from the Air Force, the Army, and the folks at the Strategic Defense Initiative. A new database/knowledge-base BAA and other bits of news from DARPA round out the funding news for this issue.	SIGMOD Record	database
1417	SIGMOD Record	Database Research at La Trobe University.	John Zeleznikow	1992	Database Research at La Trobe University.	SIGMOD Record	database
1418	Artificial Intelligence in Medicine	Inducing diagnostic rules for glomerular disease with the DLG machine learning algorithm.	Geoffrey I. Webb,John W. M. Agar	1992	Inducing diagnostic rules for glomerular disease with the DLG machine learning algorithm.	Artificial Inte	medical
1419	Artificial Intelligence in Medicine	Knowledge-based flash evoked potential recognition system.	J. Xu,S. Hyman,P. King	1992	Knowledge-based flash evoked potential recognition system.	Artificial Inte	medical
1420	Artificial Intelligence in Medicine	A fuzzy expert system shell: From minicomputer to PC.	Kwong-Sak Leung,Y. T. So,Ares Leung,W. S. Felix Wong	1992	A fuzzy expert system shell: From minicomputer to PC.	Artificial Inte	medical
1421	Artificial Intelligence in Medicine	GAIT-ER-AID: An expert system for diagnosis of human gait.	George A. Bekey,Joung-woo John Kim,JoAnne K. Gronley,Ernest L. Bontrager,Jacquelin Perry	1992	GAIT-ER-AID: An expert system for diagnosis of human gait.	Artificial Inte	medical
1422	Artificial Intelligence in Medicine	Background knowledge in diagnosis.	Elpida T. Keravnou,F. Dams,John Washbrook,R. M. Dawood,C. M. Hall,D. Shaw	1992	Background knowledge in diagnosis.	Artificial Inte	medical
1423	Artificial Intelligence in Medicine	M-HTP: A system for monitoring heart transplant patients.	Cristiana Larizza,Andrea Moglia,Mario Stefanelli	1992	M-HTP: A system for monitoring heart transplant patients.	Artificial Inte	medical
1424	Artificial Intelligence in Medicine	Flexible support for trauma management through goal-directed reasoning and planning.	Bonnie L. Webber,Ron Rymon,John R. Clarke	1992	Flexible support for trauma management through goal-directed reasoning and planning.	Artificial Inte	medical
1425	Artificial Intelligence in Medicine	Qualitative simulation of dynamic physiological models using the KEE environment.	Mauro Ursino,Guido Avanzolini,P. Barbini	1992	Qualitative simulation of dynamic physiological models using the KEE environment.	Artificial Inte	medical
1426	Artificial Intelligence in Medicine	Qualitative modeling as a paradigm for diagnosis and prediction in critical care environments.	N. Serdar Uckun,Benoit M. Dawant	1992	Qualitative modeling as a paradigm for diagnosis and prediction in critical care environments.	Artificial Inte	medical
1427	Artificial Intelligence in Medicine	Certainty factor theory: Its probabilistic interpretations and problems.	Dan Qiu,Joachim Dudeck	1992	Certainty factor theory: Its probabilistic interpretations and problems.	Artificial Inte	medical
1428	Artificial Intelligence in Medicine	Bayesian networks for patient monitoring.	Carlo Berzuini,Riccardo Bellazzi,Silvana Quaglini,David J. Spiegelhalter	1992	Bayesian networks for patient monitoring.	Artificial Inte	medical
1429	Artificial Intelligence in Medicine	Modeling disturbance management in anesthesia: A preliminary report.	Elizabeth A. Sonenberg,Jeanette A. Lawrence,John Zelcer	1992	Modeling disturbance management in anesthesia: A preliminary report.	Artificial Inte	medical
1430	Artificial Intelligence in Medicine	Automated design of diagnostic systems.	Mirsad Hadzikadic	1992	Automated design of diagnostic systems.	Artificial Inte	medical
1431	Artificial Intelligence in Medicine	Consistency checking of binary categorical relationships in a medical knowledge base.	Wolfgang Moser,Klaus-Peter Adlassnig	1992	Consistency checking of binary categorical relationships in a medical knowledge base.	Artificial Inte	medical
1432	Artificial Intelligence in Medicine	Intermediate depth representations.	Enrico W. Coiera	1992	Intermediate depth representations.	Artificial Inte	medical
1433	Artificial Intelligence in Medicine	Knowledge acquisition for multi-channel electroencephalogram interpretation.	J. Karim Meddahi,Ben H. Jansen	1992	Knowledge acquisition for multi-channel electroencephalogram interpretation.	Artificial Inte	medical
1434	Artificial Intelligence in Medicine	Therapy planning and monitoring.	Mario Stefanelli	1992	Therapy planning and monitoring.	Artificial Inte	medical
1435	Artificial Intelligence in Medicine	Indexing biomedical documents: From thesaural to knowledge-based retrieval systems.	Susanne M. Humphrey	1992	Indexing biomedical documents: From thesaural to knowledge-based retrieval systems.	Artificial Inte	medical
1436	Artificial Intelligence in Medicine	A model-based approach to the diagnosis of the cardiac arrhythmias.	Lawrence E. Widman	1992	A model-based approach to the diagnosis of the cardiac arrhythmias.	Artificial Inte	medical
1437	Artificial Intelligence in Medicine	Hybrid knowledge-based systems for therapy planning.	Silvana Quaglini,Roberto Bellazzi,Carlo Berzuini,Mario Stefanelli,Giovanni Barosi	1992	Hybrid knowledge-based systems for therapy planning.	Artificial Inte	medical
1438	Artificial Intelligence in Medicine	Ripple down rules: Turning knowledge acquisition into knowledge maintenance.	Paul Compton,Glenn Edwards,Byeong Kang,Leslie Lazarus,Ron Malor,Phillip Preston,Ashwin Srinivasan	1992	Ripple down rules: Turning knowledge acquisition into knowledge maintenance.	Artificial Inte	medical
1439	Artificial Intelligence in Medicine	MENINGE: A medical consulting system for child's meningitis. Study on a series of consecutive cases.	Patrice François,Bruno Crémilleux,Claudine Robert,Jacques Demongeot	1992	MENINGE: A medical consulting system for child's meningitis. Study on a series of consecutive cases.	Artificial Inte	medical
1440	Artificial Intelligence in Medicine	Handbook of theoretical computer science : J. van Leeuwen, ed., Vol. A: Algorithms and Complexity, Vol. B: Formal Methods and Semantics (Elsevier, Amsterdam, 1990), 2296 pp., hardcover, Dfl. 555.00.	D. B. Czerbo	1992	Handbook of theoretical computer science : J. van Leeuwen, ed., Vol. A: Algorithms and Complexity, Vol. B: Formal Methods and Semantics (Elsevier, Amsterdam, 1990), 2296 pp., hardcover, Dfl. 555.00.	Artificial Inte	medical
1441	Artificial Intelligence in Medicine	Artificial intelligence in medicine workshop: AAAI 1992 Spring Symposium Series Stanford University March 25-27, 1992 Workshop Summary.	Michael G. Kahn	1992	Artificial intelligence in medicine workshop: AAAI 1992 Spring Symposium Series Stanford University March 25-27, 1992 Workshop Summary.	Artificial Inte	medical
1442	Artificial Intelligence in Medicine	From certainty factors to belief networks.	David Heckerman,Edward H. Shortliffe	1992	From certainty factors to belief networks.	Artificial Inte	medical
1443	Artificial Intelligence in Medicine	Representing knowledge in medical decision support systems.	Cynthia Sarmiento	1992	Representing knowledge in medical decision support systems.	Artificial Inte	medical
1444	Artificial Intelligence in Medicine	Planning of therapy and tests in causal probabilistic networks.	Steen Andreassen	1992	Planning of therapy and tests in causal probabilistic networks.	Artificial Inte	medical
1445	Artificial Intelligence in Medicine	Extraction of diagnostic rules using recursive partitioning systems: A comparison of two approaches.	Ankica Babic,Ewa Krusinska,Jan-Erik Strömberg	1992	Extraction of diagnostic rules using recursive partitioning systems: A comparison of two approaches.	Artificial Inte	medical
1446	Artificial Intelligence in Medicine	Patient-specific explanation in models of chronic disease.	Holly B. Jimison,Lawrence M. Fagan,R. D. Shachter,Edward H. Shortliffe	1992	Patient-specific explanation in models of chronic disease.	Artificial Inte	medical
1447	Artificial Intelligence in Medicine	Editorial.	Lawrence E. Widman	1992	Editorial.	Artificial Inte	medical
1448	Artificial Intelligence in Medicine	Guardian: A prototype intelligent agent for intensive-care monitoring.	Barbara Hayes-Roth,Richard Washington,David Ash,Rattikorn Hewett,Anne Collinot,Angel Vina,Adam Seiver	1992	Guardian: A prototype intelligent agent for intensive-care monitoring.	Artificial Inte	medical
1449	FOCS	Halvers and Expanders	Miklós Ajtai,János Komlós,Endre Szemerédi	1992	Halvers and Expanders	FOCS	theory
1450	FOCS	Dynamic Half-Space Reporting, Geometric Optimization, and Minimum Spanning Trees	Pankaj K. Agarwal,David Eppstein,Jirí Matousek	1992	The authors describe dynamic data structures for half-space range reporting and for maintaining the minima of a decomposable function. Using these data structures, they obtain efficient dynamic algorithms for a number of geometric problems, including closest/farthest neighbor searching, fixed dimension linear programming, bi-chromatic closest pair, diameter, and Euclidean minimum spanning tree.	FOCS	theory
1451	FOCS	Efficient Minimum Cost Matching Using Quadrangle Inequality	Alok Aggarwal,Amotz Bar-Noy,Samir Khuller,Dina Kravets,Baruch Schieber	1992	The authors present efficient algorithms for finding a minimum cost perfect matching, and for solving the transportation problem in bipartite graphs, G = (Red union Blue, Red * Blue), where mod Red mod = n, mod Blue mod = m, n	FOCS	theory
1452	FOCS	Fault Tolerant Graphs, Perfect Hash Functions and Disjoint Paths	Miklós Ajtai,Noga Alon,Jehoshua Bruck,Robert Cypher,Ching-Tien Ho,Moni Naor,Endre Szemerédi	1992	Given a graph G on n nodes the authors say that a graph T on n + k nodes is a k-fault tolerant version of G, if one can embed G in any n node induced subgraph of T. Thus T can sustain k faults and still emulate G without any performance degradation. They show that for a wide range of values of n, k and d, for any graph on n nodes with maximum degree d there is a k-fault tolerant graph with maximum degree O(kd). They provide lower bounds as well: there are graphs G with maximum degree d such that any k-fault tolerant version of them has maximum degree at least Omega (d square root k).	FOCS	theory
1453	FOCS	The Algorithmic Aspects of the Regularity Lemma (Extended Abstract)	Noga Alon,Richard A. Duke,Hanno Lefmann,Vojtech Rödl,Raphael Yuster	1992	The Algorithmic Aspects of the Regularity Lemma (Extended Abstract)	FOCS	theory
1454	FOCS	Witnesses for Boolean Matrix Multiplication and for Shortest Paths	Noga Alon,Zvi Galil,Oded Margalit,Moni Naor	1992	The subcubic (O(n/sup w/) for w(3) algorithms to multiply Boolean matrices do not provide the witnesses; namely, they compute C=A.B but if C/sub ij/=1 they do not find an index k (a witness) such that A/sub ik/=B/sub kj/=1. The authors design a deterministic algorithm for computing the matrix of witnesses that runs in O(n/sup w/) time, where here O(n/sup w/) denotes O(n/sup w/(log n)/sup O(1)/). The subcubic methods to compute the shortest distances between all pairs of vertices also do not provide for witnesses; namely they compute the shortest distances but do not generate information for computing quickly the paths themselves. A witness for a shortest path from v/sub i/ to v/sub j/ is an index k such that v/sub k/ is the first vertex on such a path. They describe subcubic methods to compute such witnesses for several versions of the all pairs shortest paths problem. As a result, they derive shortest paths algorithms that provide characterization of the shortest paths in addition to the shortest distances in the same time (up to a polylogarithmic factor) needed for computing the distances; namely O(n/sup (3+w)/2/) time in the directed case and O(n/sup w/) time in the undirected case. They also design an algorithm that computes witnesses for the transitive closure in the same time needed to compute witnesses for Boolean matrix multiplication.	FOCS	theory
1455	FOCS	Read-Thrice DNF Is Hard to Learn With Membership and Equivalence Queries	Howard Aizenstein,Lisa Hellerstein,Leonard Pitt	1992	A general technique is developed to obtain nonlearnability results in the model of exact learning from equivalence and membership queries. The technique is applied to show that, assuming NP not=co-NP, there does not exist a polynomial-time membership and equivalence query algorithm for exactly learning read-thrice DNF formulas-boolean formulas in disjunctive normal form where each variable appears at most three times. This result adds evidence to the conjecture that DNF is hard to learn in the membership and equivalence query model.	FOCS	theory
1456	FOCS	Lower Bounds on the Competitive Ratio for Mobile User Tracking and Distributed Job Scheduling (Extended Abstract)	Noga Alon,Gil Kalai,Moty Ricklin,Larry J. Stockmeyer	1992	Lower Bounds on the Competitive Ratio for Mobile User Tracking and Distributed Job Scheduling (Extended Abstract)	FOCS	theory
1457	FOCS	Back to the Future: Towards a Theory of Timed Regular Languages	Rajeev Alur,Thomas A. Henzinger	1992	The authors introduce two-way timed automata-timed automata that can move back and forth while reading a timed word. Two-wayness in its unrestricted form leads, like nondeterminism, to the undecidability of language inclusion. However, if they restrict the number of times an input symbol may be revisited, then two-wayness is both harmless and desirable. The authors show that the resulting class of bounded two-way deterministic timed automata is closed under all boolean operations, has decidable (PSPACE-complete) emptiness and inclusion problems, and subsumes all decidable real-time logics we know. They obtain a strict hierarchy of real-time properties: deterministic timed automata can accept more languages as the bound on the number of times an input symbol may be revisited is increased. This hierarchy is also enforced by the number of alternations between past and future operators in temporal logic. The combination of the results leads to a decision procedure for a real-time logic with past operators.	FOCS	theory
1458	FOCS	Reconstructing Algebraic Functions from Mixed Data	Sigal Ar,Richard J. Lipton,Ronitt Rubinfeld,Madhu Sudan	1992	The authors consider the task of reconstructing algebraic functions given by black boxes. Unlike traditional settings, they are interested in black boxes which represent several algebraic functions-f/sub 1/, . . ., f/sub k/, where at each input x, the box arbitarrily chooses a subset of f/sub 1/(x), . . ., f/sub k/(x) to output. They show how to reconstruct the functions f/sub 1/,. . ., f/sub k/ from the black box. This allows them to group the same points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. The methods are robust in the presence of errors in the black box. The model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, self-correcting programs and bivariate polynomial factorization.	FOCS	theory
1459	FOCS	Proof Verification and Hardness of Approximation Problems	Sanjeev Arora,Carsten Lund,Rajeev Motwani,Madhu Sudan,Mario Szegedy	1992	The class PCP(f(n),g(n)) consists of all languages L for which there exists a polynomial-time probabilistic oracle machine that used O(f(n)) random bits, queries O(g(n)) bits of its oracle and behaves as follows: If x in L then there exists an oracle y such that the machine accepts for all random choices but if x not in L then for every oracle y the machine rejects with high probability. Arora and Safra (1992) characterized NP as PCP(log n, (loglogn)/sup O(1)/). The authors improve on their result by showing that NP=PCP(logn, 1). The result has the following consequences: (1) MAXSNP-hard problems (e.g. metric TSP, MAX-SAT, MAX-CUT) do not have polynomial time approximation schemes unless P=NP; and (2) for some epsilon >0 the size of the maximal clique in a graph cannot be approximated within a factor of n/sup epsilon / unless P=NP.	FOCS	theory
1460	FOCS	Probabilistic Checking of Proofs; A New Characterization of NP	Sanjeev Arora,Shmuel Safra	1992	The authors give a new characterization of NP: the class NP contains exactly those languages L for which membership proofs (a proof that an input x is in L) can be verified probabilistically in polynomial time using logarithmic number of random bits and sub-logarithmic number of queries to the proof. This is a non-relativizing characterization of NP. They discuss implications of this characterization; specifically, they show that approximating clique (or independent set) is NP-hard.	FOCS	theory
1461	FOCS	Randomized Consensus in Expected O(n log ^2 n) Operations Per Processor	James Aspnes,Orli Waarts	1992	This paper presents a new randomized algorithm for achieving consensus among asynchronous processors that communicate by reading and writing shared registers. The fastest previously known algorithm requires a processor to perform an expected $O(n^2 \log n)$ read and write operations in the worst case. In our algorithm, each processor executes at most an expected $O(n \log^2 n)$ read and write operations, which is close to the trivial lower bound of $\Omega(n)$. All previously known polynomial-time consensus algorithms were structured around a shared-coin protocol [J. Algorithms, 11 (1990), pp. 441--446] in which each processor repeatedly adds random $\pm 1$ votes to a common pool. Consequently, in all of these protocols, the worst-case expected bound on the number of read and write operations done by a single processor is asymptotically no better than the bound on the total number of read and write operations done by all of the processors together. We succeed in breaking this tradition by allowing the processors to cast votes of increasing weights. This grants the adversary greater control since he can choose from up to $n$ different weights (one for each processor) when determining the weight of the next vote to be cast. We prove that our shared-coin protocol is nevertheless correct using martingale arguments.	FOCS	theory
1462	FOCS	Clock Construction in Fully Asynchronous Parallel Systems and PRAM Simulation (Extended Abstract)	Yonatan Aumann,Michael O. Rabin	1992	Clock Construction in Fully Asynchronous Parallel Systems and PRAM Simulation (Extended Abstract)	FOCS	theory
1463	FOCS	On-line Load Balancing (Extended Abstract)	Yossi Azar,Andrei Z. Broder,Anna R. Karlin	1992	On-line Load Balancing (Extended Abstract)	FOCS	theory
1464	FOCS	The Distributed k-Server Problem-A Competitive Distributed Translator for k-Server Algorithms	Yair Bartal,Adi Rosén	1992	The authors consider the k-server problem in a distributed setting. Given a network of n processors, and k identical mobile servers, requests for service appear at the processors and a server must reach the request point. Besides modeling problems in computer networks where k identical mobile resources are shared by the processors of the network, this models a realistic situation where the transfer of information is costly and there is no central control that governs the behavior of servers that move around to satisfy requests for service. The problem is that of devising algorithms that minimize not only the travel of the server but also the communication cost incurred for the transmission of control messages. The main contribution is a general translator to transform any deterministic global-control competitive k-server algorithm into a distributed competitive one. As consequences they get poly(k)-competitive distributed algorithms for the line, trees and the ring.	FOCS	theory
1465	FOCS	Improved Parallel Polynomial Division and Its Extensions	Dario Bini,Victor Y. Pan	1992	The authors compute the first N coefficients of the reciprocal r(x) of a given polynomial p(x), (r(x)p(x)=1 mod x/sup N/, p(0) not=0), by using, under the PRAM arithmetic models, O(h log N) time-steps and O((N/h)(1+2/sup -h/log/sup (h)/ N)) processors, for any h, h=1,2, . . .,log/sup */ N, provided that O(logm) steps and m processors suffice to perform DFT on m points and that log/sup (0)/ N=N, log/sup (h)/ N=log/sub 2/log/sup (h-1)/N, h=1, . . .,log/sup */N, log/sup */N=max(h:log/sup (h)/N>0). The same complexity estimates apply to some other computations, such as the division with a remainder of two polynomials of degrees O(N) and the inversion of an N*N triangular Toeplitz matrix. They also show how to extend the techniques to parallel implementation of other recursive processes, such as the evaluation modulo x/sup N/ of the m-th root, p(x)/sup 1/m/, of p(x) (for any fixed natural m), for which we need O(log N log log N) time-steps and O(N/log log N) processors. The paper demonstrates some new techniques of supereffective slowdown of parallel algebraic computations, which they combine with a technique of stream contraction.	FOCS	theory
1466	FOCS	How to Denest Ramanujan's Nested Radicals	Johannes Blömer	1992	The author presents a simple condition when nested radical expressions of depth two can be denested using real radicals or radicals of some bounded degree. He describes the structure of these denestings and determines an upper bound on the maximum size of a denesting. Also for depth two radicals he describes an algorithm that will find such a denesting whenever one exists. Unlike all previous denesting algorithms the algorithm does not use Galois theory. In particular, he avoids the construction of the minimal polynomial and splitting field of a nested radical expression. Thus he can obtain the first denesting algorithm whose run time is at most, and in general much less, than polynomial in description size of the minimal polynomial. The algorithm can be used to determine non-trivial denestings for expressions of depth larger than two.	FOCS	theory
1467	FOCS	Towards a Computational Theory of Statistical Tests (Extended Abstract)	Manuel Blum,Oded Goldreich	1992	Towards a Computational Theory of Statistical Tests (Extended Abstract)	FOCS	theory
1468	FOCS	A Decomposition Theorem and Bounds for Randomized Server Problems	Avrim Blum,Howard J. Karloff,Yuval Rabani,Michael E. Saks	1992	The authors prove a lower bound of Omega ( square root logk/loglogk) for the competitive ratio of randomized algorithms for the k-server problem against an oblivious adversary. The bound holds for arbitrary metric spaces (of at least k+1 points) and provides a new lower bound for the metrical task system problem as well. This improves the previous best lower bound of Omega (loglogk) for arbitrary metric spaces, more closely approaching the conjectured lower bound of Omega (logk). They also prove a lower bound of Omega (/sup logk///sub loglogk/) for the server problem on k+1 equally-spaced points on a line, which corresponds to some natural motion-planning problems.	FOCS	theory
1469	FOCS	On the Exact Learning of Formulas in Parallel (Extended Abstract)	Nader H. Bshouty,Richard Cleve	1992	On the Exact Learning of Formulas in Parallel (Extended Abstract)	FOCS	theory
1470	FOCS	Data Structural Bootstrapping, Linear Path Compression, and Catenable Heap Ordered Double Ended Queues	Adam L. Buchsbaum,Rajamani Sundar,Robert Endre Tarjan	1992	The authors provide an efficient implementation of catenable mindeques. To prove that the resulting data structure achieves constant amortized time per operation, they consider order preserving path compression. They prove a linear bound on deque ordered spine-only path compression, a case of order persevering path compression employed by the data structure.	FOCS	theory
1471	FOCS	On the Completeness of Object-Creating Query Languages (Extended Abstract)	Jan Van den Bussche,Dirk Van Gucht,Marc Andries,Marc Gyssens	1992	On the Completeness of Object-Creating Query Languages (Extended Abstract)	FOCS	theory
1472	FOCS	Mick Gets Some (the Odds Are on His Side)	Vasek Chvátal,Bruce A. Reed	1992	Mick Gets Some (the Odds Are on His Side)	FOCS	theory
1473	FOCS	Safe and Effective Determinant Evaluation	Kenneth L. Clarkson	1992	The problem of evaluating the sign of the determinant of a small matrix aries in many geometric algorithms. Given an n*n matrix A with integer entries, whose columns are all smaller than M in Euclidean norm, the algorithm given evaluates the sign of the determinant det A exactly. The algorithm requires an arithmetic precision of less than 1.5n+2lgM bits. The number of arithmetic operations needed is O(n/sup 3/)+O(n/sup 2/) log OD(A)/ beta , where OD(A) mod det A mod is the product of the lengths of the columns of A, and beta is the number of 'extra' bits of precision, min(lg(1/u)-1.1n-2lgn-2,lgN-lgM-1.5n-1), where u is the roundoff error in approximate arithmetic, and N is the largest representable integer. Since OD(A)	FOCS	theory
1474	FOCS	The Complexity of Parallel Prefix Problems on Small Domains	Shiva Chaudhuri,Jaikumar Radhakrishnan	1992	The authors study the complexity of some prefix problems in the CRCW PRAM model. The main result is an Omega ( alpha (n)) lower bound for chaining, matching a previous upper bound and solving an open problem. They give reductions to show an Omega ( alpha (n)) lower bound on the complexity of the prefix maxima and range maxima problems even when the domain is (1,...,n). An interesting consequence is that prefix maximum is strictly harder than simple maximum. They also give a reduction to show an Omega ( alpha (n)) lower bound on a parenthesis matching problem, matching the upper bound. No lower bounds were previously known for any of these problems. The lower bounds contribute to the study of very fast parallel algorithms by introducing techniques for proving lower bounds for small domain problems.	FOCS	theory
1475	FOCS	Approximate Max Flow on Small Depth Networks	Edith Cohen	1992	The author considers the maximum flow problem on directed acyclic networks with m edges and depth r (length of the longest s-t path). The main result is a new deterministic algorithm for solving the relaxed problem of computing an s-t flow of value at least (1- epsilon ) of the maximum flow. For instances where r and epsilon /sup -1/ are small (i.e., O(polylog(m))), this algorithm is in NC and uses only O(m) processors, which is a significant improvement over existing parallel algorithms. As one consequence, he obtains an NC O(m) processor algorithm to find a bipartite matching of cardinality (1- epsilon ) of the maximum (for epsilon /sup -1/ = O(polylog(m))). The parallel bounds are based on a novel approach to the blocking flow problem that produces fractional valued flow augmentations even when capacities are integral. She shows that a fractional flow on any network with integral capacities can be rounded in polylogarithmic time to an integral flow of no smaller value using O(m) processors. Hence, within the same resource bounds, an integral flow can be obtained when desired.	FOCS	theory
1476	FOCS	Tighter Bounds on the Exact Complexity of String Matching (Extended Abstract)	Richard Cole,Ramesh Hariharan	1992	Tighter Bounds on the Exact Complexity of String Matching (Extended Abstract)	FOCS	theory
1477	FOCS	A Class of Logic Problems Solvable by Linear Programming	Michele Conforti,Gérard Cornuéjols	1992	Several problems of propositional logic, such as satisfiability, MAXSAT and logical inference, can be formulated as integer programs. The authors consider sets of clauses for which these integer programs can be solved as linear programs. They prove that balanced sets of clauses have this property.	FOCS	theory
1478	FOCS	Lower Bounds on the Depth of Monotone Arithmetic Computations (Extended Summary)	Don Coppersmith,Baruch Schieber	1992	Lower Bounds on the Depth of Monotone Arithmetic Computations (Extended Summary)	FOCS	theory
1479	FOCS	Amplification and Percolation	Moshe Dubiner,Uri Zwick	1992	Amplification and Percolation	FOCS	theory
1480	FOCS	On Efficient Band Matrix Arithmetic	Wayne Eberly	1992	An efficient parallel Las Vegas algorithm is presented for computation of the determinant of a non-singular band matrix and for the solution of a system of linear equations with a band matrix as coefficient matrix. The algorithm can be implemented using time polylogarithmic in n with O(nm/sup omega -1/) processors, in order to process an input matrix with order n and band width m, provided that n*n matrices can be multiplied in logarithmic time with O(n/sup omega /) processors. If asymptotically efficient matrix multiplication is used ( omega	FOCS	theory
1481	FOCS	Competitive Analysis of Financial Games	Ran El-Yaniv,Amos Fiat,Richard M. Karp,G. Turpin	1992	In the unidirectional conversion problem an on-line player is given the task of converting dollars to yen over some period of time. Each day, a new exchange rate is announced and the player must decide how many dollars to convert. His goal is to minimize the competitive ratio. defined as sup/sub E/ (P/sub OPT/(E)/P/sub X/E) where E ranges over exchange rate sequences. P/sub OPT/(E) is the number of yen obtained by an optimal off-line algorithm, and Px(E) is the number of yen obtained by the on-line algorithm X. The authors also consider a continuous version of the problem. in which the exchange rate varies over a continuous time interval. The on-line line players a priori information about the fluctuation of exchange rates distinguishes different variants of the problem. For three variants they show that a simple threat-based strategy is optimal for the on-line player and determine its competitive ratio. They also derive and analyze an optimal policy for the on-line player when he knows the probability distribution of the maximum value that the exchange rate will reach. Finally, they consider a bidirectional conversion problem, which the player may trade dollars for yen or yen for dollars.	FOCS	theory
1482	FOCS	Sparsification-A Technique for Speeding up Dynamic Graph Algorithms (Extended Abstract)	David Eppstein,Zvi Galil,Giuseppe F. Italiano,Amnon Nissenzweig	1992	Sparsification-A Technique for Speeding up Dynamic Graph Algorithms (Extended Abstract)	FOCS	theory
1483	FOCS	On Four-Connecting a Triconnected Graph (Extended Abstract)	Tsan-sheng Hsu	1992	On Four-Connecting a Triconnected Graph (Extended Abstract)	FOCS	theory
1484	FOCS	Exact Analysis of Hot-Potato Routing (Extended Abstract)	Uriel Feige,Prabhakar Raghavan	1992	Exact Analysis of Hot-Potato Routing (Extended Abstract)	FOCS	theory
1485	FOCS	A Theory of Wormhole Routing in Parallel Computers (Extended Abstract)	Sergio A. Felperin,Prabhakar Raghavan,Eli Upfal	1992	A Theory of Wormhole Routing in Parallel Computers (Extended Abstract)	FOCS	theory
1486	FOCS	The Isomorphism Conjecture Holds Relative to an Oracle	Stephen A. Fenner,Lance Fortnow,Stuart A. Kurtz	1992	The authors introduce symmetric perfect generic sets. these sets vary from the usual generic sets by allowing limited infinite encoding into the oracle. They then show that the Berman-Hartmanis (1977) isomorphism conjecture holds relative to any sp-generic oracle, i.e., for any symmetric perfect generic set A, all NP/sup A/-complete sets are polynomial-time isomorphic relative to A. As part of the proof that the isomorphism conjecture holds relative to symmetric perfect generic sets they also show that P/sup A/=FewP/sup A/ for any symmetric perfect generic/sup /A.	FOCS	theory
1487	FOCS	On the Bit Extraction Problem	Joel Friedman	1992	Consider a coloring of the n-dimensional Boolean cube with c=2/sup s/ colors in such a way that every k-dimensional subcube is equicolored, i.e. each color occurs the same number of times. The author shows that for such a coloring one necessarily has (k-1)/n>or= theta /sub c/=(c/2-1)/(c-1). This resolves the 'bit extraction' or 't-resilient functions' problem (also a special case of the privacy amplification problem) in many cases, such as c-1/n, proving that XOR type colorings are optimal, and always resolves this question to within c/4 in determining the optimal value of k (for any fixed n and c). He also studies the problem of finding almost equicolored colorings when (k-1)/n	FOCS	theory
1488	FOCS	Truly Alphabet-Independent Two-Dimensional Pattern Matching	Zvi Galil,Kunsoo Park	1992	A. Amir, G. Benson and M. Farach (see Proc. 24th STOC, p.59-68 (1992)) gave an algorithm for two-dimensional pattern matching (ABF for short) whose text processing is independent of the alphabet and takes O(n/sup 2/) time, but whose pattern processing is dependent on the alphabet and takes O(m/sup 2/log mod Sigma mod ) time. The authors present an algorithm that is truly independent of the alphabet and takes linear O(m/sup 2/+n/sup 2/) time. As in the Knuth-Morris-Pratt algorithm, the only operation on the alphabet is the equality test of two symbols. All previous algorithms except the ABF algorithm reduce the two-dimensional problem into one-dimensional string matching, and use known techniques in string matching. The ABF algorithm uses two-dimensional periodicity for text processing, but their pattern processing resorts to one-dimensional techniques. The authors present a two-dimensional technique for both pattern processing and text processing.	FOCS	theory
1489	FOCS	A Subexponential Algorithm for Abstract Optimization Problems	Bernd Gärtner	1992	An abstract optimization problem (AOP) is a triple (H,	FOCS	theory
1490	FOCS	Fast Algorithms for Matrix Normal Forms	Mark Giesbrecht	1992	A Las Vegas type probabilistic algorithm is presented for computing the Frobenius normal form of an n*n matrix T over any field K. The algorithm requires O/sup approximately /(MM(n))=MM(n)/sup ./(log n)/sup O(1)/ operations in K, where O(MM(n)) operations in K are sufficient to multiply two n*n matrices over K. This nearly matches the lower bound of Omega (MM(n)) operations in K for this problem, and improves on the O(n/sup 4/) operations in K required by the previously best known algorithm. The author applies the algorithm to evaluate a polynominal g in K(x) at T with /sup approximately /(MM(n)) operations in K when deg g	FOCS	theory
1491	FOCS	Hierarchies in Transitive Closure Logic, Stratified Datalog and Infinitary Logic	Erich Grädel,Gregory L. McColm	1992	The authors establish a general hierarchy theorem for quantifier classes in the infinitary logic L/sub infinity omega //sup omega / on finite structures. In particular, it is shown that no infinitary formula with bounded number of universal quantifiers can express the negation of a transitive closure. This implies the solution of several open problems in finite model theory: On finite structures, positive transitive closure logic is not closed under negation. More generally the hierarchy defined by interleaving negation and transitive closure operators is strict. This proves a conjecture of N. Immerman (1987). The authors also separate the expressive power of several extensions of Datalog, giving new insight in the fine structure of stratified Datalog.	FOCS	theory
1492	FOCS	Separating the Communication Complexities of MOD m and MOD p Circuits	Vince Grolmusz	1992	The author proves in this paper that it is much harder to evaluate depth-2, size-N circuits with MOD m gates than with MOD p gates by k-party communication protocols: he shows a k-party protocol which communicates O(1) bits to evaluate circuits with MOD p gates, while evaluating circuits with MOD m gates needs Omega (N) bits, where p denotes a prime, and m a composite, non-prime power number. As a corollary, for all m, he shows a function, computable with a depth-2 circuit with MOD m gates, but not with any depth-2 circuit with MOD p gates. He proves in the second part that the GIP function by L. Babai et al. (1989) needs exponential size in n when it is computed by some depth-3 circuits, with threshold, symmetric, and MOD m gates.	FOCS	theory
1493	FOCS	Waste Makes Haste: Tight Bounds for Loose Parallel Sorting	Torben Hagerup,Rajeev Raman	1992	Conventional parallel sorting requires the n input keys to be output in an array of size n, and is known to take Omega (log n/log log n) time using any polynomial number of processors. The lower bound does not apply to the more 'wasteful' convention of padded sorting, which requires the keys to be output in sorted order in an array of size (1+o(1))n. The authors give very fast randomised CRCW PRAM algorithms for several padded-sorting problems. Applying only pairwise comparisons to the input and using kn processors, where 2	FOCS	theory
1494	FOCS	Apple Tasting and Nearly One-Sided Learning	David P. Helmbold,Nick Littlestone,Philip M. Long	1992	In the standard on-line model the learning algorithm tries to minimize the total number of mistakes made in a series of trials. On each trial the learner sees an instance, either accepts or rejects that instance, and then is told the appropriate response. The authors define a natural variant of this model ('apple tasting') where the learner gets feedback only when the instance is accepted. They use two transformations to relate the apple tasting model to an enhanced standard model where false acceptances are counted separately from false rejections. They present a strategy for trading between false acceptances and false rejections in the standard model. From one perspective this strategy is exactly optimal, including constants. They apply the results to obtain a good general purpose apple tasting algorithm as well as nearly optimal apple tasting algorithms for a variety of standard classes, such as conjunctions and disjunctions of n boolean variables. They also present and analyze a simpler transformation useful when the instances are drawn at random rather than selected by an adversary.	FOCS	theory
1495	FOCS	Fault-tolerant Wait-free Shared Objects	Prasad Jayanti,Tushar Deepak Chandra,Sam Toueg	1992	The authors classify object failures into two broad categories: responsive and non-responsive. They require that wait-free objects subject to responsive failures continue to respond (in finite time) to operation invocations. The responses may be incorrect. In contrast, wait-free objects subject to non-responsive failures are exempt from responding to operation invocations. Such objects may 'hang' on the invoking process. They divide responsive failures into three models: R-crash,R-omission, and R-arbitrary. They divide non-responsive failures into crash, omission, and arbitrary. An object subject to crash failure behaves correctly until it fails, and once it fails, it never responds to operation invocations. An object subject to omission failures may fail to respond to the invocations of an arbitrary subset of processes, but continue to respond to the invocations of the remaining processes (forever).	FOCS	theory
1496	FOCS	A Mildly Exponential Approximation Algorithm for the Permanent	Mark Jerrum,Umesh V. Vazirani	1992	An approximation algorithm for the permanent of an n*n 0,1-matrix is presented. The algorithm is shown to have worst-case time complexity exp (0(n/sup 1/2/ log/sup 2/ n)). Asymptotically, this represents a considerable improvement over the best existing algorithm, which has worst-case time complexity of the form e/sup theta (n)/.	FOCS	theory
1497	FOCS	On the Second Eigenvalue and Linear Expansion of Regular Graphs	Nabil Kahale	1992	The authors investigate the relation between the second eigen-value and the linear expansion of regular graphs. The spectral method is the best currently known technique to prove lower bounds on the expansion. He improves this technique by showing that the expansion coefficient of linear-sized subsets of a k-regular graph G is at least k/2(1- square root max(0,1-/sub lambda 1(G)2//sup 4k-4/))/sup -/ , where lambda /sub 1/(G) is the second largest eigenvalue of the graph. In particular, the linear expansion of Ramanujan graphs, which have the property that the second largest eigenvalue is at most 2 square root k-1, is at least (k/2)/sup -/. This improves upon the best previously known lower bound of 3(k-2)/8. For any integer k such that k-1 is prime, he explicitly constructs an infinite family of k-regular graphs G/sub n/ on n vertices whose linear expansion is k/2 and such that lambda /sub 1/(G/sub n/)	FOCS	theory
1498	FOCS	Processor-Efficient Parallel Solution of Linear Systems II: The Positive Characteristic and Singular Cases (Extended Abstract)	Erich Kaltofen,Victor Y. Pan	1992	Processor-Efficient Parallel Solution of Linear Systems II: The Positive Characteristic and Singular Cases (Extended Abstract)	FOCS	theory
1499	FOCS	Drawing Planar Graphs Using the lmc-Ordering (Extended Abstract)	Goos Kant	1992	Drawing Planar Graphs Using the lmc-Ordering (Extended Abstract)	FOCS	theory
1500	FOCS	Markov Paging (Extended Abstract)	Anna R. Karlin,Steven J. Phillips,Prabhakar Raghavan	1992	Markov Paging (Extended Abstract)	FOCS	theory
1501	FOCS	On Minimum and Maximum Spanning Trees of Linearly Moving Points	Naoki Katoh,Takeshi Tokuyama,Kazuo Iwano	1992	The authors investigate the upper bounds on the numbers of transitions of minimum and maximum spanning trees (MinST and MaxST for short) for linearly moving points. Suppose that one is given a set of n points in general d-dimensional space, S=(p/sub 1/,p/sub 2/, . . ., p/sub n/), and that all points move along different straight lines at different but fixed speeds, i.e., the position of p/sub i/ is a linear function of a real parameter. They investigate the numbers of transitions of MinST and MaxST when t increases from - infinity to + infinity . They assume that the dimension d is a fixed constant. Since there are O(n/sup 2/) distances among n points, there are naively O(n/sup 4/) transitions of MinST and MaxST. They improve these trivial upper bounds for L/sub 1/ and L/sub infinity / distance metrics. Let c/sub p/(n, min) (resp. c/sub p/(n, max)) be the number of maximum possible transitions of MinST (resp. MaxST) in L/sub p/ metric for n linearly moving points. They give the following results; c/sub 1/(n, min)=O(n/sup 5/2/a(n)), c/sub infinity /(n, min)=O(n/sup 5/2/a(n)), c/sub 1/(n, max)=O(n/sup n/) and c/sub infinity /(n, max)=O(n/sup 2/) where O(n) is the inverse Ackermann function. They also investigate two restricted cases.	FOCS	theory
1502	FOCS	Tiling a Polygon with Rectangles	Claire Kenyon,Richard Kenyon	1992	The authors study the problem of tiling a simple polygon of surface n with rectangles of given types (tiles). They present a linear time algorithm for deciding if a polygon can be tiled with 1 * m and k * 1 tiles (and giving a tiling when it exists), and a quadratic algorithm for the same problem when the tile types are m * k and k * m.	FOCS	theory
1503	FOCS	Efficient Inference of Partial Types	Dexter Kozen,Jens Palsberg,Michael I. Schwartzbach	1992	Partial types for the lambda -calculus were introduced by Thatte (1988) as a means of typing objects that are not typable with simple types, such as heterogeneous lists and persistent data. He showed that type inference for partial types was semidecidable. Decidability remained open until O'Keefe and Wand gave an exponential time algorithm for type inference. The authors give an O(n/sup 3/) algorithm. The algorithm constructs a certain finite automaton that represents a canonical solution to a given set of type constraints. Moreover, the construction works equally well for recursive types.	FOCS	theory
1504	FOCS	On the Fault Tolerance of Some Popular Bounded-Degree Networks	Frank Thomson Leighton,Bruce M. Maggs,Ramesh K. Sitaraman	1992	The authors analyze the fault-tolerance properties of several bounded-degree networks that are commonly used for parallel computation. Among other things, they show that an N-node butterfly containing N/sup 1- epsilon / worst-case faults (for any constant epsilon >0) can emulate a fault-free butterfly of the same size with only constant slowdown. Similar results are proved for the shuffle-exchange graph. Hence, these networks become the first connected bounded-degree networks known to be able to sustain more than a constant number of worst-case faults without suffering more than a constant-factor slowdown in performance. They also show that an N-node butterfly whose nodes fail with some constant probability p can emulate a fault-free version of itself with a slowdown of 2/sup O(log* N)/, which is a very slowly increasing function of N. The proofs of these results combine the technique of redundant computation with new algorithms for routing packets around faults in hypercubic networks. Techniques for reconfiguring hypercubic networks around faults that do not rely on redundant computation are also presented. These techniques tolerate fewer faults but are more widely applicable since they can be used with other networks such as binary trees and meshes of trees.	FOCS	theory
1505	FOCS	Enumerating the k Closest Pairs Optimally	Hans-Peter Lenhof,Michiel H. M. Smid	1992	Let S be a set of n points in D-dimensional space, where D is a constant, and let k be an integer between 1 and (/sub 2//sup n/) An algorithm is given that computes the k closest pairs in the set S in O(nlogn+k) time, using O(n+k) space. The algorithm fits in the algebraic decision tree model and is, therefore, optimal.	FOCS	theory
1506	FOCS	Undecidability of the Horn-Clause Implication Problem	Jerzy Marcinkowski,Leszek Pacholski	1992	The authors prove that the problem 'given two Horn clauses H/sub 1/=( alpha /sub 1/ V-product alpha /sub 2/ to beta ) and H/sub 2/=( gamma /sub 1/ V-product . . . V-product gamma /sub k/ to delta ), where alpha /sub i/, beta , gamma /sub i/, delta are atomic formulas, decide if H/sub 2/, is a consequence of H/sub 1/' is not recursive. This solves one of the last open decidability problems concerning formulas in pure predicate logic (i.e. without equality symbol). The proof depends on a thorough analysis of derivation trees of one rule of inference with two premisses and one conclusion, and it may have further applications.	FOCS	theory
1507	FOCS	On the Randomized Complexity of Volume and Diameter	László Lovász,Miklós Simonovits	1992	The authors give an O(n/sup 7/log/sup 2/n) randomised algorithm to approximate the volume of a convex body, and an O(n/sup 6/log n) algorithm to sample a point from the uniform distribution over a convex body. For convex polytopes the algorithm runs in O(n/sup 7/log/sup 4/n) steps. Several tools are developed that may be interesting on their own. They extend results of Sinclair-Jerrum (1988) and the authors (1990) on the mixing rate of Markov chains from finite to arbitrary Markov chains. They describe an algorithm to integrate a function with respect to the stationary distribution of a general Markov chain. They also analyze the mixing rate of various random walks on convex bodies, in particular the random walk with steps from the uniform distribution over a unit ball. In several previous positive and negative results, the problem of computing the diameter of a convex body behaved similarly as the volume problem. In contrast to this, they show that there is no polynomial randomized algorithm to compute the diameter within a factor of n/sup 1/4/.	FOCS	theory
1508	FOCS	Computing in Solvable Matrix Groups	Eugene M. Luks	1992	The author announces methods for efficient management of solvable matrix groups over finite fields. He shows that solvability and nilpotence can be tested in polynomial-time. Such efficiency seems unlikely for membership-testing, which subsumes the discrete-log problem. However, assuming that the primes in mod G mod (other than the field characteristic) are polynomially-bounded, membership-testing and many other computational problems are in polynomial time. These problems include finding stabilizers of vectors and of subspaces and finding centralizers and intersections of subgroups. An application to solvable permutation groups puts the problem of finding normalizers of subgroups into polynomial time. Some of the results carry over directly to finite matrix groups over algebraic number fields; thus, testing solvability is in polynomial time, as is testing membership and finding Sylow subgroups.	FOCS	theory
1509	FOCS	The Asymptotic Complexity of Merging Networks	Peter Bro Miltersen,Mike Paterson,Jun Tarui	1992	Let M(m,n) be the minimum number of comparators needed in a comparator network that merges m elements x/sub 1/or=m. Batcher's odd-even merge yields the following upper bound: M(m,n)or=m to infinity :M(m,n)>or=/sup 1///sub 2/(m+n)log/sub 2/(m+1)-O(m); in particular, M(n,n)>or=nlog/sub 2/n-O(n). The authors' proof technique extends to give similarly tight lower bounds for the size of monotone Boolean circuits for merging, and for the size of switching networks capable of realizing the set of permutations that arise from merging.	FOCS	theory
1510	FOCS	Computing a Shortest k-Link Path in a Polygon	Joseph S. B. Mitchell,Christine D. Piatko,Esther M. Arkin	1992	The authors consider the problem of finding a shortest polygonal path from s to t within a simple polygon P, subject to the restriction that the path have at most k links (edges). They give an algorithm to compute a k-link path with length at most (1 + epsilon ) times the length of a shortest k-link path, for any error tolerance epsilon >0. The algorithm runs in time O(n/sup 3/k/sup 3/ log (Hk/ epsilon /sup 1/k/)), where N is the largest integer coordinate among the n vertices of P. They also study the more general problem of approximating shortest k-link paths in polygons with holes. In this case, they give an algorithm that returns a path with at most 2k links and length at most that of a shortest k-link path; the running time is O(kE/sup 2/), where E is the number of edges in the visibility graph. Finally, they study the bicriteria path problem in which the two criteria are link length and 'total turn' (the integral of mod Delta theta mod along a path). They obtain in an exact polynomial-time algorithm for polygons with holes.	FOCS	theory
1511	FOCS	Undirected Connectivity in O(log ^1.5 n) Space	Noam Nisan,Endre Szemerédi,Avi Wigderson	1992	Undirected Connectivity in O(log ^1.5 n) Space	FOCS	theory
1512	FOCS	Randomized Geometric Algorithms and Pseudo-Random Generators (Extended Abstract)	Ketan Mulmuley	1992	Randomized Geometric Algorithms and Pseudo-Random Generators (Extended Abstract)	FOCS	theory
1513	FOCS	The Power of Combining the Techiques of Algebraic and Numerical Computing: Improved Approximate Multipoint Polynomial Evaluation and Improved Multipole Algorithms	Victor Y. Pan,John H. Reif,Stephen R. Tate	1992	The authors demonstrate the power of combining the techniques of algebraic computation with ones of numerical computation. They do this by improving the known methods for polynomial evaluation on a set of real points and for simulation of n charged particles on the plane. In both cases they approximate (rather than exactly compute) the solutions and do this by exploiting algebraic techniques of the algorithm design.	FOCS	theory
1514	FOCS	The Complexity of the Hajós Calculus	Toniann Pitassi,Alasdair Urquhart	1992	The Hajos construction is a simple, nondeterministic procedure for generating the class of graphs that are not 3-colorable. A.J. Mansfield and D.J.A. Welsh have posed the problem of proving whether or not there exists a polynomial-size Hajos construction for every non-3-colorable graph. The main result of this paper is a proof that the Hajos calculus is polynomially-bounded if and only if extended Frege proof systems are polynomially bounded. This result links an open problem in graph theory to an important open problem in the complexity of propositional proof systems. In addition, the authors establish an exponential lower bound for a strong subsystem of the Hajos calculus. Lastly, they discuss an interesting graph-theoretical consequence of this result.	FOCS	theory
1515	FOCS	Improved Lower Bounds for Shellsort	C. Greg Plaxton,Bjorn Poonen,Torsten Suel	1992	The authors give improved lower bounds for Shellsort based on a new and relatively simple proof idea. The lower bounds obtained are both stronger and more general than the previously known bounds. In particular, they hold for nonmonotone increment sequences and adaptive Shellsort algorithms, as well as for some recently proposed variations of Shellsort.	FOCS	theory
1516	FOCS	Quadratic Dynamical Systems (Preliminary Version)	Yuri Rabinovich,Alistair Sinclair,Avi Wigderson	1992	Quadratic Dynamical Systems (Preliminary Version)	FOCS	theory
1517	FOCS	Newton's Method for Fractional Combinatorial Optimization	Tomasz Radzik	1992	The authors considers Newton's method for the linear fractional combinatorial optimization. He proves a strongly polynomial bound on the number of iterations for the general case. He considers the maximum mean-weight cut problem, which is a special case of the linear fractional combinatorial optimization. This problem is closely related to the parametric flow problem and the flow problem when the maximum arc cost is being minimised. He proves that Newton's method runs in O(m) iterations for the maximum mean-weight cut problem. One iteration is dominated by the maximum flow computation. This gives the best known strongly polynomial bound of O(m/sup 2/n) for all three problems mentioned.	FOCS	theory
1518	FOCS	Fully Dynamic Biconnectivity in Graphs	Monika Rauch	1992	The author presents an algorithm for maintaining the bi-connected components of a graph during a sequence of edge insertions and deletions. It requires linear storage and preprocessing time. The amortized running time for insertions and for deletions is O(m/sup 2/3/), where m is the number of edges in the graph. Each query of the form 'Are the vertices u and v biconnected?' can be answered in time O(1). This is the first sublinear algorithm for this problem. If the input is a planar embedded graph, the amortized running time for insertions and deletions drops to O( square root nlogn) and the worst case query time is O((logn)/sup 2/), where n is the number of vertices in the graph. The best previously known solution takes time O(n/sup 2/3/) per update or query.	FOCS	theory
1519	FOCS	Zero-Knowledge Proofs of Knowledge Without Interaction (Extended Abstract)	Alfredo De Santis,Giuseppe Persiano	1992	Zero-Knowledge Proofs of Knowledge Without Interaction (Extended Abstract)	FOCS	theory
1520	FOCS	Communication on Noisy Channels: A Coding Theorem for Computation	Leonard J. Schulman	1992	Communication is critical to distributed computing, parallel computing, or any situation in which automata interact-hence its significance as a resource in computation. In view of the likelihood of errors occurring in a lengthy interaction, it is desirable to incorporate this possibility in the model of communication. The author relates the noisy channel and the standard (noise less channel) complexities of a communication problem by establishing a 'two-way' or interactive analogue of Shanon's coding theorem: every noiseless channel protocol can be simulated by a private-coin noisy channel protocol whose time bound is proportional to the original (noiseless) time bound and inversely proportional to the capacity of the channel, while the protocol errs with vanishing probability. The method involves simulating the original protocol while implementing a hierarchical system of progress checks which ensure that errors of any magnitude in the simulation are, with high probability, rapidly eliminated.	FOCS	theory
1521	FOCS	Efficient Self-Embedding of Butterfly Networks with Random Faults	Hisao Tamaki	1992	The author studies the embedding of the butterfly network in a faulty version of itself where each node is independently faulty with some constant probability. He shows that such a self-embedding of the N-node butterfly with O(1) load, O((log logN)/sup 2.6/) dilation, and 0((log log N)/sup 8.2/) congestion is possible with high probability, assuming sufficiently small node-failure probability. This embedding is level-preserving in the sense that each node is mapped to a node in the same level of the butterfly. He also derives a lower bound of log log log N-c on the dilation of a level-preserving embedding with O(log/sup alpha / N) load, for any alpha , 00, and some constant c depending on alpha and p.	FOCS	theory
1522	FOCS	Maximizing Non-Linear Concave Functions in Fixed Dimension	Sivan Toledo	1992	Consider a convex set P in R/sup d/ and a piece wise polynomial concave function F: P to R. Let A be an algorithm that given a point x in IR/sup d/ computes F(x) if x in P, or returns a concave polynomial p such that p(x) or= 0. The author assumes that d is fixed and that all comparisons in A depend on the sign of polynomial functions of the input point. He shows that under these conditions, one can find max/sub P/ F in time which is polynomial in the number of arithmetic operations of A. Using this method he gives the first strongly polynomial algorithms for many nonlinear parametric problems in fixed dimension, such as the parametric max flow problem, the parametric minimum s-t distance, the parametric spanning tree problem and other problems. In addition he shows that in one dimension, the same result holds even if one only knows how to approximate the value of F. Specifically, if one can obtain an alpha -approximation for F(x) then one can alpha -approximate the value of maxF. He thus obtains the first polynomial approximation algorithms for many NP-hard problems such as the parametric Euclidean traveling salesman problem.	FOCS	theory
1523	FOCS	Optimal Parallel Hull Construction for Simple Polygons in \calO(log log n) Time	Hubert Wagener	1992	Optimal Parallel Hull Construction for Simple Polygons in \calO(log log n) Time	FOCS	theory
1524	FOCS	Algebraic Decision Trees and Euler Characteristics	Andrew Chi-Chih Yao	1992	For any set S contained in R/sup n/, let chi (S) denote its Euler characteristic. The author shows that any algebraic computation tree or fixed-degree algebraic decision tree must have height Omega (log mod chi (S) mod )for deciding the membership question of a compact semi-algebraic set S. This extends a result by A. Bjorner, L. Lovasz and A. Yao where it was shown that any linear decision tree for deciding the membership question of a closed polyhedron S must have height greater than or equal to log/sub 3/ mod chi (S) mod .	FOCS	theory
1525	FOCS	Fast Unimodular Reduction: Planar Integer Lattices (Extended Abstract)	Chee-Keng Yap	1992	Fast Unimodular Reduction: Planar Integer Lattices (Extended Abstract)	FOCS	theory
1526	FOCS	33rd Annual Symposium on Foundations of Computer Science, 24-27 October 1992, Pittsburgh, Pennsylvania, USA		1992	33rd Annual Symposium on Foundations of Computer Science, 24-27 October 1992, Pittsburgh, Pennsylvania, USA	FOCS	theory
1527	SODA	Comparison-Sorting and Selecting in Totally Monotone Matrices.	Noga Alon,Yossi Azar	1992	An m x n matrix A is called totally monotone if for all i1 < i2 and j1 < j2, A[i1, j1] > A[i1, j2 implies A[i2, j1] > A[i2, j2]. We consider the complexity of comparison-based selection and sorting algorithms in such matrices. Although our selection algorithm counts only comparisons its advantage on all previous work is that it can also handle selection of elements of different (and arbitrary) ranks in different rows (or even selection of elements of several ranks in each row), in time which is slightly better than that of the best known algorithm for selecting elements of the same rank in each row. We also determine the decision tree complexity of sorting each row of a totally monotone matrix up to a factor of at most log n by proving a quadratic lower bound and by slightly improving the upper bound. No nontrivial lower bound was previously known for this problem. In particular for the case m = n we prove a tight &OHgr;(n2) lower bound. This bound holds for any decision-tree algorithm, and not only for a comparison-based algorithm. The lower bound is proved by an exact characterization of the bitonic totally monotone matrices, whereas our new algorithms depend on techniques from parallel comparison algorithms.	SODA	theory
1528	SODA	Relative Neighborhood Graphs in Three Dimensions.	Pankaj K. Agarwal,Jirí Matousek	1992	The relative neighborhood graph (RNG) of a set S of n points in R is a graph (S, E), where (p, q) &egr; E if and only if there is no point z &egr; S such that max {d(p, z), d(q,z)} < d(p,q). We show that in R , RNG(S) has O(n4/3) edges. We present a randomized algorithm that constructs RNG(S) in expected time O(n3/2+&egr;) assuming that the points of S are in general position. If the points of S are arbitrary, the expected running time is O(n7/4+&egr;). These algorithms can be made deterministic without affecting their asymptotic running time.	SODA	theory
1529	SODA	Finding a Line Transversal of Axial Objects in Three Dimensions.	Nina Amenta	1992	An axial object in E3 is a box or rectangle, all of whose edges are parallel to the coordinate axes. A line transveral of a set of axial objects is a line that intersects every object. We present an algorithm which finds a line transversal, if one exists, in expected linear time. In the process, we generalize a randomized linear programming algorithm, and prove that the set of line transversals of axial objects has a constant number of connected components.	SODA	theory
1530	SODA	Two-Dimensional Periodicity and Its Applications.	Amihood Amir,Gary Benson	1992	String matching is rich with a variety of algorithmic tools. In contrast, multidimensional matching has a rather sparse set of techniques. This paper presents a new algorithmic technique for two-dimensional matching, that of periodicity analysis. Periodicity in strings has been used to solve string matching problems. The success of these algorithms suggests that periodicity can be as important a tool in multidimensional matching. However, multidimensional periodicity is not as simple as it is in strings and was not formally studied or used in pattern matching. This paper's main contribution is defining and analysing two-dimensional periodicity in rectangular arrays. In addition, we introduce a new pattern matching paradigm - Compressed Matching. A text array T and a pattern array P are given in compressed forms c(T) and c(P). We seek all appearances of P in T, without decompressing T. By using periodicity analysis, we show that for the two-dimensional run-length compression there is a O(|c(T)|log|P|+|P|), or almost optimal algorithm that can achieve a search time that is sublinear in the size of the text |T|.	SODA	theory
1531	SODA	Applications of Parametric Searching in Geometric Optimization.	Pankaj K. Agarwal,Micha Sharir,Sivan Toledo	1992	We present several applications in computational geometry of Megiddo's parametric searching technique. These applications include; (1) Finding the minimum Hausdorff distance in the Euclidean metric between two polygonal regions under translation; (2) Computing the biggest line segment that can be placed inside a simple polygon; (3) Computing the smallest width annulus that can contain a given set of points in the plane; (4) Solving the 1-segment center problem&mdash;given a set of points in the plane, find a placement for a given line segment (under translation and rotation) which minimizes the largest distance from the segment to the given points; (5) Given a set of n points in 3-space, finding the largest radius r such that if we place a ball of radius r around each point, no segment connecting a pair of points is intersected by a third ball. Besides obtaining efficient solutions to all these problems (which, in every case, either improve considerably previous solutions or are the first non-trivial solutions to these problems), our goal is to demonstrate the versatility of the parametric searching technique.	SODA	theory
1532	SODA	Counting Networks with Arbitrary Fan-Out.	Eran Aharonson,Hagit Attiya	1992	It is shown that an acyclic smoothing network (and hence counting network) with fan-out n cannot be constructed from balancers of fan-out b1,..., bk, if there exists a prime factor p of n, such that p does not divide bi, for all i, 1 ≤ i ≤ k. This holds regardless of the depth, fan-in or size of the network, as long as they are finite. On the positive side, a simple construction of cyclic counting networks with fan-out n, for arbitrary n, is presented. An acyclic counting network with fan-in and fan-out p2k, for any integer k ≥ 0, is constructed out of 2-balancers and p-balancers.	SODA	theory
1533	SODA	Improved Parallel Integer Sorting Without Concurrent Writing.	Susanne Albers,Torben Hagerup	1992	We show that n integers in the range 1..n can be stably sorted on an EREW PRAM using O((log n)1/2) time, O(n(log n)1/2(log log n)1/2) operations and O(n) space. In addition, we are able to stably sort n integers in the range 1..n on a deterministic CREW PRAM in O((log n)3/2) time with O(n(log n)1/2) operations and O(n) space and to stably sort n arbitrary integers on a randomized CREW PRAM within the same complexity bounds with high probability. In each case our algorithm is closer to optimality than all previous algorithms for the stated problem in the stated model, and our third result matches the operation count of the best known sequential algorithm. We also show that m integers in the range 1..m can be sorted in O((log n)2) time with O(n) operations on an EREW PRAM using a nonstandard word length of O(log n log log n log m) bits, thereby greatly improving the upper bound on the word length necessary to sort integers with a linear time-processor product, even sequentially. Our algorithms were inspired by, and in one case directly use, the fusion trees recently introduced by Fredman and Willard.	SODA	theory
1534	SODA	Optimal Link Path Queries in a Simple Polygon.	Esther M. Arkin,Joseph S. B. Mitchell,Subhash Suri	1992	We develop a data structure for answering link distance queries between two arbitrary points in a simple polygon. The data structure requires O(n3) time and space for its construction and answers link distance queries in O(log n) time. Our result extends to link distance queries between pairs of segments or polygons. We also propose a simpler data structure for computing a link distance approximately, where the error is bounded by a small additive constant. Finally, we also present a scheme for approximating the link and the shortest path distance simultaneously.	SODA	theory
1535	SODA	The Competitiveness of On-Line Assignments.	Yossi Azar,Joseph Naor,Raphael Rom	1992	Consider the on-line problem where a number of servers are ready to provide service to a set of customers. Each customer's job can be handled by any of a subset of the servers. Customers arrive one-by-one and the problem is to assign each customer to an appropriate server in a manner that will balance the load on the servers. This problem can be modeled in a natural way by a bipartite graph where the vertices of one side (customers) appear one at a time and the vertices of the other side (servers) are known in advance. We derive tight bounds on the competitive ratio in both deterministic and randomized cases. Let n denote the number of servers. In the deterministic case we provide an on-line algorithm that achieves a competitive ratio of k = [log2 n] (up to an additive 1) and prove that this is the best competitive ratio that can be achieved by any deterministic on-line algorithm. In a similar way we prove that the competitive ratio for the randomized case is k=ln(n) (up to an additive 1). We conclude that for this problem, randomized algorithms differ from deterministic ones by precisely a constant factor.	SODA	theory
1536	SODA	Deciding Finiteness of Matrix Groups in Las Vegas Polynomial Time.	László Babai	1992	Let G be a group of matrices with integer entries, given by a list of generators. It is known that membership in such a group is undecidable, even for 4 x 4 integral matrices [Mi]. In this paper we show that one can decide whether or not G is finite, in Las Vegas polynomial time. The key estimate derived makes the entire &ldquo;black box group&rdquo; theory ([BSz], [BCFLS], [Ba2], [BKL]) applicable to the finite groups of integral matrices. In particular it follows that in this case, structural properties such as solvability and nilpotence are decidable in Monte Carlo polynomial time; and membership, order, isomorphism, and a host of other problems are in the relatively low complexity class AM &cap; coAM [Ba1]. We give two algorithms. The simpler one (Monte Carlo but not Las Vegas) employs a refinement of the random walk technique over groups, developed in [Ba3] (applied here to infinite groups). The termination rule rests on a new estimate on the bit-size of the elements of finite groups G, obtained via polynomial time symbolic manipulation of representations over algebraic number fields using results of [BR]. This symbolic manipulation technique is the basis of the Las Vegas algorithm. (A Las Vegas algorithm is a rnadomized algorithm which never errs; but with small probability, it may r eport failure.)	SODA	theory
1537	SODA	On-Line Navigation in a Room.	Eldad Bar-Eli,Piotr Berman,Amos Fiat,Peiyuan Yan	1992	We consider the problem of navigating through an unknown environment in which the obstacles are disjoint oriented rectangles enclosed in an n x n square room. The task of navigating algorithm is to reach the center of the room starting from one of the corners. While there always exists a path of length n, the best previously known navigating algorithm finds paths of length n201nn . We give an efficient deterministic algorithm which finds a path of length O(n ln n); this algorithm uses tactile information only. Moreover, we prove that any deterministic algorithm can be forced to traverse a distance of &OHgr;(n ln n), even if it uses visual information.	SODA	theory
1538	SODA	Dynamic Point Location in General Subdivisions.	Hanna Baumgarten,Hermann Jung,Kurt Mehlhorn	1992	The dynamic planar point location problem is the task of maintaining a dynamic set S of n non-intersecting, except possibly at endpoints, line segments in the plane under the following operations: &bull;Locate(q point): Report the segment immediately above q, i.e., the first segment intersected by an upward vertical ray starting at q; &bull;Insert(s segment): Add segment s to the collection S segments; &bull;Delete(s segment): Remove segment s from the collection S of segments. We present a solution which requires space O(n), has query and insertion time O(log n loglog n) and deletion time O(log2 n). A query time below O(log2 n) was previously only known for monotone subdivisions and horizontal segments and required non-linear space.	SODA	theory
1539	SODA	Improved Approximations for the Steiner Tree Problem.	Piotr Berman,Viswanathan Ramaiyer	1992	For a set S contained in a metric space, a Steiner tree of S is a tree that connects the points in S. Finding a minimum cost Steiner tree is an NP-hard problem in euclidean and rectilinear metrics as well as in graphs. We give an approximation algorithm and show that the worst-case ratio of the cost of our solutions to the optimal cost is better than previously known ratios in graphs, and in rectilinear metric on the plane. Our method offers a trade-off between the running time and the ratio; on one hand it always allows to improve the ratio, on the other it allows to obtain previously known ratios with much greater efficiency. We use properties of optimal rectilinear Steiner trees to obtain significantly better ratio and running time in rectilinear metric.	SODA	theory
1540	SODA	The Complexity of Heaps.	Svante Carlsson,Jingsen Chen	1992	In this paper, we investigate the complexity of heaps. In particular, we study the construction problem and the search problem for heaps. We derive an adversary-based lower bound for the heap construction problem. It is shown that 1.5(n + 1)&ndash;log(n + 1)&ndash;2 comparisons are necessary to construct a heap of size n in the worst case. This is the first non-trivial adversary lower bound for this problem, which improves the previous best lower bound based on an information theoretical argument for the heap construction. Furthermore, we prove fairly trivial tight upper and lower bounds on the number of comparisons needed to search for a given element in a heap. An optimal 3/4n-time search algorithm is presented. Our lower bound for searching is also demonstrated by an adversary argument, which improves the information theory bound for the problem as well.	SODA	theory
1541	SODA	Directed Bumberings, Rubber Bands, and Testing Digraph -Vertex Connectivity.	Joseph Cheriyan,John H. Reif	1992	Directed Bumberings, Rubber Bands, and Testing Digraph -Vertex Connectivity.	SODA	theory
1542	SODA	Generosity Helps, or an 11-Competitive Algorithm for Three Servers.	Marek Chrobak,Lawrence L. Larmore	1992	Generosity Helps, or an 11-Competitive Algorithm for Three Servers.	SODA	theory
1543	SODA	On Playing Twenty Questions with a Liar.	Aditi Dhagat,Péter Gács,Peter Winkler	1992	On Playing Twenty Questions with a Liar.	SODA	theory
1544	SODA	Approximating the Minimum Weight Triangulation.	David Eppstein	1992	In O(n log n) time we compute a triangulation with O(n) new points, and no obtuse triangles, that has length within a constant factor of the minimum possible. We also approximate the minimum weight Steiner triangulation using triangulations with no sharp angles. No previous polyonomial time triangulation achieved an approximation factor better than O(log n).	SODA	theory
1545	SODA	New Algorithms for Minimum Area -gons.	David Eppstein	1992	Given a set P of n points in the plane, we wish to find a set Q &sub; P of k points for which the convex hull conv(Q> has the minimum area. We solve this, and the related problem of finding a minimum area convex k-gon, in time O(n2 log n) for fixed k, almost matching known bounds for the minimum area triangle problem. Our algorithm is based on finding a certain number of nearest vertical neighbors to each line segment determined by two input points. We use a classical result of Ramsey theory to prove that these nearest neighbors suffice to determine the minimum convex k-gon.	SODA	theory
1546	SODA	Approximating the Minimum Degree Spanning Tree to Within One from the Optimal Degree.	Martin Fürer,Balaji Raghavachari	1992	We consider the problem of constructing a spanning tree for a graph G = (V,E) with n vertices whose maximal degree is the smallest among all spanning trees of G. This problem is easily shown to be NP-hard. We describe an iterative polynomial time approximation algorithm for this problem. This algorithm computes a spanning tree whose maximal degree is at most O(&Dgr; + log n), where &Dgr; is the degree of some optimal tree. The result is generalized to the case where only some vertices need to be connected (Steiner case) and to the case of directed graphs. It is then shown that our algorithm can be refined to produce a spanning tree of degree at most &Dgr; + 1. Unless P = NP, this is the best bound achievable in polynomial time.	SODA	theory
1547	SODA	A General Approximation Technique for Constrained Forest Problems.	Michel X. Goemans,David P. Williamson	1992	We present a general approximation technique for a large class of graph problems. Our technique mostly applies to problems of covering, at minimum cost, the vertices of a graph with trees, cycles or paths satisfying certain requirements. In particular, many basic combinatorial optimization problems fit in this framework, including the shortest path, minimum spanning tree, minimum-weight perfect matching, traveling salesman and Steiner tree problems. Our technique produces approximation algorithms that run in O(n2 log n) time and come within a factor of 2 of optimal for most of these problems. For instance, we obtain a 2-approximation algorithm for the minimum-weight perfect matching problem under the triangle inequality. Our running time of O(n2 log n) time compares favorably with the best strongly polynomial exact algorithms running in O(n3) time for dense graphs. A similar result is obtained for the 2-matching problem and its variants.We also derive the first approximation algorithms for many NP-complete problems, including the non-fixed point-to-point connection problem, the exact path partitioning problem and complex location-design problems. Moreover, for the prize-collecting traveling salesman or Steiner tree problems, we obtain 2-approximation algorithms, therefore improving the previously best-known performance guarantees of 2.5 and 3, respectively [4].	SODA	theory
1548	SODA	The On-Line -Dimensional Dictionary Problem.	Teofilo F. Gonzalez	1992	We present a new algorithm for the on-line d-dimensional dictionary problem which has many applications including the management of geometrical objects and geometrical searching. The dictionary problem consists of executing on-line any sequence of the following operations: INSERT(p), DELETE(p) and MEMBERSHIP(p), where p is any point in d-space. We introduce a clean structure based on balanced binary search trees, which we call d-dimensional balanced binary search trees, to represent the set of points. We present algorithms for each of the above operations that take O(d + log n) time, where n is the current number of points in the set, and each INSERT and DELETE operation requires no more than a constant number of rotations. Our procedures are almost identical to the ones for balanced binary search trees. The main difference is in the way we search for an element. Our search strategy is based on the principle &ldquo;assume, verify and conquer&rdquo; (AVC). We apply this principle as follows. To avoid multiple verifications we shall assume that some prefixes of strings match. At the end of our search we must determine whether or not these assumptions were valid. This can be done by performing one simple verification step that takes O(d) time. The elimination of multiple verifications is important because in the worst case there are &OHgr;(log n) verifications, and each could take &OHgr;(d) time.	SODA	theory
1549	SODA	Theoretical and Practical Aspects of Combinatorial Problem Solving.	Martin Grötschel	1992	Theoretical and Practical Aspects of Combinatorial Problem Solving.	SODA	theory
1550	SODA	The Robot Localization Problem in Two Dimensions.	Leonidas J. Guibas,Rajeev Motwani,Prabhakar Raghavan	1992	We consider the following problem: given a simple polygon P and a star-shaped polygon V, find a point (or the set of points) in P from which the portion of P that is visible is congruent to V. The problem arises in the localization of robots using a range-finder&mdash;P is a map of a known environment, V is the portion visible from the robot's position, and the robot must use this information to determine its position in the map. We give a scheme that preprocesses P so that any subsequent query V is answered in optimal time O(m + log n + A), where m and n are the number of vertices in V and P, and A is the number of points in P that are valid answers (the output size). Our technique allows us to trade off smoothly between the query time and the preprocessing time or space. We also devise a data structure for output-sensitive determination of the visibility polygon of a query point inside a polygon P. We then consider a variant of the localization problem in which there is a maximum distance to which the robot can &ldquo;see&rdquo;&mdash;this is motivated by practical considerations, and we outline a similar solution for this case. We also show that a single localization query V can be answered in time O(mn) with no preprocessing.	SODA	theory
1551	SODA	Parametric Optimization of Sequence Alignment.	Dan Gusfield,K. Balasubramanian,Dalit Naor	1992	The optimal alignment or the weighted minimum edit distance between two DNA or amino acid sequences for a given set of weights is computed by classical dynamic programming techniques, and is widely used in Molecular Biology. However, in DNA and amino acid sequences there is considerable disagreement about how to weight matches, mismatches, insertions/deletions (indels) and gaps. Parametric Sequence alignment is the problem of computing the optimal valued alignment between two sequences as a function of variable weights for matches, mismatches, spaces and gaps. The goal is to partition the parameter space into regions (which are necessarily convex) such that in each region one alignment is optimal throughout and such that the regions are maximal for this property. In this paper we are primarily concerned with the structure of this convex decomposition, and secondarily with the complexity of computing the decomposition. The most striking results are the following: For the special case where only matches, mismatches and spaces are counted, and where spaces are counted throughout the alignment, we show that the decomposition is surprisingly simple: all regions are infinite; there are at most n2/3 regions; the lines that bound the regions are all of the form &bgr; = c+(c + 0.5)&agr;; and the entire decomposition can be found in O(knm) time, where k is the actual number of regions and n < m are the lengths of the two strings. These results were found while implementing a large software package to do parametric sequence analysis, and in turn have led to faster algorithms for those tasks.	SODA	theory
1552	SODA	Lower Bounds for On-Line Graph Coloring.	Magnús M. Halldórsson,Mario Szegedy	1992	An algorithm for vertex-coloring graphs is said to be online if each vertex is irrevocably assigned a color before any later vertices are considered. We show that such algorithms are inherently ineffective. The performance ratio of any such algorithm can be no better than &OHgr;(n/log2 n), even for randomized algorithms against oblivious adversary. We also show that various means of relaxing the constraints of the on-line model do not reduce these lower bounds. The features include presenting the input in blocks of log2 n vertices, recoloring any fraction of the vertices, presorting vertices according to degree, and disclosing the adversary's previous coloring.	SODA	theory
1553	SODA	Computing Minimal Spanning Subgraphs in Linear Time.	Xiaofeng Han,Pierre Kelsen,Vijaya Ramachandran,Robert Endre Tarjan	1992	Let P be a property of undirected graphs. We consider the following problem: given a graph G that has property P, find a minimal spanning subgraph of G with property P. We describe two related algorithms for this problem and prove their correctness under some rather weak assumptions about P. We devise a general technique for analyzing the worst-case behavior of these algorithms. By applying the technique to 2-edge-connectivity and biconnectivity, we obtain an &OHgr;(m + n log n) lower bound on the worst-case running time of the algorithms for these two properties, thus settling open questions posed earlier with regard to these properties. We then describe refinements of the basic algorithms that yield the first linear-time algorithms for finding a minimal 2-edge-connected spanning subgraph and a minimal biconnected spanning subgraph of a graph.	SODA	theory
1554	SODA	A Faster Algorithm for Finding the Minimum Cut in a Graph.	Jianxiu Hao,James B. Orlin	1992	We consider the problem of finding the minimum capacity cut in a network G with n nodes. This problem has applications to network reliability and survivability and is useful in subroutines for other network optimization problems. One can use a maximum flow problem to find a minimum cut separating a designated source node s from a designated sink node t, and by varying the sink node one can find a minimum cut in G as a sequence of at most 2n - 2 maximum flow problems. We then show how to reduce the running time of these 2n - 2 maximum flow algorithms to the running time for solving a single maximum flow problem. The resulting running time is O(nm log n2/m) for finding the minimum cut in either a directed or undirected network. The algorithm also determines the arc connectivity of either a directed or undirected network in O(nm) steps.	SODA	theory
1555	SODA	On Efficient Unsuccessful Search.	Lucas Chi Kwong Hui,Charles U. Martel	1992	This paper introduces a general technique for speeding up unsuccessful search using very little extra space (2 bits per key). This technique is applicable to many data structures including linear lists, and search trees. For linear lists we get on-line algorithms for processing a sequence of successful and unsuccessful searches which are competitive with strong off-line algorithms. In a virtual memory environment our self-adjusting algorithm for multi-way search trees is competitive with an optimal static multi-way tree and will often outperform the static tree.	SODA	theory
1556	SODA	Strongly Competitive Algorithms for Paging with Locality of Reference.	Sandy Irani,Anna R. Karlin,Steven Phillips	1992	What is the best paging algorithm if one has partial information about the possible sequences of page requests? We give a partial answer to this question, by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference, given by an arbitrary access graph. We first consider optimal algorithms for undirected access graphs. Borodin et al. [2] define an algorithm, called FAR, and proved that it is within a logarithmic factor of the optimal. We prove that FAR is in fact strongly competitive, i.e. within a constant factor of the optimum. For directed access graphs, we present an algorithm that is strongly competitive on all structured program graphs&mdash;graphs modeling the request sequences of structured programs.	SODA	theory
1557	SODA	Sequential and Parallel Algorithms to Find a K Minor.	André E. Kézdy,Patrick McGuinness	1992	Sequential and Parallel Algorithms to Find a K Minor.	SODA	theory
1558	SODA	A Faster Deterministic Maximum Flow Algorithm.	V. King,S. Rao,Robert Endre Tarjan	1992	We describe a deterministic version of a 1990 Cheriyan, Hagerup, and Mehlhorn randomized algorithm for computing the maximum flow on a directed graph with n nodes and m edges which runs in time O(mn + n2+&egr;, for any constant &egr;. This improves upon Alon's 1989 bound of O(mn + n8/3log n) [A] and gives an O(mn) deterministic algorithm for all m > n1+&egr;. Thus it extends the range of m/n for which an O(mn) algorithm is known, and matches the 1988 algorithm of Goldberg and Tarjan [GT] for smaller values of m/n.	SODA	theory
1559	SODA	Pattern Matching in a Digitized Image.	Gad M. Landau,Uzi Vishkin	1992	The continuous pattern matching problem is defined. Given are two pictures, each consisting of unicolor regions; one picture is called the scene and the other the pattern. The problem is to find all occurrences of the pattern in the scene. As a step towards efficient algorithmic handling of the continuous pattern matching problem by computers, where discretized representations are involved, we give several algorithms. Our strongest algorithmic result is for a one-dimensional version of the problem, where running time which is linear in the length of a digitized representation is achieved. The definitions of our problems are derived from a &ldquo;digitized-based&rdquo; approach to object recognition problems in computer vision, which is different from a common computer vision approach. The digitized based approach may lead towards further research within the discrete algorithms community on computer vision problems.	SODA	theory
1560	SODA	On the Number of Eularian Orientations of a Graph.	Milena Mihail,Peter Winkler	1992	We give efficient randomized schemes to sample and approximately count Eulerian orientations of any Eulerian graph. Eulerian orientations are natural flow-like structures, and Welsh has pointed out that computing their number (i)corresponds to evaluating the Tutte polynomial at the point (0, &ndash;2) [8,19] and (ii) is equivalent to evaluating &ldquo;ice-type partition functions&rdquo; in statistical physics [20]. Our algorithms are based on a reduction to sampling and approximately counting perfect matchings for a class of graphs for which the methods of Broder [3, 10] and others [4, 6] apply. A crucial step of the reduction is the &ldquo;Monotonicity Lemma&rdquo; (Lemma 3.3) which is of independent combinatorial interest. Roughly speaking, the Monotonicity Lemma establishes the intuitive fact that &ldquo;increasing the number of constraints applied on a flow problem can only decrease the number of solutions&rdquo;. In turn, the proof of the lemma involves a new decomposition technique which decouples problematically overlapping structures (a recurrent obstacle in handling large combinatorial populations) and allows detailed enumeration arguments. As a byproduct, (i) we exhibit a class of graphs for which perfect and near-perfect matchings are polynomially related, and hence the permanent can be approximated, for reasons other than &ldquo;short augmenting paths&rdquo; (previously the only known approach); and (ii) we obtain a further direct sampling scheme for Eulerian orientations which is faster than the one suggested by the reduction to perfect matchings. Finally, with respect to our approximate counting algorithm, we give the complementary hardness result, namely, that counting exactly Eulerian orientations is #P-complete, and provide some connections with Eulerian tours.	SODA	theory
1561	SODA	On Parallel Complexity of Integer Linear Programming, GCD and the Iterated mod Function.	Yu Lin-Kriz,Victor Y. Pan	1992	We study parallel computational methods for integer linear programming problem with two variables. Applying several novel techniques, we prove that this problem is NC-equivalent to computing the continued fraction expansion of a rational number, that is, to computing all the intermediate remainders in the Euclidean algorithm applied to two integers, plus to computing the output of an iterated modulo function, with the remainder sequence from the Euclidean algorithm (that is, with the continued fraction expansion of a rational number) as its input arguments. The best previously known results are special cases of our theorem.	SODA	theory
1562	SODA	Separation and Approximation of Polyhedral Objects.	Joseph S. B. Mitchell,Subhash Suri	1992	Given a family of disjoint polygons P1, P2,&hellip;, Pk in the plane, and an integer parameter m, it is NP-complete to decide if the Pi's can be separated by a polygonal family consisting of m edges, that is, if there exist polygons R1, R2,&hellip;, Rk with pairwise-disjoint boundaries such that Pi *** Ri and &Sgr;|Ri| &le; m. In three dimensions, the problem of separating even two nested convex polyhedra by a k-facet polyhedron is NP-complete. Many other extensions and generalizations of the polyhedral separation problem, either to families of polyhedra or to higher dimensions, are also intractable. In this paper, we present efficient approximation algorithms for constructing separating families of near-optimal size. Our main results are as follows. In two dimensions, we give an O(n log n) time algorithm for constructing a separating family whose size is within a constant factor of an optimal separating family; n is the number of edges in the input family of polygons. In three dimensions, we can separate a convex polyhedron from a nonconvex polyhedron with a convex polyhedral surface whose facet-complexity is O(log n, times the optimal, where n = |P|+|Q| is the complexity of the input polyhedra. Our algorithm runs in O(n4) time, but improves to O (n3) time if the two polyhedra are nested and convex. Our algorithm for separating a convex polyhedron from a nonconvex polyhedron extends to higher dimensions. In d dimensions, for d &ge; 4, the facet-complexity of the approximation polyhedron is O(d log n) times the optimal, and the algorithm runs in O(nd+1)time. Finally, we also obtain results on separating sets of points, a family of convex polyhedra, and separation by non-polyhedral surfaces, such as spherical patches.	SODA	theory
1563	SODA	Load Balancing Requires Omega(log) Expected Time.	Philip D. MacKenzie	1992	In order to obtain very fast parallel algorithms, it is almost always necessary to have some sort of load balancing procedure, so that processors which have finished their required tasks can help processors which have not. If the overloaded processors are not helped, then the expected time of the entire algorithm suffers. In general, we would like to distribute the remaining work as evenly as possible among the processors, or more formally, given at most n independent tasks distributed in an arbitrary way among n processors, we would like to redistribute the tasks so that each processor contains O(1) tasks. We show here that even on the strongest randomized CRCW PRAM model, for a simple random distribution tasks load balancing requires &OHgr;(log* n) expected time. Gil, Matias, and Vishkin [9] give an O(log* n) expected time randomized algorithm which solves the load balancing problem in the worst case, so the lower bound is tight. By reduction we show that both Padded Sort [12], and Linear Approximate Compaction [13] require &OHgr;(log* n) expected time. We note that our basic technique is one of the few parallel lower bound techniques known which only require 0/1 inputs. We also note that the bounds given in this paper do not place any restriction on the instruction set of the machine, the amount of information which can be stored in a memory cell, or on the number of memory cells.	SODA	theory
1564	SODA	Deterministic Skip Lists.	J. Ian Munro,Thomas Papadakis,Robert Sedgewick	1992	We explore techniques based on the notion of a skip list to guarantee logarithmic search, insert and delete costs. The basic idea is to insist that between any pair of elements above a given height are a small number of elements of precisely that height. The desired behaviour can be achieved by either using some extra space for pointers, or by adding the constraint that the physical sizes of the nodes be exponentially increasing. The first approach leads to simpler code, whereas the second is ideally suited to a buddy system of memory allocation. Our techniques are competitive in terms of time and space with balanced tree schemes, and, we feel, inherently simpler when taken from first principles.	SODA	theory
1565	SODA	Percolation Theory and Computing with Faulty Arrays of Processors.	Thomas R. Mathies	1992	Let H be an n x n mesh-connected array of processors. Each processor is assumed to fail (independently) with probability p. Raghavan [5] gave an algorithm that with high probability routes packets in this mesh with O(log n) dilation and O(log2n) load so long as p &le; 0.29. KKLMRRTT [3] improve the load to O(1) for &ldquo;small&rdquo; p while keeping the O(log n) bound for dilation and showing an o(1) bound for congestion. In this paper we show these bounds hold for p as high as *** 0.4. We also consider the problem where links rather than processors fail and shows these same bounds hold for q < 1/2. In both cases these bounds are tight: for greater probabilities of failure the above embedding bounds cannot be achieved. This short cutoff follows from a zero-one result of percolation theory.	SODA	theory
1566	SODA	Randomized Parallel Algorithms for Matroid Union and Intersection, with Applications to Arboresences and Edge-Disjoint Spanning Trees.	H. Narayanan,Huzur Saran,Vijay V. Vazirani	1992	The strong link between matroids and matching is used to extend the ideas that resulted in the design of Random NC algorithms for matching to obtain RNC algorithms for the well-known problems of finding an arboresence and a maximum cardinality set of edge-disjoint spanning trees in a graph. The key tools used are linear algebra and randomization.	SODA	theory
1567	SODA	Strong Concentration for Quicksort.	Colin McDiarmid,Ryan Hayward	1992	Let Qn be the random number of comparisons made by quicksort in sorting n distinct keys, when we assume that all n! possible orderings are equally likely. Known results concerning moments for Qn do not show how rare it is for Qn to make large deviations from its mean. Here we give a good approximation to the probability of such a large deviation, and find that this probability is quite small. As well as the basic quicksort we consider the variant in which the partitioning key is chosen as the median of (2t+1) keys.	SODA	theory
1568	SODA	Tail Estimates for the Space Complexity of Randomized Incremental Algorithms.	Kurt Mehlhorn,Micha Sharir,Emo Welzl	1992	We give tail estimates for the space complexity of randomized incremental algorithms for line segment intersection in the plane. For n the number of segments, m is the number of intersections, and m &ge; n ln n ln(3) n, there is a constant c such that the probability that the total space cost exceeds c times the expected space cost is e-&OHgr;(m/(n ln n)).	SODA	theory
1569	SODA	Self-Testing Polynomial Functions Efficiently and Over Rational Domains.	Ronitt Rubinfeld,Madhu Sudan	1992	In this paper we give the first self-testers and checkers for polynomials over rational and integer domains. We also show significantly stronger bounds on the efficiency of a simple modification of the algorithm for self-testing polynomials over finite fields given in [8].	SODA	theory
1570	SODA	On Likely Solutions of a Stable Matching Problem.	Boris Pittel	1992	On Likely Solutions of a Stable Matching Problem.	SODA	theory
1571	SODA	An O(n log n log log n) Algorithm for the On-Line Closest Pair Problem.	Christian Schwarz,Michiel H. M. Smid	1992	An O(n log n log log n) Algorithm for the On-Line Closest Pair Problem.	SODA	theory
1572	SODA	Minimizing Capacity Violations in a Transshipment Network.	Tomasz Radzik	1992	The problem of minimizing capacity violation is a variation of the transshipment problem. It is equivalent to the problem of computing maximum mean surplus cuts which arises in the dual approach to the minimum cost network circulation problem. McCormick and Ervolina [15] proposed an algorithm which computes a sequence of cuts with increasing mean surpluses, and stops when an optimal one is found. The mean surplus of this cut is equal to the minimum possible maximum capacity violation. McCormick and Ervolina proved that the number of iterations in this algorithm is O(m). One iteration, i.e., finding the subsequent cut, amounts to computing maximum flow in an appropriate network. We prove that the number of iterations in this algorithm is &thgr;(n). This gives the best known upper bound O(n2m) for the problem. We also show a tight analysis of this algorithm for the case with integral capacities and demands, and present some improvements.	SODA	theory
1573	SODA	The Probabilistic Method.	Joel Spencer	1992	The use of randomness is now an accepted tool in Theoretical Computer Science but not everyone is aware of the underpinnings of this methodology in Combinatorics - particularly, in what is now called the probabilistic Method as developed primarily by Paul Erdo&huml;s over the past half century. Here I will explore a particular set of problems - all dealing with &ldquo;good&rdquo; colorings of an underlying set of points relative to a given family of sets. A central point will be the evolution of these problems from the purely existential proofs of Erdo&huml;s to the algorithmic aspects of much interest to this audience.	SODA	theory
1574	SODA	Finding the Repeated Median Regression Line.	Andrew Stein,Michael Werman	1992	The repeated median regression line is a robust regression estimate, having a maximal 50% breakdown point. This paper presents an O(n(log n)2) algorithm for finding the repeated median regression line through n points in the plane.	SODA	theory
1575	SODA	(Un)expected Behavior of Typical Suffix Trees.	Wojciech Szpankowski	1992	Suffix tree is a data structure widely used in algorithms on words and data compression. Despite this, very little is known about its typical behavior. Recently, Chang and Lawler have designed a sublinear expected time algorithm for approximate string matching using simple estimates of some parameters of suffix trees. It seems that any further advances in such an endover are subject to better understanding of suffix trees behavior. In this paper, we use a novel technique called string ruler approach to provide a characterization of several basic parameters of suffix trees (dependency among symbols are allowed !). These findings are used to :(i) settle in the negative the conjecture of Wyner and Ziv regarding the typical behavior of the universal data compression scheme of Lampel and Ziv; (ii) prove an open problem regarding the length of a block in the Lampel-Ziv parsing algorithm; (iii) provide new insights and generalizations of string matching algorithms, particularly the one by Chang and Lawler.	SODA	theory
1576	SODA	Efficient Algorithms for the Hitchcock Transportation Problem.	Takeshi Tokuyama,Jun Nakano	1992	We consider the Hitchcock transportation problem on n supply points and k demand points when n is much greater than k. The problem is solved in O(n2k log n + n2 log2 n) time if n > k log k. Further, applying a geometric method named splitter finding and randomization, we improve the time complexity for a case in which the ratio c of the least supply and the maximum supply satisfies the inequality log cn < n/k4 log n. Indeed, if n < k5 log3 k and c = poly(n), the problem is solved in O(kn) time, which is optimal.	SODA	theory
1577	SODA	Searching Tree Structures on a Mesh of Processors.	Jyh-Jong Tsay	1992	Searching Tree Structures on a Mesh of Processors.	SODA	theory
1578	SODA	Applications of the Fusion Tree Method to Computational Geometry and Searching.	Dan E. Willard	1992	Applications of the Fusion Tree Method to Computational Geometry and Searching.	SODA	theory
1579	SODA	On the Approximation of Maximum Satisfiability.	Mihalis Yannakakis	1992	We present a 3/4 polynomial time approximation algorithm for the Maximum Satisfiability problem: Given a set of clauses, find a truth assignment that satisfies the maximum number of clauses. The algorithm applies to the weighted case as well, and involves nontrival application of network flow techniques.	SODA	theory
1580	SODA	Algorithms for Subset Testing and Finding Maximal Sets.	Daniel M. Yellin	1992	In this paper we consider two related problems: subset testing and finding maximal sets. First, consider a sequence of n operations, where each operation either creates a set, inserts (deletes) an element into (from) a set, queries whether a particular element is in a set, queries whether or not one set is a subset of another, or queries whether or not the intersection of two sets is empty. We show that for any integer k, one can implement subset and intersection testing in time O(n1-(1/k) log n) and all of the other operations in time O(n1/k log n)). It requires O(nk+1)/k) space. When k = 2, this yields a worst case time complexity of O(n1/2 log n) per operation, and uses O(n3/2) space. Second, consider a set of sets, where the total size of the input is O(n). We show that one can find those sets that are maximal (a set is maximal if it is not contained in any other set) in time O(mn), where m is the number of maximal sets.	SODA	theory
1581	SODA	Proceedings of the Third Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 27-29 January 1992, Orlando, Florida.	Greg N. Frederickson	1992	Proceedings of the Third Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 27-29 January 1992, Orlando, Florida.	SODA	theory
1582	STOC	Alphabet Independent Two Dimensional Matching	Amihood Amir,Gary Benson,Martin Farach	1992	Alphabet Independent Two Dimensional Matching	STOC	theory
1583	STOC	Parallel Computation Over Hyperbolic Groups	Jin-yi Cai	1992	Hyperbolic groups are a rich class of groups frequently encountered in mathematical research, particularly in topology. It has been the focus of intense study by many combinatorial group theorists and topologists recently. We present some computational results for infinite groups, especially for hyperbolic groups. It is shown that the word problem for hyperbolic groups is solvable in NC2. This is the first NC algorithm for a class of groups in combinatorial group theory. We also consider the isomorphism problem of randomly generated groups using a novel technique: the Alexander polynomial from knot theory. These randomly generated groups are almost always hyperbolic groups.	STOC	theory
1584	STOC	A Deterministic Poly(log log N)-Time N-Processor Algorithm for Linear Programming in Fixed Dimension	Miklós Ajtai,Nimrod Megiddo	1992	It is shown that for any fixed number of variables, the linear programming problems with n linear inequalities can be solved deterministically by n parallel processors in sub-logarithmic time. The parallel time bound is O((log log n)d) where d is the number of variables. In the one-dimensional case this bound is optimal.	STOC	theory
1585	STOC	Polynomial Algorithms for Linear Programming over the Algebraic Numbers	Ilan Adler,Peter A. Beling	1992	We derive an algorithm based on the ellipsoid method that solves linear programs whose coefficients are real algebraic numbers. By defining the encoding size of an algebraic number to be the bit size of the coefficients of its minimal polynomial, we prove the algorithm runs in time polynomial in the dimension of the problem, the encoding size of the input coefficients, and the degree of any algebraic extension which contains the input coefficients. This bound holds even if all input and arithmetic is performed symbolically, using rational numbers only.	STOC	theory
1586	STOC	Ray Shooting and Parametric Search	Pankaj K. Agarwal,Jirí Matousek	1992	Ray Shooting and Parametric Search	STOC	theory
1587	STOC	Computational Learning Theory: Survey and Selected Bibliography	Dana Angluin	1992	Computational Learning Theory: Survey and Selected Bibliography	STOC	theory
1588	STOC	A Correctness Condition for High-Performance Multiprocessors (Extended Abstract)	Hagit Attiya,Roy Friedman	1992	Hybrid consistency, a new consistency condition for shared memory multiprocessors, attempts to capture the guarantees provided by contemporary high-performance architectures. It combines the expressiveness of strong consistency conditions(e.g., sequential consistency, linearizability) and the efficiency of weak consistency conditions (e.g., Pipelined RAM, causal memory). Memory access operations are classified either strong or weak. A global ordering of strong operations at different processes is guaranteed, but there is very little guarantee on the ordering of weak operations at different processes, except for what is implied by their interleaving with the strong operations. A formal and precise definition of this condition is given. An efficient implementation of hybrid consistency on distributed memory machines is presented. In this implementation, weak opearations are executed instantaneously, while the response time for strong operations is linear in the network delay. (It is proven that this is within a constant factor of the optimal time bounds.) To motivate hybrid consistency it is shown that weakly consistent memories do not support non-cooperative (in particular, non-centralized) algorithms for mutual exclusion.	STOC	theory
1589	STOC	Computing with Faulty Arrays	Yonatan Aumann,Michael Ben-Or	1992	We present and O(1) slowdown emulation of a fault-free N x N two dimensional mesh with a slack of O(log N log log N) by a faulty mesh of the same size and slack. All components of the faulty mesh, including the memory modules, are assumed to be subject to failure. The faults may occur at any time during the emulation and the system readjusts dynamically.	STOC	theory
1590	STOC	Competitive Distributed Job Scheduling (Extended Abstract)	Baruch Awerbuch,Shay Kutten,David Peleg	1992	This paper examines the problem of balancing the job load in a network of processors, and introduces an online algorithm for scheduling a sequence of jobs in a competitive manner. The algorithm is shown to be polylog (n)-competitive according to a strict definition that forces the online algorithm to be competitive even when considering any bounded area of the network and bounded period of time. We also analyze the common greedy feedback-based approach, and provide matching lower and upper bounds (up to a polylogarithmic factor) for the tradeoff between the costs of searches and updates under this approach.	STOC	theory
1591	STOC	Adapting to Asynchronous Dynamic Networks (Extended Abstract)	Baruch Awerbuch,Boaz Patt-Shamir,David Peleg,Michael E. Saks	1992	The computational power of different communication models is a fundamental question in the theory of distributed computation. For example, in the synchronous model messages are assumed to be delivered within one time unit, whereas in the asynchronous model message delays may be arbitrary. Another important parameter of the model is the assumptions about the topology. In the dynamic topology model, links are assumed to crash and recover dynamically, but their status is known to the incident node processors. A meaningful computation can be carried out if the topology stabilizes for a sufficiently long period. In this paper we show that the model of asynchronous, dynamic-topology network is equivalent, up to polylogarithmic factors, to the synchronous, static protocols that can withstand arbitrary link delays and changing topology at the expense of only polylogarithmic blowup in the running time, the number of messages, and the space requirement. Previous methods entailed a linear blowup in at least one of these resources. The generality of our method is demonstrated by a series of improvements for important applications, including Breadth First Search, computing compact efficient routing tables, and packet routing on asynchronous networks.	STOC	theory
1592	STOC	Biased Random Walks	Yossi Azar,Andrei Z. Broder,Anna R. Karlin,Nathan Linial,Steven Phillips	1992	How much can an imperfect source of randomness affect an algorithm? We examine several simple questions of this type concerning the long-term behavior of a random walk on a finite graph. In our setup, each step of the random walk a &ldquo;controller&rdquo; can, with a certain small probability, fix the next step, thus introducing a bias. We analyze the extent to which the bias can affect the limit behavior of the walk. The controller is assumed to associate a real, nonnegative, &ldquo;benefit&rdquo; with each state, and to strive to maximize the long-term expected benefit. We derive tight bounds on the maximum of this objective function over all controller's strategies, and present polynomial time algorithms for computing the optimal controller strategy.	STOC	theory
1593	STOC	Symmetry and Complexity	László Babai,Robert Beals,Pál Takácsi-Nagy	1992	Symmetry and Complexity	STOC	theory
1594	STOC	Representing Boolean Functions as Polynomials Modulo Composite Numbers (Extended Abstract)	David A. Mix Barrington,Richard Beigel,Steven Rudich	1992	Representing Boolean Functions as Polynomials Modulo Composite Numbers (Extended Abstract)	STOC	theory
1595	STOC	New Algorithms for an Ancient Scheduling Problem	Yair Bartal,Amos Fiat,Howard J. Karloff,Rakesh Vohra	1992	We consider the on-line version of the original m-machine scheduling problem: given m machines and n positive real jobs, schedule the n jobs on the m machines so as to minimize the makespan, the completion time of the last job. In the on-line version, as soon as job j arrrives, it must be assigned immediately to one of the m machines. We present two main results. The first is a (2&ndash;&egr;)-competitive deterministic algorithm for all m. The competitive ratio of all previous algorithms approaches 2 as m&rarr; &infin; . Indeed, the problem of improving the competitive ratio for large m had been open since 1966, when the first algorithm for this problem appeared. The second result is an optimal randomized algorithm for the case m = 2. To the best of our knowledge, our 4/3-competitive algorithm is the first specifically randomized algorithm for the original, m-machine, on-line scheduling problem.	STOC	theory
1596	STOC	Competitive Algorithms for Distributed Data Management (Extended Abstract)	Yair Bartal,Amos Fiat,Yuval Rabani	1992	We deal with the competitive analysis of algorithms for managing data in a distributed environment. We deal with the file allocation problem ([C], [DF], [ML]), where copies of a file may be stored in the local storage of some subset of processors, copies may be replicated and discarded over time so as to optimize communication costs, but multiple copies must be kept consistent and at least one copy must be stored somewhere in the network at all times. We deal with competitive algorithms for minimizing communication costs, over arbitrary sequences of reads and writes, and arbitrary network topologies. We define the constrained file allocation problem to be the solution of many individual file allocation problems simultaneously, subject to the constraints of local memory size. We give competitive algorithms for this prblem on uniform networks. We then introduce distributed competitive algorithms for on-line data tracking (a generalization of mobile user tracking [AP1, AP3] to transform our competitive distributed data management algorithms into distributed algorithms themselves.	STOC	theory
1597	STOC	Feasibility Testing for Systems of Real Quadratic Equations	Alexander I. Barvinok	1992	We consider the problem of deciding whether a given system of quadratic homogeneous equations over the reals has non-trivial solution. We design an approximative algorithm whose complexity is polynomial in the number of variables and exponential in the number of equations. Some applications to general systems of polynomial equations and inequalities over the reals are discussed.	STOC	theory
1598	STOC	Structure Forest and Composition Factors for Small Base Groups in Nearly Linear Time	Robert Beals,Ákos Seress	1992	Structure Forest and Composition Factors for Small Base Groups in Nearly Linear Time	STOC	theory
1599	STOC	Exponential Lower Bounds for the Pigeonhole Principle	Paul Beame,Russell Impagliazzo,Jan Krajícek,Toniann Pitassi,Pavel Pudlák,Alan R. Woods	1992	Exponential Lower Bounds for the Pigeonhole Principle	STOC	theory
1600	STOC	Randomized versus Nondeterministic Communication Complexity	Paul Beame,Joan Lawry	1992	Our main result is the demonstration of a Boolean function f with nondeterministic and co-nondeterministic complexities O(log n) and &egr;-error randomized complexity &OHgr;(log2 n), for 0 &le; &egr; < 1/2. This is the first separation of this kind for a decision problem.	STOC	theory
1601	STOC	When Do Extra Majority Gates Help? Polylog(n) Majority Gates Are Equivalent to One	Richard Beigel	1992	When Do Extra Majority Gates Help? Polylog(n) Majority Gates Are Equivalent to One	STOC	theory
1602	STOC	A New Recursion-Theoretic Characterization of the Polytime Functions (Extended Abstract)	Stephen Bellantoni,Stephen A. Cook	1992	We give a recursion-theoretic characterization of FP which describes polynomial time computation independently of any externally imposed resource bounds. In particular, this syntactic characterization avoids the explicit size bounds on recursion (and the initial function 2|x|.|y|) of Cobham.	STOC	theory
1603	STOC	Making Zero-Knowledge Provers Efficient	Mihir Bellare,Erez Petrank	1992	Making Zero-Knowledge Provers Efficient	STOC	theory
1604	STOC	Can Finite Samples Detect Singularities of Real-Valued Functions?	Shai Ben-David	1992	Consider the following type of problem: There is an unknown function, f : Rn &rarr; Rm, there is also a black-box that on query x (&egr; Rn) returns f(x). Is there an algorithm that, using probes to the black-box, can figure out analytic information about f? (For an example: &ldquo;Is f a polynomial?&rdquo;, &ldquo;Is f a second order differentiable at x = (0,0,&hellip;,0)?&rdquo; etc.). Clearly, for examples as these, if we bound the number of probes an algorithm has to settle for, no algorithm can carry the task. On the other hand, if one allows an infinite iteration of a &ldquo;probe compute and guess&rdquo; process, then, (quite surprisingly) for many such questions, there are algorithms that are guaranteed to be correct in all but finitely many of their guesses. We call such questions Decidable In the Limit, (DIL). We analyze the class of DIL problems and provide a necessary and sufficient condition for the membership of a decision problem in this class. We offer an algorithm for any DIL problem, and apply it to several types of learning tasks. Furthermore, if an a-priori probability distribution P, according to which f is being chosen, is available to the algorithm, then it can be strengthened into a finite algorithm. More precisely, for many distributions P, there exists a polynomial function, l, such that for every 0<&dgr;<1, there is an algorithm using at most l(log(&dgr;)) many probes that succeeds on more than (1&ndash;&dgr;) of the f's (as measured by P). We believe that the new approach presented here will be found useful for many further applications.	STOC	theory
1605	STOC	Fast Learning of k-Term DNF Formulas with Queries	Avrim Blum,Steven Rudich	1992	This paper presents an algorithm that uses equivalence and membership queries to learn the class of k-term DNF formulas in time O(n&bull;2o(k)), where n is the number of input variables. This improves upon previous O(nk) bounds and allows one to learn DNF of O(log n) terms in polynomial time. We present the algorithm in its most natural form as a randomized algorithm, and then show how recent derandomization techniques can be used to make it deterministic. The algorithm is an exact learning algorithm, but one where the equivalance query hypotheses and the final output are general (not necessarily k-term) DNF formulas. For the special case of 2-term DNF formulas, we give a simpler version of our algorithm that uses at most 4n + 2 total membership and equivalence queries.	STOC	theory
1606	STOC	Fault Tolerant Planar Communication Networks	Geng Lin	1992	Fault Tolerant Planar Communication Networks	STOC	theory
1607	STOC	Linear Decision Trees: Volume Estimates and Topological Bounds	Anders Björner,László Lovász,Andrew Chi-Chih Yao	1992	Linear Decision Trees: Volume Estimates and Topological Bounds	STOC	theory
1608	STOC	Target Shooting with Programmed Random Variables	Graham Brightwell,Teunis J. Ott,Peter Winkler	1992	LetX1,...,Xn be pairwise independent random variables of known (but not necessarily identical) distribution; we wish to select a subset of these whose sum will be as close as possible to some known target value T. Conditions described below force the selections to be made by a primitive distributed system (similar to one considered by Papadimitriou and Yannakakis [2] in PODC '91); here we are able to obtain a surprising amount of information about optimal solutions. The conditions are that each variable must be &ldquo;programmed&rdquo; in advance, joining the selected set according to its own value. Thus, for example, one variable might be programmed to join just if its value lies between &agr; and &bgr;, while another is told to join regardless of its value. Our object is to find a strategy, that is, a collection of programs, which minimizes the mean square error in approximating T. Typical applications involve producing a steady flow of some commodity when supply is controlled at a multiplicity of random sources. It turns out that there is always an optimal strategy in which each Xi is programmed to join if its value is between 0 and &thgr;i, for appropriate choice of thresholds &thgr;i. When the variables are identically distributed, we examine conditions under which the &thgr;i's must be equal. The case of uniform distributions on [0,1], for which the above conditions are not satisfied, is analyzed in detail, showing the rather bizarre behavior of the &thgr;i's which may take place in general as the target value is gradually changed. Next, we analyze the problem in which the variables are permitted to contribute any part of themselves to the sum; here it turns out that in an optimal strategy each program will be of the form &ldquo;contribute the minimum of Xi and &eegr;i&rdquo; with all the &eegr;i's equal in the i.i.d. case. Finally, we show how the original target shooting problem can be generalized to a kind of load balancing, where variables are assigned to different buckets, each with its own target, and the penalty is a weighted sum of squared errors. The surprising result here is that when the weights are equal, an optimal solution assigns variables only according to their signs.	STOC	theory
1609	STOC	Existence and Construction of Edge Disjoint Paths on Expander Graphs	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1992	Existence and Construction of Edge Disjoint Paths on Expander Graphs	STOC	theory
1610	STOC	Learning Arithmetic Read-Once Formulas	Nader H. Bshouty,Thomas R. Hancock,Lisa Hellerstein	1992	A formula is read-once if each variable appears at most once in it. An arithmetic read-once formula is one in which the operators are addition, subtraction, multiplication, and division. We present polynomial time algorithm for exactly learning (or interpolating) arithmetic read-once formulas computing functions over a field. We present an algorithm that uses randomized membership queries (or substitutions) to identify such formulas over large finite fields and infinite fields. We also present a deterministic algorithm that uses equivalence queries as well as membership queries to identify arithmetic read-once formulas over small finite fields. We then non-constructively show the existence of deterministic membership query (interpolation) algorithms for arbitrary formulas over fields of characteristic 0 and for division-free formulas over large or infinite fields. Our algorithms assume we are able to efficiently perform arithmetic operations on field elements and compute square roots in the field. It is shown that the ability to compute square roots is necessary, in the sense that the problem of computing n &ndash; 1 square roots in a field can be reduced to the problem of identifying an arithmetic formula over n variables in that field. Our equivalence queries are of a slightly non-standard form, in which counterexamples are required to not be inputs on which the formula evaluates to 0/0. This assumption is shown to be necessary for fields of size o(n/log n), for which it is shown that there is no polynomial time identification algorithm that uses just membership and standard equivalence queries.	STOC	theory
1611	STOC	A Decomposition of Multi-Dimensional Point-Sets with Applications to k-Nearest-Neighbors and n-Body Potential Fields (Preliminary Version)	Paul B. Callahan,S. Rao Kosaraju	1992	We define the notion of a well-separated pair decomposition of points in d-dimensional space. We develop efficient sequential and parallel algorithms for computing such a decomposition. We apply the resulting decomposition to the efficient computation of k-nearest neighbors and n-body potential fields.	STOC	theory
1612	STOC	Efficient Fault Tolerant Algorithms for Resource Allocation in Distributed Systems	Manhoi Choy,Ambuj K. Singh	1992	Solutions to resource allocation problems in distributed systems are examined with respect to the measures of response time, message complexity, and failure locality. Response time measures the time it takes for an algorithm to respond to the requests of a process, message complexity measures the number of messages sent and received by a process, and failure locality characterizes the size of the network that is affected by the failure of a single process. An algorithm that achieves a constant failure locality of four along with a quadratic response time and a quadratic message complexity is presented.	STOC	theory
1613	STOC	The Complexity of Multiway Cuts (Extended Abstract)	Elias Dahlhaus,David S. Johnson,Christos H. Papadimitriou,Paul D. Seymour,Mihalis Yannakakis	1992	In the Multiway Cut problem we are given an edge-weighted graph and a subset of the vertices called terminals, and asked for a minimum weight set of edges that separates each terminal from all the others. When the number k of terminals is two, this is simply the min-cut, max-flow problem, and can be solved in polynomial time. We show that the problem becomes NP-hard as soon as k = 3, but can be solved in polynomial time for planar graphs for any fixed k. The planar problem is NP-hard, however, if k is not fixed. We also describe a simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of 2&ndash;2/k of the optimal cut weight.	STOC	theory
1614	STOC	Graph Decomposition Is NPC-A Complete Proof of Holyer's Conjecture	Dorit Dor,Michael Tarsi	1992	An H-decomposition of a graph G = (V,E) is a partition of E into subgraphs isomorphic to H. Given a fixed graph H, the H-decomposition problem is to determine whether an input graph G admits an H-decomposition. I. Holyer (1980) conjectured that H-decomposition is Np-complete whenever H is connected and has at least 3 edges. Some partial results have been obtained during the last decade. A complete proof for Holyer's conjecture is the content of this paper.	STOC	theory
1615	STOC	Simple and Efficient Bounded Concurrent Timestamping or Bounded Concurrent Timestamp Systems are Comprehensible!	Cynthia Dwork,Orli Waarts	1992	Simple and Efficient Bounded Concurrent Timestamping or Bounded Concurrent Timestamp Systems are Comprehensible!	STOC	theory
1616	STOC	Approximations of General Independent Distributions	Guy Even,Oded Goldreich,Michael Luby,Noam Nisan,Boban Velickovic	1992	We describe efficient constructions of small probability spaces that approximate the independent distribution for general random variables. Previous work on efficient constructions concentrate on approximations of the independent distribution for the special case of uniform boolean-valued random variables. Our results yield efficient constructions of small sets with low discrepancy in high dimensional space and have applications to derandomizing randomized algorithms.	STOC	theory
1617	STOC	Balanced Matroids	Tomás Feder,Milena Mihail	1992	Balanced Matroids	STOC	theory
1618	STOC	On the Hardness of Computing the Permanent of Random Matrices (Extended Abstract)	Uriel Feige,Carsten Lund	1992	We study the complexity of computing the permanent on random inputs. We consider matrices drawn randomly from the space of n by n matrices with integer values between 0 and p&ndash;1, for any large enough prime p. We show that any polynomial time algorithm which computes the permanent correctly on even an exponentially small fraction of these matrices, implies the collapse of the polynomial-time hierarchy to its second level. We also show that it is hard to get partial information about the value of the permanent modulo p. We show that any balanced polynomial-time 0/1 predicate (e.g., the least significant bit, the parity of all the bits, the quadratic residuosity character) cannot be guessed with probability significantly greater than 1/2 (unless the polynomial hierarchy collapses). This result can be extended to showing simultaneous hardness for linear size groups of bits.	STOC	theory
1619	STOC	Two-Prover One-Round Proof Systems: Their Power and Their Problems (Extended Abstract)	Uriel Feige,László Lovász	1992	We characterize the power of two-prover one-round (MIP(2,1)) proof systems, showing that MIP(2,1)=NEXPTIME. However, the following intriguing question remains open: Does parallel repetition decrease the error probability of MIP(2,1) proof systems?. We use techniques based on quadratic programming to study this problem, and prove the parallel repetition conjecture in some special cases. Interestingly, our work leads to a general polynomial time heuristic for any NP-problem. We prove the effectiveness of this heuristic for several problems, such as computing the chromatic number of perfect graphs.	STOC	theory
1620	STOC	Communication Complexity of Secure Computation (Extended Abstract)	Matthew K. Franklin,Moti Yung	1992	A secret-ballot vote for a single proposition is an example of a secure distributed computation. The goal is for m participants to jointly compute the output of some n-ary function (in this case, the sum of the votes), while protecting their individual inputs against some form of misbehavior. In this paper, we initiate the investigation of the communication complexity of unconditionally secure multi-party computation, and its relation with various fault-tolerance models. We present upper and lower bounds on communication, as well as tradeoffs among resources. First, we consider the &ldquo;direct sum problem&rdquo; for communications complexity of perfectly secure protocols: Can the communication complexity of securely computing a single function f : Fn &rarr; F at k sets of inputs be smaller if all are computed simultaneously than if each is computed individually? We show that the answer depends on the failure model. A factor of O(n/log n) can be gained in the privacy model (where processors are curious but correct); specifically, when f is n-ary addition (mod 2), we show a lower bound of &OHgr;(n2 log n) for computing f O(n) times simultaneously. No gain is possible in a slightly stronger fault model (fail-stop mode); specifically, when f is n-ary addition over GF(q), we show an exact bound of &THgr;(kn2 log q) for computing f at k sets of inputs simultaneously (for any k &ge; 1). However, if one is willing to pay an additive cost in fault tolerance (from t to t-k+1), then a variety of known non-cryptographic protocols (including &ldquo;provably unparallelizable&rdquo; protocols from above!) can be systematically compiled to compute one function at k sets of inputs with no increase in communication complexity. Our compilation technique is based on a new compression idea of polynomial-based multi-secret sharing. Lastly, we show how to compile private protocols into error-detecting protocols at a big savings of a factor of O(n3) (up to a log factor) over the best known error-correcting protocols. This is a new notion of fault-tolerant protocols, and is especially useful when malicious behavior is infrequent, since error-detection implies error-correction in this case.	STOC	theory
1621	STOC	A Constant-Time Optimal Parallel String-Matching Algorithm	Zvi Galil	1992	Given a pattern string, we describe a way to preprocess it. We design a constant-time optimal parallel algorithm for finding all occurences of the (preprocessed) pattern in any given text.	STOC	theory
1622	STOC	Fully Dynamic Planarity Testing (Extended Abstract)	Zvi Galil,Giuseppe F. Italiano,Neil Sarnak	1992	Fully Dynamic Planarity Testing (Extended Abstract)	STOC	theory
1623	STOC	Computing Frobenius Maps and Factoring Polynomials (Extended Abstract)	Joachim von zur Gathen,Victor Shoup	1992	Computing Frobenius Maps and Factoring Polynomials (Extended Abstract)	STOC	theory
1624	STOC	Planar Separators and Parallel Polygon Triangulation (Preliminary Version)	Michael T. Goodrich	1992	Planar Separators and Parallel Polygon Triangulation (Preliminary Version)	STOC	theory
1625	STOC	Asymptotic Conditional Probabilities for First-Order Logic	Adam J. Grove,Joseph Y. Halpern,Daphne Koller	1992	Motivated by problems that arise in computing degrees of belief, we consider the problem of computing asymptotic conditional probabilities for first-order formulas. That is, given first-order formulas &fgr; and &thgr;, we consider the number of structures with domain {1,&hellip;,N} that satisfy &thgr;, and compute the fraction of them in which &fgr; is true. We then consider what happens to this probability of first-order formulas, except that now we are considering asymptotic conditional probabilities. Although work has been done on special cases of asymptotic conditional probabilities, no general theory has been developed. This is probably due in part to the fact that it has been known that, if there is a binary predicate symbol in the vocabulary, asymptotic conditional probabilities do not always exist. We show that in this general case, almost all the questions one might want to ask (such as deciding whether the asymptotic probability exists) are highly undecidable. On the other hand, we show that the situation with unary predicates only is much better. If the vocabulary consists only of unary predicate and constant symbols, it is decidable whether the limit exists, and if it does, there is an effective algorithm for computing it. The complexity depends on two parameters: whether there is a fixed finite vocabulary or an infinite one, and whether there is a bound on the depth of quantifier nesting.	STOC	theory
1626	STOC	Entropy and Sorting	Jeff Kahn,Jeong Han Kim	1992	We reconsider the old problem of sorting under partial information, and give polynomial time algorithms for the following tasks. (1) Given a partial order P, find (adaptively) a sequence of comparisons (questions of the form, &ldquo;is x < y?&rdquo;) which sorts (i.e. finds an unknown linear extension of) P using O(log(e(P))) comparisons in worst case (where e(P) is the number of linear extensions of P). (2) Compute (on line) answers to any comparison algorithm for sorting a partial order P which force the algorithm to use &OHgr;(log(e(P))) comparisons. (3) Given a partial order P of size n, estimate e(P) to within a factor exponential in n. (We give upper and lower bounds which differ by the factor nn/n!.) Our approach, based on entropy of the comparability graph of P and convex minimization via the ellipsoid method, is completely different from earlier attempts to deal with these questions.	STOC	theory
1627	STOC	A Subexponential Randomized Simplex Algorithm (Extended Abstract)	Gil Kalai	1992	A Subexponential Randomized Simplex Algorithm (Extended Abstract)	STOC	theory
1628	STOC	Efficient PRAM Simulation on a Distributed Memory Machine	Richard M. Karp,Michael Luby,Friedhelm Meyer auf der Heide	1992	We present a randomized simulation of a nlog log (n) log (n)-processor shared memory machine (DMM) with optimal expected delay O(log log (n)) per step of simulation. The time bound for the delay is guaranteed with overwhelming probability. The algorithm is based on hashing and uses a novel simulation scheme. The best previous simulations use a simpler scheme based on hashing and have much larger expected delay: &THgr;(log(n)/log log (n)) for the simulation of an n-processor PRAM on an n processor DMM, and &THgr;(log(n)) in the case where the simulation preserves the processor-time product.	STOC	theory
1629	STOC	Efficient Program Transformations for Resilient Parallel Computation via Randomization (Preliminary Version)	Zvi M. Kedem,Krishna V. Palem,Michael O. Rabin,A. Raghunathan	1992	In this paper, we address the problem of automatically transforming arbitrary programs written for an ideal parallel machine to run on a completely asynchronous machine. We present a transformation which can be applied to an ideal program such that the resulting program's execution on an asynchronous machine is work and space efficient, relative to the ideal program from which it is derived. Above all, the transformation will guarantee that the ideal program will execute in a continually progressive manner on the asynchronous machine; these instructions are not universal. Furthermore, the individual processors can get delayed for arbitrary amounts of time while executing any instruction. In contrast, previous work relied either on the asynchronous machine having universal read-modify-write instructions as primitives, or on limited asynchrony by restricting the relative speeds of the processors.	STOC	theory
1630	STOC	On the Parallel Complexity of Computing a Maximal Independent Set in a Hypergraph	Pierre Kelsen	1992	A maximal independent set in a hypergraph is a subset of vertices that is maximal with respect to the property of not containing any edge of the hypergraph. We show that an algorithm proposed by Beame and Luby is in randomized NC for hypergraphs in which the maximum edge size is bounded by a constant. To prove this, we bound the upper tail of sums of dependent random variables defined on the edges of a hypergraph. These bounds may be viewed as extensions of bounds on the tail of the binomial distribution. We derandomize this algorithm to obtain the first sublinear time deterministic algorithm for hypergraphs with edges of size O(1). The algorithm exhibits the following time-processor tradeoff: it can be made to run in time O(n&egr;) with nO(1/&egr;) processors for a hypergraph on n vertices, for any &egr; &ge; 2d+1&bull; (log log n)/(log n); here d = O(1) denotes the maximum size of an edge in H. In particular, for any constant &egr; > O, we have an algorithm running in time O(n&egr;) on a polynomial number of processors, and we have an algorithm running in time (log n)O(1) on nO(log n/log log n) processors.	STOC	theory
1631	STOC	Biconnectivity Approximations and Graph Carvings	Samir Khuller,Uzi Vishkin	1992	A spanning tree in a graph is the smallest connected spanning subgraph. Given a graph, how does one find the smallest (i.e., least number of edges) 2-connected spanning subgraph (connectivity refers to both edge and vertex connectivity, if not specified)? Unfortunately, the problem is known to be NP-hard. We consider the problem of finding an approximation to the smallest 2-connected subgraph, by an efficient algorithm. For 2-edge connectivity our algorithm guarantees a solution that is no more than 3/2 times the optimal. For 2-vertex connectivity our algorithm guarantees a solution that is no more than 5/3 times the optimal. The previous best approximation factor is 2 for each of these problems. The new algorithms (and their analyses) depend upon a structure called a carving of a graph, which is of independent interest. We show that approximating the optimal solution to within an additive constant is NP-hard as well. We also consider the case where the graph has edge weights. We show that an approximation factor of 2 is possible in polynomial time for finding a k-edge connected spanning subgraph. This improves an approximation factor of 3 for k=2 due to [FJ81], and extends it for any k (with an increased running time though).	STOC	theory
1632	STOC	A Note on Efficient Zero-Knowledge Proofs and Arguments (Extended Abstract)	Joe Kilian	1992	In this note, we present new zero-knowledge interactive proofs and arguments for languages in NP. To show that x &egr; L, with an error probability of at most 2-k, our zero-knowledge proof system requires O(|x|c1)+O(lgc2|x|)k ideal bit commitments, where c1 and c2 depend only on L. This construction is the first in the ideal bit commitment model that achieves large values of k more efficiently than by running k independent iterations of the base interactive proof system. Under suitable complexity assumptions, we exhibit zero knowledge arguments that require O(lgc|x|kl bits of communication, where c depends only on L, and l is the security parameter for the prover. This is the first construction in which the total amount of communication can be less than that needed to transmit the NP witness. Our protocols are based on efficiently checkable proofs for NP[4].	STOC	theory
1633	STOC	A Parallel Randomized Approximation Scheme for Shortest Paths	Philip N. Klein,Sairam Sairam	1992	We give a randomized parallel algorithm for approximate shortest path computation in an undirected weighted graph. The algorithm is based on a technique used by Ullman and Yannakakis in a parallel algorithm for breadth-first search. It has application, e.g., in approximate solution of multicommodity flow problems with unit capacities. We also show how to adapt the algorithm to perform better for planar graphs.	STOC	theory
1634	STOC	Small-Depth Counting Networks	Michael Klugerman,C. Greg Plaxton	1992	Small-Depth Counting Networks	STOC	theory
1635	STOC	Online Minimization of Transition Systems (Extended Abstract)	David Lee,Mihalis Yannakakis	1992	We are given a transition system implicitly through a compact representation and wish to perform simultaneously reachability analysis and minimization without constructing first the whole system graph. We present an algorithm for this problem that applies to general systems, provided we have appropriate primitive operations for manipulating blocks of states and we can determine termination; the number of operations needed to construct the minimal reachable graph is quadratic in the size of this graph. We specialize the method to obtain efficient algorithms for extended finite state machines that apply separable affine transformations on the variables.	STOC	theory
1636	STOC	Methods for Message Routing in Parallel Machines	Frank Thomson Leighton	1992	Methods for Message Routing in Parallel Machines	STOC	theory
1637	STOC	epsilon-Approximations with Minimum Packing Constraint Violation (Extended Abstract)	Jyh-Han Lin,Jeffrey Scott Vitter	1992	We present efficient new randomized and deterministic methods for transforming optimal solutions for a type of relaxed integer linear program into provably good solutions for the corresponding NP-hard discrete optimization problem. Without any constraint violation, the &egr;-approximation problem for many problems of this type is itself NP-hard. Our methods provide polynomial-time &egr;-approximations while attempting to minimize the packing constraint violation. Our methods lead to the first known approximation algorithms with provable performance guarantees for the s-median problem, the tree prunning problem, and the generalized assignment problem. These important problems have numerous applications to data compression, vector quantization, memory-based learning, computer graphics, image processing, clustering, regression, network location, scheduling, and communication. We provide evidence via reductions that our approximation algorithms are nearly optimal in terms of the packing constraint violation. We also discuss some recent applications of our techniques to scheduling problems.	STOC	theory
1638	STOC	A Logspace Algorithm for Tree Canonization (Extended Abstract)	Steven Lindell	1992	We present a solution to the problem of assigning to each directed tree T of size n a unique isomorphism invariant name for T, using only work space O(log n). Hence, tree isomorphism is computable in logspace. As another consequence, we obtain the corollary that the set of logspace computable queries (Lspace) on trees is recursively enumerable. Our results extend easily to undirected trees and even forests.	STOC	theory
1639	STOC	Ham-Sandwich Cuts in R^d	Chi-Yuan Lo,Jirí Matousek,William L. Steiger	1992	Ham-Sandwich Cuts in R^d	STOC	theory
1640	STOC	Simple Algorithms for Routing on Butterfly Networks with Bounded Queues (Extended Abstract)	Bruce M. Maggs,Ramesh K. Sitaraman	1992	Simple Algorithms for Routing on Butterfly Networks with Bounded Queues (Extended Abstract)	STOC	theory
1641	STOC	On the Angular Resolution of Planar Graphs	Seth M. Malitz,Achilleas Papakostas	1992	It is a well-known fact that every planar graph admits a planar straight-line drawing. The angular resolution of such a drawing is the minimum angle subtended by any pair of incident edges. The angular resolution of the graph is the supremum angular resolution over all planar straight-line drawings of the graph. In a recent paper by Formann et al. [Proc. 31st IEEE Sympos. on Found. of Comput. Sci., 1990, pp. 86-95], the following question is posed: Does there exist a constant $r(d) > 0$ such that every planar graph of maximum degree $d$ has angular resolution $\geq r(d)$ radians? The present authors show that the answer is yes and that it follows easily from results in the literature on disk-packings. The conclusion is that every planar graph of maximum degree $d$ has angular resolution at least $\alpha^d$ radians, $0	STOC	theory
1642	STOC	Self-Stabilizing Symmetry Breaking in Constant-Space (Extended Abstract)	Alain J. Mayer,Yoram Ofek,Rafail Ostrovsky,Moti Yung	1992	We investigate the problem of self-stabilizing round-robin token management scheme on an anonymous bidirectional ring of identical processors, where each processor is an asynchronous probabilistic (coin-flipping) finite state machine which sends and receives messages. We show that the solution to this problem is equivalent to symmetry breaking (i.e., leader election). Requiring only constant-size messages and message-passing model has practical implications: our solution can be implemented in high-speed networks using a universal fast hardware switches (i.e., finite state machines) of size independent of the size of the network.	STOC	theory
1643	STOC	RL\subseteqSC	Noam Nisan	1992	RL\subseteqSC	STOC	theory
1644	STOC	On the Degree of Boolean Functions as Real Polynomials	Noam Nisan,Mario Szegedy	1992	Every boolean function may be represented as a real polynomial. In this paper we characterize the degree of this polynomial in terms of certain combinatorial properties of the boolean function. Our first result is a tight lower bound of &OHgr;(log n) on the degree needed to represent any boolean function that depends on n variables. Our second result states that for every boolean function f the following measures are all polynomially related:(1) The decision tree complexity of f. (2) The degree of the polynomial representing f. (3) The smallest degree of a polynomial approximating f in the Lmax norm.	STOC	theory
1645	STOC	Shallow Multiplication Circuits and Wise Financial Investments	Mike Paterson,Uri Zwick	1992	Paterson, Pippenger and Zwick have recently obtained a general theory that describes the optimal way in which given carry-save adders can be combined into carry-save networks. Their work produces, in particular, multiplication circuits of depth 3.71 log* n (these circuits put out two numbers whose sum is the result of the multiplication). In this work an extension of the above general theory is obtained. We now consider carry-save adders that may receive inputs and produce outputs using several different representation methods. We describe the optimal way of utilising any such collection of carry-save adders. The optimality proof uses the min-max theorem of game theory. By using several different representation standards, the depth of multiplication circuits can be surprisingly reduced to 3.48 log* n (again two output numbers are produced). We introduce bit level redundancy by using a novel coding scheme in which each bit is distributed over four wires. Interestingly, the information on these four wires is usually not transmitted simultaneously. Finally, an analogy is made between the optimisation problem faced by the circuit designer and the optimisation problem faced by an investor, offered a collection of financial investment plans, each involving perhaps several different currencies. This analogy is used to obtain intuitive explanations of the results obtained.	STOC	theory
1646	STOC	Improved Distributed Algorithms for Coloring and Network Decomposition Problems	Alessandro Panconesi,Aravind Srinivasan	1992	Improved Distributed Algorithms for Coloring and Network Decomposition Problems	STOC	theory
1647	STOC	Faster Algorithms for Finding Small Edge Cuts in Planar Graphs (Extended Abstract)	Satish Rao	1992	Faster Algorithms for Finding Small Edge Cuts in Planar Graphs (Extended Abstract)	STOC	theory
1648	STOC	On the Degree of Polynomials that Approximate Symmetric Boolean Functions (Preliminary Version)	Ramamohan Paturi	1992	In this paper, we provide matching (up to a constant factor) upper and lower bounds on the degree of polynomials that represent symmetric boolean functions with an error 1/3. Let &Ggr;(f)=min{|2k&ndash;n+1|:fk &ne; fk+ 1 and 0 &le; k &le; n &ndash; 1} where fi is the value of f on inputs with exactly i 1's. We prove that the minimum degree over all the approximating polynomials of f is &THgr;((n(n-&Ggr;(f))).5). We apply the techniques and tools from approximation theory to derive this result.	STOC	theory
1649	STOC	A Hypercubic Sorting Network with Nearly Logarithmic Depth	C. Greg Plaxton	1992	A natural class of &ldquo;hypercubic&rdquo; sorting networks is defined. The regular structure of these sorting networks allows for elegant and efficient implementations on any of the so-called hypercubic networks (e.g., the hypercube, shuffle-exchange, butterfly, and cube-connected cycles). This class of sorting networks contains Batcher's O(lg2 n)-depth bitonic sort, but not the O(lg n)-depth sorting network of Ajtai, Komlo&acute;s, and Szemere&acute;di. In fact, no o(lg2 n)-depth compare-interchange sort was previously known for any of the hypercubic networks. In this paper, we prove the existence of a family of 2O((lg lg n)1/2) lg n-depth hypercubic sorting networks. Note that this depth is o(lg1+&egr; n) for any constant &egr; > 0.	STOC	theory
1650	STOC	Finding Approximate Separators and Computing Tree Width Quickly	Bruce A. Reed	1992	We show that for any fixed k, there is a linear-time algorithm which given a graph G either: (i) finds a cutset X of G with |X| &le; k such that no component of G&ndash;X contains more than 3/4|G&ndash;X| vertices, or (ii) determines that for any set X of vertices of G with |X| &le; k, there is a component of G&ndash;X which contains more than 2/3|G&ndash;X| vertices. This approximate separator algorithm can be used to develop and O(n log n algorithm for determining if G has a tree decomposition of width at most k (for fixed k) and finding such a tree decomposition if it exists.	STOC	theory
1651	STOC	Exponential Determinization for omega-Automata with Strong-Fairness Acceptance Condition (Extended Abstract)	Shmuel Safra	1992	In [Saf88] an exponential determination procedure for Bu&uml;chi automata was shown, yielding tight bounds for decision procedures of some logics ([EJ88, Saf88, SV89, KT89]). In [SV89] the complexity of determinization and complementation of &ohgr;-automata was further investigated, leaving as an open question the complexity of the determinization of a single class of &ohgr;-automata. For this class of &ohgr;-automata with strong fairness as acceptance condition (Street automata), [SV89] managed to show an exponential complementation procedure, but showed that the blow-up of the translation of these automata to any of the classes known to admit exponential determinization is inherently exponential. This might suggest that the blow-up of the determinization of Street automata is inherently doubly exponential. Surprisingly, we show an exponential determinization construction for any Streett automaton. In fact, the complexity of our construction is roughly the same as the complexity achieved in [Saf88] for Bu&uml;chi automata. Moreover, a simple observation extends this upper bound to the complexity of the complementation problem. Since any &ohgr;-automaton that admits exponential determinization can be easily converted into a Streett automaton, we get one procedure that can be used for all of these conversions. This construction is optimal (up to a constant factor in the exponent) for all of these conversions. Our results imply that Streett automata (with strong fairness as acceptance condition) can be used instead of Bu&uml;chi automata (with the weaker acceptance condition) without any loss of efficiency.	STOC	theory
1652	STOC	The History and Status of the P versus NP Question	Michael Sipser	1992	The History and Status of the P versus NP Question	STOC	theory
1653	STOC	Sample Spaces Uniform on Neighborhoods	Leonard J. Schulman	1992	Let a universe of m elements be given, along with a family of subsets of the universe (neighborhoods), each of size at most k. We describe methods for assigning the m elements to points in a small-dimensional vector space (over GF(2)), in such a way that the elements in each neighborhood are assigned to an independent set of vectors. Such constructions lead, through a standard correspondence between linear and statistical independence, to the construction of small sample spaces which restrict to the uniform distribution in each neighborhood. (The sample space is a uniformly-weighted family of binary m-vectors). The size of such a small space will be a function of the number of neighborhoods; and for sparse families, will be substantially smaller than any space which restricts to the uniform distribution in all k-sets. Previous work on small spaces with limited independence focused on providing independence or near-independence in every k-set of the universe. We show how to construct the sample spaces efficiently both sequentially and in parallel. In case there are polynomially many (in m) neighborhoods, each of size O(log m), the parallel construction is in NC. These spaces provide a new derandomization technique for algorithms; particularly, algorithms related to the Lova&acute;sz local lemma. We also describe applications to the exhaustive testing of VLSI circuits, and to coding for burst errors on noisy channels.	STOC	theory
1654	STOC	On the All-Pairs-Shortest-Path Problem	Raimund Seidel	1992	On the All-Pairs-Shortest-Path Problem	STOC	theory
1655	STOC	On the Complexity of RAM with Various Operation Sets	Janos Simon,Mario Szegedy	1992	We prove that polynomial time bounded RAMs with the instruction set [shift, +, X, boolean ] accept exactly the languages in PSPACE. This generalizes previous results: [5] showed the same for the instruction set that does not include multiplication, [5] and [7] proved the weaker theorems, that RAMs (and even PRAMs) with this instruction set could be simulated in EXPTAPE. The PRAM result is a simple corollary to our theorems. We also introduce other powerful string-manipulating instructions for RAMs, show a nontrivial simulation of Turing machines by these RAMs, and show that in a sense such simulations are optimal.	STOC	theory
1656	STOC	Average Case Intractability of Matrix and Diophantine Problems (Extended Abstract)	Ramarathnam Venkatesan,Sivaramakrishnan Rajagopalan	1992	Average Case Intractability of Matrix and Diophantine Problems (Extended Abstract)	STOC	theory
1657	STOC	Proceedings of the Twenty Fourth Annual ACM Symposium on Theory of Computing, 4-6 May 1992, Victoria, British Columbia, Canada		1992	Proceedings of the Twenty Fourth Annual ACM Symposium on Theory of Computing, 4-6 May 1992, Victoria, British Columbia, Canada	STOC	theory
1658	IEEE Visualization	Towards a Comprehensive Volume Visualization System.	Ricardo S. Avila,Lisa M. Sobierajski,Arie E. Kaufman	1992	The VolVis system has been developed to satisfy the diverse requirements of the volume visualization community by comfortably housing numerous visualization algorithms and methods within a consistent and well organized framework. The VolVis system is supported by a generalized abstract model which provides for both geometric and volumetric constructs. VolVis contains several rendering algorithms that span the speed versus accuracy continuum. A fast volume rendering algorithm has been developed, which is capable of exploiting existing graphics hardware without placing any viewing restrictions or compromising accuracy. In addition. VolVis includes a volumetric navigation facility, key-frame animation generator, quantitative analysis tools, and a generalized protocol for communicating with 3D input devices.	IEEE Visualizat	visu
1659	IEEE Visualization	Virtual Spacetime: An Environment for the Visualization of Curved Spacetimes via Geodesic Flows.	Steve Bryson	1992	We describe an implementation of a virtual environment for visualizing the geometry of curved spacetime by the display of interactive geodesics. This technique displays the paths of particles under the influence of gravity as described by the general theory of relativity, and is useful in the investigation of solutions to the field equations of that theory. A boom-mounted six degree of freedom head position sensitive stereo CRT system is used for display. A hand position sensitive glove controller is used to control the initial positions and directions of geodesics in spacetime. A multiprocessor graphics workstation is used for computation and rendering. We describe and illustrate with examples several techniques for visualizing the geometry of spacetime using geodesics. Though this work is described exclusively in the context of physical four-dimensional spacetimes, it extends to arbitrary geometries in arbitrary dimensions. While this work is intended for researchers, it is also useful for the teaching of general relativity.	IEEE Visualizat	visu
1660	IEEE Visualization	Automated Design of Virtual Worlds for Visualizing Multivariate Relations.	Clifford Beshers,Steven Feiner	1992	Interactive visualization systems provide a powerful means to explore complex data, especially when coupled with 3D interaction and display devices to produce virtual worlds. While designing a quality static 2D visualization is already a difficult task for most users, designing an interactive 3D one is even more challenging. To address this problem, we are developing Auto Visual, a research system that designs interactive virtual worlds for visualizing and exploring multivariate relations of arbitrary arity. Auto Visual uses worlds within worlds, an interactive visualization technique that exploits nested, heterogeneous coordinate systems to map multiple variables onto each of our spatial dimensions. Auto Visual's designs are guided by user-specified visualization tasks, and by a catalog of design principles encoded using a rule-based language.	IEEE Visualizat	visu
1661	IEEE Visualization	Visualization of High-Resolution, 3-D, Nonlinear, Finite Element Analyses.	Mark A. Christon,T. Spelce	1992	Visualization of High-Resolution, 3-D, Nonlinear, Finite Element Analyses.	IEEE Visualizat	visu
1662	IEEE Visualization	Volume Rendering on a Distributed Memory Parallel Computer.	T. Todd Elvins	1992	Volume rendering ideally produces high-quality images at interactive rates. High CPU and memory requirements make this goal unreachable with current off-the-shelf technology. Exploiting highly parallel computers is one way that future systems may approach acceptable speeds. This paper discusses the adaptation of a known volume rendering algorithm to a new commercially available distributed memory MIMD parallel architecture.	IEEE Visualizat	visu
1663	IEEE Visualization	Visualizing n-Dimensional Implications of 2-D Design Decisions.	Stephen M. Ervin	1992	Visualizing n-Dimensional Implications of 2-D Design Decisions.	IEEE Visualizat	visu
1664	IEEE Visualization	Logical Time in Visualizations Produced by Parallel Programs.	Janice E. Cuny,Alfred Hough,Joydip Kunda	1992	Visualization tools that display data as it is manipulated by a parallel, MIMD computation must contend with the effects of asynchronous execution. We have developed techniques that manipulate logical time in order to produce coherent animations of parallel program behavior despite the presence of asynchrony. Our techniques interpret program behavior in light of user-defined abstractions and generate animations based on a logical rather than a physical view of time. If this interpretation succeeds, the resulting animation is easily understood; if it fails, the programmer can be assured that the failure was not an artifact of the visualization. Here we demonstrate that these techniques can be generally applied to enhance visualizations of a variety of types of data as it is produced by parallel, MIMD computations.	IEEE Visualizat	visu
1665	IEEE Visualization	Visualization of Second-Order Tensor Fields and Matrix Data.	Thierry Delmarcelle,Lambertus Hesselink	1992	We present a study of the visualization of 3-D second order tensor fields and matrix data. The general problem of visualizing unsymmetric real or complex Hermitian second order tensor fields can be reduced to the simultaneous visualization of a real and symmetric second order tensor field and a real vector field. As opposed to the discrete iconic techniques commonly used in multivariate data visualization, the emphasis is on exploiting the mathematical properties of tensor fields in order to facilitate their visualization and to produce a continuous representation of the data. We focus on interactively sensing and exploring real and symmetric second order tensor data by generalizing the vector notion of streamline to the tensor concept of hyperstreamline. We stress the importance of a structural analysis of the data field analogous to the techniques of vector field topology extraction in order to obtain a unique and objective representation of second order tensor fields.	IEEE Visualizat	visu
1666	IEEE Visualization	Visualizing Code Profiling Line Oriented Statistics.	Stephen G. Eick,Joseph L. Steffen	1992	Code tuning is a well-known technique for improving the run-time performance of software. There are several widely used profilers available that show the heavily used functions. Other profilers provide fine grain profiling detail such as basic block counts. The difficulty in using fine grain profilers is coping with the large volumes of data that they generate.We describe a visualization technique that enables us to display and analyze line count profile data. Our technique is to make a reduced picture of code with the line execution counts identified with the color. We show hot spots in red, warm spots in orange, and so on. We are also able to identify nonexecuted code and nonexecutable code such as declarations and static tables.	IEEE Visualizat	visu
1667	IEEE Visualization	Visualization for the Document Space.	X. Lin	1992	Visualization for the document space is an important issue for future information retrieval systems. This article describes an information retrieval framework that promotes graphical displays which will make documents in the computer visualizable to the searcher. As examples of such graphical displays, two simulation results of using Kohonen's feature map to generate map displays for information retrieval are presented and discussed. The map displays are a mapping from a high-dimensional document space to a two-dimensional space. They show document relationships by various visual cues such as dots, links, clusters and areas as well as their measurement and spatial arrangement. Using the map displays as an interface for document retrieval systems, we will provide the user with richer visual information to support browsing and searching.	IEEE Visualizat	visu
1668	IEEE Visualization	Visualizing the Universe.	M. J. Geller,E. E. Flaco,D. G. Fabricant,B. Estus	1992	These decades are the first in which we can begin to map the universe. Recent surveys reveal patterns in the distribution of galaxies --- patterns coherent on scales of 150 million light years or more. These patterns contrast with the smoothness of the radiation background measured by the COBE satellite. Together these observations challenge our understanding of the origin of galaxies --- structure --- in the universe.Visualizing the universe is crucial for exploring the 3-dimensional map, for analyzing it, for designing instruments to make deeper maps with new large telescopes, and for sharing the excitement of discovery with the public.	IEEE Visualizat	visu
1669	IEEE Visualization	Visualization of Fuzzy Data Using Generalized Animation.	Nahum D. Gershon	1992	In this paper, we present methods for visualization of fuzzy data based on the sensitivity of the human visual system to motion and dynamic changes and the ease with which electronic display devices can change their display. The methods presented include taking an otherwise static image and displaying in an animation loop either its segmented components or a series of blurred versions of the whole image. This approach was applied to seasurface temperature data and was found to be effective in showing fuzzy details embedded in the data and in drawing the viewer's attention. This approach and methods could play a significant role in the display of browse products for massive data and information systems.	IEEE Visualizat	visu
1670	IEEE Visualization	Flow Visualization as a Basic Tool to Investigate the Dynamics and Topology of Jets.	Fernando Grinstein,Upul Obeysekare,Gopal Patnaik	1992	We address relevant issues and difficulties involved in the practical implementation of flow visualization techniques based on database generated in numerical simulations of unsteady square jets. Instantaneous visualizations provide basic information on the topological features of the flow, while animation of these visualizations gives an insight into the detailed dynamics of formation, development and interaction of the coherent structures controlling the entrainment and mixing processes.	IEEE Visualizat	visu
1671	IEEE Visualization	Generalized Focal Surfaces: A New Method for Surface Interrogation.	Hans Hagen,Stefanie Hahmann	1992	The generation of smooth surfaces from a mesh of three-dimensional data points is an important problem in geometric modeling. Apart from the pure construction of these curves and surfaces, the analysis of their quality is equally important in the design and manufacturing process. Generalized focal surfaces are presented here as a new surface interrogation tool.	IEEE Visualizat	visu
1672	IEEE Visualization	Massively Parallel Isosurface Extraction.	Charles D. Hansen,P. A. Hinker	1992	We describe experiences during the investigation of parallel methods for faster isosurface generation on SIMD machines. A sequential version of a well known isosurfacing algorithm is algorithmically enhanced for a particular type of SIMD architecture. The SIMD implementation takes full advantage of the data parallel nature of the algorithm and experiments have proven the implementation to be highly scalable. A parallel tool, which can generate 170K polygons / second, gives scientists the means to explore large 3D scalar or vector fields interactively.	IEEE Visualizat	visu
1673	IEEE Visualization	Four-Dimensional Views of 3-D Scalar Fields.	Andrew J. Hanson,P. A. Hinker	1992	Four-Dimensional Views of 3-D Scalar Fields.	IEEE Visualizat	visu
1674	IEEE Visualization	Display of Scientific Data Structures for Algorithm Visualization.	William L. Hibbard,Charles R. Dyer,Brian E. Paul	1992	We present a technique for defining graphical depictions for all the data types defined in an algorithm, The ability to display arbitrary combinations of an algorithm's data objects in a common frame of reference, coupled with interactive control of algorithm execution, provides a powerful way to understand algorithm behavior. Type definitions are constrained so that all primitive values occurring in data objects are assigned scalar types. A graphical display, including user interaction with the display, is modeled by a special data type. Mappings from the scalar types into the display model type provide a simple user interface for controlling how all data types are depicted, without the need for type-specific graphics logic.	IEEE Visualizat	visu
1675	IEEE Visualization	Anatomical Atlases Based on Volume Visualization.	Karl Heinz Höhne,Andreas Pommert,Martin Riemer,Thomas Schiemann,Rainer Schubert,Ulf Tiede,W. Lierse	1992	In current practice computerized anatomical atlasses are based on a collection of images that can be accessed via a hypermedia program shell. In order to overcome the drawback of a limited number of available views, we propose an approach that uses an anatomical model as data base. The model has a two layer structure. The lower level is a volume model with a set of semantic attributes belonging to each voxel. Its spatial representation is derived from data sets of Magnetic Resonance Imaging and Computer Tomography. The semantic attributes are assigned by an anatomist using a volume editor. The upper level is a set of relations between these attributes which are specified by the expert as well. Interactive visualization tools such as multiple surface display, transparent rendering and cutting are provided. As a substantial feature of the implementation the semantic and the visualization oriented descriptions are stored in a knowledge base. It is shown that the combination of this object oriented data structure with advanced volume visualization tools provides the look and feel of a real dissection. The concept which even allows simulations like surgery rehearsal, is claimed to be superior to all presently known atlas techniques.	IEEE Visualizat	visu
1676	IEEE Visualization	Constructing Stream Surfaces in Steady 3-D Vector Fields.	Jeff P. Hultquist	1992	Constructing Stream Surfaces in Steady 3-D Vector Fields.	IEEE Visualizat	visu
1677	IEEE Visualization	SuperGlue: A Programming Environment for Scientific Visualization.	Jeff P. Hultquist,E. L. Raible	1992	Visualization environments have two audiences: scientists and programmers. We suggest that many existing platforms overemphasize ease-of-use and do not adequately address issues of extensibility. We have built a visualization testbed, called SuperGlue, which is particularly suited for the rapid development of new visualization methods. An interpreter supports rapid development of new code and an extensive class hierarchy encourages code reuse.By explicitly designing for ease of programming, we have produced a visualization system which is powerful, easy to use, and rapidly improving. This report describes the motivation of the work, the architecture of the system, and our plans for further development.	IEEE Visualizat	visu
1678	IEEE Visualization	Visualizing a 3-D Hydrodynamic Model.	C. S. Jones,J. A. Baca	1992	Visualizing a 3-D Hydrodynamic Model.	IEEE Visualizat	visu
1679	IEEE Visualization	Interactive Terrain Rendering van Volume Visualization on the Princeton Engine.	J. Kaba,J. Matey,Gordon Stoll,Herb Taylor,Pat Hanrahan	1992	Interactive Terrain Rendering van Volume Visualization on the Princeton Engine.	IEEE Visualizat	visu
1680	IEEE Visualization	Visualization in Anthropology: Reconstruction of Human Fossils.	Alan D. Kalvin,D. Dean,J. J. Hublin,M. Braun	1992	Visualization in Anthropology: Reconstruction of Human Fossils.	IEEE Visualizat	visu
1681	IEEE Visualization	Visualization of Simulated Airflow in a Clean Room.	K. Koyamada	1992	Techniques for visualizing a simulated air flow in a clean room are developed by using an efficient cell traverse of tetrahedral cells generated from irregular volumes. The proposed techniques are probing and stream line display, which are related to the measurement techniques used in actual clean rooms. The efficient traverse makes it possible to move freely around a given irregular volume and to spawn off stream lines. A successful application of these techniques to a problem in a clean room is also described.	IEEE Visualizat	visu
1682	IEEE Visualization	Virtual Smoke: An Interactive 3-D Flow Visualization Technique.	K. L. Ma,P. J. Smith	1992	Virtual Smoke: An Interactive 3-D Flow Visualization Technique.	IEEE Visualizat	visu
1683	IEEE Visualization	Visual Query Specification in a Multimedia Database System.	Daniel A. Keim,Vincent Y. Lum	1992	In this paper we describe a visual interface for a Multimedia Database Management System (MDBMS). In spite of the technological advances in display devices, DBMS query languages are still linear in syntax as it was two decades ago. Although natural language interfaces have been found to be useful, natural language is ambiguous and difficult to process. For queries on standard (relational) data these difficulties may be easily avoided with the use of a visual, graphical interface to guide the user in specifying the query. For image and other media data which are ambiguous in nature, we use natural language processing combined with direct graphical access to the domain knowledge to interpret and evaluate the natural language query. The system fully supports graphical and image input/output in different formats. The combination of visual effect and natural language specification, the support of media data, and the allowance of incremental query specification are very effective to simplify the process of query specification not only for image or multimedia databases but also for all databases.	IEEE Visualizat	visu
1684	IEEE Visualization	A 3-D Streamline Tracking Algorithm Using Dual Stream Functions.	David N. Kenwright,G. D. Mallison	1992	A new methodology has been developed for constructing streamlines and particle paths in numerically generated fluid velocity fields. A graphical technique is used to convert the discretely defined flow within a cell into one represented by two three-dimensional stream functions. Streamlines are calculated by tracking constant values of each stream function, a process which corresponds to finding the intersection of two stream surfaces. The tracking process is mass conservative and does not use a time stepping method for integration, thus eliminating a computationally intensive part of traditional tracking algorithms. The method can be applied generally to any three-dimensional compressible or incompressible steady flow. Results presented here compare the performance of the new method to the most commonly used scheme and show that calculation times can be reduced by an order of magnitude.	IEEE Visualizat	visu
1685	IEEE Visualization	An Efficient Range Search Algorithm for Visualizing Extrema of Volume Data.	X. Wu,Y. Fang	1992	This article presents a new, fast range search algorithm for visualizing extrema of d-dimensional volume data in real time as the user interactively moves the query range. The new algorithm is based on an efficient data structure, called index heap, which needs only O(N/logN) space and O(d2dN) preprocessing time to be set up, where N is the size of d-dimensional data volume. The algorithm can answer an extremum query in O(4d) expected time and its worst case time complexity is O(2d log N) per query. For dimensions two and three, we can consider that the range search for extrema is effected in average O(1) time per query independent of the size of query range. Unlike the present range query algorithms in the computational geometry literature, the proposed algorithm is very simple and can be easily implemented by practitioners.	IEEE Visualizat	visu
1686	IEEE Visualization	A Scientific Visualization Renderer.	Bruce Lucas	1992	While scientific visualization systems share many requirements with other graphical applications, they also pose special requirements that make solutions based on standard rendering hardware or software not entirely satisfactory. This paper illustrates those requirements by describing the renderer used in a production scientific visualization system, Data Explorer [1].We begin by setting forth the requirements for a visualization renderer derived from our experiences. We then describe implementation techniques used to meet the requirements of parallelism, volume rendering of irregular data, clipping, and integration of rendering modalities. The renderer described is a software renderer, but it is hoped that the requirements and implementation described here might influence the design of future generations of rendering hardware.	IEEE Visualizat	visu
1687	IEEE Visualization	An Architecture for a Scientific Visualization System.	Bruce Lucas,G. D. Abrams,Nancy S. Collins,D. A. Epstien,Donna L. Gresh,Kevin P. McAuliffe	1992	This paper describes the architecture of Data Explorer, a scientific visualization system. Data Explorer supports visualization of a wide variety of data by means of a flexible set of visualization modules. This paper discusses five elements of the system architecture: 1) A single powerful data model common to all modules that allows a wide range of data types to be imported and passed between modules. 2) Integral support for parallelism, affecting the data model and the execution model. 3) A powerful set of visualization modules that are highly interoperable, due in part to the common data model, and exemplified by the renderer. 4) An execution model designed to facilitate parallelization of modules and incorporating optimizations such as caching. 5) A two-process clientserver system structure consisting of a user interface that communicates with an executive via a dataflow language.	IEEE Visualizat	visu
1688	IEEE Visualization	Visualization of Cardiac Bioelectricty - A Case Study.	Robert S. MacLeod,N. E. Harrison,Christopher R. Johnson,Michael A. Matheson	1992	Visualization of Cardiac Bioelectricty - A Case Study.	IEEE Visualizat	visu
1689	IEEE Visualization	Approximation and Rendering of Volume Data Using Wavelet Transforms.	Shigeru Muraki	1992	A method is presented to obtain a unique shape description of an object by using wavelet transforms. Wavelet transform is a new signal analysis technique which decomposes a signal using a family of functions having a local property in both time and frequency domains. A multiresolution expression of 3D volume data was first obtained by applying 3D orthogonal wavelet transforms, with the shape then being approximated with a relatively small number of 3D orthogonal functions using only the significant functions. In addition, the resolution of the approximation can be varied point by point using the local property of the wavelets. The method is applied to real volume data, i.e., facial range data and MR images of a human head, and typical results are shown.	IEEE Visualizat	visu
1690	IEEE Visualization	Network Video Device Control.	David R. Nadeau,Michael J. Bailey	1992	Today's highly-networked visualization computing environments include systems from a wide variety of hardware vendors, each running its own operating system and sporting its own input, output, display, and storage peripherals. Faced with such a bewildering variety of hardware and software, today's visualization user is in dire need of software systems that integrate these resources over a network and allow him or her to take maximum advantage of them with a minimum of hassle and networking technical knowledge.Video equipment has become one such network resource. Visualization video equipment is used to record visualization animations, process the video signal, play back animations at varying speeds forward and backward, and edit animations into polished final productions. Computer control of video equipment allows many of these operations to be performed automatically or through slick graphical user interfaces. However, the single serial communications line connecting the video device to a host means that one can only access that device via that host. This paper discusses the Video Tools software developed at the San Diego Supercomputer Center (SDSC) to overcome these restrictions and turn a site's video equipment into a network-accessible resource.	IEEE Visualizat	visu
1691	IEEE Visualization	Visualizing Wind Velocities by Advecting Cloud Textures.	Nelson L. Max,Roger Crawfis,D. Williams	1992	In order to visualize both clouds and wind in climate simulations, we have rendered clouds using a 3-D texture which is advected by the wind flow.	IEEE Visualizat	visu
1692	IEEE Visualization	Visualizing Seafloor Structures with Satellite Gravity Measurements.	J. McLeod,C. Small	1992	In recent years, the development of satellite altimetry has opened previously unexplored regions of the world's oceans to exploration by marine geoscientists. By correlating sea surface gravity with seafloor depth, researchers gain insight into the kinematics of seafloor spreading and the physical mechanisms by which the seafloor is formed and deformed. Given that the ocean comprises two thirds of the earth's surface, under which lies a vastly unexplored domain, visualization holds the key in isolating regions of exploration and providing an encompassing perspective that can not be achieved in nature. This case study describes the process of seafloor spreading and discusses some of the concerns with visualizing gravitational acceleration.	IEEE Visualizat	visu
1693	IEEE Visualization	The Microscopist's Workstation.	Philip J. Mercurio,T. Todd Elvins,Stephen J. Young	1992	This case study looks at the issues involved in operating a sophisticated scientific instrument as a computer peripheral accessible over a high-speed network.A custom interactive visualization application was constructed to support investigation using a unique computer-controlled high voltage electron microscope. The researcher's workstation forms the visible third of a triumvirate, with the instrument and the compute resource comprising the other two parts. The software was designed to support not only image acquisition, but also many of the tasks that microscope researchers perform in analyzing images.The result of this case study is the identification of some of the issues regarding interacting with scientific instrumentation over high-speed networks and the construction of custom applications to support many of the tasks within a laboratory's research methodology.	IEEE Visualizat	visu
1694	IEEE Visualization	Visualization of Neutron Scattering Data Using AVS.	R. Popovic	1992	This case study is a result of a six weeks feasibility exercise, the aim of which was to explore the extent to which the existing visualisation software can be used for visualising ISIS Neutron Scattering Data.ISIS, situated at Rutherford Appleton Laboratory, is a world class experimental facility devoted to the use of pulsed neutrons and muons to investigate the microscopic structure and dynamics of all classes of condensed matter.The result of the feasibility study demonstrated the benefits of using visualisation in exploring material science data and it also proved that it is possible to satisfy most of the requirements ISIS researchers place on a software environment by using AVS and without writing any new code.The paper lists the problems encountered and where possible suggests solutions.	IEEE Visualizat	visu
1695	IEEE Visualization	Color, Change and Control for Quantitative Data Display.	Penny Rheingans	1992	Color is used widely and reliably to display the value of a single scalar variable. It is more rarely, and far less reliably, used to display multivariate data. Calico, a dynamic tool for the creation and manipulation of color mappings, adds the element of dynamic control over the color mapping to that of color itself for the more effective display and exploration of multivariate spatial data. Using Calico, a one-or two variable color mapping can be created using parametric equations and a variety of color models. This mapping can be manipulated by moving input devices referenced in the parametric expressions, by applying affine transforms, or by performing free-form deformations. As the user changes the mapping, an image showing the data displayed using the current mapping is updated in real time, along with the images describing the mapping. This paper presents an empirical study investigating the effects of user control and smooth change in the display of quantitative data on user accuracy, confidence, and preference. While the user control did not quite produce a significant effect on accuracy, it did produce significant increases in user preference and confidence.	IEEE Visualizat	visu
1696	IEEE Visualization	Visualization Requirements in the Atmospheric and Environmental Sciences (Five Case Study Reports).	Theresa-Marie Rhyne,M. Bolstad,Penny Rheingans,L. Petterson,W. Shackelford,Mike E. Botts,E. Pepke,K. W. Johnson,William L. Hibbard,Charles R. Dyer,Brian E. Paul,Lloyd Treinish	1992	Visualization Requirements in the Atmospheric and Environmental Sciences (Five Case Study Reports).	IEEE Visualizat	visu
1697	IEEE Visualization	Interactive Visualization of Large Scalar Voxel Fields.	Georgios Sakas,J. Hartig	1992	We present a technique allowing interactive visualization of large, scalar, discrete volume fields as semi-transparent clouds on the fly, i.e., without preprocessing. Interactivity is not restricted to geometric transformations, but includes all possible methods of processing the data (thresholds, filtering, clipping, illumination, etc.). Our system flexibly trades-off quality for performance at any desirable level. In particular, by using a scanline based method and a DDA-based traversing scheme instead of ray-tracing we achieve real-time processing during previewing. By means of the pyramidal volume traversing technique we achieve highquality, constant-time filtering independent of the data resolution. Several filters help to detect fuzzy, obscured hot spots, even within noisy data. Our visualization pipeline allows the application of filters at four different stages, maximizing thereby flexibility. Four different illumination models have been implemented. Our method can be used in numerous areas, including 3-D medical imaging, geologic, technical, and environmental applications.	IEEE Visualizat	visu
1698	IEEE Visualization	Optimizing Triangulation by Curvature Equalization.	Lori L. Scarlatos,Theo Pavlidis	1992	Triangulated irregular networks (TINs) are an attractive form of surface approximation because triangle vertices and edges may be adaptively selected to produce a good fit with a minimal number of triangles. Finding methods for selecting these vertices and edges, however, is still an active area of research. Numerous refinement algorithms have been proposed, but these may produce more triangles than necessary. In this paper we present an algorithm that attempts to improve a triangulation by shifting the vertices so that curvature within the triangles is nearly equal. In addition, unnecessary triangles are removed. We finish with results produced by running this algorithm on simple geometric surfaces and real terrain data.	IEEE Visualizat	visu
1699	IEEE Visualization	VISAGE: An Object-Oriented Scientific Visualization System.	William J. Schroeder,William E. Lorensen,G. D. Montanaro,Christopher R. Volpe	1992	VISAGE is a scientific visualization system implemented in an object-oriented, message passing environment. The system includes over 500 classes ranging from visualization and graphics to Xlib and Motif user interface. Objects are created using compiled C and interact through an interpreted scripting language. The result is a flexible yet efficient system that has found wide application in our user community. This paper describes the object architecture and the major issues we faced when designing the visualization classes. Sample applications are also described.	IEEE Visualizat	visu
1700	IEEE Visualization	Surface Curvature Analysis Using Color.	L. R. Seidenberg,Robert B. Jerard,J. Megewick	1992	In the automotive industry it is highly important that the exterior body panels be esthetically pleasing. One aspect of creating esthetically pleasing surfaces is to require that they be fair. In this paper we present a system which has proven useful for diagnosis of surface fairness problems. We describe how to choose a set of colors with perceptually uniform spacing, and also show the usefulness of a logarithmic scale for relating curvature to colors.	IEEE Visualizat	visu
1701	IEEE Visualization	A Characterization of the Scientific Data Analysis Process.	R. R. Springmeyer,Meera Blattner,Nelson L. Max	1992	Extensible scientific visualization tools are often offered as data analysis tools. While images may be the goal of visualization, insight is the goal of analysis. Visualization tools often fail to reflect this fact both in functionality and in their user interfaces, which typically focus on graphics and programming concepts rather than on concepts more meaningful to end-user scientists. This paper presents a characterization which shows how data visualization fits into the broader process of scientific data analysis. We conducted an empirical study, observing scientists from several disciplines while they analyzed their own data. Examination of the observations exposed process elements outside conventional image viewing. For example, analysts queried for quantitative information, made a variety of comparisons, applied math, managed data, and kept records. The characterization of scientific data analysis reveals activity beyond that traditionally supported by computer. It offers an understanding which has the potential to be applied to many future designs, and suggests specific recommendations for improving the support of this important aspect of scientific computing.	IEEE Visualizat	visu
1702	IEEE Visualization	Representing Medical Images with Partitioning Trees.	Kalpathi R. Subramanian,Bruce F. Naylor	1992	Discrete space representation of images arise as a consequence of the transducers between the physical and informational domains. While discrete representations (arrays of pixels) are simple, they are also verbose and structureless. We present a method of converting between a discrete space representation to a particular continuous space representation, viz. the <u>binary space partitioning tree</u>. The conversion is accomplished using standard discrete space operators developed for edge detection, followed by a Hough transform to generate candidate hyperplanes that are used to construct the partitioning tree. The result is a segmented and compressed image represented in continuous space suitable for elementary computer vision operations and improved image transmission/storage. The method is more noise tolerant than methods whose target is a topological representation, and more adaptive than axis-aligned spatial partitioning schemes. Affine transformations needed for interactive manipulation are fast and edges do not blur with enlargement of the image. Efficient algorithms are known for spatial operations, such as masking/clipping and compositing. We give several examples of 256x256 medical images for which we have estimated the compression to range between 1 and 0.5 bits/pixel.	IEEE Visualizat	visu
1703	IEEE Visualization	Volume Warping.	T. J. True,J. F. Hughes	1992	We present volume warping, a technique for deforming sampled volumetric data using B-splines that is related to image warping and to the free-form deformations of Sederberg/Parry and Coquillart. We accelerate the process to near-real-time speed, and explain the compromises that are made to effect such speeds. This technique expands the repertoire of volumetric modeling techniques, and can be applied to any form of volumetric data.	IEEE Visualizat	visu
1704	IEEE Visualization	Improving the Visualization of Hierarchies with Treemaps: Design Issues and Experimentation.	David Turo,B. Johnson	1992	Controlled experiments with novice treemap users and real data highlight the strengths of treemaps and provide direction for improvement. Issues discussed include experimental results, layout algorithms, nesting offsets, labeling, animation and small multiple displays. Treemaps prove to be a potent tool for hierarchy display. The principles discussed are applicable to many information visualization situations.	IEEE Visualizat	visu
1705	IEEE Visualization	Rendering Surface Particles.	Jarke J. van Wijk	1992	Rendering Surface Particles.	IEEE Visualizat	visu
1706	IEEE Visualization	Interactive Splatting of Nonrectilinear Volumes.	Peter L. Williams	1992	This paper describes various techniques for achieving interactive direct volume rendering of nonrectilinear data sets using fast projection (splatting) methods. The use of graphics hardware, rendering approximations, parallelization and reduced resolution meshes are discussed. Results from the use of these techniques are presented in the form of color photos and comparative timings.	IEEE Visualizat	visu
1707	IEEE Visualization	The State of the Art of Visual Languages for Visualization.	Carla S. Williams,John Rasure,C. Hansen	1992	Data flow visual language systems are now being used to provide sophisticated environments for the visualization of scientific data. These systems are evolving rapidly and are beginning to encompass related technologies such as distributed computing and user interface development systems. This paper presents a hierarchical classification of the components and issues involved, giving the reader an understanding of the design decisions and trade-offs that the developers of these systems are making. The component categories can be used as a framework for discussing where interoperability of competing visual programming environments might occur and what the future holds for these systems.	IEEE Visualizat	visu
1708	IEEE Visualization	Direct Volumetric Visualization.	R. D. Williams,F. L. Wefer,T. E. Clifton	1992	The need for true 3D volumetric displays derives from the fact that the human visual system has evolved to perceive and comprehend the world in three dimensions. The Texas Instruments OmniView&trade; display technology provides the capability to display computer graphics images in true 3D. Viewers can see the display from all angles and change views simply by walking around the display volume. The OmniView&trade;; device uses lasers of three different colors to project images on a moving surface sweeping through the 3D cylindrical display volume. The concept of operations is discussed, along with some details of the moving surface and parameters of the resulting display. The transport theory for this type of display involves only the source term in the linear Boltzmann equation. Constraints of the technology imposed by this limitation are discussed, along with discussions of image quality, current applications, and plans for improved devices.	IEEE Visualizat	visu
1709	IEEE Visualization	A Voxel-Based, Forward-Projection Algorithm for Rendering Surface and Volumetric Data.	John R. Wright,Julia C. Hsieh	1992	In this paper we present a voxel-based, forward projection algorithm with a pipeline architecture for real-time applications. The multi-sensor capabilities (electro-optical, or visual, and infrared) currently implemented in software have also been applied to non-real-time imaging applications on workstations and minicomputers. Most suited for terrain based applications, the system features haze, imbedded targets, moving objects, smooth shading, and specular reflections.	IEEE Visualizat	visu
1710	IEEE Visualization	Visualizing Classical Problems in CFD.	Norman Zabusky,Deborah Silver	1992	Visualizing Classical Problems in CFD.	IEEE Visualizat	visu
1711	IEEE Visualization	Proceedings IEEE Visualization '92	Arie E. Kaufman,Gregory M. Nielson	1992	Proceedings IEEE Visualization '92	IEEE Visualizat	visu
1712	ICDE	IsaLog: A declarative language for complex objects with hierarchies.	Paolo Atzeni,Luca Cabibbo,Giansalvatore Mecca	1993	The IsaLog model and language are presented. The model has complex objects with classes, relations, and is a hierarchies. The language is strongly types and declarative. The main issue is the definition of the semantics of the language, given in three different ways that are shown to be equivalent: a model-theoretic semantics, a reduction to logic programming with function symbols, and a fixpoint semantics. Each of the semantics presents new aspects with respect to existing proposals because of the interaction of oid-invention with general is a hierarchies. The solutions are based on the explicit Skolem functors, which provide a powerful tool for manipulating object-identifiers	ICDE	database
1713	ICDE	A Query Model for Object-Oriented Databases.	Reda Alhajj,M. Erol Arkun	1993	A formal object-oriented query model is described in terms of an object algebra. Both the structure and the behavior of objects are handled. An operand and the output from a query in the object algebra are defined to have a pair of sets, i.e. a set of objects and a set of message expressions, where a message expression is a valid sequence of messages. The closure property is therefore maintained in a natural way. In addition, it is proven that the output from a query has the characteristics of a class; hence, the inheritance relationship between the operand and the output from a query is derived	ICDE	database
1714	ICDE	Integrating Functional and Data Modeling in a Computer Integrated Manufacturing System.	Nabil R. Adam,Aryya Gangopadhyay	1993	A structured methodology for linking data modeling with functional modeling in a computer integrated manufacturing system is presented. The target application, the functional and data models, and a method for developing the data model starting from the functional model are described. This approach ensures that the data model is complete and non-redundant with respect to the functional model. A scheme that enables various functions in the functional model to be linked with the data elements of the data model is also presented. Such a linkage makes it possible to determine the impact of a change in the functional model on the data model and vice versa	ICDE	database
1715	ICDE	Dynamic Query Optimization in Rdb/VMS.	Gennady Antoshenkov	1993	Addresses the key theoretical and practical issues of dynamic query optimization and reviews the underlying reasoning that cements the basic concepts of dynamic query optimization. The optimization mechanics are described, in concert with explanations of why and how certain arrangements contribute to a given optimization goal. Compared to traditional approaches, dynamic query optimization offers a much more realistic view of cost distribution modeling. It is a competition-based architecture that is capable of resolving the major limitations of static optimization, viz. the problems of data skew, cost function instability, and host-variable sensitivity	ICDE	database
1716	ICDE	The O++ Database Programming Language: Implementation and Experience.	Rakesh Agrawal,Shaul Dar,Narain H. Gehani	1993	Ode, a database system and environment based on the object paradigm, is discussed. Ode is defined, queried and manipulated using the database programming language O++, which is based on C++. The O++ compiler translates O++ programs into C++ programs that contain calls to the Ode object manager. The implementation of O++, the Ode object manager, and the translation of the database facilities in O++ are described. The problems encountered in the implementation and their resolutions are reviewed	ICDE	database
1717	ICDE	An Access Structure for Generalized Transitive Closure Queries.	Rakesh Agrawal,Jerry Kiernan	1993	An access structure that accelerates the processing of generalized transitive closure queries is presented. For an acyclic graph, the access structure consists of source-destination pairs arranged in a topologically sorted order. For a cyclic graph, entries in the structure are approximately topologically sorted. The authors present a breadth-first algorithm for creating such a structure, show how it can be used to process queries, and describe incremental techniques for maintaining it	ICDE	database
1718	ICDE	Adaptive Block Rearrangement.	Sedat Akyürek,Kenneth Salem	1993	An adaptive technique for reducing disk seek times is described. The technique copies frequently referenced blocks from their original locations to reserved space near the middle of the disk. Reference frequencies need not be known in advance. Instead, they are estimated by monitoring the stream of arriving requests. Trace-driven simulations show that seek times can be cut substantially by copying only a small number of blocks using this technique. The technique has been implemented by modifying a UNIX device driver. No modifications are required to the file system that uses the driver.	ICDE	database
1719	ICDE	The Gold Mailer.	Daniel Barbará,Chris Clifton,Fred Douglis,Hector Garcia-Molina,Stephen Johnson,Ben Kao,Sharad Mehrotra,Jens Tellefsen,Rosemary Walsh	1993	The Gold Mailer, a system that provides users with an integrated way to send and receive messages using different media, efficiently store and retrieve these messages, and access a variety of sources of other useful information, is described. The mailer solves the problems of information overload, organization of messages and multiple interfaces. By providing good storage and retrieval facilities, it can be used as a powerful information processing engine covering a range of useful office information. The Gold Mailer's query language, indexing engine, file organization, data structures, and support of mail message data and multimedia documents are discussed	ICDE	database
1720	ICDE	A New Algorithm for Computing Joins with Grid Files.	Ludger Becker,Klaus Hinrichs,Ulrich Finke	1993	The BR2-directory representation, a directory structure for grid files, and a join algorithm for the evaluation of general n -ary joins on grid files are presented. It is shown that the CPU cost of the join algorithm is successfully reduced by introducing an inner join. A comparison with the hash join algorithm and a join algorithm on k-d trees for equijoins is based on a cost model developed for query processing with grid files. The join algorithm outperforms the hash join, a specialized join method for equijoins, and the join algorithm on k-d trees for equijoins	ICDE	database
1721	ICDE	Title, Message from the General Chairs, Message from the Program Chairs, Committees, Reviewers, Author Index.		1993	Title, Message from the General Chairs, Message from the Program Chairs, Committees, Reviewers, Author Index.	ICDE	database
1722	ICDE	Comparison of Approximations of Complex Objects Used for Approximation-based Query Processing in Spatial Database Systems.	Thomas Brinkhoff,Hans-Peter Kriegel,Ralf Schneider	1993	The minimum bounding box, the convex hull, the minimum bounding four- and five-corner, rotated boxes, and the minimum bounding ellipses and circles convex conservative approximation methods for handling complex spatial objects in spatial access methods are discussed. Results indicate that, depending on the complexity of the objects and the type of queries, the approximations five-corner, ellipse and rotated bounding box clearly outperform the bounding box. It is the reduced number of false hits that yields a considerable improvement in total query time when using the proposed approximations	ICDE	database
1723	ICDE	A Simple Analysis of the LRU Buffer Policy and Its Relationship to Buffer Warm-Up Transient.	Anupam Bhide,Asit Dan,Daniel M. Dias	1993	A simple analysis for the transient buffer hit probability for a system starting with an empty buffer is presented. The independent reference model (IRM) is used for buffer accesses. It is shown that the expected buffer hit probability when the buffer becomes full is virtually identical to the steady state buffer hit probability when the replacement policy is least recently used (LRU). The method is generalized to estimate the transient behavior of the LRU policy starting with a non-empty buffer. It is shown that this method can be used to estimate the effect of a load surge on the buffer hit probability. It is also shown that after a short load surge, it can take much longer than the surge duration for the buffer hit probability to return to its steady state value	ICDE	database
1724	ICDE	A Language Multidatabase System Communication Protocol.	Omran A. Bukhres,eva Kühn,Franz Puntigam	1993	Rapid growth in the area of multidatabase systems (MDBSs), which involve both the access of global data and distributed transaction processing, has created a need for programming languages that provide communication reliability and powerful synchronization. The requirements of MDBSs are reviewed, and the Vienna Parallel Logic programming language is presented. The ways to realize an MDBS communication protocol in this language are discussed. The Vienna Parallel Logic language incorporates a concurrent logic language, as well as features of both distributed operating systems and database management systems. These features combine to support the communication and synchronization required by distributed transaction processing. The Vienna Parallel Logic language is suitable for use as a general-purpose distributed programming and coordination language	ICDE	database
1725	ICDE	A Bottom-up Query Evaluation Method for Stratified Databases.	Yangjun Chen	1993	A labeling algorithm for stratified databases is presented. The algorithm that is performed prior to the magic-set algorithm can be used to distinguish the context for constructing magic sets. It is shown that the culprit cycles cause the destratification of a database. Based on this analysis, three subprocedures are developed to remove the different kinds of culprit cycles. The negnumber procedure numbers the different occurrences of a negative literal in a rule. The dynlabel procedure gives each negative body literal a dynamic subscript when it appears in a recursive rule. The label procedure labels each body literal p when there exists a sequence of paths connecting it to a negative body literal-q in the same rule, or a sequence of paths with at least one path being negative connecting it to a positive body literal q in the same rule and there is an arc of the form N&rarr;r in the sideways information-passing strategy (SIPS) such that q&isin;N and p=r	ICDE	database
1726	ICDE	Using Active Database Techniques For Real Time Engineering Applications.	Aloysius Cornelio,Shamkant B. Navathe	1993	An active database model for representing engineering design, simulation and monitoring applications is described. The physical aspects of these applications are modeled by structural objects. The functions of the application are modeled by functional objects. The interaction between structures and functions is modeled by interaction objects. Events relate structures and functions such that any state change will cause the functional model to compute the new consistent state of the application. Ways to model event correlation, event recall, and ways to define schemas for continuous systems are presented. A parallel computing architecture and a set of guidelines on task distributing that make the model applicable to real-time application are discussed	ICDE	database
1727	ICDE	Database Technology and Standards: Are we Getting Anywhere? (Panel Abstract).	Peter Dadam,Shamkant B. Navathe	1993	Database Technology and Standards: Are we Getting Anywhere? (Panel Abstract).	ICDE	database
1728	ICDE	Database Access Characterization for Buffer Hit Prediction.	Asit Dan,Philip S. Yu,Jen-Yao Chung	1993	Presents a database access characterization method that first distinguishes three types of access pattern from a trace-locality within a transaction, random accesses by transactions, and sequential accesses by long queries. The authors describe a concise way to characterize the access skew across the randomly accessed pages by assuming that the large number of data pages may be logically grouped into a small number of partitions, such that the frequency of accessing each page within a partition can be treated as equal. They present an extensive validation of the buffer hit predictions, both for single-node as well as multiple-node systems, based on access characterization using production database traces. This approach can be applied to predict the buffer hit probability of a composite workload from those of its component files	ICDE	database
1729	ICDE	Polyglot: Extensions to Relational Databases for Sharable Types and Functions in a Multi-Language Environment.	Linda G. DeMichiel,Donald D. Chamberlin,Bruce G. Lindsay,Rakesh Agrawal,Manish Arya	1993	Polyglot is an extensible relational-database-type system that supports inheritance, encapsulation, and dynamic method dispatch. It allows use from multiple application languages and permits objects to retain their behavior as they cross the boundary between database and application program. The authors describe the design of Polyglot, extensions to the structured query language (SQL) to support the use of Polyglot types and methods, and the implementation of Polyglot in the Starburst relational database system	ICDE	database
1730	ICDE	Valid-time Indeterminancy.	Curtis E. Dyreson,Richard T. Snodgrass	1993	Valid-time Indeterminancy.	ICDE	database
1731	ICDE	The Design, Implementation, and Evaluation of an Object-Based Sharing Mechanism for Federated Database Systems.	Doug Fang,Shahram Ghandeharizadeh,Dennis McLeod,Antonio Si	1993	An approach and mechanism to support the sharing of objects are described, an experimental implementation is presented, and the performance of the system is analyzed and evaluated. The mechanism is based on a core set of constructs that characterize object-based database systems. The approach provides a basis for controlled sharing in a heterogeneous database environment, using a kernel object-base model as an intercomponent exchange forum. A major goal is to make the importation of nonlocal information as transparent to a component as possible	ICDE	database
1732	ICDE	Voltaire: A Database Programming Language with a Single Execution Model for Evaluating Queries, Constraints amd Functions.	Sunit K. Gala,Shamkant B. Navathe,Manuel E. Bermudez	1993	Voltaire: A Database Programming Language with a Single Execution Model for Evaluating Queries, Constraints amd Functions.	ICDE	database
1733	ICDE	Deriving Integrity Maintaining Triggers from Transition Graphs.	Michael Gertz,Udo W. Lipeck	1993	Methods for deriving constraint maintaining triggers from dynamic integrity constraints represented by transition graphs are presented. The methods reduce integrity monitoring to checking changing static conditions according to life cycle situations. Thus, triggers have to be generated from these graphs, which depend not only on the operations that have occurred in a transaction, but also on the situations that have been reached by the objects mentioned in the constraints. The techniques presented work for dynamic constraints and their corresponding transition graphs as well as for simple static constraints. Only passive reactions (rollbacks) to constraint violations are provided by the trigger patterns, but the systematic generation of such patterns should help the database designer in identifying possible active reactions for repairing constraint violations	ICDE	database
1734	ICDE	Audio/Video Databases: An Object-Oriented Approach.	Simon J. Gibbs,Christian Breiteneder,Dennis Tsichritzis	1993	The notion of an audio/video (AV) database is introduced. An AV database is a collection of AV values such as digital audio and video data and AV activities such as interconnectable components used to process AV values. Two abstraction mechanisms, temporal composition and flow composition, allow the aggregation of AV values and AV activities respectively. An object-oriented framework, incorporating an AV data model and prescribing AV database/application interaction, is described	ICDE	database
1735	ICDE	A Descriptive Semantic Formalism for Medicine.	Carole A. Goble,Andrzej J. Glowinski,W. A. Nowlan,Alan L. Rector	1993	It is argued that current clinical information systems incorporate oversimplistic, prescriptive data models that are not faithful to clinicians' observations. A non-prescriptive descriptive semantic formalism, Structured Meta Knowledge (SMK), which unifies a terminological knowledge base with controlled assertional capabilities with the medical record and supports the semantic control necessitated by such an approach, is proposed. The three-layer model of categories, individuals, and occurrences described is more appropriate to medical applications than the two layers of classes and instances. The application of SMK in predictive data entry is considered	ICDE	database
1736	ICDE	Definition and Application of Metaclasses in an Object-Oriented Database Model.	Jutta Göers,Andreas Heuer	1993	The metalevel concepts for an object-oriented database model are presented. Usually, systems that include a metaclass concept are either only implicitly supporting the management of meta information, which restricts the application of this concept, or explicitly giving unrestricted access to manipulate metaclasses, which results in inconsistent states of the system. To make the explicit support more system-controlled, the metascheme is partitioned into two parts: the system view and the application view. Possible scheme level operations, the representation of methods and their implementation as a special kind of meta information, and a simple extension to the query algebra of the underlying object-oriented database system that allow users to query objects and metaobjects within a single algebra expression are described	ICDE	database
1737	ICDE	The Volcano Optimizer Generator: Extensibility and Efficient Search.	Goetz Graefe,William J. McKenna	1993	The Volcano project, which provides efficient, extensible tools for query and request processing, particularly for object-oriented and scientific database systems, is reviewed. In particular, one of its tools, the optimizer generator, is discussed. The data model, logical algebra, physical algebra, and optimization rules are translated by the optimizer generator into optimizer source code. It is shown that, compared with the EXODUS optimizer generator prototype, the search engine of the Volcano optimizer generator is more extensible and powerful. It provides effective support for non-trivial cost models and for physical properties such as sorting order. At the same time, it is much more efficient, as it combines dynamic programming with goal-directed searching and branch-and-bound pruning. Compared with other rule-based optimization systems, it provides complete data model independence and more natural extensibility	ICDE	database
1738	ICDE	Efficient Computation of Spatial Joins.	Oliver Günther	1993	Spatial joins are join operations that involve spatial data types and operators. Due to basic properties of spatial data, many conventional join strategies suffer serious performance penalties or are not applicable at all. The join strategies known from conventional databases that can be applied to spatial joins and the ways in which some of these techniques can be modified to be more efficient in the context of spatial data are discussed. A class of tree structures, called generalization trees, that can be applied efficiently to compute spatial joins in a hierarchical manner are described. The performances of the most promising strategies are analytically modeled and compared	ICDE	database
1739	ICDE	Normalization of Linear Recursions in Deductive Databases.	Jiawei Han,Kangsheng Zeng,Tong Lu	1993	A graph-matrix expansion-based compilation technique that transforms complex linear recursions into highly regular linear normal forms (LNFs) is introduced. A variable connection graph-matrix, the V-matrix, is constructed to simulate the expansions of a linear recursion and discover its expansion regularity. Based on the expansion regularity, a linear recursion can be normalized into an LNF. The normalization of linear recursions not only captures the bindings that are difficult to be captured otherwise but also facilitates the development of powerful query analysis and evaluation techniques for complex linear recursions in deductive databases	ICDE	database
1740	ICDE	Data fragmentation for parallel transitive closure strategies.	Maurice A. W. Houtsma,Peter M. G. Apers,Gideon L. V. Schipper	1993	Addresses the problem of fragmenting a relation to make the parallel computation of the transitive closure efficient, based on the disconnection set approach. To better understand this design problem, the authors focus on transportation networks. These are characterized by loosely interconnected clusters of nodes with a high internal connectivity rate. Three requirements that have to be fulfilled by a fragmentation are formulated, and three different fragmentation strategies are presented, each emphasizing one of these requirements. Some test results are presented to show the performance of the various fragmentation strategies	ICDE	database
1741	ICDE	Efficient Evaluation of Traversal Recursive Queries Using Connectivity Index.	Kien A. Hua,Jeffrey X. W. Su,Chau M. Hua	1993	Introduces the connectivity index, an access structure for the efficient evaluation of traversal-recursive queries. Unlike conventional bottom-up evaluation techniques that require the creation of temporary files and scanning of the relations many times in computing the relational operators, the new access strategy requires only a single-pass scan of the index file. The proposed scheme is illustrated using examples. Algorithms for the maintenance of the index structure are presented	ICDE	database
1742	ICDE	A Competitive Dynamic Data Replication Algorithm.	Yixiu Huang,Ouri Wolfson	1993	A distributed algorithm for dynamic data replication of an object in a distributed system is presented. The algorithm changes the number of replicas and their location in the distributed system to optimize the amount of communication. The algorithm dynamically adapts the replication scheme of an object to the pattern of read-write requests in the distributed system. It is shown that the cost of the algorithm is within a constant factor of the lower bound	ICDE	database
1743	ICDE	Performance Characteristics of Epsilon Serializability with Hierarchical Inconsistency Bounds.	Mohan Kamath,Krithi Ramamritham	1993	Epsilon serializability (ESR) is a weaker form of correctness designed to provide more concurrency than classic serializability (SR) by allowing, for example, query transactions to view incon- sistent data in a controlled fashion $i.e.$ limiting the incon- sistency within the specified bounds. In the previous literature on ESR, inconsistency bounds have been specified with respect to transactions or with respect to objects. In this paper, we in- troduce the notion of hierarchical inconsistency bounds that al- lows inconsistency to be specified at different granularities. The motivation for this comes from the way data is usually organ- ized, in hierarchical groups, based on some common features and interrelationships. Bounds on transactions are specified at the top of the hierarchy, while bounds on the objects are specified at the bottom and on groups in between. We also discuss mechan- isms needed to control the inconsistency so that it lies within the specified bounds. While executing a transaction, the system checks for possible violation of inconsistency bounds bottom up, starting with the object level and ending with the transaction level. Thus far, to our knowledge, no work has been done to determine the quantitative performance improvement resulting from ESR. Hence in this paper we report on an evaluation of the performance improvement due to ESR incorporating hierarchical inconsistency bounds. The tests were performed on a prototype transaction pro- cessing system that uses timestamp based concurrency control. For simplicity, our implementation uses a two level hierarchy for inconsistency specification - the transaction level and the ob- ject level. We present the results of our performance tests and discuss how the behavior of the system is influenced by the tran- saction and object level inconsistency bounds. We make two im- portant observations from the tests. First, the thrashing point shifts to a higher multiprogramming level when transaction incon- sistency bounds are increased. Further, for a particular mul- tiprogramming level and a particular transaction inconsistency bound, the throughput does not increase with increasing object inconsistency bounds but peaks at some intermediate value. --------------- This material is based upon work supported by the National Science Foundation under grant IRI-9109210. ******************************************************************************	ICDE	database
1744	ICDE	A Framework for Declarative Updates and Constraint Maintenance in Object-Oriented Databases.	Anton P. Karadimce,Susan Darling Urban	1993	A framework for supporting ad-hoc declarative update requests in an object-oriented database (OODB) while maintaining database consistency and atomicity of update requests is described. The framework is based on the emulation of classic update methods in an OODB by a controlled, active, and user-transparent interaction between a predefined set of elementary updates and a set of integrity methods designed to maintain database consistency upon violations of integrity constraints. Given an object-oriented data model and a declarative query language, this framework is extended by isolating declaratively stated integrity constraints as a separate concept, developing a high-level update language on top of the query language, and developing active integrity methods from the integrity constraints. The advantage of this approach is that users can freely pose declarative ad-hoc updates without jeopardizing database consistency	ICDE	database
1745	ICDE	Unification of Temporal Data Models.	Christian S. Jensen,Michael D. Soo,Richard T. Snodgrass	1993	A conceptual temporal data model that captures the time-dependent semantics of data while permitting multiple data models at the representation level is described. A conceptual notion of a bitemporal relation in which tuples are stamped with sets of two-dimensional chronons in transaction-time/valid-time space is defined. A tuple-timestamped first normal form representation is introduced to show how the conceptual bitemporal data model is related, by means of snapshot equivalence, with representational models. Querying within the two-level framework is discussed. An algebra is defined at the conceptual level and mapped to the sample representational model in such a way that new operators compute equivalent results for different representations of the same conceptual bitemporal relation	ICDE	database
1746	ICDE	Adaptable Pointer Swizzling Strategies in Object Bases.	Alfons Kemper,Donald Kossmann	1993	Four different approaches to optimizing the access to main memory resident persistent objects-techniques which are commonly referred to as pointer swizzling-are classified and evaluated. To speed up the access along inter-object references, the persistent pointers are transformed (swizzled) into main memory pointers (addresses). The pointer swizzling techniques allow the displacement of objects from the buffer before the end of an application, and the authors contrast them with the performance of an object manager using no pointer swizzling. The results of the quantitative evaluation prove that there is no one superior strategy for all application profiles. An adaptable system that uses the full range of pointer swizzling strategies is presented	ICDE	database
1747	ICDE	Post-crash Log Processing for Fuzzy Checkpointing Main Memory Databases.	Xi Li,Margaret H. Eich	1993	The impact of updating policy and access pattern on the performance of post-crash log processing with a fuzzy checkpointing main memory database (MMDB) is discussed. The problem of restoring the database to a consistent state and several algorithms for post-crash log processing under the various updating alternatives are reviewed. Using an analytic model, the checkpoint behavior and post-crash log processing performance of these algorithms are examined. Analytic results show that deferred updating always takes less time to process the log after a crash	ICDE	database
1748	ICDE	Deterministic Semantics of Set-Oriented Update Sequences.	Christian Laasch,Marc H. Scholl	1993	An iterator is proposed that allows sequences of update operations to be applied in a set-oriented way with deterministic semantics. Because the mechanism is independent of a particular model, it can be used in the relational and in object-oriented ones. Thus, the deterministic semantics of embedded structured query language (SQL) cursors and of triggers that are applied after (set-oriented) SQL updates can be checked. The iterator can be used to apply object-oriented methods, which are usually update sequences defined on a single object, to sets in a deterministic way	ICDE	database
1749	ICDE	Efficient Support of Historical Queries for Multiple Lines of Evolution.	Gad M. Landau,Jeanette P. Schmidt,Vassilis J. Tsotras	1993	A general framework for solving multiple-line history queries is presented. The authors address two important historical queries in this environment: the vertical query and the horizontal query. The vertical query enables a design team to find what its design was at a past instant on its own path of evolution, while the horizontal query provides a design team with the designs of relevant teams at concurrent times in the past	ICDE	database
1750	ICDE	Updating Intensional Predicates in Deductive Databases.	Dominique Laurent,Viet Phan Luong,Nicolas Spyratos	1993	A method for updating deductive databases that allows the insertion or deletion of a fact over intensional predicates in a deterministic manner is presented. It is shown that, contrary to most other approaches, inserting or deleting facts over tensional predicates can always be accomplished without having to make choices. The approach relies on well-founded semantics and on the following two basic approaches: deleted facts are explicitly stored in the database and the inserted and deleted facts may concern any predicate, not just extensional predicates	ICDE	database
1751	ICDE	Representation and Querying in Temporal Databases: the Power of Temporal Constraints.	Manolis Koubarakis	1993	A temporal database model capable of representing absolute, relative, imprecise, and infinite temporal data is proposed. The model is based on temporal tables such as relation-like representations that can contain variables constrained by the formulas of a temporal theory. An algebraic query language for temporal tables is defined, and some problems related to query answering are discussed	ICDE	database
1752	ICDE	Workload Balance and Page Access Scheduling For Parallel Joins In Shared-Nothing Systems.	Chiang Lee,Zue-An Chang	1993	A methodology to resolve balancing and scheduling issues for parallel join execution in a shared-nothing multiprocessor environment are presented. In the past, research on parallel join methods focused on the design of algorithms for partitioning relations and distributing data buckets as evenly as possible to the processors. Once data are uniformly distributed to the processors, it is assumed that all processors will complete their tasks at about the same time. The authors stress that this is true if no further information, such as page-level join index, is available. Otherwise, the join execution can be further optimized and the workload in the processors may still be unbalanced. The authors study these problems in a shared-nothing environment	ICDE	database
1753	ICDE	Entity Identification in Database Integration.	Ee-Peng Lim,Jaideep Srivastava,Satya Prabhakar,James Richardson	1993	The objective of entity identification is to determine the correspondence between object instances from more than one database. Entity identification at the instance level, assuming that schema level heterogeneity has been resolved a priori, is examined. Soundness and completeness are defined as the desired properties of any entity identification technique. To achieve soundness, a set of identity and distinctness rules are established for entities in the integrated world. The use of extended key, which is the union of keys, and possibly other attributes, from the relations to be matched, and its corresponding identify rule are proposed to determine the equivalence between tuples from relations which may not share any common key. Instance level functional dependencies (ILFD), a form of semantic constraint information about the real-world entities, are used to derive the missing extended key attribute values of a tuple	ICDE	database
1754	ICDE	Automating Fine Concurrency Control in Object-Oriented Databases.	Carmelo Malta,José Martinez	1993	Four major problems that complicate read and write accesses to instances in object-oriented databases are discussed. The four problems are: difficulty in providing ad hoc commutativity relations, lacking overhead, lacking escalation, and pseudo-conflicts. It is shown that all of these problems can be solved by providing a simple form of commutativity. This kind of commutativity is syntactically extracted from the source codes of the methods at compile-time. Then, an efficient linear algorithm calculates the transitive access vectors. Finally, transitive access vectors are translated into classical access modes in order not to incur performance penalty at run-time. Related works on access vectors and field locking are reviewed	ICDE	database
1755	ICDE	Object Queries over Relational Databases: Language, Implementation, and Applications.	Victor M. Markowitz,Arie Shoshani	1993	A query language called the Concise Object Query Language (COQL) is described. COQL is unique in its conciseness, in its support of inheritance, and in the capabilities it provides for defining application-specific structures. The COQL-to-SQL translation, its implementation on top of a commercial relational DBMS, and the ways in which COQL can be used for constructing application-specific views for scientific applications are discussed. The typical three-level architecture approach for supporting data management applications and previous work on the translation of extended entity-relationships schemas into relational database management system schemas are reviewed	ICDE	database
1756	ICDE	Feature-Based Retrieval of Similar Shapes.	Rajiv Mehrotra,James E. Gary	1993	A shape similarity-based retrieval method for image databases that supports a variety of queries is proposed. It is flexible with respect to the choice of feature and definition of similarity and is implementable using existing multidimensional point access methods. A prototype system that handles the problems of distortion and occlusion is described. Experiments with one specific point access method (PAM) are presented	ICDE	database
1757	ICDE	Batch Scheduling in Parallel Database Systems.	Manish Mehta,Valery Soloviev,David J. DeWitt	1993	Many techniques for query scheduling in a parallel database system schedule a single query at a time. The scheduling of queries for parallel database systems by dividing the workload into batches is investigated. Scheduling algorithms that exploit the common operations within the queries in a batch are proposed. The performance of the proposed algorithms is studied using a simple analytical model and a detailed simulation model. It is shown that batch scheduling can provide significant savings compared to single query scheduling for a variety of system and workload parameters	ICDE	database
1758	ICDE	Construction of a Relational Front-end for Object-Oriented Database Systems.	Weiyi Meng,Clement T. Yu,Won Kim,Gaoming Wang,Tracy Pham,Son Dao	1993	Proposes a solution for the construction of a relational front-end for object-oriented database systems (OODBs). Rules are provided to transform the structural part of an OODB scheme to an equivalent relational scheme to provide relational users with a relational view of the OODB scheme. A mechanism based on a relational predicate graph and an OODB predicate graph is provided to translate relational queries to OODB queries to allow relational users access to data stored in an OODB database system	ICDE	database
1759	ICDE	SQL/XNF - Processing Composite Objects as Abstractions over Relational Data.	Bernhard Mitschang,Hamid Pirahesh,Peter Pistor,Bruce G. Lindsay,Norbert Südkamp	1993	SQL/XNF - Processing Composite Objects as Abstractions over Relational Data.	ICDE	database
1760	ICDE	Towards More Flexible Schema Management in Object Bases.	Guido Moerkotte,Andreas Zachmann	1993	An approach to database schema management is presented that allows easy tailoring of schema management, high-level specification of schema consistency, and development of advanced tools supporting the user during schema evolution. The application of this approach to the development of a simple schema manager for the core of the GOM database programming language is described. The flexibility afforded both developers and users by the approach is also discussed	ICDE	database
1761	ICDE	ARIES/LHS: A Concurrency Control and Recovery Method Using Write-Ahead Logging for Linear Hashing with Separators.	C. Mohan	1993	The algorithm for recovery and isolation exploitation semantics for linear hashing with separators (ARIES/LHS) that controls concurrent operations on storage structures by different users is presented. The algorithm uses fine granularity locking, guarantees serializability, and prevents rolling back transactions from getting involved in deadlocks	ICDE	database
1762	ICDE	Algorithms for the Management of Remote Backup Data Bases for Disaster Recovery.	C. Mohan,Kent Treiber,Ron Obermarck	1993	A method for managing a remote backup database to provide protection from disasters that destroy the primary database is presented. The method is general enough to accommodate the ARIES-type recovery and concurrency control methods as well as the methods used by other systems such as DB2, DL/I and IMS Fast Path. It provides high performance by exploiting parallelism and by reducing inputs and outputs using different means, like log analysis and choosing a different buffer management policy from the primary one. Techniques are proposed for checkpointing the state of the backup system so that recovery can be performed quickly in case the backup system fails, and for allowing new transaction activity to begin even as the backup is taking over a primary failure. Some performance measurements taken from a prototype are also presented	ICDE	database
1763	ICDE	The Correctness of Concurrency Control for Multiversion Database Systems with Limited Number of Versions.	Tadeusz Morzy	1993	The concurrency control problem for multiversion database systems (MVDBSs) with system-imposed upper bounds on the total number of data item versions stored in the database is considered. Concurrency control theory for MVDBSs is reviewed. The inadequacy of this theory for analyzing concurrency control algorithms for k-version database systems (KVDBSs) is demonstrated. A formal concurrency control theory for KVDBS is presented. It is developed in terms of KV schedules. The relationships among mono-multi, and KV schedules are summarized	ICDE	database
1764	ICDE	Semantic Concurrency Control in Object-Oriented Database Systems.	Peter Muth,Thomas C. Rakow,Gerhard Weikum,Peter Brössler,Christof Hasse	1993	A locking protocol for object-oriented database systems (OODBSs) is presented. The protocol can exploit the semantics of methods invoked on encapsulated objects. Compared to conventional page-oriented or record-oriented concurrency control protocols, the proposed protocol greatly improves the possible concurrency because commutative method executions on the same object are not considered as a conflict. An OODBS application example is presented. The principle of open-nested transactions is reviewed. It is shown that, using the locking protocol in an open-nested transaction, the locks of a subtransaction are released when the subtransaction completes, and only a semantic lock is held further by the parent of the subtransaction	ICDE	database
1765	ICDE	Sampling from Spatial Databases.	Frank Olken,Doron Rotem	1993	Techniques for obtaining random point samples from spatial databases are described. Random points are sought from a continuous domain that satisfy a spatial predicate which is represented in the database as a collection of polygons. Several applications of spatial sampling are described. Sampling problems are characterized in terms of two key parameters: coverage (selectivity), and expected stabbing number (overlap). Two fundamental approaches to sampling with spatial predicates, depending on whether one samples first or evaluates the predicate first, are discussed. The approaches are described in the context of both quadtrees and R-trees, detailing the sample-first, A/R-tree, and partial area tree algorithms. A sequential algorithm, the one-pass spatial reservoir algorithm, is also described	ICDE	database
1766	ICDE	An Object-Oriented View Onto Public, Heterogeneous Text Databases.	Andreas Paepcke	1993	Even though companies maintain highly-structured traditional business data in relational databases, large amounts of information are available in semi-structured text sources such as indexed online newspapers, patent information, literature citations, or business profiles. This information is offered by commercial providers who maintain complete control over access language, schemas and update capabilities. One way to unify access to all of this material is to make it look like a collection of objects in an object-oriented database. Such a view has been prototyped on an information service that provides some 400 full-text, bibliographic and numeric databases. The authors explain how the illusion of object-orientedness is put together and how it is maintained in queries. They also know how the object-oriented approach is used to handle some classes of schema heterogeneity	ICDE	database
1767	ICDE	JazzMatch: Fine-Grained Parallel Matching for Large Rule Sets.	Marco Richeldi,Jack Tan	1993	JazzMatch, a parallel matching algorithm explicitly designed for secondary memory-based production systems, is presented. JazzMatch is a state-saving algorithm that performs incremental match. It exploits extremely fine-grained parallelism and optimizes the storage state by permitting the sharing of common conditions in the rules. JazzMatch is supported by a message passing parallel architecture. A cost and performance analysis of JazzMatch is provided, and the results are compared with those for other schemes in current literature	ICDE	database
1768	ICDE	SLEVE: Semantic Locking for EVEnt synchronisation.	Andrea H. Skarra	1993	SLEVE: Semantic Locking for EVEnt synchronisation.	ICDE	database
1769	ICDE	Path Computation Algorithms for Advanced Traveller Information System (ATIS).	Shashi Shekhar,Ashim Kohli,Mark Coyle	1993	Three path-planning algorithms for single-pair path computation are evaluated. These algorithms are the iterative breath-first search, Dijkstra's single-source path-planning algorithm, and the A* single-path planning algorithm. The performance of the algorithms is evaluated on graphs representing the roadmap of Minneapolis. In order to get an insight into their relative performance, synthetic grid maps are used as a benchmark computation. The effects of two parameters, namely path length and edge-cost-distribution, on the performance of the algorithms are examined. The effects of implementation decisions on the performance of the A* algorithm are discussed. The main hypothesis is that estimator functions can improve the average-case performance of single-pair path computation when the length of the path is small compared to the diameter of the graph. This hypothesis is examined using experimental studies and analytical cost modeling	ICDE	database
1770	ICDE	Two-Phase Commit Optimizations and Tradeoffs in the Commercial Environment.	George Samaras,Kathryn Britton,Andrew Citron,C. Mohan	1993	Eleven two-phase commit (2PC) protocol variations that optimize towards the normal case are described and compared with a baseline 2PC protocol. Environments in which they are most effective are discussed. The variations are compared and contrasted in terms of number of message flows, number of log writes (both forced and non-forced), probability of heuristic damage, how damage is reported, and other tradeoffs	ICDE	database
1771	ICDE	Algebraic Foundation and Optimization for Object Based Query Languages.	Vijay M. Sarathy,Lawrence V. Saxton,Dirk Van Gucht	1993	The Tarski algebra, an algebraic foundation for object-based query languages, is presented. While maintaining physical data independence, the Tarski algebra is shown to be both simple and powerful enough to express all reasonable queries. It is shown how queries expressed in a graph-oriented query language (based on the functional data model) can be translated into the Tarski algebra. The graphical representation of queries in combination with the Tarski algebra is shown to be a convenient mechanism for effective query optimization	ICDE	database
1772	ICDE	Transaction Support in a Log-Structured File System.	Margo I. Seltzer	1993	The design and implementation of a transaction manager embedded in a log-structured file system are described. Measurements indicate that transaction support on a log-structured file system offers a 10% performance improvement over transaction support on a conventional read-optimized file system. When the transaction manager is embedded in the log-structured file system, the resulting performance is comparable to that of a more traditional, user-level system. The performance results also indicate that embedding transactions in the file system need not impact the performance of nontransaction applications	ICDE	database
1773	ICDE	Can OODB Technology Solve CAD Design Data Management Problems? (Panel Abstract).	Anoop Singhal	1993	Can OODB Technology Solve CAD Design Data Management Problems? (Panel Abstract).	ICDE	database
1774	ICDE	Recursive Functions in Iris.	Philippe De Smedt,Stefano Ceri,Marie-Anne Neimat,Ming-Chien Shan,Rafi Ahmed	1993	A complete and efficient implementation of linear, one-side recursive queries in Iris, an object-oriented database management system, is described. It is shown that recursion can be easily and efficiently added to a large class of existing database management systems. A B-tree type access path called the B++ tree that has been implemented to support the computation of recursive functions in Iris is also described. The perforamnce of B++ trees is reviewed	ICDE	database
1775	ICDE	A Truncating Hash Algorithm for Processing Band-Join Queries.	Valery Soloviev	1993	The truncating-hash band join algorithm for evaluating band joins is described. This algorithm is based on the idea of truncating join attribute values in order to execute band joins in a way similar to hash join algorithms for equijoins. Unlike previously proposed algorithms for band joins, it does not sort either of the input relations during its execution. A comparison between the truncating-hash band join algorithm and previous algorithms for band joins using an analytical model is presented. The model also compares an evaluation of band join for a parallel implementation on a shared-nothing multiprocessor system. The results show that the truncating-hash band join algorithm outperforms the other band join algorithms because of a significantly lower CPU cost	ICDE	database
1776	ICDE	Model-Based Design Bases for Task-Oriented Systems.	Christian Stary	1993	The nature of task-oriented application design and the rationale in building interactive design support tools are discussed. A model-based approach for the representation of design knowledge is introduced. The approach comprises an end-user task model, a problem domain data model, and an interaction domain model. These models are mapped onto an object hierarchy, allowing the construction of a design knowledge base with reusable objects	ICDE	database
1777	ICDE	Are We Polishing a Round Ball? (Panel Abstract).	Michael Stonebraker	1993	Are We Polishing a Round Ball? (Panel Abstract).	ICDE	database
1778	ICDE	Large Object Support in POSTGRES.	Michael Stonebraker,Michael A. Olson	1993	This paper presents four implementations for support of large objects in POSTGRES. The four implementations offer varying levels of support for user-defined storage managers available in POSTGRES is also detailed. The performance of all four large object implementations on two different storage devices is presented.	ICDE	database
1779	ICDE	Execution of Extended Multidatabase SQL.	L. Suardi,Marek Rusinkiewicz,Witold Litwin	1993	The multidatabase structured query language (MSQL) is an extension of the SQL query language that provides new functions for nonprocedural manipulation of data in different and mutually non-integrated relational databases. The problems introduced by these new functions are discussed, and the semantics of multiple updates, global commitment, and rollback are analyzed. New language constructs are developed to allow declarative specification of multidatabase transactions. The design and implementation of an environment for the execution of extended MSQL queries in a heterogeneous multidatabase environment are also discussed	ICDE	database
1780	ICDE	A Polynomial Time Algorithm for Optimizing Join Queries.	Arun N. Swami,Balakrishna R. Iyer	1993	The dynamic programming algorithm for query optimization has exponential complexity. An alternative polynomial time algorithm, the IK-KBZ algorithm, is severely limited in the queries it can optimize. Other algorithms have been proposed, including the greedy algorithm, iterative improvement, and simulated annealing. The AB algorithm, which combines randomization and neighborhood search with the IK-KBZ algorithm, is presented. The AB algorithm is much more generally applicable than IK-KBZ, has polynomial time and space complexity, and produces near optimal plans in the space of outer linear join trees. On average, it does better than the other algorithms that do not do an exhaustive search like dynamic programming	ICDE	database
1781	ICDE	Continuous Backup Systems Utilizing Flash Memory.	Hiroki Takakura,Yahiko Kambayashi	1993	A continuous-backup mechanism for main-memory databases that transmits data to archive storage during utilization of main memory without any software assistance is described. It is suggested that flash memory-based storage can improve the efficiency of conventional disk systems since it can realize faster read and write operations. As sequential access is performed by a series of direct accesses, the overhead caused by scheduling to utilize sequential access is not required. One serious drawback of flash memory is the limit of the number of rewrite operations. Mechanisms that have a five-year lifetime have been developed using existing technology. Results of a performance evaluation of the backup system are presented	ICDE	database
1782	ICDE	An Evaluation of Physical Disk I/Os for Complex Object Processing.	Wouter B. Teeuw,Christian Rich,Marc H. Scholl,Henk M. Blanken	1993	In order to obtain the performance required for nonstandard database environments, a hierarchical complex object model with object references is used as a storage structure for complex objects. Several storage models for these complex objects, as well as a benchmark to evaluate their performance, are described. A cost model for analytical performance evaluation is developed, and the analytical results are validated by means of measurements on the DASDBS, complex object storage system. The results show which storage structures for complex objects are the most efficient under which circumstances	ICDE	database
1783	ICDE	The Efficient Computation of Strong Partial Transitive-Closures.	Ismail H. Toroslu,Ghassan Z. Qadah	1993	The development of efficient algorithms to process the different forms of transitive-closure queries within the context of large database systems has attracted a large volume of research efforts. The authors present a new algorithm that is suitable for processing one of these forms, the strong partially instantiated query, in which one of the query's arguments is instantiated to a set of constants. The processing of this algorithm yields a set of tuples that draw their values from both of the query's instantiated and uninstantiated arguments. This algorithm avoids the redundant computations and the high storage costs found in a number of similar algorithms	ICDE	database
1784	ICDE	On Modularity for Conceptual Data Models and the Consequences for Subtyping, Inheritance & Overriding.	Olga De Troyer,René Janssen	1993	On Modularity for Conceptual Data Models and the Consequences for Subtyping, Inheritance & Overriding.	ICDE	database
1785	ICDE	Computation, Information, Communication, Imagination (Abstract).	Dennis Tsichritzis	1993	Computation, Information, Communication, Imagination (Abstract).	ICDE	database
1786	ICDE	Parallel Database Systems: the case for shared-something.	Patrick Valduriez	1993	Parallel database systems are becoming the primary application of multiprocessor computers. The reason for this is that they can provide high-performance and high-availability database support at a much lower price than do equivalent mainframe computers. The traditional shared-memory, shared-disk, and shared-nothing architectures of parallel database systems are compared, based on the following dimensions: simplicity, cost, performance, availability and extensibility. Based on these comparisons, the case is made for the shared-something architecture, which can provide a better trade-off between the various objectives	ICDE	database
1787	ICDE	Data Quality Requirements Analysis and Modeling.	Richard Y. Wang,Henry B. Kon,Stuart E. Madnick	1993	A set or premises, terms, and definitions for data quality management are established, and a step-by-step methodology for defining and documenting data quality parameters important to users is developed. These quality parameters are used to determine quality indicators about the data manufacturing process, such as data source creation time, and collection method, that are tagged to data items. Given such tags, and the ability to query over them, users can filter out data having undesirable characteristics. The methodology provides a concrete approach to data quality requirements collection and documentation. It demonstrates that data quality can be an integral part of the database design process. A perspective on the migration towards quality management of data in a database environment is given	ICDE	database
1788	ICDE	Dynamic Finite Versioning: An Effective Versioning Approach to Concurrent Transaction and Query Processing.	Kun-Lung Wu,Philip S. Yu,Ming-Syan Chen	1993	Dynamic finite versioning (DFV) schemes that effectively support concurrent processing of transaction and queries are presented. Without acquiring locks, queries read from a small, fixed number of dynamically derived, transaction-consistent, possibly slightly obsolete, logical snapshots of the database. On the other hand, transactions access the most up-to-date data in the database without data contention from queries. Intermediate versions created between snapshots are automatically discarded. Dirty pages updated by active transactions are allowed to be written back into the database before commitment and, at the same time, consistent logical snapshots can be advanced automatically without quiescing the ongoing transactions or queries	ICDE	database
1789	ICDE	On Updates and Inconsistency Repairing in Knowledge Bases.	Beat Wüthrich	1993	A technique to compute a solution for a given update and a given knowledge base is presented. The salient features of this approach are: the problem is tackled in a general way and presents a technique for repairing inconsistency; the user can interact with the system, actively influence the solution to be generated, and is not forced to generate all possible minimal solutions from which the user finally draws the most preferred one; solutions are obtained by set-oriented fact processing rather than by single fact accesses to the old knowledge base; and, in contrast to the other proposed techniques, the consistency of the old knowledge base is exploited when generating a solution	ICDE	database
1790	SIGMOD Conference	Database System Issues in Nomadic Computing.	Rafael Alonso,Henry F. Korth	1993	Mobile computers and wireless networks are emerging technologies that will soon be available to a wide variety of computer users. Unlike earlier generations of laptop computers, the new generation of mobile computers can be an integrated part of a distributed computing environment, one in which users change physical location frequently. The result is a new computing paradigm, nomadic computing. This paradigm will affect the design of much of our current systems software, including that of database systems. This paper discusses in some detail the impact of nomadic computing on a number of traditional database system concepts. In particular, we point out how the reliance on short-lived batteries changes the cost assumptions underlying query processing. In these systems, power consumption competes with resource utilization in the definition of cost metrics. We also discuss how the likelihood of temporary disconnection forces consideration of alternative transaction processing protocols. The limited screen space of mobile computers along with the advent of pen-based computing provides new opportunities and new constraints on database interfaces and languages. Lastly, we believe that the movement of computers and data among networks potentially belonging to distinct, autonomous organizations creates serious security problems.	SIGMOD Conferen	database
1791	SIGMOD Conference	A New Perspective on Rule Support for Object-Oriented Databases.	Eman Anwar,L. Maugis,Sharma Chakravarthy	1993	This paper proposes a new approach for supporting reactive capability in an object-oriented database. We introduce an event interface, which extends the conventional object semantics to include the role of an event generator. This interface provides a basis for the specification of events spanning sets of objects, possibly from different classes, and detection of primitive and complex events. This approach clearly separated event detection from rules. New rules can be added and use existing objects, enabling objects to react to their own changes as well as to the changes of other objects. We use a runtime subscription mechanism, between rules and objects to selectively monitor particular objects dynamically. This elegantly supports class level as well as instance level rules. Both events and rules are treated as first class objects.	SIGMOD Conferen	database
1792	SIGMOD Conference	SIMS: Retrieving and Integrating Information From Multiple Sources.	Yigal Arens,Craig A. Knoblock	1993	SIMS: Retrieving and Integrating Information From Multiple Sources.	SIGMOD Conferen	database
1793	SIGMOD Conference	Methods and Rules.	Serge Abiteboul,Georg Lausen,Heinz Uphoff,Emmanuel Waller	1993	We show how classical datalog semantics can be used directly and very simply to provide semantics to a syntactic extension of datalog with methods, classes, inheritance, overloading and late binding. Several approaches to resolution are considered, implemented in the model, and formally compared. They range from resolution in C++ style to original kinds of resolution suggested by the declarative nature of the language. We show connections to view specification and a further extension allowing runtime derivation of the class hierarchy.	SIGMOD Conferen	database
1794	SIGMOD Conference	Mining Association Rules between Sets of Items in Large Databases.	Rakesh Agrawal,Tomasz Imielinski,Arun N. Swami	1993	We are given a large database of customer transactions. Each transaction consists of items purchased by a customer in a visit. We present an efficient algorithm that generates all significant association rules between items in the database. The algorithm incorporates buffer management and novel estimation and pruning techniques. We also present results of applying this algorithm to sales data obtained from a large retailing company, which shows the effectiveness of the algorithm.	SIGMOD Conferen	database
1795	SIGMOD Conference	Using the Co-existence Approach to Achieve Combined Functionality of Object-Oriented and Relational Systems.	R. Ananthanarayanan,Vibby Gottemukkala,Wolfgang Käfer,Tobin J. Lehman,Hamid Pirahesh	1993	Once considered a novelty, object oriented systems have now entered the mainstream. Their impressive performance and rich type systems have created a demand for object oriented features in other areas, such as relational database systems. We believe the current efforts to combine object oriented and relational features into a single hybrid system will fall short of the mark, whereas our approach, the co-existence approach, has the distinction of requiring far less work, but at the same time promising both the desired functionality and performance. We describe the attributes of our co-existing systems, an object oriented system (C++) and a relational system (Starburst), and show how this combination supports the desired features of both object-oriented and relational systems.	SIGMOD Conferen	database
1796	SIGMOD Conference	The SUPER Project.	Martin Andersson,Annamaria Auddino,Yann Dupont,Edi Fontana,M. Gentile,Stefano Spaccapietra	1993	The SUPER Project.	SIGMOD Conferen	database
1797	SIGMOD Conference	Experiences Building the Open OODB Query Optimizer.	José A. Blakeley,William J. McKenna,Goetz Graefe	1993	This paper reports our experiences building the query optimizer for TI's Open OODB system. To the best of our knowledge, it is the first working object query optimizer to be based on a complete extensible optimization framework including logical algebra, execution algorithms, property enforcers, logical transformation rules, implementation rules, and selectivity and cost estimation. Our algebra incorporates a new materialize operator with its corresponding logical transformation and implementation rules that enable the optimization of path expressions. Initial experiments on queries obtained from the object query optimization literature demonstrate that our optimizer is able to derive plans that are as efficient as, and often substantially more efficient than, the plans generated by other query optimization strategies. These experiments demonstrate that our initial choices for populating each part of our optimization framework are reasonable. Our experience also shows that having a complete optimization framework is crucial for two reasons. First, it allows the optimizer to discover plans that cannot be revealed by exploring only the alternatives provided by the logical algebra and its transformations. Second, it helps and forces the database system designer to consider all parts of the framework and to maintain a good balance of choices when incorporating a new logical operator, execution algorithm, transformation rule, or implementation rule. The Open OODB query optimizer was constructed using the Volcano Optimizer Generator, demonstrating that this second-generation optimizer generator enables rapid development of efficient and effective query optimizers for non-standard data models and systems.	SIGMOD Conferen	database
1798	SIGMOD Conference	On the Power of Algebras with Recursion.	Catriel Beeri,Tova Milo	1993	We consider the relationship between the deductive and the functional/algebraic query language paradigms. Previous works considered this subject for a non-recursive algebra, or an algebra with a fixed point operation, and the corresponding class of deductive queries is that defined by stratified programs. We consider here algebraic languages extended by general recursive definitions. We also consider languages that allow non-restricted use of negation. It turns out that recursion and negation in the algebraic paradigm need to be studied together. The semantics used for the comparison is the valid semantics, although other well-known declarative semantics can also be used to derive similar results. We show that the class of queries expressed by general deduction with negation can be captured using algebra with recursive definitions.	SIGMOD Conferen	database
1799	SIGMOD Conference	Loading Data into Description Reasoners.	Alexander Borgida,Ronald J. Brachman	1993	Knowledge-base management systems (KBMS) based on description logics are being used in a variety of situations where access is needed to large amounts of data stored in existing relational databases. We present the architecture and algorithms of a system that converts most of the inferences made by the KBMS into a collection of SQL queries, thereby relying on the optimization facilities of existing DBMS to gain efficiency, while maintaining an object-centered view of the world with a substantive semantics and significantly different reasoning facilities than those provided by Relational DBMS and their deductive extensions. We address a number of optimization issues that arise in the translation process due to the fact that SQL queries with different syntax (but identical semantics) are not treated uniformly by current database management systems.	SIGMOD Conferen	database
1800	SIGMOD Conference	Index Support for Rule Activation.	David A. Brant,Daniel P. Miranker	1993	Integrated rule and database systems are quickly moving from the research laboratory into commercial systems. However, the current generation of prototypes are designed to work with small rule sets involving limited inferencing. The problem of supporting large complex rule programs within database management systems still presents significant challenges. The basis for many of these challenges is providing support for rule activation. Rule activation is defined as the process of determining which rules are satisfied and what data satisfies them. In this paper we present performance results for the DATEX database rule system and its novel indexing technique for supporting rule activation. Our approach assumes that both the rule program and the database must be optimized synergistically. However, as an experimental result we have determined that DATEX requires very few changes to a standard DBMS environment, and we argue that these changes are reasonable for the problems being solved. Based on the performance of DATEX we believe we have demonstrated a satisfactory solution to the rule activation problem for complex rule programs operating within a database system.	SIGMOD Conferen	database
1801	SIGMOD Conference	Efficient Processing of Spatial Joins Using R-Trees.	Thomas Brinkhoff,Hans-Peter Kriegel,Bernhard Seeger	1993	Spatial joins are one of the most important operations for combining spatial objects of several relations. The efficient processing of a spatial join is extremely important since its execution time is superlinear in the number of spatial objects of the participating relations, and this number of objects may be very high. In this paper, we present a first detailed study of spatial join processing using R-trees, particularly R*-trees. R-trees are very suitable for supporting spatial queries and the R*-tree is one of the most efficient members of the R-tree family. Starting from a straightforward approach, we present several techniques for improving its execution time with respect to both, CPU- and I/O-time. Eventually, we end up with an algorithm whose total execution time is improved over the first approach by an order of magnitude. Using a buffer of reasonable size, I/O-time is almost optimal, i.e. it almost corresponds to the time for reading each required page of the relations exactly once. The performance of the various approaches is investigated in an experimental performance comparison where several large data sets from real applications are used.	SIGMOD Conferen	database
1802	SIGMOD Conference	InterBase: A Multidatabase Prototype System.	Omran A. Bukhres,Jiansan Chen,Ahmed K. Elmagarmid,Xianging Liu,James G. Mullen	1993	InterBase: A Multidatabase Prototype System.	SIGMOD Conferen	database
1803	SIGMOD Conference	An InterBase System at BNR.	Omran A. Bukhres,Jiansan Chen,Rob Pezzoli	1993	An InterBase System at BNR.	SIGMOD Conferen	database
1804	SIGMOD Conference	The LOGRES prototype.	Filippo Cacace,Stefano Ceri,Stefano Crespi-Reghizzi,Piero Fraternali,Stefano Paraboschi,Letizia Tanca	1993	Logres is a new-generation database system integrating features from deductive and object-oriented databases [1, 2, 3, 4, 5]. The data model of Logres supports structural and semantic complexity through a rich collection of concepts from object-oriented models. The rule language allows for the manipulation of complex objects, the generation of new objects, and the definition of passive and active constraints. The application of set of rules to database states is controlled by means of qualifiers, which dictate the side effects of rules; qualifiers are the unique procedural feature of Logres, otherwise a fully declarative language.	SIGMOD Conferen	database
1805	SIGMOD Conference	The oo7 Benchmark.	Michael J. Carey,David J. DeWitt,Jeffrey F. Naughton	1993	The oo7 Benchmark.	SIGMOD Conferen	database
1806	SIGMOD Conference	Tapes Hold Data, Too: Challenges of Tuples on Tertiary Store.	Michael J. Carey,Laura M. Haas,Miron Livny	1993	Tapes Hold Data, Too: Challenges of Tuples on Tertiary Store.	SIGMOD Conferen	database
1807	SIGMOD Conference	The Design and Implementation of CoBase.	Wesley W. Chu,M. A. Merzbacher,L. Berkovich	1993	CoBase, a cooperative database, is a new type of distributed database that integrates knowledge base technology with database systems to provide cooperative (approximate and conceptual) query answering. Based on the database schema and application characteristics, data are organized into conceptual (type abstraction) hierarchies. The higher levels of the hierarchy provide a more abstract data representation than the lower levels. Generalization (moving up in the hierarchy), specialization (moving down in the hierarchy) and association (moving between hierarchies) are the three key operations in deriving cooperative query answers. Relaxation in CoBase can also be specified explicitly in the query by the user or calling program through cooperative operators. We have extended SQL to CSQL by adding cooperative primitives. We describe the CoBase software implementation, including an inter-module data protocol that provides a uniform module interface. This modular approach provides flexibility in adding new relaxation modules and simplifies software maintenance. CoBase uses LOOM as its knowledge representation and inference system and supports relational data bases (e.g. Oracle and Sybase). We have demonstrated the feasibility and functionality of CoBase on top of a Transportation Database. The CoBase methodology has also been adopted in the multi-media medical distributed database project at UCLA, which provides approximate query answers to medical queries.	SIGMOD Conferen	database
1808	SIGMOD Conference	Role of Interoperability in Business Application Development.	David Cohen,Gary Larson,Larry Berke	1993	Role of Interoperability in Business Application Development.	SIGMOD Conferen	database
1809	SIGMOD Conference	Replicated Data in a Distributed Environment.	Malcolm Colton	1993	Replication Server, a forthcoming product that dynamically maintains subsets of data in a distributed environment, providing several transaction models to maintain loose consistency, is contrasted with existing products which provide location-transparent reads and high-consistency coordinated commits. Replication Server makes it possible to build systems that are much more robust in the face of system component failures. By moving transactions rather than data, and by locating data at the point of processing, it maximizes the use of network bandwidth, enabling the deployment of robust, high-performance applications at a lower cost than with traditional approaches	SIGMOD Conferen	database
1810	SIGMOD Conference	Hy+: A Hygraph-based Query and Visualization System.	Mariano P. Consens,Alberto O. Mendelzon	1993	Hy+: A Hygraph-based Query and Visualization System.	SIGMOD Conferen	database
1811	SIGMOD Conference	Practical Prefetching via Data Compression.	Kenneth M. Curewitz,P. Krishnan,Jeffrey Scott Vitter	1993	An important issue that affects response time performance in current OODB and hypertext systems is the I/O involved in moving objects from slow memory to cache. A promising way to tackle this problem is to use prefetching, in which we predict the user's next page requests and get those pages into cache in the background. Current databases perform limited prefetching using techniques derived from older virtual memory systems. A novel idea of using data compression techniques for prefetching was recently advocated in [KrV, ViK], in which prefetchers based on the Lempel-Ziv data compressor (the UNIX compress command) were shown theoretically to be optimal in the limit. In this paper we analyze the practical aspects of using data compression techniques for prefetching. We adapt three well-known data compressors to get three simple, deterministic, and universal prefetchers. We simulate our prefetchers on sequences of page accesses derived from the OO1 and OO7 benchmarks and from CAD applications, and demonstrate significant reductions in fault-rate. We examine the important issues of cache replacement, size of the data structure used by the prefetcher, and problems arising from bursts of &ldquo;fast&rdquo; page requests (that leave virtually no time between adjacent requests for prefetching and book keeping). We conclude that prediction for prefetching based on data compression techniques holds great promise.	SIGMOD Conferen	database
1812	SIGMOD Conference	Third Generation TP Monitors: A Database Challenge.	Umeshwar Dayal,Hector Garcia-Molina,Meichun Hsu,Ben Kao,Ming-Chien Shan	1993	In a 1976 book, &ldquo;Algorithms + Data Structures = Programs&rdquo; [15], Niklaus Wirth defined programs to be algorithms and data structures. Of course, by now we know that man does not live from programs alone, and that there is a second fundamental computer science equation: &ldquo;Programs + Databases = Information Systems.&rdquo; Database researchers have traditionally focused on the database component of the equation, providing shared and persistent repositories for the data that programs need and produce. As a matter of fact, a lot of us have worked hard to hide or ignore the programs component. For instance, non-procedural languages like SQL and relational algebra have been the holy grail of the database field, letting us describe the data in the way we want without need to write messy programs. The magic wand of transactions makes programs that execute concurrently with our non-procedural statements suddenly disappear: these other programs appear as atomic actions that are either executed before we started looking at our data, or will be executed after we are all done with our work. The wonders of fault tolerance and automatic recovery guarantee that we never have to concern ourselves with our statements failing or being interrupted. The data we need will always be there for us, and our statements will always run to completion. Unfortunately, the real programs that operate on databases are in many cases more complex than the classical ones like &ldquo;withdraw 100 dollars from my account&rdquo; or &ldquo;find me all my blue eyed great-grandfathers.&rdquo; For one, programs may be much longer, requiring many database interactions. Furthermore, programs need to interact with other concurrent programs, getting results from and to them. They may also need to be aware of their environment, perhaps monitoring the execution of another program, or taking corrective action when some system components fail. Of course, this is not to say that transactions and non-procedural query languages have not been great contributions. In many cases, they are all that is needed to program one's application. But beyond that there are many cases when one must deal with multiple concurrent applications. Indeed, a critical problem facing complex enterprises is the automation of complex business processes. Enterprises today are drowning in an ocean of data, with a few isolated islands of automation consisting of heterogeneous databases and legacy application programs, each of which automates some point function (e.g., order entry, inventory, accounting, billing) within the enterprise. As the enterprise attempts to automate its business processes, these isolated islands have to be bridged: complex information systems must be developed that need to span many of these databases and application programs. Traditional database systems do not provide the supporting environment for this. Our programming languages colleagues have been working on the programs component of our fundamental equation, but the database component has traditionally been ignored or hidden. There has been a lot of recent interest on languages that support persistent objects, but often the goal is to make the database that holds the objects look as little as possible like a database. That is, the persistent objects are to be handled just as if they were volatile objects, even though they are not. Also, the programming languages researchers have borrowed the notions of transactions and serializable schedules to hide as much as possible concurrent execution and failures of programs. Finally, traditional programming languages (there are exceptions[4, 13]) have focused on &ldquo;programming in the small,&rdquo; as opposed to &ldquo;programming in the large.&rdquo; The goal of the former is to program single applications or to solve single problems, as opposed to programming an entire enterprise and all of its interacting applications. Researchers from both camps have recently been addressing both components of the &ldquo;Programs + Databases&rdquo; equation. For example, database researchers have been adding triggers and procedures to database objects[2], resulting in so called active databases. These are important steps in the right direction (other related steps are listed below), but still do not address the full programming in the large problem. In our opinion, the only software providers that have tackled both components of the &ldquo;Programs + Databases&rdquo; equation, and have a proven track record with real applications, are the Transaction Processing Monitor (TPM) builders[9].	SIGMOD Conferen	database
1813	SIGMOD Conference	Design and Implementation of the Glue-Nail Database System.	Marcia A. Derr,Shinichi Morishita,Geoffrey Phipps	1993	We describe the design and implementation of the Glue-Nail database system. The Nail language is a purely declarative query language; Glue is a procedural language used for non-query activities. The two languages combined are sufficient to write a complete application. Nail and Glue code both compile into the target language IGlue. The Nail compiler uses variants of the magic sets algorithm, and supports well-founded models. Static optimization is performed by the Glue compiler using techniques that include peephole methods and data flow analysis. The IGlue code is executed by the IGlue interpreter, which features a run-time adaptive optimizer. The three optimizers each deal with separate optimization domains, and experiments indicate that an effective synergism is achieved. The Glue-Nail system is largely complete and has been tested using a suite of representative applications.	SIGMOD Conferen	database
1814	SIGMOD Conference	What's Special about Spatial? Database Requirements for Vehicle Navigation in Geographic Space (Extended Abstract).	Max J. Egenhofer	1993	What's Special about Spatial? Database Requirements for Vehicle Navigation in Geographic Space (Extended Abstract).	SIGMOD Conferen	database
1815	SIGMOD Conference	Open OODB: A Modular Object-Oriented DBMS.	Steve Ford,José A. Blakeley,Thomas J. Bannon	1993	The Open OODB project, part of the DARPA Persistent Object Base (POB) Program, is an effort to build an open, extensible object-oriented database management system (OODB) in which database functionality can be tailored for particular applications within an incrementally improvable framework. The system is designed to serve both as a platform for research and as a testbed that can meet the needs of demanding, next generation database applications. The Open OODB project goals are to describe the design space of OODBs; build an architectural framework that enables configuring independently useful modules to form an OODB; verify the suitability of this open approach by implementing an OODB to these specifications; and identify opportunities for building consensus that can lead to much-needed OODB standards. The motivating factors in this approach were that our previous experience in object-oriented databases had convinced us that different applications have differing requirements, and that a monolithic system is unlikely to meet the needs of many demanding kinds of applications.	SIGMOD Conferen	database
1816	SIGMOD Conference	GREO: A Commercial Database Processor Based on A Pipelined Hardware Sorter.	Shinya Fushimi,Masaru Kitsuregawa	1993	GREO: A Commercial Database Processor Based on A Pipelined Hardware Sorter.	SIGMOD Conferen	database
1817	SIGMOD Conference	GOOD: AGraph-Oriented Object Database System.	Marc Gemis,Jan Paredaens,Inge Thyssens,Jan Van den Bussche	1993	GOOD: AGraph-Oriented Object Database System.	SIGMOD Conferen	database
1818	SIGMOD Conference	Maintaining Views Incrementally.	Ashish Gupta,Inderpal Singh Mumick,V. S. Subrahmanian	1993	We present incremental evaluation algorithms to compute changes to materialized views in relational and deductive database systems, in response to changes (insertions, deletions, and updates) to the relations. The view definitions can be in SQL or Datalog, and may use UNION, negation, aggregation (e.g. SUM, MIN), linear recursion, and general recursion. We first present a counting algorithm that tracks the number of alternative derivations (counts) for each derived tuple in a view. The algorithm works with both set and duplicate semantics. We present the algorithm for nonrecursive views (with negation and aggregation), and show that the count for a tuple can be computed at little or no cost above the cost of deriving the tuple. The algorithm is optimal in that it computes exactly those view tuples that are inserted or deleted. Note that we store only the number of derivations, not the derivations themselves. We then present the Delete and Rederive algorithm, DRed, for incremental maintenance of recursive views (negation and aggregation are permitted). The algorithm works by first deleting a superset of the tuples that need to be deleted, and then rederiving some of them. The algorithm can also be used when the view definition is itself altered.	SIGMOD Conferen	database
1819	SIGMOD Conference	Local Verification of Global Integrity Constraints in Distributed Databases.	Ashish Gupta,Jennifer Widom	1993	We present an optimization for integrity constraint verification in distributed databases. The optimization allows a global constraint, i.e. a constraint spanning multiple databases, to be verified by accessing data at a single database, eliminating the cost of accessing remote data. The optimization is based on an algorithm that takes as input a global constraint and data to be inserted into a local database. The algorithm produces a local condition such that if the local data satisfies this condition then, based on the previous satisfaction of the global constraint, the global constraint is still satisfied. If the local data does not satisfy the condition, then a conventional global verification procedure is required.	SIGMOD Conferen	database
1820	SIGMOD Conference	Second-Order Signature: A Tool for Specifying Data Models, Query Processing, and Optimization.	Ralf Hartmut Güting	1993	Second-Order Signature: A Tool for Specifying Data Models, Query Processing, and Optimization.	SIGMOD Conferen	database
1821	SIGMOD Conference	Papyrus GIS Demonstration.	Waqar Hasan,Michael L. Heytens,Curtis P. Kolovson,Marie-Anne Neimat,Spyros Potamianos,Donovan A. Schneider	1993	The goal of the Papyrus project [3] is to provide tools and services to enable the integration and parallelization of specialized data managers so that data-intensive applications can be constructed easily and efficiently. In our terminology, a data manager (DM) is a set of specialized methods that manage persistent data. A collection of functions defines the interface to a DM and provides the only means of accessing its persistent data.	SIGMOD Conferen	database
1822	SIGMOD Conference	Predicate Migration: Optimizing Queries with Expensive Predicates.	Joseph M. Hellerstein,Michael Stonebraker	1993	The traditional focus of relational query optimization schemes has been on the choice of join methods and join orders. Restrictions have typically been handled in query optimizers by &ldquo;predicate pushdown&rdquo; rules, which apply restrictions in some random order before as many joins as possible. These rules work under the assumption that restriction is essentially a zero-time operation. However, today's extensible and object-oriented database systems allow users to define time-consuming functions, which may be used in a query's restriction and join predicates. Furthermore, SQL has long supported subquery predicates, which may be arbitrarily time-consuming to check. Thus restrictions should not be considered zero-time operations, and the model of query optimization must be enhanced. In this paper we develop a theory for moving expensive predicates in a query plan so that the total cost of the plan &mdash; including the costs of both joins and restrictions &mdash; is minimal. We present an algorithm to implement the theory, as well as results of our implementation in POSTGRES. Our experience with the newly enhanced POSTGRES query optimizer demonstrates that correctly optimizing queries with expensive predicates often produces plans that are orders of magnitude faster than plans generated by a traditional query optimizer. The additional complexity of considering expensive predicates during optimization is found to be manageably small.	SIGMOD Conferen	database
1823	SIGMOD Conference	Real-Time Transaction Scheduling: A Cost Conscious Approach.	D. Hong,Theodore Johnson,Sharma Chakravarthy	1993	Real-time databases are an important component of embedded real-time systems. In a real-time database context, transactions must not only maintain the consistency constraints of the database but must also satisfy the timing constraints specified for each transaction. Although several approaches have been proposed to integrate real-time scheduling and database concurrency control methods, none of them take into account the dynamic cost of scheduling a transaction. In this paper, we propose a new cost conscious real-time transaction scheduling algorithm which considers dynamic costs associated with a transaction. Our dynamic priority assignment algorithm adapts to changes in the system load without causing excessive numbers of transaction restarts. Our simulations show its superiority over EDF-HP algorithm.	SIGMOD Conferen	database
1824	SIGMOD Conference	Comparing Rebuild Algorithms for Mirrored and RAID5 Disk Arrays.	Robert Y. Hou,Yale N. Patt	1993	Several disk array architectures have been proposed to provide high throughput for transaction processing applications. When a single disk in a redundant array fails, the array continues to operate, albeit in a degraded mode with a corresponding reduction in performance. In addition, the lost data must be rebuilt to a spare disk in a timely manner to reduce the probability of permanent data loss. Several researchers have proposed and examined algorithms for rebuilding the failed disk in a disk array with parity. We examine the use of these algorithms to rebuild a mirrored disk array and compare the rebuild time and performance of the RAID5 and mirrored arrays. Redirection of Reads provides comparable average response times and better rebuild times than Piggybacking for a mirrored array, whereas these two algorithms perform similarly for a RAID5 array. In our experiments comparing the two architectures, a mirrored array has more disks than a RAID5 array and can sustain 150% more I/Os per second during the rebuild process. Even if the size of the RAID5 array is increased to match the mirrored array, the mirrored array reduces response times by up to 60% and rebuild times by up to 45%.	SIGMOD Conferen	database
1825	SIGMOD Conference	Evaluation of Signature Files as Set Access Facilities in OODBs.	Yoshiharu Ishikawa,Hiroyuki Kitagawa,Nobuo Ohbo	1993	Object-oriented database systems (OODBs) need efficient support for manipulation of complex objects. In particular, support of queries involving evaluations of set predicates is often required in handling complex objects. In this paper, we propose a scheme to apply signature file techniques, which were originally invented for text retrieval, to the support of set value accesses, and quantitatively evaluate their potential capabilities. Two signature file organizations, the sequential signature file and the bit-sliced signature file, are considered and their performance is compared with that of the nested index for queries involving the set inclusion operator (&sube;). We develop a detailed cost model and present analytical results clarifying their retrieval, storage, and update costs. Our analysis shows that the bit-sliced signature file is a very promising set access facility in OODBs.	SIGMOD Conferen	database
1826	SIGMOD Conference	Issues in Multimedia Datbases (Panel).	H. V. Jagadish	1993	Issues in Multimedia Datbases (Panel).	SIGMOD Conferen	database
1827	SIGMOD Conference	Concurrency Control and Recovery of Multidatabase Work Flows in Telecommunication Applications.	W. Woody Jin,Marek Rusinkiewicz,Linda Ness,Amit P. Sheth	1993	In a research and technology application project at Bellcore, we used multidatabase transactions to model multisystem work flows of telecommunication applications. During the project a prototype scheduler for executing multi-database transactions was developed. Two of the issues addressed in this project were concurrent execution of multi-database transactions and their failure recovery. This paper discusses our use of properties of the application and the telecommunication systems to develop simple and efficient solutions to the concurrency control and recovery problems.	SIGMOD Conferen	database
1828	SIGMOD Conference	Lazy Updates for Distributed Search Structure.	Theodore Johnson,Padmashree Krishna	1993	Very large database systems require distributed storage, which means that they need distributed search structures for fast and efficient access to the data. In this paper, we present an approach to maintaining distributed data structures that uses lazy updates, which take advantage of the semantics of the search structure operations to allow for scalable and low-overhead replication. Lazy updates can be used to design distributed search structures that support very high levels of concurrency. The alternatives to lazy update algorithms (eager updates) use synchronization to ensure consistency, while lazy update algorithms avoid blocking. Since lazy updates avoid the use of synchronization, they are much easier to implement than eager update algorithms. We demonstrate the application of lazy updates to the dB-tree, which is a distributed B+ tree that replicates its interior nodes for highly parallel access. We develop a correctness theory for lazy updates so that our algorithms can be applied to other distributed search structures.	SIGMOD Conferen	database
1829	SIGMOD Conference	Performance Evaluation of Ephemeral Logging.	John S. Keen,William J. Dally	1993	Ephemeral logging (EL) is a new technique for managing a log of database activity on disk. It does not require periodic checkpoints and does not abort lengthy transactions as frequently as traditional firewall logging for the same amount of disk space. Therefore, it is well suited for highly concurrent databases and applications which have a wide distribution of transaction lifetimes. This paper briefly explains EL and then analyzes its performance. Simulation studies indicate that it can offer significant savings in disk space, at the expense of slightly higher bandwidth for logging and more main memory. The reduced size of the log implies much faster recovery after a crash as well as cost savings. EL is the method of choice in some but not all situations. We assess the limitations of our current knowledge about EL and suggest promising directions for further research.	SIGMOD Conferen	database
1830	SIGMOD Conference	Persistence Software: Bridging Object-Oriented Programming and Relational Databases.	Arthur M. Keller,Richard Jensen,Shailesh Agrawal	1993	Building object-oriented applications which access relational data introduces a number of technical issues for developers who are making the transition to C++. We describe these issues and discuss how we have addressed them in Persistence, an application development tool that uses an automatic code generator to merge C++ applications with relational data. We use client-side caching to provide the application program with efficient access to the data.	SIGMOD Conferen	database
1831	SIGMOD Conference	Open DECdtm: Constraint Based Transaction Management.	Johannes Klein,Francis Upton IV	1993	Open DECdtm offers portable transaction management services layered on OSF DCE which support the application (TX), resource manager (XA), and transactional DCE RPC (TxRPC) interfaces specified by X/Open. Open DECdtm also provides interoperability with OSI Transaction Processing (OSI TP) and OpenVMS systems using the DECdtm OpenVMS protocol. Protocols executed by Open DECdtm are specified by constraints. This simplifies the development of transactional gateways between different data transfer protocols and transaction models.	SIGMOD Conferen	database
1832	SIGMOD Conference	Atomic Incremental Garbage Collection and Recovery for a Large Stable Heap.	Elliot K. Kolodner,William E. Weihl	1993	A stable heap is storage that is managed automatically using garbage collection, manipulated using atomic transactions, and accessed using a uniform storage model. These features enhance reliability and simplify programming by preventing errors due to explicit deallocation, by masking failures and concurrency using transactions, and by eliminating the distinction between accessing temporary storage and permanent storage. Stable heap management is useful for programming languages for reliable distributed computing, programming languages with persistent storage, and object-oriented database systems. Many applications that could benefit from a stable heap (e.g., computer-aided design, computer-aided software engineering, and office information systems) require large amounts of storage, timely responses for transactions, and high availability. We present garbage collection and recovery algorithms for a stable heap implementation that meet these goals and are appropriate for stock hardware. The collector is incremental: it does not attempt to collect the whole heap at once. The collector is also atomic: it is coordinated with the recovery system to prevent problems when it moves and modifies objects. The time for recovery is independent of heap size, even if a failure occurs during garbage collection.	SIGMOD Conferen	database
1833	SIGMOD Conference	NAUDA - A Cooperative, Natural Language Interface to Relational Databases.	Detlef Küpper,M. Strobel,Dietmar Rösner	1993	The NAUDA1 System is a cooperative natural (German) language database interface for relational databases. The project is carried out at FAW2 - funded by the state of Baden-W&uuml;rttemberg and IBM Germany. This paper describes the extension of a natural language interface to relational databases with respect to its cooperative behavior. We argue that cooperative support of users is especially important for a complex domain such as environmental protection. In order to enrich traditional database reports our system provides dialog-oriented features such as over-answering (providing more information than explicitly requested) and handling of presupposition failure, as well as presentation-oriented features such as natural language responses and geographical maps. Additional information by the system includes (meta-) information about the domain.	SIGMOD Conferen	database
1834	SIGMOD Conference	On Optimal Processor Allocation to Support Pipelined Hash Joins.	Ming-Ling Lo,Ming-Syan Chen,Chinya V. Ravishankar,Philip S. Yu	1993	In this paper, we develop algorithms to achieve optimal processor allocation for pipelined hash joins in a multiprocessor-based database system. A pipeline of hash joins is composed of several stages, each of which is associated with one join operation. The whole pipeline is executed in two phases: (1) the table-building phase, and (2) the tuple-probing phase. We focus on the problem of allocating processors to the stages of a pipeline to minimize the query execution time. We formulate the processor allocation problem as a two-phase mini-max optimization problem, and develop three optimal allocation schemes under three different constraints. The effectiveness of our problem formulation and solution is verified through a detailed tuple-by-tuple simulation of pipelined hash joins. Our solution scheme is general and applicable to any optimal resource allocation problem formulated as a two-phase mini-max problem.	SIGMOD Conferen	database
1835	SIGMOD Conference	A Modeling Study of the TPC-C Benchmark.	Scott T. Leutenegger,Daniel M. Dias	1993	The TPC-C benchmark is a new benchmark approved by the TPC council intended for comparing database platforms running a medium complexity transaction processing workload. Some key aspects in which this new benchmark differs from the TPC-A benchmark are in having several transaction types, some of which are more complex than that in TPC-A, and in having data access skew. In this paper we present results from a modelling study of the TPC-C benchmark for both single node and distributed database management systems. We simulate the TPC-C workload to determine expected buffer miss rates assuming an LRU buffer management policy. These miss rates are then used as inputs to a throughput model. From these models we show the following: (i) We quantify the data access skew as specified in the benchmark and show what fraction of the accesses go to what fraction of the data. (ii) We quantify the resulting buffer hit ratios for each relation as a function of buffer size. (iii) We show that close to linear scale-up (about 3% from the ideal) can be achieved in a distributed system, assuming replication of a read-only table. (iv) We examine the effect of packing hot tuples into pages and show that significant price/performance benefit can be thus achieved. (v) Finally, by coupling the buffer simulations with the throughput model, we examine typical disk/memory configurations that maximize the overall price/performance.	SIGMOD Conferen	database
1836	SIGMOD Conference	Algorithms for Loading Parallel Grid Files.	Jianzhong Li,Doron Rotem,Jaideep Srivastava	1993	The paper describes three fast loading algorithms for grid files on a parallel shared nothing architecture. The algorithms use dynamic programming and sampling to effectively partition the data file among the processors to achieve maximum parallelism in answering range queries. Each processor then constructs in parallel its own portion of the grid file. Analytical results and simulations are given for the three algorithms.	SIGMOD Conferen	database
1837	SIGMOD Conference	Information Organization Using Rufus.	Allen Luniewski,Peter M. Schwarz,Kurt A. Shoens,Jim Stamos,John Thomas	1993	Computer system users today are inundated with a flood of semi-structured information, such as documents, electronic mail, programs, and images. Today, this information is typically stored in filesystems that provide limited support for organizing, searching, and operating upon this data, all operations that are vital to the ability of users to effectively use this data. Database systems provide good function for organizing, searching, managing and writing applications on structured data. Current database systems are inappropriate for semi-structured information because moving the data into the database breaks all existing applications that use the data. The Rufus system attacks the problems of semi-structured information by using database function to help users manage semi-structured information without requiring that the user's information reside in the database.	SIGMOD Conferen	database
1838	SIGMOD Conference	LH* - Linear Hashing for Distributed Files.	Witold Litwin,Marie-Anne Neimat,Donovan A. Schneider	1993	LH* generalizes Linear Hashing to parallel or distributed RAM and disk files. An LH* file can be created from objects provided by any number of distributed and autonomous clients. It can grow gracefully, one bucket at a time, to virtually any number of servers. The number of messages per insertion is one in general, and three in the worst case. The number of messages per retrieval is two in general, and four in the worst case. The load factor can be about constant, 65-95%, depending on the file parameters. The file can also support parallel operations. An LH* file can be much faster than a single site disk file, and/or can hold a much larger number of objects. It can be more efficient than any file with a centralized directory, or a static parallel or distributed hash file.	SIGMOD Conferen	database
1839	SIGMOD Conference	Enhancing Inter-Operability and Data Sharing In Medical Information Systems.	Dhamir N. Mannai,Khaled M. Bugrara	1993	Clinical care generates an immense amount of patient data that has been archived and manipulated by computer-based information systems. Such computer-based medical record systems improved the accessibility of clinical information and made several studies of such information possible. Unfortunately, the care provider's task of retrieving, integrating, and interpreting only those portions of the patient's record that are relevant to a specific clinical problem is actually becoming increasingly difficult. This difficulty can be attributed primarily to the large variety of minimum data sets, the heterogeneous formats used to store the data, the heterogeneous data access methods and procedures, the varying granularity of access to data, the different rigid views of the data, and the lack of inter-operability among the information repositories of such data sets. Recognizing the aforementioned issues, we are engaged in a project to build a multi-database environment tailored for the interoperability of medical information systems. The main building blocks of such a system are a multi-disciplinary minimum data set and a catalogue for the support of interoperability and customization functions. In this paper, we report on the design approach used and describe the general architecture of the system.	SIGMOD Conferen	database
1840	SIGMOD Conference	A Logical Semantics for Object-Oriented Databases.	José Meseguer,Xiaolei Qian	1993	Although the mathematical foundations of relational databases are very well established, the state of affairs for object-oriented databases is much less satisfactory. We propose a semantic foundation for object-oriented databases based on a simple logic of change called rewriting logic, and a language called MaudeLog that is based on that logic. Some key advantages of our approach include its logical nature, its simplicity without any need for higher-order features, the fact that dynamic aspects are directly addressed, the rigorous integration of user-definable algebraic data types within the framework, the existence of initial models, and the integration of query, update, and programming aspects within a single declarative language.	SIGMOD Conferen	database
1841	SIGMOD Conference	The COMFORT Prototype: A Step Toward Automated Database Performance Tuning.	Axel Mönkeberg,Peter Zabback,Christof Hasse,Gerhard Weikum	1993	The COMFORT Prototype: A Step Toward Automated Database Performance Tuning.	SIGMOD Conferen	database
1842	SIGMOD Conference	IBM's Relational DBMS Products: Features and Technologies.	C. Mohan	1993	This paper very briefly summarizes the features and technologies implemented in the IBM relational DBMS products. The topics covered include record and index management, concurrency control and recovery methods, commit protocols, query optimization and execution techniques, high availability and support for parallelism and distributed data. Some indications of likely future product directions are also given.	SIGMOD Conferen	database
1843	SIGMOD Conference	An Efficient and Flexible Method for Archiving a Data Base.	C. Mohan,Inderpal Narang	1993	We describe an efficient method for supporting incremental and full archiving of data bases (e.g., individual files). Customers archive their data bases quite frequently to minimize the duration of data outage. Because of the growing sizes of data bases and the ever increasing need for high availability of data, the efficiency of the archive copy utility is very important. The method presented here minimizes interferences with concurrent transactions by not acquiring any locks on the data being copied. It significantly reduces disk I/Os by not keeping on data pages any extra tracking information in connection with archiving. These features make the archive copy operation be more efficient in terms of resource consumption compared to other methods. The method is also flexible in that it optionally supports direct copying of data from disks, bypassing the DBMS's buffer pool. This reduces buffer pool pollution and processing overheads, and allows the utility to take advantage of device geometries for efficiently retrieving data. We also describe extensions to the method to accommodate the multisystem shared disks transaction environment. The method tolerates gracefully system failures during the archive copy operation.	SIGMOD Conferen	database
1844	SIGMOD Conference	What to Teach about Datbases (Panel).	Amihai Motro	1993	What to Teach about Datbases (Panel).	SIGMOD Conferen	database
1845	SIGMOD Conference	Interoperability Using APPC.	Debajyoti Mukhopadhyay	1993	The complex and competitive business world of today needs to access data for various operations from different systems placed at different geographical locations. In order to fulfil this need, one should have a reliable distributed computing environment. Various components of that environment may be supplied by different vendors. This means that the computing environment not only needs to be distributed but also requires interoperability. Today, Interoperability is no more just an idea but a reality. There is also a growing need to support interactions among various systems in a dialog mode. Integrating distributed systems can only help to achieve the goal of developing a reliable distributed computing environment. In this paper, a conceptual framework for an architecture is described in conjunction with Advanced Program-to-Program Communications LU 6.2 protocol to handle that challenge. This architecture discusses the required contracting services for integrating distributed systems. This contracting service has three major components: the contract interaction services, the contract support services, and the communications infrastructure services.	SIGMOD Conferen	database
1846	SIGMOD Conference	VODAK Open Nested Transactions - Visualizing Database Internals.	Peter Muth,Thomas C. Rakow	1993	VODAK Open Nested Transactions - Visualizing Database Internals.	SIGMOD Conferen	database
1847	SIGMOD Conference	Issues and Approaches for Migration/Cohabitation between Legacy and new Systems.	Rodolphe Nassif,Don Mitchusson	1993	Corporate Subject Data Bases (CSDB) are being introduced to reduce data redundancy, maintain the integrity of the data, provide a uniform data access interface, and have data readily available to make business decisions. During the transition phase, there is a need to maintain Legacy Systems (LS), CSDB, and to synchronize between them. Choosing the right granularity for migration of data and functionality is essential to the success of the migration strategy. Technologies being used to support the transition to CSDB include relational systems supporting stored procedures, remote procedures, expert systems, object-oriented approach, reengineering tools, and data transition tools. For our Customer CSDB to be deployed in 1993, cleanup of data occurs during initial load of the CSDB. Nightly updates are needed during the transition phase to account for operations executed through LS. There is a lack of an integrated set of tools to help in the transition phase.	SIGMOD Conferen	database
1848	SIGMOD Conference	The LRU-K Page Replacement Algorithm For Database Disk Buffering.	Elizabeth J. O'Neil,Patrick E. O'Neil,Gerhard Weikum	1993	This paper introduces a new approach to database disk buffering, called the LRU-K method. The basic idea of LRU-K is to keep track of the times of the last K references to popular database pages, using this information to statistically estimate the interarrival times of references on a page by page basis. Although the LRU-K approach performs optimal statistical inference under relatively standard assumptions, it is fairly simple and incurs little bookkeeping overhead. As we demonstrate with simulation experiments, the LRU-K algorithm surpasses conventional buffering algorithms in discriminating between frequently and infrequently referenced pages. In fact, LRU-K can approach the behavior of buffering algorithms in which page sets with known access frequencies are manually assigned to different buffer pools of specifically tuned sizes. Unlike such customized buffering algorithms however, the LRU-K method is self-tuning, and does not rely on external hints about workload characteristics. Furthermore, the LRU-K algorithm adapts in real time to changing patterns of access.	SIGMOD Conferen	database
1849	SIGMOD Conference	Database Challenges in Global Information Systems.	Joann J. Ordille,Barton P. Miller	1993	Database Challenges in Global Information Systems.	SIGMOD Conferen	database
1850	SIGMOD Conference	Doubly Distorted Mirrors.	Cyril U. Orji,Jon A. Solworth	1993	Traditional mirrored disk systems provide high reliability by multiplexing disks. Performance is improved with parallel reads and shorter read seeks. However, writes must be performed by both disks, limiting performance. Doubly distorted mirrors increase the number of physical writes per logical write from 2 to 3, but performs logical writes more efficiently. This reduces the cost of a random logical write to 1/3 of the cost of a read. Moreover, much of the write cost can be absorbed in the rotational latency of the reads, performing under certain conditions all the writes for free. Doubly distorted mirrors achieves a 135% performance improvement over traditional mirrors in the TP1 benchmark. Although these techniques require a disk cache for writes, the cache need not be safe nor is recovery time impacted very much.	SIGMOD Conferen	database
1851	SIGMOD Conference	Partially Preemptive Hash Joins.	HweeHwa Pang,Michael J. Carey,Miron Livny	1993	With the advent of real-time and goal-oriented database systems, priority scheduling is likely to be an important feature in future database management systems. A consequence of priority scheduling is that a transaction may lose its buffers to higher-priority transactions, and may be given additional memory when transactions leave the system. Due to their heavy reliance on main memory, hash joins are especially vulnerable to fluctuations in memory availability. Previous studies have proposed modifications to the hash join algorithm to cope with these fluctuations, but the proposed algorithms have not been extensively evaluated or compared with each other. This paper contains a performance study of these algorithms. In addition, we introduce a family of memory-adaptive hash join algorithms that turns out to offer even better solutions to the memory fluctuation problem that hash joins experience.	SIGMOD Conferen	database
1852	SIGMOD Conference	The V3 Video Server - Managing Analog and Digital Video Clips.	Thomas C. Rakow,Peter Muth	1993	The V3 Video Server is a demonstration showing a multimedia application developed on top of the VODAK database management system. VODAK is a prototype of an object-oriented and distributed database management system (DBMS) developed at GMD-IPSI. The V3 Video Server allows a user to interactively store, retrieve, manipulate, and present analog and short digital video clips. A video clip consists of a sequence of pictures and corresponding sound. Several attributes like author, title, and a set of keywords are annotated. The highlights of the demonstration are as follows. (1) It is shown that an object-oriented database management systems is very useful for the development of multimedia applications. (2) The video server gives valuable hints for the development of an object-oriented database management system in direction to a multimedia database management system.	SIGMOD Conferen	database
1853	SIGMOD Conference	The CORAL Deductive Database System.	Raghu Ramakrishnan,William G. Roth,Praveen Seshadri,Divesh Srivastava,S. Sudarshan	1993	The CORAL Deductive Database System.	SIGMOD Conferen	database
1854	SIGMOD Conference	Implementation of the CORAL Deductive Database System.	Raghu Ramakrishnan,Divesh Srivastava,S. Sudarshan,Praveen Seshadri	1993	CORAL is a deductive database system that supports a rich declarative language, provides a wide range of evaluation methods, and allows a combination of declarative and imperative programming. The data can be persistent on disk or can reside in main-memory. We describe the architecture and implementation of CORAL. There were two important goals in the design of the CORAL architecture: (1) to integrate the different evaluation strategies in a reasonable fashion, and (2) to allow users to influence the optimization techniques used so as to exploit the full power of the CORAL implementation. A CORAL declarative program can be organized as a collection of interacting modules and this modular structure is the key to satisfying both these goals. The high level module interface allows modules with different evaluation techniques to interact in a transparent fashion. Further, users can optionally tailor the execution of a program by selecting from among a wide range of control choices at the level of each module. CORAL also has an interface with C++, and users can program in a combination of declarative CORAL, and C++ extended with CORAL primitives. A high degree of extensibility is provided by allowing C++ programmers to use the class structure of C++ to enhance the CORAL implementation.	SIGMOD Conferen	database
1855	SIGMOD Conference	Instrumental Complex of Parallel Software System Development and Operating Environment Support for Distributed Processing within Multitransputer Systems, TRANSSOFT.	Boris E. Polyachenko,Filipp I. Andon	1993	Instrumental Complex of Parallel Software System Development and Operating Environment Support for Distributed Processing within Multitransputer Systems, TRANSSOFT.	SIGMOD Conferen	database
1856	SIGMOD Conference	The INterset Concept for Multidatabase System Integration in the Pharmaceutical Industry.	Tony Schaller	1993	The industry trends facing information systems in the 1990's involve a matrix of complex requirements. The migration from centralized mainframe computing to desktop personal computing has created opportunities and challenges in moving access to and control of information closer to the end-user. Within this new wave of computing, there has been a drive to move the access control for information to the desktop of the user. Although, graphical user standards were introduced in order to ease of use and provide a consistent look and feel to desktop applications. This provided some assistance in shielding the complexity of the various systems, however it did not address the difficulties presented in accessing heterogeneous database systems on various platforms.	SIGMOD Conferen	database
1857	SIGMOD Conference	Pegasus Architecture and Design Principles.	Ming-Chien Shan	1993	Pegasus Architecture and Design Principles.	SIGMOD Conferen	database
1858	SIGMOD Conference	Using Shared Virtual Memory for Parallel Join Processing.	Ambuj Shatdal,Jeffrey F. Naughton	1993	In this paper, we show that shared virtual memory, in a shared-nothing multiprocessor, facilitates the design and implementation of parallel join processing algorithms that perform significantly better in the presence of skew than previously proposed parallel join processing algorithms. We propose two variants of an algorithm for parallel join processing using shared virtual memory, and perform a detailed simulation to investigate their performance. The algorithm is unique in that it employs both the shared virtual memory paradigm and the message-passing paradigm used by current shared-nothing parallel database systems. The implementation of the algorithm requires few modifications to existing shared-nothing parallel database systems.	SIGMOD Conferen	database
1859	SIGMOD Conference	Architecture of the Encina Distributed Transaction Processing Family.	Marek Sherman	1993	This paper discusses how the Encina&reg; family of distributed transaction processing software can be used to build reliable, distributed applications. We start with the toolkit components of Encina and how they are used for implementing ACID properties. We then consider how the toolkit can be applied in building higher level components in a DCE environment. We conclude with a discussion of the Encina Monitor, which provides a framework for organizing a collection of machines and servers.	SIGMOD Conferen	database
1860	SIGMOD Conference	Multidatabase Interdependencies in Industry.	Amit P. Sheth,George Karabatis	1993	In this paper we address the problem of data consistency between interrelated data. In industrial environments, lack of consistent data creates difficulties in interoperation between systems and often requires manual interventions to restart operations that fail due to inconsistent data. We report the results of a study to understand applicability, adequacy and advantages of a framework we had proposed earlier to specify interdatabase dependencies in multidatabase environments. We studied several existing Bellcore systems and identified examples of interdependent data. The examples demonstrate that the framework allows precise and detailed specification of complex interdependencies that lead to efficient strategies to enforce the consistency requirements among the corporate data managed in multiple databases. We believe that our specification framework can help in the maintenance of data that meet a business's consistency needs, reduce time consuming and costly manual operations, and provide data of better quality to end users.	SIGMOD Conferen	database
1861	SIGMOD Conference	An Instant and Accurate Estimation Method for Joins and Selection in a Retrieval-Intensive Environment.	Wei Sun,Yibei Ling,Naphtali Rishe,Yi Deng	1993	An Instant and Accurate Estimation Method for Joins and Selection in a Retrieval-Intensive Environment.	SIGMOD Conferen	database
1862	SIGMOD Conference	DDB: An Object Oriented Design Data Manager for VLSI CAD.	Anoop Singhal,Robert M. Arlein,Chi-Yuan Lo	1993	In this paper we present an object oriented data model for VLSI/CAD data. A design data manager (DDB) based on such a model has been implemented under the UNIX/C++ environment. It has been used by a set of diverse VLSI/CAD applications of our organization. Benchmarks have shown it to perform better as compared to commercial object oriented database systems. In conjunction with the ease of data access, the data manger served to improve software productivity and a modular program architecture for our CAD system.	SIGMOD Conferen	database
1863	SIGMOD Conference	OSAM*KBMS: An Object-Oriented Knowledge Base Management System for Supporting Advanced Applications.	Stanley Y. W. Su,Herman Lam,Srinivasa Eddula,Javier Arroyo,Neeta Prasad,Ronghao Zhuang	1993	OSAM*KBMS: An Object-Oriented Knowledge Base Management System for Supporting Advanced Applications.	SIGMOD Conferen	database
1864	SIGMOD Conference	The International Directory Network and Connected Data Information Systems for Research in the Earth and Space Sciences.	James R. Thieman	1993	Many researchers are becoming aware of the International Directory Network (IDN), an interconnected federation of international directories to Earth and space science data. These directories may become distributed nodes of a single, virtual master data directory of the future. Not as many are aware, however, of the many Earth-and-space-sciece-relevant information systems which can be accessed automatically from the directories. After determining potentially useful data sets in various disciplines through IDN directories it is becoming increasingly possible to get detailed information about the correlative possibilities of these data sets through the connected guide/catalog and inventory systems. Such capabilities as data set browse, subsetting, analysis, etc. are available now and will be improving in the future.	SIGMOD Conferen	database
1865	SIGMOD Conference	Caching and Database Scaling in Distributed Shard-Nothing Information Retrieval Systems.	Anthony Tomasic,Hector Garcia-Molina	1993	A common class of existing information retrieval system provides access to abstracts. For example Stanford University, through its FOLIO system, provides access to the INSPECT database of abstracts of the literature on physics, computer science, electrical engineering, etc. In this paper this database is studied by using a trace-driven simulation. We focus on physical index design, inverted index caching, and database scaling in a distributed shared-nothing system. All three issues are shown to have a strong effect on response time and throughput. Database scaling is explored in two ways. One way assumes an &ldquo;optimal&rdquo; configuration for a single host and then linearly scales the database by duplicating the host architecture as needed. The second way determines the optimal number of hosts given a fixed database size.	SIGMOD Conferen	database
1866	SIGMOD Conference	The Miro DBMS.	Michael Stonebraker	1993	This short paper explains the key object-relational (OR) DBMS technology used by the Miro DBMS.	SIGMOD Conferen	database
1867	SIGMOD Conference	The Sequoia 2000 Benchmark.	Michael Stonebraker,James Frew,Kenn Gardels,Jeff Meredith	1993	The Sequoia 2000 Benchmark.	SIGMOD Conferen	database
1868	SIGMOD Conference	Parallel Database Processing on the KSR1 Computer.	Emy Tseng,David S. Reiner	1993	The Kendall Square Research high performance computer (KSR1) provides a spectrum of parallel database processing techniques to achieve scalability and performance in a shared memory environment. The techniques include running multiple transactions in parallel, decomposing queries into parallel subqueries, running multiple instances of the DBMS and partitioning data over disks. These techniques enable on-line transactions to be run in parallel at high throughput rates and decision-support queries to be parallelized and executed very rapidly. This paper focuses upon two of the parallel database processing techniques used on the KSR1&mdash;the Kendall Square Query Decomposer and the Oracle Parallel Server. The Query Decomposer intercepts costly decision support queries and decomposes them into subqueries which are executed in parallel. Parallel Server enables multiple ORACLE instances to run simultaneously on the same database.	SIGMOD Conferen	database
1869	SIGMOD Conference	Towards a Unified Visual Database Access.	Kumar V. Vadaparty,Y. Alp Aslandogan,Gultekin Özsoyoglu	1993	Since the development of QBE, over fifty visual query languages have been proposed to facilitate easy database access. Although these languages have introduced some very useful paradigms, a number of these have some severe limitations, such as: (a) not extending beyond the relational model (b) not considering negation and safety, formally (c) using ad hoc constructs, with no analysis of expressivity or complexity done, etc. Note that visual database access is an important issue being revisted, with the emergence of different flavors of object-oriented databases. We believe that there is a need for developing a unified visual query language. Specifically, our goal is to develop a visual query language that has the following properties: (i) It has a few core constructs using which &ldquo;expert-users&rdquo; can define new (derived) constructs easily (ii) &ldquo;Normal users&rdquo; can use easily either the core or the derived constructs for database querying (iii) It can implement representative constructs of other (textual or visual) query language straightforwardly, and (iv) It has formal semantics, with its theoretical properties, such as complexity, analyzed. We believe that we make a first step towards the above goal by introducing a new logical construct called restricted universal quantifier and combining it with the hierarchical structure of windows to develop a Visual Query Language, called VQL. The core constructs of VQL can encode easily a number of representative constructs of different (about six visual and four non-visual) relational, nested and object-oriented query languages. We also study the theoretical aspects such as safety, complexity, etc., of VQL.	SIGMOD Conferen	database
1870	SIGMOD Conference	Modularity and Tuning Mechanisms in the O2 System.	Fernando Vélez	1993	The O2 System is a commercial Object-Oriented Database Management System with a complete development environment and a set of user interface tools. In this presentation, we focus on the modularity and application tuning facilities of the system.	SIGMOD Conferen	database
1871	SIGMOD Conference	A Deductive and Object-Oriented Database System: Why and How?	Laurent Vieille	1993	This talk will outline the principles, the architecture and the potential target applications of a Deductive and Object-Oriented Database System (DOOD). Such systems combine the novel functionalities (relying on the associated technology) developed in deductive database projects, the ability to manipulate the complex objects appearing in many applications and the architectural advances achieved by Object-Oriented DBMS's.	SIGMOD Conferen	database
1872	SIGMOD Conference	Single Logical View over Enterprise-Wide Distributed Databases.	Andrew E. Wade	1993	Two trends in today's corporate world demand distribution: downsizing from centralized mainframe single database environments; and wider integration, connecting finance, engineering, manufacturing information systems for enterprise-wide modeling and operations optimization. The resulting environment consists of multiple databases, at the group level, department level, and corporate level, with the need to manage dependencies among data in all of them. The solution is full distribution, providing a single logical view to objects anywhere, from anywhere. Users see a logical model of objects connected to objects, with atomic transactions and propagating methods, even if composite objects are split among multiple databases, each under separate administrative control, on multiple, heterogeneous platforms, operating systems, and network protocols. Support for production environments includes multiple schemas, which may be shared among databases, private, or encrypted, dynamic addition of schemas, and schema evolution. Finally, the logical view must remain valid, and applications must continue to work, as the mapping to the physical environment changes, moving objects and databases to new platforms.	SIGMOD Conferen	database
1873	SIGMOD Conference	Temporal Modules: An Approach Toward Federated Temporal Databases.	Xiaoyang Sean Wang,Sushil Jajodia,V. S. Subrahmanian	1993	In a federated database environment, different constituents of the federation may use different temporal models or physical representations for temporal information. This paper introduces a new concept, called a temporal module, to resolve these differences, or mismatches, among the constituents. Intuitively, a temporal module hides the implementation details of a temporal relation by exposing its information only through two windowing functions: The first function associates each time point with a set of tuples and the second function links each tuple to a set of time points. A calculus-style language is given to form queries on temporal modules. Temporal modules are then extended to resolve another type of mismatch among the constituents of a federation, namely, the mismatch involving different time units (e.g., month, week and day) used to record temporal information. Our solution relies on &ldquo;information conversions&rdquo; provided by each constituent. Specifically, each temporal module is extended to provide several &ldquo;windows&rdquo; to its information, each in terms of a different time unit. The first step to process a query addressed to the federation is to select suitable windows to the underlying temporal modules. In order to facilitate such a process, time units are formally defined and studied. A federated temporal database model and its query language are proposed. The query language is an extension of the above calculus-style language.	SIGMOD Conferen	database
1874	SIGMOD Conference	Interpreting a Reconstructed Relational Calculus (Extended Abstract).	Aaron Watters	1993	This paper describes a method for answering all relational calculus queries under the assumption that the domain of data values is sufficiently large. The method extends recent theoretical results that use extended relation representations to answer domain dependent queries, without the use of auxilliary variables or invented constants or an explicit enumeration of the active domain. The method is shown to be logically correct and to have polynomial data complexity. By identifying relational algebra operations with relational calculus queries this approach extends relational algebra to a full boolean algebra, where intersection, union, and difference are defined between any two relations, whether or not they are union compatible. An example illustrates that this approach can be useful in distributed query optimization.	SIGMOD Conferen	database
1875	SIGMOD Conference	Intelligent Integration of Information.	Gio Wiederhold	1993	This paper describes and classifies methods to transform data to information in a three-layer, mediated architecture. The layers can be characterized from the top down as information-consuming applications, mediators which perform intelligent integration of information (I3), and data, knowledge and simulation resources. The objective of modules in the I3 architecture is to provide end users' apoplications with information obtained through selection, abstraction, fusion, caching, extrapolation, and pruning of data. The data is obtained from many diverse and heterogeneous sources. The I3 objective requires the establishment of a consensual information system architecture, so that many participants and technologies can contribute. An attempt to provide such a range of services within a single, tightly integrated system is unlikely to survive technological or environmental change. This paper focuses on the computational models needed to support the mediating functions in this architecture and introduces initial applicatiions. The architecture has been motivated in [Wied:92C].	SIGMOD Conferen	database
1876	SIGMOD Conference	Task Scheduling Using Intertask Dependencies in Carot.	Darrell Woelk,Paul C. Attie,Philip Cannata,Greg Meredith,Amit P. Sheth,Munindar P. Singh,Christine Tomlinson	1993	The Carnot Project at MCC is addressing the problem of logically unifying physically-distributed, enterprise-wide, heterogeneous information. Carnot will provide a user with the means to navigate information efficiently and transparently, to update that information consistently, and to write applications easily for large, heterogeneous, distributed information systems. A prototype has been implemented which provides services for (a) enterprise modeling and model integration to create an enterprise-wide view, (b) semantic expansion of queries on the view to queries on individual resources, and (c) inter-resource consistency management. This paper describes the Carnot approach to transaction processing in environments where heterogeneous, distributed, and autonomous systems are required to coordinate the update of the local information under their control. In this approach, subtransactions are represented as a set of tasks and a set of intertask dependencies that capture the semantics of a particular relaxed transaction model. A scheduler has been implemented which schedules the execution of these tasks in the Carnot environment so that all intertask dependencies are satisfied.	SIGMOD Conferen	database
1877	SIGMOD Conference	Modeling Battlefield Sensor Environments with an Object Database Management System.	Mark A. Woyna,John H. Christiansen,Christopher W. Hield,Kathy Lee Simunich	1993	The Visual Intelligence and Electronic Warfare Simulation (VIEWS) Workbench software system has been developed by Argonne National Laboratory (ANL) to enable Army intelligence and electronic warfare (IEW) analysts at Unix workstations to conveniently build detailed IEW battlefield scenarios, or &ldquo;sensor environments&rdquo;, to drive the Army's high-resolution IEW sensor performance models. VIEWS is fully object-oriented, including the underlying database.	SIGMOD Conferen	database
1878	SIGMOD Conference	Incremental Database Systems: Databases from Ground Up.	Stanley B. Zdonik	1993	Incremental Database Systems: Databases from Ground Up.	SIGMOD Conferen	database
1879	VLDB	Data Sharing Analysis for a Database Programming Lanaguage via Abstract Interpretation.	Giuseppe Amato,Fosca Giannotti,Gianni Mainetto	1993	Data Sharing Analysis for a Database Programming Lanaguage via Abstract Interpretation.	VLDB	database
1880	VLDB	Querying and Updating the File.	Serge Abiteboul,Sophie Cluet,Tova Milo	1993	Querying and Updating the File.	VLDB	database
1881	VLDB	An Object Data Model with Roles.	Antonio Albano,Roberto Bergamini,Giorgio Ghelli,Renzo Orsini	1993	An Object Data Model with Roles.	VLDB	database
1882	VLDB	Specifying and Enforcing Intertask Dependencies.	Paul C. Attie,Munindar P. Singh,Amit P. Sheth,Marek Rusinkiewicz	1993	Specifying and Enforcing Intertask Dependencies.	VLDB	database
1883	VLDB	Object Database Morphology.	François Bancilhon	1993	Object Database Morphology.	VLDB	database
1884	VLDB	Collections of Objects in SQL3.	David Beech	1993	Collections of Objects in SQL3.	VLDB	database
1885	VLDB	Object-Oriented Database Systems: Promises, Reality, and Future.	Won Kim	1993	Object-Oriented Database Systems: Promises, Reality, and Future.	VLDB	database
1886	VLDB	STDL - A Portable Language for Transaction Processing.	Philip A. Bernstein,Per O. Gyllstrom,Tom Wimberg	1993	STDL - A Portable Language for Transaction Processing.	VLDB	database
1887	VLDB	Toward Practical Constraint Databases.	Alexander Brodsky,Joxan Jaffar,Michael J. Maher	1993	Toward Practical Constraint Databases.	VLDB	database
1888	VLDB	Managing Memory to Meet Multiclass Workload Response Time Goals.	Kurt P. Brown,Michael J. Carey,Miron Livny	1993	Managing Memory to Meet Multiclass Workload Response Time Goals.	VLDB	database
1889	VLDB	Managing Semantic Heterogeneity with Production Rules and Persistent Queues.	Stefano Ceri,Jennifer Widom	1993	Managing Semantic Heterogeneity with Production Rules and Persistent Queues.	VLDB	database
1890	VLDB	Declustering Objects for Visualization.	Ling Tony Chen,Doron Rotem	1993	Declustering Objects for Visualization.	VLDB	database
1891	VLDB	Adaptive Database Buffer Allocation Using Query Feedback.	Chung-Min Chen,Nick Roussopoulos	1993	Adaptive Database Buffer Allocation Using Query Feedback.	VLDB	database
1892	VLDB	Managing Temporal Financial Data in an Extensible Database.	Rakesh Chandra,Arie Segev	1993	Managing Temporal Financial Data in an Extensible Database.	VLDB	database
1893	VLDB	Query Optimization in the Presence of Foreign Functions.	Surajit Chaudhuri,Kyuseok Shim	1993	Query Optimization in the Presence of Foreign Functions.	VLDB	database
1894	VLDB	A Practical Issue Concerning Very Large Data Bases: The Need for Query Governors.	Gerald Cohen	1993	A Practical Issue Concerning Very Large Data Bases: The Need for Query Governors.	VLDB	database
1895	VLDB	An Adaptive Algorithm for Incremental Evaluation of Production Rules in Databases.	Françoise Fabret,Mireille Régnier,Eric Simon	1993	An Adaptive Algorithm for Incremental Evaluation of Production Rules in Databases.	VLDB	database
1896	VLDB	Problems/Challenges facing Industry Data Base Users.	Kevin Fitzgerald	1993	Problems/Challenges facing Industry Data Base Users.	VLDB	database
1897	VLDB	Local Disk Caching for Client-Server Database Systems.	Michael J. Franklin,Michael J. Carey,Miron Livny	1993	Local Disk Caching for Client-Server Database Systems.	VLDB	database
1898	VLDB	A Model of Methods Access Authorization in Object-oriented Databases.	Nurit Gal-Oz,Ehud Gudes,Eduardo B. Fernández	1993	A Model of Methods Access Authorization in Object-oriented Databases.	VLDB	database
1899	VLDB	On Implementing a Language for Specifying Active Database Execution Models.	Shahram Ghandeharizadeh,Richard Hull,Dean Jacobs,Jaime Castillo,Martha Escobar-Molano,Shih-Hui Lu,Junhui Luo,Chiu Tsang,Gang Zhou	1993	On Implementing a Language for Specifying Active Database Execution Models.	VLDB	database
1900	VLDB	Combining Theory and Practice in Integrity Control: A Declarative Approach to the Specification of a Transaction Modification Subsystem.	Paul W. P. J. Grefen	1993	Combining Theory and Practice in Integrity Control: A Declarative Approach to the Specification of a Transaction Modification Subsystem.	VLDB	database
1901	VLDB	Managing Derived Data in the Gaea Scientific DBMS.	Nabil I. Hachem,Ke Qiu,Michael A. Gennert,Matthew O. Ward	1993	Managing Derived Data in the Gaea Scientific DBMS.	VLDB	database
1902	VLDB	Performance of Catalog Management Schemes for Running Access Modules in a Locally Distributed Database System.	Eui Kyeong Hong	1993	Performance of Catalog Management Schemes for Running Access Modules in a Locally Distributed Database System.	VLDB	database
1903	VLDB	Update Logging for Persistent Programming Languages: A Comparative Performance Evaluation.	Antony L. Hosking,Eric W. Brown,J. Eliot B. Moss	1993	Update Logging for Persistent Programming Languages: A Comparative Performance Evaluation.	VLDB	database
1904	VLDB	Implementation and Performance Evaluation of a Parallel Transitive Closure Algorithm on PRISMA/DB.	Maurice A. W. Houtsma,Annita N. Wilschut,Jan Flokstra	1993	Implementation and Performance Evaluation of a Parallel Transitive Closure Algorithm on PRISMA/DB.	VLDB	database
1905	VLDB	Universality of Serial Histograms.	Yannis E. Ioannidis	1993	Universality of Serial Histograms.	VLDB	database
1906	VLDB	An Active Object-Oriented Database: A Multi-Paradigm Approach to Constraint Management.	Hiroshi Ishikawa,Kazumi Kubota	1993	An Active Object-Oriented Database: A Multi-Paradigm Approach to Constraint Management.	VLDB	database
1907	VLDB	Recovering from Main-Memory Lapses.	H. V. Jagadish,Abraham Silberschatz,S. Sudarshan	1993	Recovering from Main-Memory Lapses.	VLDB	database
1908	VLDB	Database Research Strategies of Funding Agencies (Panel).	Keith G. Jeffery	1993	Database Research Strategies of Funding Agencies (Panel).	VLDB	database
1909	VLDB	A Blackboard Architecture for Query Optimization in Object Bases.	Alfons Kemper,Guido Moerkotte,Klaus Peithner	1993	A Blackboard Architecture for Query Optimization in Object Bases.	VLDB	database
1910	VLDB	Mobile Computing: Fertile Research Area or Black Hole? (Panel).	Henry F. Korth,Tomasz Imielinski	1993	Mobile Computing: Fertile Research Area or Black Hole? (Panel).	VLDB	database
1911	VLDB	A New Presumed Commit Optimization for Two Phase Commit.	Butler W. Lampson,David B. Lomet	1993	A New Presumed Commit Optimization for Two Phase Commit.	VLDB	database
1912	VLDB	On the Effectiveness of Optimization Search Strategies for Parallel Execution Spaces.	Rosana S. G. Lanzelotte,Patrick Valduriez,Mohamed Zaït	1993	On the Effectiveness of Optimization Search Strategies for Parallel Execution Spaces.	VLDB	database
1913	VLDB	Queries Independent of Updates.	Alon Y. Levy,Yehoshua Sagiv	1993	Queries Independent of Updates.	VLDB	database
1914	VLDB	Key Range Locking Strategies for Improved Concurrency.	David B. Lomet	1993	Key Range Locking Strategies for Improved Concurrency.	VLDB	database
1915	VLDB	Exploiting A History Database for Backup.	David B. Lomet,Betty Salzberg	1993	Exploiting A History Database for Backup.	VLDB	database
1916	VLDB	The Voice of the Customer: Innovative and Useful Research Directions (Panel).	Stuart E. Madnick	1993	The Voice of the Customer: Innovative and Useful Research Directions (Panel).	VLDB	database
1917	VLDB	Dynamic Memory Allocation for Multiple-Query Workloads.	Manish Mehta,David J. DeWitt	1993	Dynamic Memory Allocation for Multiple-Query Workloads.	VLDB	database
1918	VLDB	The Use of Information Capacity in Schema Integration and Translation.	Renée J. Miller,Yannis E. Ioannidis,Raghu Ramakrishnan	1993	The Use of Information Capacity in Schema Integration and Translation.	VLDB	database
1919	VLDB	Control of an Extensible Query Optimizer: A Planning-Based Approach.	Gail Mitchell,Umeshwar Dayal,Stanley B. Zdonik	1993	Control of an Extensible Query Optimizer: A Planning-Based Approach.	VLDB	database
1920	VLDB	A Cost-Effective Method for Providing Improved Data Availability During DBMS Restart Recovery After a Failure.	C. Mohan	1993	A Cost-Effective Method for Providing Improved Data Availability During DBMS Restart Recovery After a Failure.	VLDB	database
1921	VLDB	Memory-Adaptive External Sorting.	HweeHwa Pang,Michael J. Carey,Miron Livny	1993	Memory-Adaptive External Sorting.	VLDB	database
1922	VLDB	The Need for Data Quality.	Blake Patterson	1993	The Need for Data Quality.	VLDB	database
1923	VLDB	Integrity Constraint and Rule Maintenance in Temporal Deductive Knowledge Bases.	Dimitris Plexousakis	1993	Integrity Constraint and Rule Maintenance in Temporal Deductive Knowledge Bases.	VLDB	database
1924	VLDB	Disk Mirroring with Alternating Deferred Updates.	Christos A. Polyzois,Anupam Bhide,Daniel M. Dias	1993	Disk Mirroring with Alternating Deferred Updates.	VLDB	database
1925	VLDB	Towards a Formal Approach for Object Database Design.	Pascal Poncelet,Maguelonne Teisseire,Rosine Cicchetti,Lotfi Lakhal	1993	Towards a Formal Approach for Object Database Design.	VLDB	database
1926	VLDB	A Domain-theoretic Approach to Integrating Functional and Logic Database Languages.	Alexandra Poulovassilis,Carol Small	1993	A Domain-theoretic Approach to Integrating Functional and Logic Database Languages.	VLDB	database
1927	VLDB	Analysis of Dynamic Load Balancing Strategies for Parallel Shared Nothing Database Systems.	Erhard Rahm,Robert Marek	1993	Analysis of Dynamic Load Balancing Strategies for Parallel Shared Nothing Database Systems.	VLDB	database
1928	VLDB	Database Requirements of Knowledge-based Production Scheduling and Control: A CIM Perspective.	Ulf Schreier	1993	Database Requirements of Knowledge-based Production Scheduling and Control: A CIM Perspective.	VLDB	database
1929	VLDB	Reading a Set of Disk Pages.	Bernhard Seeger,Per-Åke Larson,Ron McFadyen	1993	Reading a Set of Disk Pages.	VLDB	database
1930	VLDB	Predictions and Challenges for Database Systems in the Year 2000.	Patricia G. Selinger	1993	Predictions and Challenges for Database Systems in the Year 2000.	VLDB	database
1931	VLDB	Multi-Join Optimization for Symmetric Multiprocessors.	Eugene J. Shekita,Honesty C. Young,Kian-Lee Tan	1993	Multi-Join Optimization for Symmetric Multiprocessors.	VLDB	database
1932	VLDB	The Rufus System: Information Organization for Semi-Structured Data.	Kurt A. Shoens,Allen Luniewski,Peter M. Schwarz,James W. Stamos,Joachim Thomas II	1993	The Rufus System: Information Organization for Semi-Structured Data.	VLDB	database
1933	VLDB	Coral++: Adding Object-Orientation to a Logic Database Language.	Divesh Srivastava,Raghu Ramakrishnan,Praveen Seshadri,S. Sudarshan	1993	Coral++: Adding Object-Orientation to a Logic Database Language.	VLDB	database
1934	VLDB	DBMS Research at a Crossroads: The Vienna Update.	Michael Stonebraker,Rakesh Agrawal,Umeshwar Dayal,Erich J. Neuhold,Andreas Reuter	1993	DBMS Research at a Crossroads: The Vienna Update.	VLDB	database
1935	VLDB	Tioga: Providing Data Management Support for Scientific Visualization Applications.	Michael Stonebraker,Jolly Chen,Nobuko Nathan,Caroline Paxson,Jiang Wu	1993	Tioga: Providing Data Management Support for Scientific Visualization Applications.	VLDB	database
1936	VLDB	Viewers: A Data-World Analogue of Procedure Calls.	Kazimierz Subieta,Florian Matthes,Joachim W. Schmidt,Andreas Rudloff	1993	Viewers: A Data-World Analogue of Procedure Calls.	VLDB	database
1937	VLDB	Versions of Simple and Composite Objects.	Guilaine Talens,Chabane Oussalah,M. F. Colinas	1993	Versions of Simple and Composite Objects.	VLDB	database
1938	VLDB	A Plan-Operator Concept for Client-Based Knowledge Progressing.	Joachim Thomas,Stefan Deßloch	1993	A Plan-Operator Concept for Client-Based Knowledge Progressing.	VLDB	database
1939	VLDB	Applying Hash Filters to Improving the Execution of Bushy Trees.	Ming-Syan Chen,Hui-I Hsiao,Philip S. Yu	1993	Applying Hash Filters to Improving the Execution of Bushy Trees.	VLDB	database
1940	VLDB	NCR 3700 - The Next-Generation Industrial Database Computer.	Andrew Witkowski,Felipe Cariño,Pekka Kostamaa	1993	NCR 3700 - The Next-Generation Industrial Database Computer.	VLDB	database
1941	VLDB	Algebraic Optimization of Computations over Scientific Databases.	Richard H. Wolniewicz,Goetz Graefe	1993	Algebraic Optimization of Computations over Scientific Databases.	VLDB	database
1942	VLDB	Searching Large Lexicons for Partially Specified Terms using Compressed Inverted Files.	Justin Zobel,Alistair Moffat,Ron Sacks-Davis	1993	Searching Large Lexicons for Partially Specified Terms using Compressed Inverted Files.	VLDB	database
1943	VLDB	Hamming Filters: A Dynamic Signature File Organization for Parallel Stores.	Pavel Zezula,Paolo Ciaccia,Paolo Tiberio	1993	Hamming Filters: A Dynamic Signature File Organization for Parallel Stores.	VLDB	database
1944	SIGMOD Record	Helping Computer Scientists in Romania.	I. Athanasiu	1993	As a Professor in the Computer Science Department of the Polytechnical Institute of Bucharest, Romania, I would like to bring to your attention the effort of a group of professionals, researchers, students and professors around the world. This effort, called &ldquo;Free UNIX for Romania&rdquo;, has been initiated and coordinated by Marius Hancu, an advisor at the Parallel Architectures Group, Center de Recherche Informatique de Montreal, Montreal, Canada.	SIGMOD Record	database
1945	SIGMOD Record	Bibliography on Spatiotemporal Databases.	Khaled K. Al-Taha,Richard T. Snodgrass,Michael D. Soo	1993	Spatial and temporal databases are important and well-established sub-disciplines of database research. Some 350 papers in temporal databases have appeared, authored by almost 300 researchers. The literature on spatial databases is also substantial; the bibliography of Samet's landmark book on spatial data structures lists 823 references.	SIGMOD Record	database
1946	SIGMOD Record	Extending the Scope of Database Services.	Daniel Barbará	1993	A wide variety of important data remains outside of the scope of database management systems. In recent years researchers have been making efforts in two directions: first, developing database management systems that can support non-traditional data, and secondly, offering database services for data that remains under control of autonomous (not necessarily database) systems. The purpose of this paper is to provide a brief review of these efforts.	SIGMOD Record	database
1947	SIGMOD Record	MoodView: An Advanced Graphical User Interface for OODBMSs.	Ismailcem Budak Arpinar,Asuman Dogac,Cem Evrendilek	1993	OODBMSs need more than declarative query languages and programming languages as their interfaces since they are designed and implemented for complex applications requiring more advanced and easy to use visual interfaces. We have developed a complete programming environment for this purpose, called MoodView. MoodView translates all the user actions performed through its graphical interface to SQL statements and therefore it can be ported onto any object-oriented database systems using SQL. MoodView provides the database programmer with tools and functionalities for every phase of object oriented database application development. Current version of MoodView allows a database user to design, browse, and modify database schema interactively and to display class inheritance hierarchy as a directed acyclic graph. MoodView can automatically generate graphical displays for complex and multimedia database objects which can be updated through the object browser. Furthermore, a database administration tool, a full screen text-editor, a SQL based query manager, and a graphical indexing tool for the spatial data, i.e., R Trees are also implemented.	SIGMOD Record	database
1948	SIGMOD Record	Merging Application-centric and Data-centric Approaches to Support Transaction-oriented Multi-system Workflows.	Yuri Breitbart,Andrew Deacon,Hans-Jörg Schek,Amit P. Sheth,Gerhard Weikum	1993	Workflow management is primarily concerned with dependencies between the tasks of a workflow, to ensure correct control flow and data flow. Transaction management, on the other hand, is concerned with preserving data dependencies by preventing execution of conflicting operations from multiple, concurrently executing tasks or transactions. In this paper we argue that many applications will be served better if the properties of transaction and workflow models are supported by an integrated architecture. We also present preliminary ideas towards such an architecture.	SIGMOD Record	database
1949	SIGMOD Record	Remarks on Two New Theorems of Date and Fagin.	H. W. Buff	1993	Remarks on Two New Theorems of Date and Fagin.	SIGMOD Record	database
1950	SIGMOD Record	SIRIO: A Distributed Information System over a Heterogeneous Computer Network.	Carmen Costilla,M. J. Bas,J. Villamor	1993	This paper presents the SIRIO project, a commercial experience within Spanish industry, developed for Tecnatom S.A. by the Data and Knowledge Bases Research Group at the Technical University of Madrid. SIRIO runs over a heterogeneous local area network, with a client-server architecture, using the following tools: Oracle as RDBMS, running over a Unix server, TCP/IP as a communication protocol, Ethernet TOOLKIT for the distributed client-server architecture, and C as the host programming language for the distributed applications (every one of them is rather complex and very different from the rest). The system uses computers with MS-DOS, connected to the server over the LAN. SIRIO is mainly based on the conceptual design of an Rdb, upon which several distributed applications are operational as big software modules. These applications are: 1.- The inspection programs, the management of their corresponding criteria and the automatic generation of queries. 2.- Graphics processing and interface definition. 3.- Interactive Rdb updating. 4.- Historical db management. 5.- Massive load of on-field obtained data. 6.- Report and query application. The approach of the SIRIO integrated information system presented here is a pioneering one. There are about two dozen companies worldwide in this field and none has developed such an advanced system to this day. From 1992, SIRIO is totally operational in the Tecnatom S.A. industry. It constitutes an important tool to obtain the reports (from different plants) for the clients, for the State control organizations, and for the specialized analyst staff.	SIGMOD Record	database
1951	SIGMOD Record	Response to Remarks on Two New Theorems of Date and Fagin.	C. J. Date,Ronald Fagin	1993	Response to Remarks on Two New Theorems of Date and Fagin.	SIGMOD Record	database
1952	SIGMOD Record	Report of the Workshop on Semantic Heterogeneity and Interoperation in Multidatabase Systems.	Pamela Drew,Roger King,Dennis McLeod,Marek Rusinkiewicz,Abraham Silberschatz	1993	This report presents a review of the problems that were discussed during the Workshop on Semantic Heterogeneity and Interoperability in Multidatabase Systems. The workshop participants discussed the importance of interoperation in the U S WEST information processing environment and the progress that has been achieved in three major research areas: resolution of semantic heterogeneity among cooperating heterogeneous systems, transaction management in such environments, and software architecture for interoperation. The workshop provided researchers with necessary feedback from the industrial perspective and helped in identifying the major issues that need further research. The following problems concerning the applicability of the methods proposed for data processing in the heterogeneous, autonomous information systems have been identified: (i) many of the assumptions made in the research community are too restrictive to make the results directly applicable to existing environments; (ii) performance ramifications of various heterogeneous architectures need to be understood; (iii) the prototype systems need to be put to the test with real data, schemas, and transaction streams to verify their utility.	SIGMOD Record	database
1953	SIGMOD Record	PARDES - A Data-Driven Oriented Active Database Model.	Opher Etzion	1993	Most active database models adopted an event-driven approach in which whenever a given event occurs the database triggers some actions. Many derivations are data-driven by nature, deriving the values of data-elements as a function of the values of other derived data-elements. The handling of such rules by current active databases suffers from semantic and pragmatic fallacies. This paper explores these fallacies and reports about the PARDES language and supporting architecture, aiming at the support of data-driven rules, in an active database framework.	SIGMOD Record	database
1954	SIGMOD Record	Parametric Databases: Seamless Integration of Spatial, Temporal, Belief and Ordinary Data.	Shashi K. Gadia	1993	Our model, algebra and SQL-like query language for temporal databases extend naturally to parametric data, of which spatial, temporal, spatio-temporal, belief and ordinary data are special cases.	SIGMOD Record	database
1955	SIGMOD Record	Options in Physical Database Design.	Goetz Graefe	1993	A cornerstone of modern database systems is physical data independence, i.e., the separation of a type and its associated operations from its physical representation in memory and on storage media. Users manipulate and query data at the logical level; the DBMS translates these logical operations to operations on files, indices, records, and disks. The efficiency of these physical operations depends very much on the choice of data representations. Choosing a physical representation for a logical database is called physical database design. The number of possible choices in physical database design is very large; moreover, they very often interact with each other. We attempt to list and classify these choices and to explore their interactions. The purpose of this paper is to provide an overview of possible options to the DBMS developer and some guidance to the DBMS administrator and user. While much of our discussion will draw on the relational data model, physical database design is of even more importance for object-oriented and extensible systems. The reasons are simple: First, the number of logical data types and their operations is larger, requiring and permitting more choices for their representation. Second, the state of the art in query optimization for these systems is much less developed than for relational systems, making careful physical database design even more imperative for object-oriented database systems.	SIGMOD Record	database
1956	SIGMOD Record	Data Management for Mobile Computing.	Tomasz Imielinski,B. R. Badrinath	1993	Mobile Computing is a new emerging computing paradigm of the future. Data Management in this paradigm poses many challenging problems to the database community. In this paper we identify these new challenges and plan to investigate their technical significance. New research problems include management of location dependent data, wireless data broadcasting, disconnection management and energy efficient data access.	SIGMOD Record	database
1957	SIGMOD Record	A Performance Study of Concurrency Control in a Real-Time Main Memory Database System.	Le Gruenwald,Sichen Liu	1993	Earlier performance studies of concurrency control algorithms show that in a disk-resident real-time database system, optimistic algorithms perform better than two phase locking with higher priority (2PL-HP). In a main memory real-time database system, disk I/Os are eliminated and thus more transactions are enabled to meet their real-time constraints. Lack of disk I/Os in this environment requires concurrency control be re-examined. This paper conducts a simulation study to compare 2PL-HP with a real time optimistic concurrency control algorithm (OPT-WAIT-50) for a real time main memory database system, MARS. The results show that OPT-WAIT-50 outperforms 2PL-HP with finite resources.	SIGMOD Record	database
1958	SIGMOD Record	Database Research at AT&T Bell Laboratories.	H. V. Jagadish	1993	Database Research at AT&T Bell Laboratories.	SIGMOD Record	database
1959	SIGMOD Record	NSF Workshop on Visual Information Management Systems.	Ramesh Jain	1993	One of the most important technologies needed across many traditional areas as well as emerging new frontiers of computing, is the management of visual information. For example, most of the Grand Challenge applications, under the High Performance Computing and Communication (HPCC) initiative, require management of large volumes of non-alphanumeric information, computations, communication, and visualization of results. Considering the growing need and interest in the organization and retrieval of visual and other non-alphanumeric information, and in order to stimulate academic projects in this area, a workshop on Visual Information Management Systems (VIMS) was sponsored by the National Science Foundation. This workshop was held in Redwood, CA, on February 24-25, 1992. The goal of the workshop was to identify major research areas that should be addressed by researchers for VIMS that would be useful in scientific, industrial, medical, environmental, educational, entertainment, and other applications. The major findings of the workshop were that VIMS require new techniques in all aspects of databases, computer vision, and knowledge representation and management; and that such techniques are best developed in the context of concrete, practical applications. VIMS will provide impetus and testbeds for many techniques being explored for the future database systems. Researchers from image processing and understanding, knowledge representation and knowledge based systems, and databases must work very closely to develop VIMS. Such systems should be developed in the context of applications that will be of immediate interest in industrial, medical, or scientific contexts. Without concrete applications and ambitious implementation projects, most of the important and difficult issues are likely to be ignored. Considering the interdisciplinary nature of the research in this area, a few major research projects in this area are essential for its growth. Increased emphasis on HPCC by many Federal agencies can help in the rapid development of VIMS technology. Similarly, by addressing some of the Grand Challenges, research interested in VIMS can understand critical issues and develop techniques to solve them, in a concrete and useful context. Parallel processing is essential for implementing VIMS. As is well known, the processing of images is one of the most computation-intensive tasks. For entering images in databases and for performing required operations at query time, an enormous volume of data must be processed. Parallel computing will be essential for implementing a VIMS that can insert images in reasonable time and provide fast response to user queries. The computational requirements of video databases are likely to be one of the most demanding. It is very likely that video databases will require research in highly parallel-pipelined architectures. In interdisciplinary research areas such as VIMS, most important and difficult problems usually fall through the cracks. The three most relevant areas for the development of VIMS are: databases, computer vision, and knowledge representation. Data compression, fault-tolerant real time access to image data through networks, and parallel processing issues should be addressed in the context of databases for VIMS. VIMS should not be considered as an application of the existing state of the art in any of these fields to manage and process images. Database researchers must understand the issues specific to managing and processing images and other forms of data by granting them the same status that has been given to alphanumeric information. Computer vision researchers should identify features required for interactive image understanding, rather than their discipline's current emphasis on automatic techniques, and develop techniques to compute features in interactive environments. Most knowledge representation research has been concerned with symbolic k knowledge. For VIMS and HPCC applications, techniques for representing symbolic and non-symbolic representations at the same level will be required. Reasoning approaches that can deal with such representations will be useful not only in VIMS, but in many other applications also. Finally, performance issues pose a significant challenge in all aspects of VIMS, from memory organization to information retrieval.	SIGMOD Record	database
1960	SIGMOD Record	Database Conference Calendar / Calls For Papers.	Keith G. Jeffery	1993	Database Conference Calendar / Calls For Papers.	SIGMOD Record	database
1961	SIGMOD Record	Database Conference Calendar.	Keith G. Jeffery	1993	Database Conference Calendar.	SIGMOD Record	database
1962	SIGMOD Record	Chair's Message.	Won Kim	1993	Chair's Message.	SIGMOD Record	database
1963	SIGMOD Record	Chair's Message.	Won Kim	1993	Chair's Message.	SIGMOD Record	database
1964	SIGMOD Record	Chair's Message.	Won Kim	1993	Chair's Message.	SIGMOD Record	database
1965	SIGMOD Record	An Update of the Temporal Database Bibliography.	Nick Kline	1993	An Update of the Temporal Database Bibliography.	SIGMOD Record	database
1966	SIGMOD Record	Implementation of a Graph-Based Data Model for Complex Objects.	Mark Levene,Alexandra Poulovassilis,Kerima Benkerimi,Sara Schwartz,Eran Tuv	1993	We have developed a graph-based data model called the Hypernode Model whose single data structure is the hypernode, a directed graph whose nodes may themselves reference further directed graphs. A prototype database system supporting this model is being developed at London University as part of a project whose aims are threefold: (i) to ascertain the expressiveness and flexibility of the hypernode model, (ii) to experiment with various querying paradigms for this model, and (iii) to investigate the suitability of the directed graph as a data structure supported throughout all levels of the implementation. The purpose of this paper is to report upon our findings to date.	SIGMOD Record	database
1967	SIGMOD Record	A Survey on Usage of SQL.	Hongjun Lu,Hock Chuan Chan,Kwok Kee Wei	1993	Relational database systems have been on market for more than a decade. SQL has been accepted as the standard query language of relational systems. To further understand the usage of relational systems and relational query language SQL, we conducted a survey recently that covers various aspects of the usage of SQL in industrial organizations. In this paper, we present those results that may interest DBMS researcher and developers, including the profiles of SQL users, the application areas where SQL is used, the usage of different features of SQL and difficulties encountered by SQL users.	SIGMOD Record	database
1968	SIGMOD Record	Database Research at the Data-Intensive Systems Center.	David Maier,Lois M. L. Delcambre,Calton Pu,Jonathan Walpole,Goetz Graefe,Leonard D. Shapiro	1993	Database Research at the Data-Intensive Systems Center.	SIGMOD Record	database
1969	SIGMOD Record	Schema Evolution in OODBs Using Class Versioning.	Simon R. Monk,Ian Sommerville	1993	This paper describes work carried out on a model for the versioning of class definitions in an object-oriented database. By defining update and backdate functions on attributes of the previous and current version of a class definition, instances of any version of the class can be converted to instances of any other version. This allows programs written to access an old version of the schema to still use data created in the format of the changed schema.	SIGMOD Record	database
1970	SIGMOD Record	Database Research at the University of Queensland.	Maria E. Orlowska	1993	Database Research at the University of Queensland.	SIGMOD Record	database
1971	SIGMOD Record	Workshop Report: International Workshop on Distributed Object Management.	M. Tamer Özsu,Umeshwar Dayal,Patrick Valduriez	1993	The International Workshop on Distributed Object Management (IWDOM) was organized in Edmonton, Canada on the University of Alberta campus between August 19-21, 1992. The Workshop addressed the theory and practice of developing distributed object-oriented database management systems (OODBMS). The objective was to take note of the state-of-the-art in distributed object management technology and to identify the issues that need to be resolved. The recent developments in standards-related activities, notably the release of the CORBA specifications by the Object Management Group, contributed to the timeliness and importance of the Workshop.	SIGMOD Record	database
1972	SIGMOD Record	Role-Based Security, Object Oriented Databases & Separation of Duty.	Matunda Nyanchama,Sylvia L. Osborn	1993	Role-Based Security, Object Oriented Databases & Separation of Duty.	SIGMOD Record	database
1973	SIGMOD Record	On Temporal Modeling in the Context of Object Databases.	Niki Pissinou,Kia Makki,Yelena Yesha	1993	On Temporal Modeling in the Context of Object Databases.	SIGMOD Record	database
1974	SIGMOD Record	Parallel Query Processing in Shared Disk Database Systems.	Erhard Rahm	1993	System developments and research on parallel query processing have concentrated either on &ldquo;Shared Everything&rdquo; or &ldquo;Shared Nothing&rdquo; architectures so far. While there are several commercial DBMS based on the &ldquo;Shared Disk&rdquo; alternative, this architecture has received very little attention with respect to parallel query processing. A comparison between Shared Disk and Shared Nothing reveals many potential benefits for Shared Disk with respect to parallel query processing. In particular, Shared Disk supports more flexible control over the communication overhead for intra-transaction parallelism, and a higher potential for dynamic load balancing and efficient processing of mixed OLTP/query workloads. We also sketch necessary extensions for transaction management (concurrency/coherency control, logging/recovery) to support intra-transaction parallelism in the Shared Disk environment.	SIGMOD Record	database
1975	SIGMOD Record	Deadlock Prevention in a Distributed Database System.	P. Krishna Reddy,Subhash Bhalla	1993	The distributed locking based approaches to concurrency control in a distributed database system, are prone to occurrence of deadlocks. An algorithm for deadlock prevention has been considered in this proposal. In this algorithm, a transaction is executed by forming wait for relations with other conflicting transactions. The technique for generation of this kind of precedence graph for transaction execution is analyzed. This approach is a fully distributed approach. The technique is free from deadlocks, avoids resubmission of transactions, and hence reduces processing delays within the distributed environment.	SIGMOD Record	database
1976	SIGMOD Record	Database Compression.	Mark A. Roth,Scott J. Van Horn	1993	Despite the fact that computer memory costs have decreased dramatically over the past few years, data storage still remains, and will probably always remain, an important cost factor for many large scale database applications. Compressing data in a database system is attractive for two reasons: data storage reduction and performance improvement. Storage reduction is a direct and obvious benefit, while performance improves because smaller amounts of physical data need to be moved for any particular operation on the database. We address several aspects of reversible data compression and compression techniques: general concepts of data compression; a number of compression techniques; a comparison of the effects of compression on common data types; advantages and disadvantages of compressing data; and future research needs.	SIGMOD Record	database
1977	SIGMOD Record	Relational Database Integration in the IBM AS/400.	S. Scholerman,L. Miller,J. Tenner,S. Tomanek,M. Zolliker	1993	A great deal of research has been focused on the development of database machines. In parallel to this work some vendors have developed general purpose machines with database function built directly into the machine architecture. The IBM AS/400 is one of the principle examples of this approach. Designed with a strong object orientation and the basis functions of the relational database model integrated into it's architecture, the AS/400 has proved to be a commercial success. In the present work we look at the database component of the AS/400.	SIGMOD Record	database
1978	SIGMOD Record	Editor's Notes.	Arie Segev	1993	Editor's Notes.	SIGMOD Record	database
1979	SIGMOD Record	Editor's Notes.	Arie Segev	1993	Editor's Notes.	SIGMOD Record	database
1980	SIGMOD Record	Editor's Notes.	Arie Segev	1993	Editor's Notes.	SIGMOD Record	database
1981	SIGMOD Record	Database Research at Wisconsin.		1993	Database Research at Wisconsin.	SIGMOD Record	database
1982	SIGMOD Record	Concurrency Control in Trusted Database Management Systems: A Survey.	Bhavani M. Thuraisingham,Hai-Ping Ko	1993	Recently several algorithms have been proposed for concurrency control in a Trusted Database Management System (TDBMS). The various research efforts are examining the concurrency control algorithms developed for DBMSs and adapting them for a multilevel environment. This paper provides a survey of the concurrency control algorithms for a TDBMS and discusses future directions.	SIGMOD Record	database
1983	SIGMOD Record	Schema Transformation without Database Reorganization.	Markus Tresch,Marc H. Scholl	1993	We argue for avoiding database reorganizations due to schema modification in object-oriented systems, since these are expensive operations and they conflict with reusing existing software components. We show that data independence, which is a neglected concept in object databases, helps to avoid reorganizations in case of capacity preserving and reducing schema transformations. We informally present a couple of examples to illustrate the idea of a schema transformation methodology that avoids database reorganization.	SIGMOD Record	database
1984	SIGMOD Record	Experiences with HyperBase: A Hypertext Database Supporting Collaborative Work.	Uffe Kock Wiil	1993	This paper describes the architecture and experiences with a hyperbase (hypertext database). HyperBase is based on the client-server model and has been designed especially to support collaboration. HyperBase has been used in a number of (hypertext) applications in our lab and is currently being used in research projects around the world to provide database support to all kinds of applications. One application from our lab is a multiuser hypertext system for collaboration which deals with three fundamental issues in simultaneous sharing: access contention, real-time monitoring and real-time communication. Major experiences with HyperBase (collaboration support, data modeling and performance) gained from use both in our lab and in different projects at other research sites are reported. One major lesson learned is that HyperBase can provide powerful support for data sharing among multiple users simultaneously sharing the same environment.	SIGMOD Record	database
1985	SIGMOD Record	Change at ONR, and Many Funding Announcements Elsewhere.	Marianne Winslett	1993	In this issue, we describe recent changes at the US Office of Naval Research, and then cover a dozen recent announcements of funding in the US for postdocs, sabbaticals, summer jobs, equipment, and research grants&mdash;just about anything you might need&mdash;from DARPA, the Army, the Air Force, NSF, NIST, and the National Center for Automated Information Research. We also list the newly funded NSF Grand Challenge proposals.	SIGMOD Record	database
1986	SIGMOD Record	SIGMOD Goes On Line: New Member Service Via Internet.	Marianne Winslett	1993	SIGMOD Goes On Line: New Member Service Via Internet.	SIGMOD Record	database
1987	SIGMOD Record	Update on SIGMOD On-Line Services.	Marianne Winslett	1993	Update on SIGMOD On-Line Services.	SIGMOD Record	database
1988	SIGMOD Record	NSF and HPCC Under Attack.	Marianne Winslett	1993	In this issue we describe recent turmoil over NSF, ARPA, and HPCC, and cover funding opportunities from NSF, CRA, NIH, the Army, the Air Force, NIST, and NASA.	SIGMOD Record	database
1989	SIGMOD Record	Timely Access to Future Funding Announcements.	Marianne Winslett,Iris Sheauyin Chu	1993	The last issue of this column appeared six months ago, so in the interim many requests for proposals have been issued, with many of their due dates already past. We are happy to announce the availability of up-to-the-minute funding information on line, so that the Record's publication schedule need not prevent readers' timely access to funding information. In addition, we briefly recap recent requests for proposals from NASA, NLM, the Human Brain Project, the US Army, the US Navy, ARPA, NSF, and Intel; more detailed information on any of these (except Intel) can be found in the on-line archives. We also report on news at NSF and NIST.	SIGMOD Record	database
1990	SIGMOD Record	Database Research at the University of Florida.		1993	Database Research at the University of Florida.	SIGMOD Record	database
1991	SIGMOD Record	Database Research at the University of Twente.		1993	Database Research at the University of Twente.	SIGMOD Record	database
1992	SIGMOD Record	Calls for Papers.		1993	Calls for Papers.	SIGMOD Record	database
1993	SIGMOD Record	Calls for Papers.		1993	Calls for Papers.	SIGMOD Record	database
1994	Artificial Intelligence in Medicine	On the soundness and safety of expert systems.	J. Fox	1993	On the soundness and safety of expert systems.	Artificial Inte	medical
1995	Artificial Intelligence in Medicine	Multiple disorder diagnosis with adaptive competitive neural networks.	Sungzoon Cho,James A. Reggia	1993	Multiple disorder diagnosis with adaptive competitive neural networks.	Artificial Inte	medical
1996	Artificial Intelligence in Medicine	A constraint logic programming framework for constructing DNA restriction maps.	R. Y. Chuan	1993	A constraint logic programming framework for constructing DNA restriction maps.	Artificial Inte	medical
1997	Artificial Intelligence in Medicine	Guaranteeing real-time response with limited resources.	David Ash,G. Gold,Adam Seiver,Barbara Hayes-Roth	1993	Guaranteeing real-time response with limited resources.	Artificial Inte	medical
1998	Artificial Intelligence in Medicine	Intelligent monitoring and control of dynamic physiological systems.	Enrico W. Coiera	1993	Intelligent monitoring and control of dynamic physiological systems.	Artificial Inte	medical
1999	Artificial Intelligence in Medicine	Probabilistic and decision-theoretic systems in medicine.	Gregory F. Cooper	1993	Probabilistic and decision-theoretic systems in medicine.	Artificial Inte	medical
2000	Artificial Intelligence in Medicine	A tutorial introduction to stochastic simulation algorithms for belief networks.	Steve B. Cousins,W. Chen,Mark E. Frisse	1993	A tutorial introduction to stochastic simulation algorithms for belief networks.	Artificial Inte	medical
2001	Artificial Intelligence in Medicine	Symbolic decision support in medical care.	Jiandong Huang,J. Fox,C. Gordon,A. Jackson-Smale	1993	Symbolic decision support in medical care.	Artificial Inte	medical
2002	Artificial Intelligence in Medicine	Physiological applications of consistency-based diagnosis.	Keith L. Downing	1993	Physiological applications of consistency-based diagnosis.	Artificial Inte	medical
2003	Artificial Intelligence in Medicine	Towards a statistically oriented decision support system for the management of septicaemia.	Richard Dybowski,William R. Gransden,Ian Phillips	1993	Towards a statistically oriented decision support system for the management of septicaemia.	Artificial Inte	medical
2004	Artificial Intelligence in Medicine	Logic-based integrity constraints and the design of dental prostheses.	Peter Hammond,John C. Davenport,F. J. Fitzpatrick	1993	Logic-based integrity constraints and the design of dental prostheses.	Artificial Inte	medical
2005	Artificial Intelligence in Medicine	Graphical knowledge acquisition for medical diagnostic expert systems.	Ute Gappa,Frank Puppe,Stefan Schewe	1993	Graphical knowledge acquisition for medical diagnostic expert systems.	Artificial Inte	medical
2006	Artificial Intelligence in Medicine	Medical decision making based on inductive learning method.	J. Kern,G. Dezelic,T. Durrigl,S. Vuletic	1993	Medical decision making based on inductive learning method.	Artificial Inte	medical
2007	Artificial Intelligence in Medicine	Consistency enforcement in medical knowledge base construction.	D. A. Giuse,N. B. Giuse,R. A. Miller	1993	Consistency enforcement in medical knowledge base construction.	Artificial Inte	medical
2008	Artificial Intelligence in Medicine	Inferential knowledge acquisition.	Giordano Lanzola,Mario Stefanelli	1993	Inferential knowledge acquisition.	Artificial Inte	medical
2009	Artificial Intelligence in Medicine	Bayesian inference for model-based segmentation of computed radiographs of the hand.	Tod S. Levitt,Marcus W. Hedgcock,John W. Dye,Scott E. Johnston,Vera M. Shadle,Dmitry Vosky	1993	Bayesian inference for model-based segmentation of computed radiographs of the hand.	Artificial Inte	medical
2010	Artificial Intelligence in Medicine	The representation of medical reasoning models in resolution-based theorem provers.	Peter J. F. Lucas	1993	The representation of medical reasoning models in resolution-based theorem provers.	Artificial Inte	medical
2011	Artificial Intelligence in Medicine	Neural network based classification of single-trial EEG data.	Nikola Masic,Gert Pfurtscheller	1993	Neural network based classification of single-trial EEG data.	Artificial Inte	medical
2012	Artificial Intelligence in Medicine	Connectionist expert systems as medical decision aid.	Jorge Muniz Barreto,Fernando Mendes de Azevedo	1993	Connectionist expert systems as medical decision aid.	Artificial Inte	medical
2013	Artificial Intelligence in Medicine	Computing the confidence in a medical decision obtained from an influence diagram.	R. E. Neopolitan	1993	Computing the confidence in a medical decision obtained from an influence diagram.	Artificial Inte	medical
2014	Artificial Intelligence in Medicine	Specification of models in large expert systems based on causal probabilistic networks.	Kristian G. Olesen,Steen Andreassen	1993	Specification of models in large expert systems based on causal probabilistic networks.	Artificial Inte	medical
2015	Artificial Intelligence in Medicine	Neural computation in medicine.	James A. Reggia	1993	Neural computation in medicine.	Artificial Inte	medical
2016	Artificial Intelligence in Medicine	The design and implementation of a ventilator-management advisor.	Geoffrey Rutledge,George E. Thomsen,Brad R. Farr,Maria A. Tovar,Jeanette X. Polaschek,Ingo A. Beinlich,Lewis B. Sheiner,Lawrence M. Fagan	1993	The design and implementation of a ventilator-management advisor.	Artificial Inte	medical
2017	Artificial Intelligence in Medicine	The adolescence of AI in medicine: will the field come of age in the '90s?	Edward H. Shortliffe	1993	The adolescence of AI in medicine: will the field come of age in the '90s?	Artificial Inte	medical
2018	Artificial Intelligence in Medicine	Exploring the relationship between rationality and bounded rationality in medical knowledge-based systems.	Jack W. Smith,A. Bayazitoglu	1993	Exploring the relationship between rationality and bounded rationality in medical knowledge-based systems.	Artificial Inte	medical
2019	Artificial Intelligence in Medicine	European research efforts in medical knowledge-based systems.	Mario Stefanelli	1993	European research efforts in medical knowledge-based systems.	Artificial Inte	medical
2020	Artificial Intelligence in Medicine	Artificial intelligence in medicine: state-of-the-art and future prospects.	N. Serdar Uckun	1993	Artificial intelligence in medicine: state-of-the-art and future prospects.	Artificial Inte	medical
2021	Artificial Intelligence in Medicine	Model-based diagnosis in intensive care monitoring: the YAQ approach.	N. Serdar Uckun,Benoit M. Dawant,D. P. Lindstrom	1993	Model-based diagnosis in intensive care monitoring: the YAQ approach.	Artificial Inte	medical
2022	Artificial Intelligence in Medicine	Automatic knowledge base refinement: learning from examples and deep knowledge in rheumatology.	Gerhard Widmer,Werner Horn,Bernhard Nagele	1993	Automatic knowledge base refinement: learning from examples and deep knowledge in rheumatology.	Artificial Inte	medical
2023	Artificial Intelligence in Medicine	Multiply sectioned Bayesian networks for neuromuscular diagnosis.	Yang Xiang,B. Pant,A. Eisen,Michael P. Beddoes,David Poole	1993	Multiply sectioned Bayesian networks for neuromuscular diagnosis.	Artificial Inte	medical
2024	FOCS	Synchronization power depends on the register size (Preliminary Version)	Yehuda Afek,Gideon Stupp	1993	Synchronization power depends on the register size (Preliminary Version)	FOCS	theory
2025	FOCS	A Polynomial-Time Algorithm for the Perfect Phylogeny Problem when the Number of Character States is Fixed	Richa Agarwala,David Fernández-Baca	1993	We present a polynomial-time algorithm for determining whether a set of species, described by the characters they exhibit, has a perfect phylogeny, assuming the maximum number of possible states for a character is fixed. This solves a longstanding open problem. Our result should be contrasted with the proof by Steel and Bodlaender, Fellows, and Warnow that the perfect phylogeny problem is NP-complete in general.	FOCS	theory
2026	FOCS	Scale-sensitive Dimensions, Uniform Convergence, and Learnability	Noga Alon,Shai Ben-David,Nicolò Cesa-Bianchi,David Haussler	1993	Learnability in Valiant's PAC learning model has been shown to be strongly related to the existence of uniform laws of large numbers. These laws define a distribution-free convergence property of means to expectations uniformly over classes of random variables. Classes of real-valued functions enjoying such a property are also known as uniform Gliveako-Cantelli classes. In this paper we prove, through a generalization of Sauer's lemma that may be interesting in its own right, a new characterization of uniform Glivenko-Cantelli classes. Our characterization yields Dudley, Gine, and Zinn's previous characterization as a corollary. Furthermore, it is the first based on a simple combinatorial quantity generalizing the Vapnik-Chervonenkis dimension. We apply this result to characterize PAC learnability in the statistical regression framework of probabilistic concepts, solving an open problem posed by Kearns and Schapire. Our characterization shows that the accuracy parameter plays a crucial role in determining the effective complexity of the learner's hypothesis class.	FOCS	theory
2027	FOCS	The Union of Convex Polyhedra in Three Dimensions	Boris Aronov,Micha Sharir	1993	We show that the number of vertices, edges, and faces of the union of k convex polyhedra in 3-space, having a total of n faces, is O(k/sup 3/+knlog/sup 2/ k). This bound is almost tight in the worst case. We also describe a rather simple randomized incremental algorithm for computing the boundary of the union in O(k/sup 3/+knlog/sup 3/ k) expected time.	FOCS	theory
2028	FOCS	The Hardness of Approximate Optimia in Lattices, Codes, and Systems of Linear Equations	Sanjeev Arora,László Babai,Jacques Stern,Z. Sweedyk	1993	We prove the following about the Nearest Lattice Vector Problem (in any l/sub p/ norm), the Nearest Code-word Problem for binary codes, the problem of learning a halfspace in the presence of errors, and some other problems. 1. Approximating the optimum within any constant factor is NP-hard. 2. If for some /spl epsiv/>0 there exists a polynomial time algorithm that approximates the optimum within a factor of 2/sup log(0.5-/spl epsiv/)/ /sup n/ then NP is in quasi-polynomial deterministic time: NP/spl sube/DTIME(n/sup poly(log/ /sup n)/). Moreover, we show that result 2 also holds for the Shortest Lattice Vector Problem in the l/sub /spl infin// norm. Improving the factor 2/sup log(0.5-/spl epsiv/)/ /sup n/ to /spl radic/(dim) for either of the lattice problems would imply the hardness of the Shortest Vector Problem in l/sub 2/ norm; an old open problem. Our proofs use reductions from few-prover, one-round interactive proof systems, either directly, or through a set-cover problem.	FOCS	theory
2029	FOCS	General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Bounding	Javed A. Aslam,Scott E. Decatur	1993	We derive general bounds on the complexity of learning in the statistical query model and in the PAC model with classification noise. We do so by considering the problem of boosting the accuracy of weak learning algorithms which fall within the statistical query model. This new model was introduced by M. Kearns (1993) to provide a general framework for efficient PAC learning in the presence of classification noise.	FOCS	theory
2030	FOCS	Highly Efficient Asynchronous Execution of Large-Grained Parallel Programs	Yonatan Aumann,Zvi M. Kedem,Krishna V. Palem,Michael O. Rabin	1993	An n-thread parallel program p is large-grained if in every parallel step the computations on each of the threads are complex procedures requiring numerous processor instructions. This practically relevant style of programs differs from PRAM programs in its large granularity and the possibility that within a parallel step the computations on different threads may considerably vary in size. Let M be an n-processor asynchronous parallel system, with no restriction on the degree of asynchrony and without any specialized synchronization mechanisms. It is a challenging theoretical as well as practically important problem to ensure correct execution of P on such a parallel machine. Let P be a large-grained program requiring total work W for its execution on a synchronous a-processor parallel system. We present a transformation (compilation) of P into a program C(P) which correctly and efficiently effects the computation of P on the asynchronous machine M. Under moderate assumptions on the granularity of threads and the size of the program variables, execution of C(P) requires just O(Wlog* n) expected total work, and the memory space overhead is a small multiplicative constant.	FOCS	theory
2031	FOCS	Throughput-Competitive On-Line Routing	Baruch Awerbuch,Yossi Azar,Serge A. Plotkin	1993	We develop a framework that allows us to address the issues of admission control and routing in high-speed networks under the restriction that once a call is admitted and routed, it has to proceed to completion and no reroutings are allowed. The no rerouting restriction appears in all the proposals for future high-speed networks and stems from current hardware limitations, in particular the fact that the bandwidth-delay product of the newly developed optical communication links far exceeds the buffer capacity of the network. In case the goal is to maximize the throughput, our framework yields an on-line O(log nT)-competitive strategy, where n is the number of nodes in the network and T is the maximum call duration. In other words, our strategy results in throughput that is within O(log nT) factor of the highest possible throughput achievable by an omniscient algorithm that knows all of the requests in advance. Moreover, we show that no on-line strategy can achieve a better competitive ratio. Our framework leads to competitive strategies applicable in several more general settings. Extensions include assigning each connection an associated profit that represents the importance of this connection, and addressing the issue of call-establishment costs.	FOCS	theory
2032	FOCS	Near-Linear Cost Sequential and Distribured Constructions of Sparse Neighborhood Covers	Baruch Awerbuch,Bonnie Berger,Lenore Cowen,David Peleg	1993	This paper introduces the first near-linear (specifically, O(Elog n+nlog/sup 2/ n)) time algorithm for constructing a sparse neighborhood cover in sequential and distributed environments. This automatically implies analogous improvements (from quadratic to near-linear) to all the results in the literature that rely on network decompositions, both in sequential and distributed domains, including adaptive routing schemes with O/spl tilde/(1) stretch and memory, small edge cuts in planar graphs, sequential algorithms for dynamic approximate shortest paths with O/spl tilde/(E) cost for edge insertion/deletion and O/spl tilde/(1) time to answer shortest-path queries, weight and distance-preserving graph spanners with O/spl tilde/(E) running time and space, and distributed asynchronous from-scratch breadth-first-search and network synchronizer constructions with O/spl tilde/(1) message and space overhead (down from O(n)).	FOCS	theory
2033	FOCS	Heat & Dump: Competitive Distributed Paging	Baruch Awerbuch,Yair Bartal,Amos Fiat	1993	Heat & Dump: Competitive Distributed Paging	FOCS	theory
2034	FOCS	A Simple Local-Control Approximation Algorithm for Multicommodity Flow	Baruch Awerbuch,Frank Thomson Leighton	1993	A Simple Local-Control Approximation Algorithm for Multicommodity Flow	FOCS	theory
2035	FOCS	Genome Rearrangements and Sorting by Reversals	Vineet Bafna,Pavel A. Pevzner	1993	Sequence comparison in molecular biology is in the beginning of a major paradigm shift-a shift from gene comparison based on local mutations to chromosome comparison based on global rearrangements. In the simplest form the problem of gene rearrangements corresponds to sorting by reversals, i.e. sorting of an array using reversals of arbitrary fragments. Kececioglu and Sankoff gave the first approximation algorithm for sorting by reversals with guaranteed error bound and identified open problems related to chromosome rearrangements. One of these problems is Gollan's conjecture on the reversal diameter of the symmetric group. We prove this conjecture and further study the problem of expected reversal distance between two random permutations. We demonstrate that the expected reversal distance is very close to the reversal diameter thereby indicating that reversal distance provides a good separation between related and non-related sequences. The gene rearrangement problem forces us to consider reversals of signed permutations, as the genes in DNA are oriented. Our approximation algorithm for signed permutation provides a 'performance guarantee' of 3/2. Finally, we devise an approximation algorithm for sorting by reversals with a performance ratio of 7/4.	FOCS	theory
2036	FOCS	Time-Space Bounds for Directed s-t Connectivity on JAG Models (Extended Abstract)	Greg Barnes,Jeff Edmonds	1993	Time-Space Bounds for Directed s-t Connectivity on JAG Models (Extended Abstract)	FOCS	theory
2037	FOCS	A Polynomial Time Algorithm for Counting Integral Points in Polyhedra when the Dimension Is Fixed	Alexander I. Barvinok	1993	We prove that for any dimension d there exists a polynomial time algorithm for counting integral points in polyhedra in the d-dimensional Euclidean space. Previously such algorithms were known for dimensions d=1,2,3, and 4 only.	FOCS	theory
2038	FOCS	Las Vegas algorithms for matrix groups	Robert Beals,László Babai	1993	We consider algorithms in finite groups, given by a list of generators. We give polynomial time Las Vegas algorithms (randomized, with guaranteed correct output) for basic problems for finite matrix groups over the rationals (and over algebraic number fields): testing membership, determining the order, finding a presentation (generators and relations), and finding basic building blocks: center, composition factors, and Sylow subgroups. These results extend previous work on permutation groups into the potentially more significant domain of matrix groups. Such an extension has until recently been considered intractable. In case of matrix groups G of characteristic p, there are two basic types of obstacles to polynomial-time computation: number theoretic (factoring, discrete log) and large Lie-type simple groups of the same characteristic p involved in the group. The number theoretic obstacles are inherent and appear already in handling abelian groups. They can be handled by moderately efficient (subexponential) algorithms. We are able to locate all the nonabelian obstacles in a normal subgroup N and solve all problems listed above for G/N.	FOCS	theory
2039	FOCS	When can we sort in o(n log n) time?	Amir M. Ben-Amram,Zvi Galil	1993	When can we sort in o(n log n) time?	FOCS	theory
2040	FOCS	An On-Line Algorithm for Improving Performance in Navigation	Avrim Blum,Prasad Chalasani	1993	Recent papers have shown optimally-competitive on-line strategies for a robot traveling from a point s to a point t in certain unknown geometric environments. We consider the question: Having gained some partial information about the scene on its first trip from s to t, can the robot improve its performance on subsequent trips it might make? This is a type of on-line problem where a strategy must exploit partial information about the future (e.g., about obstacles that lie ahead). For scenes with axis-parallel rectangular obstacles where the Euclidean distance between s and t is n, we present a deterministic algorithm whose average trip length after t trips, k/spl les/n, is O(/spl radic/n/k) times the length of the shortest s-t path in the scene. We also show that this is the best a deterministic strategy can do. This algorithm can be thought of as performing an optimal tradeoff between search effort and the goodness of the path found. We improve this algorithm so that for every i/spl les/n, the robot's ith trip length is O(/spl radic/n/t) times the shortest s-t path length. A key idea of the paper is that a tree structure can be defined in the scene, where the nodes are portions of certain obstacles and the edges are short paths from a node to its children. The core of our algorithms is an on-line strategy for traversing this tree optimally.	FOCS	theory
2041	FOCS	Learning an Intersection of k Halfspaces over a Uniform Distribution	Avrim Blum,Ravi Kannan	1993	We present a polynomial-time algorithm to learn an intersection of a constant number of halfspaces in n dimensions, over the uniform distribution on an n-dimensional ball. The algorithm we present in fact can learn an intersection of an arbitrary (polynomial) number of halfspaces over this distribution, if the subspace spanned by the normal vectors to the bounding hyperplanes has constant dimension. This generalizes previous results for this distribution, in particular a result of E.B. Baum (1990) who showed how to learn an intersection of 2 halfspaces defined by hyperplanes that pass through the origin (his results in fact held for a variety of symmetric distributions). Our algorithm uses estimates of second moments to find vectors in a low-dimensional relevant subspace. We believe that the algorithmic techniques studied here may be useful in other geometric learning applications.	FOCS	theory
2042	FOCS	A Quantum Bit Commitment Scheme Provably Unbreakable by both Parties	Gilles Brassard,Claude Crépeau,Richard Jozsa,Denis Langlois	1993	We describe a complete protocol for bit commitment based on the transmission of polarized photons. We show that under the laws of quantum physics, this protocol cannot be cheated by either party except with exponentially small probability (exponential in the running time needed to implement the honest protocol). A more thorough analysis is required to adjust all the constants used in this paper to get the best performance from our construction. Better performances may probably be achieved by using a third conjugate transmission-reception basis of circular polarization.	FOCS	theory
2043	FOCS	Product Range Spaces, Sensitive Sampling, and Derandomization	Hervé Brönnimann,Bernard Chazelle,Jirí Matousek	1993	We introduce the concept of a sensitive /spl epsi/-approximation, and use it to derive a more efficient algorithm for computing /spl epsi/-nets. We define and investigate product range spaces, for which we establish sampling theorems analogous to the standard finite VC-dimensional case. This generalizes and simplifies results from previous works. We derive a simpler optimal deterministic convex hull algorithm, and by extending the method to the intersection of a set of balls with the same radius, we obtain an O(nlog/sup 3/ n) deterministic algorithm for computing the diameter of an n-point set in 3-dimensional space.	FOCS	theory
2044	FOCS	Exact Learning via the Monotone Theory (Extended Abstract)	Nader H. Bshouty	1993	Exact Learning via the Monotone Theory (Extended Abstract)	FOCS	theory
2045	FOCS	Geometric Discrepancy Revisited	Bernard Chazelle	1993	Discrepancy theory addresses the general issue of approximating one measure by another one. Originally an offshoot of diophantine approximation theory, the area has expanded into applied mathematics, and now, computer science. Besides providing the theoretical foundation for sampling, it holds some of the keys to understanding the computational power of randomization. A few applications of discrepancy theory are listed. We give elementary algorithms for estimating the discrepancy between various measures arising in practice. We also present a general technique for proving discrepancy lower bounds.	FOCS	theory
2046	FOCS	Using Difficulty of Prediction to Decrease Computation: Fast Sort, Priority Queue and Convex Hull on Entropy Bounded Inputs	Shenfeng Chen,John H. Reif	1993	Studies have indicated that sorting comprises about 20% of all computing on mainframes. Perhaps the largest use of sorting in computing (particularly business computing) is the sort required for large database operations (e.g. required by joint operations). In these applications the keys are many words long. Since our sorting algorithm hashes the key (rather than compare entire keys as in comparison sorts such as quicksort), our algorithm is even more advantageous in the case of large key lengths; in that case the cutoff is much lower. In case that the compression ratio is high, which can be determined after building the dictionary, we just adopt the previous sorting algorithm, e.g. quick sort. The same techniques can be extended to other problems (e.g. computational geometry problems) to decrease computation by learning the distribution of the inputs.	FOCS	theory
2047	FOCS	Optimal Parallel All-Nearest-Neighbors Using the Well-Separated Pair Decomposition (Preliminary Version)	Paul B. Callahan	1993	Optimal Parallel All-Nearest-Neighbors Using the Well-Separated Pair Decomposition (Preliminary Version)	FOCS	theory
2048	FOCS	A Tight Lower Bound for k-Set Agreement	Soma Chaudhuri,Maurice Herlihy,Nancy A. Lynch,Mark R. Tuttle	1993	We prove tight bounds on the time needed to solve k-set agreement, a natural generalization of consensus. We analyze this problem in a synchronous, message-passing model where processors fail by crashing. We prove a lower bound of [f/k]+1 rounds of communication for solutions to k-set agreement that tolerate f failures. This bound is tight, and shows that there is an inherent tradeoff between the running time, the degree of coordination required, and the number of faults tolerated, even in idealized models like the synchronous model. The proof of this result is interesting because it is a geometric combination of other well-known proof techniques.	FOCS	theory
2049	FOCS	On Bounded Queries and Approximation	Richard Chang,William I. Gasarch	1993	This paper investigates the computational complexity of approximating NP-optimization problems using the number of queries to an NP oracle as a complexity measure. The results show a trade-off between the closeness of the approximation and the number of queries required. For an approximation factor k(n), loglog/sub k(n/) n queries to an NP oracle can be used to approximate the maximum clique size of a graph within a factor of k(n). However, this approximation cannot be achieved using fewer than loglog/sub k(n/) n-c queries to any oracle unless P=NP, where c is a constant that does not depend on k. These results hold when k(n) belongs to a class of functions which include any integer constant function, log n, log/sup a/ n and n/sup 1/a/. Similar results are obtained for graph coloring, set cover and other NP-optimization problems.	FOCS	theory
2050	FOCS	Sensitive Functions and Approximate Problems	Shiva Chaudhuri	1993	We investigate properties of functions that are good measures of the CRCW PRAM complexity of computing them. While the block sensitivity is known to be a good measure of the CREW PRAM complexity, no such measure is known for CRCW PRAMs. We show that the complexity of computing a function is related to its everywhere sensitivity, introduced by Vishkin and Wigderson (1985). Specifically we show that the time required to compute a function f:D/sup n//spl rarr/R of everywhere sensitivity es(f) with P/spl ges/n processors and unbounded memory is /spl Omega/(log[log es(f)/(log 4P|D|- log es(f))]). This improves previous results of Azar (1992), and Vishkin and Wigderson. We use this lower bound to derive new lower bounds for some approximate problems. These problems can often be solved faster than their exact counterparts and for many applications, it is sufficient to solve the approximate problem. We show that approximate selection requires time /spl Omega/(log[log n/log k]) with kn, processors and approximate counting with accuracy /spl lambda//spl ges/2 requires time /spl Omega/(log[log n/(log k+log /spl lambda/)]) with kn processors. In particular, for constant accuracy, no lower bounds were known for these problems.	FOCS	theory
2051	FOCS	Parallel computable higher type functionals (Extended Abstract)	Peter Clote,Aleksandar Ignjatovic,Bruce M. Kapron	1993	Parallel computable higher type functionals (Extended Abstract)	FOCS	theory
2052	FOCS	Fast algorithms for constructing t-spanners and paths with stretch t	Edith Cohen	1993	The distance between two vertices in a weighted graph is the weight of a minimum-weight path between them. A path has stretch t if its weight is at most t times the distance between its end points. We consider a weighted undirected graph G=(V, E) and present algorithms that compute paths with stretch 2/spl les/t/spl les/log n. We present a O/spl tilde/((m+k)n/sup (2+/spl epsiv///t)) time randomized algorithm that finds paths between k specified pairs of vertices and a O/spl tilde/((m+ns)n/sup 2(1+log(n)/ /sup m+/spl epsiv/)/t/) deterministic algorithm that finds paths from s specified sources to all other vertices (for any fixed /spl epsiv/>0), where n=|V| and m=|E|. This improves significantly over the slower O/spl tilde/(min{k, n}m) exact shortest paths algorithms and a previous O/spl tilde/(mn/sup 64/t/+kn/sup 32/t/) time algorithm by Awerbuch et al. A t-spanner of a graph G is a set of weighted edges on the vertices of G such that distances in the spanner are not smaller and within a factor of t from the corresponding distances in G. Previous work was concerned with bounding the size and efficiently constructing t-spanners. We construct t-spanners of size O/spl tilde/(n/sup 1+(2+/spl epsiv///t)) in O/spl tilde/(mn/sup (2+/spl epsiv///t)) expected time (for any fixed /spl epsiv/>0), what constitutes a faster construction (by a factor of n/sup (3+2//t)) of sparser spanners than was previously attainable. We also provide efficient parallel constructions. Our algorithms are based on new structures called pairwise-covers and a novel approach to construct them efficiently.	FOCS	theory
2053	FOCS	Optimally fast parallel algorithms for preprocessing and pattern matching in one and two dimensions	Richard Cole,Maxime Crochemore,Zvi Galil,Leszek Gasieniec,Ramesh Hariharan,S. Muthukrishnan,Kunsoo Park,Wojciech Rytter	1993	All algorithms below are optimal alphabet-independent parallel CRCW PRAM algorithms. In one dimension: Given a pattern string of length m for the string-matching problem, we design an algorithm that computes a deterministic sample of a sufficiently long substring in constant time. This problem used to be a bottleneck in the pattern preprocessing for one- and two-dimensional pattern matching. The best previous time bound was O(log/sup 2/ m/log log m). We use this algorithm to obtain the following results. 1. Improving the preprocessing of the constant-time text search algorithm from O(log/sup 2/ m/log log m) to n(log log m), which is now best possible. 2. A constant-time deterministic string-matching algorithm in the case that the text length n satisfies n=/spl Omega/(m/sup 1+/spl epsiv//) for a constant /spl epsiv/>0. 3. A simple probabilistic string-matching algorithm that has constant time with high probability for random input. 4. A constant expected time Las-Vegas algorithm for computing the period of the pattern and all witnesses and thus string matching itself, solving the main open problem remaining in string matching.	FOCS	theory
2054	FOCS	Logical Reducibility and Monadic NP	Stavros S. Cosmadakis	1993	It is shown that, by choosing appropriate encodings of instances as relational structures, several known polynomial-time many-one reductions can he described in first-order logic, and furthermore they are monadic. As a corollary, several known NP-complete problems in monadic NP are shown not to be in monadic co-NP. It is further shown that there is no monadic first-order reduction from connectivity to directed reachability, even in the presence of successor. Finally, some classes of syntactically restricted first-order reductions are shown to be incomparable.	FOCS	theory
2055	FOCS	The Complexity of the Theory of p-adic Numbers	Lavinia Egidi	1993	This paper addresses the question of the complexity of the decision problem for the theory Th(Q/sub p/) of p-adic numbers. The best known lower bound for the theory is double exponential alternating time with a linear number of alternations. I have designed an algorithm that determines the truth value of sentences of the theory requiring double exponential space. My algorithm is based on techniques used by G.E. Collins (1975) for the theory Th(R) of the reals, and on J. Denef's work (1986) on semi-algebraic sets and cell decomposition for p-adic fields. No elementary upper bound had been previously established.	FOCS	theory
2056	FOCS	Better Lower Bounds on Detecting Affine and Spherical Degeneracies	Jeff Erickson,Raimund Seidel	1993	We show that in the worst case, /spl Omega/(n/sup d/) sidedness queries are required to determine whether a set of n points in R/sup d/ is affinely degenerate, i.e., whether it contains d+1 points on a common hyperplane. This matches known upper bounds. We give a straightforward adversary argument, based on the explicit construction of a point set containing /spl Omega/(n/sup d/) collapsible simplices, any one of which can be made degenerate without changing the orientation of any other simplex. As an immediate corollary, we have an /spl Omega/(n/sup d/) lower bound on the number of sidedness queries required to determine the order type of a set of n points in R/sup d/. Using similar techniques, we also show that /spl Omega/(n/sup d+1/) in-sphere queries are required to decide the existence of spherical degeneracies in a set of n points in R/sup d/.	FOCS	theory
2057	FOCS	Signal Propagation, with Application to a Lower Bound on the Depth of Noisy Formulas	William S. Evans,Leonard J. Schulman	1993	We study the decay of an information signal propagating through a series of noisy channels. We obtain exact bounds on such decay, and as a result provide a new lower bound on the depth of formulas with noisy components. This improves upon previous work of N. Pippenger (1988) and significantly decreases the gap between his lower bound and the classical upper bound of von Neumann. We also discuss connections between our work and the study of mixing rates of Markov chains.	FOCS	theory
2058	FOCS	Testing Equalities of Multiplicative Representations in Polynomial Time (Extended Abstract)	Guoqiang Ge	1993	Testing Equalities of Multiplicative Representations in Polynomial Time (Extended Abstract)	FOCS	theory
2059	FOCS	A Randomized Time-Space Tradefoff of \tildeO(m\tildeR) for USTCON	Uriel Feige	1993	A Randomized Time-Space Tradefoff of \tildeO(m\tildeR) for USTCON	FOCS	theory
2060	FOCS	Dynamic Word Problems	Gudmund Skovbjerg Frandsen,Peter Bro Miltersen,Sven Skyum	1993	Let M be a fixed finite monoid. We consider the problem of implementing a data type containing a vector x=(x/sub 1/,x/sub 2/,...,x/sub n/)/spl isin/M/sup n/, initially (1,1,...,1) with two kinds of operations, for each i/spl isin/{1,...,n}, a/spl isin/M, an operation change/sub i,a/ which changes x/sub i/ to a and a single operation product returning /spl Pi//sub i=1//sup n/x/sub i/. This is the dynamic word problem. If we in addition for each j/spl isin/{1,...,n} have an operation prefix/sub j/ returning /spl Pi//sub i=1//sup j/x/sub i/, we talk about the dynamic prefix problem. We analyze the complexity of these problems in the cell probe or decision assignment tree model for two natural cell sizes, 1 bit and log n bits. We obtain a classification of the complexity based on algebraic properties of M.	FOCS	theory
2061	FOCS	Eavesdropping Games: A Graph-Theoretic Approach to Privacy in Distributed Systems	Matthew K. Franklin,Zvi Galil,Moti Yung	1993	We initiate a graph-theoretic approach to study the (information-theoretic) maintenance of privacy in distributed environments in the presence of a bounded number of mobile eavesdroppers (bugs). For two fundamental privacy problems-secure message transmission and distributed database maintenance-we assume an adversary is playing eavesdropping games, coordinating the movement of the bugs among the sites to learn the current memory contents. We consider various mobility settings (adversaries), motivated by the capabilities (strength) of the bugging technologies (e.g., how fast can a bug be reassigned). We combinatorially characterize and compare privacy maintenance problems, determine their feasibility (under numerous bug models), suggest protocols for the feasible cases, and analyze their computational complexity.	FOCS	theory
2062	FOCS	A Framework for Cost-scaling Algorithms for Submodular Flow Problems	Harold N. Gabow	1993	The submodular flow problem includes such problems as minimum-cost network flow, dijoin, edge-connectivity orientation and others. We present a cost-scaling algorithm for submodular flow problems. The algorithm applies to these problems in general; we also examine its efficiency for the dijoin and edge-connectivity orientation problems. A minimum-cost dijoin is found in time O(min{m/sup 1/2/, n/sup 2/3/}nmlog(nN)), where n, m and N denote the number of vertices, number of edges and largest magnitude of an integral edge cost. The previous best-known bound is O(n/sup 2/m) if fast matrix multiplication is not used. A k-edge-connected orientation is found in time O(kn/sup 2/(/spl radic/(kn)+k/sup 2/log(n/k))). A minimum-cost k-edge-connected orientation is found on the above time bound for dijoins when k=O(1) (and a more complicated bound for general k). The scaling algorithm uses a transformation that eliminates vertex weights in edge-capacitated graphs. It also incorporates a scheme to limit the growth in the size of intermediate solutions, using a dual minimum-cost network flow problem.	FOCS	theory
2063	FOCS	A Sub-Linear Time Distributed Algorithm for Minimum-Weight Spanning Trees (Extended Abstract)	Juan A. Garay,Shay Kutten,David Peleg	1993	A Sub-Linear Time Distributed Algorithm for Minimum-Weight Spanning Trees (Extended Abstract)	FOCS	theory
2064	FOCS	Solving Systems of Set Constraints with Negated Subset Relationships	Rémi Gilleron,Sophie Tison,Marc Tommasi	1993	We present a decision procedure, based on tree automata techniques, for satisfiability of systems of set constraints including negated subset relationships. This result extends all previous works on set constraints solving and solves a problem which was left open by L. Bachmair et al. (1993). We prove in a constructive way that a non empty set of solutions always contains a regular solution, that is a tuple of regular tree languages. Moreover, we think that the new class of tree automata described here could be interesting in its own.	FOCS	theory
2065	FOCS	External-Memory Computational Geometry (Preliminary Version)	Michael T. Goodrich,Jyh-Jong Tsay,Darren Erik Vengroff,Jeffrey Scott Vitter	1993	External-Memory Computational Geometry (Preliminary Version)	FOCS	theory
2066	FOCS	A Chernoff bound for random walks on expander graphs	David Gillman	1993	We consider a finite random walk on a weighted graph G; we show that the sample average of visits to a set of vertices A converges to the stationary probability /spl pi/(A) with error probability exponentially small in the length of the random walk and the square of the size of the deviation from /spl pi/(A). The exponential bound is in terms of the expansion of G and improves previous results. We show that the method of taking the sample average from one trajectory is a more efficient estimate of /spl pi/(A) than the standard method of generating independent sample points from several trajectories. Using this more efficient sampling method, we improve the algorithms of Jerrum and Sinclair (1989) for approximating the number of perfect matchings in a dense graph and for approximating the partition function of an Ising system. We also give a fast estimate of the entropy of a random walk on an unweighted graph.	FOCS	theory
2067	FOCS	NP Trees and Carnap's Modal Logic	Georg Gottlob	1993	We consider problems and complexity classes definable by interdependent queries to an oracle in NP. How the queries depend on each other is specified by a directed graph G. We first study the class of problems where G is a general dag and show that this class coincides with /spl Delta//sub 2//sup P/. We then consider the class where G is a tree. Our main result states that this class is identical to P/sup NP/ [O(log n)], the class of problems solvable in polynomial time with a logarithmic number of queries to an oracle in NP. Using this result we show that the following problems are all P/sup NP/[O(logn)] complete: validity-checking of formulas in Carnap's modal logic, checking whether a formula is almost surely valid over finite structures in modal logics K, T, and S4, and checking whether a formula belongs to the stable set of beliefs generated by a propositional theory.	FOCS	theory
2068	FOCS	Gages Accept Concurrent Behavior	Vineet Gupta,Vaughan R. Pratt	1993	We represent concurrent processes as Boolean propositions or gates, cast in the role of accepters of concurrent behavior. This properly extends other mainstream representations of concurrent behavior such as event structures, yet is defined more simply. It admits an intrinsic notion of duality that permits processes to be viewed as either schedules or automata. Its algebraic structure is essentially that of linear logic, with its morphisms being consequence-preserving renamings of propositions, and with its operations forming the core of a natural concurrent programming language.	FOCS	theory
2069	FOCS	Directed vs. Undirected Monotone Contact Networks for Threshold Functions	Magnús M. Halldórsson,Jaikumar Radhakrishnan,K. V. Subrahmanyam	1993	We consider the problem of computing threshold functions using directed and undirected monotone contact networks. Our main results are the following. First, we show that there exist directed monotone contact networks that compute T/sub k//sup n/, 2/spl les/k/spl les/n-1, of size O(k(n-k+2)log(n-k+2)). This bound is almost optimal for small thresholds, since there exists an /spl Omega/(knlog (n/(k-1))) lower bound. Our networks are described explicitly; the previously best upper bound known, obtained from the undirected networks of Dubiner and Zwick, used non-constructive arguments and gave directed networks of size O(k/sup 3.99/nlog n). Second, we show a lower bound of O(nlogloglog n) on the size of undirected monotone contact networks computing T/sub n-1//sup n/, improving the 2(n-1) lower bound of Markov. Combined with our upper bound result, this shows that directed monotone contact networks compute some threshold functions more easily than undirected networks.	FOCS	theory
2070	FOCS	Near-Quadratic Bounds for the Motion Planning Problem for a Polygon in a Polygonal Environment	Dan Halperin,Micha Sharir	1993	We consider the problem of planning the motion of an arbitrary k-sided polygonal robot B, free to translate and rotate in a polygonal environment V bounded by n edges. We show that the combinatorial complexity of a single connected component of the free configuration space of B is k/sup 3/n/sup 2/2/sup O(log(2/3)/ n). This is a significant improvement of the naive bound O((kn)/sup 3/); when k is constant, which is often the case in practice, this yields a near-quadratic bound on the complexity of such a component, which almost settles (in this special case) a long-standing conjecture regarding the complexity of a single cell in a three-dimensional arrangement of surfaces. We also present an algorithm that constructs a single component of the free configuration space of B in time O(n/sup 2+/spl epsi//), for any /spl epsi/>0, assuming B has a constant number of sides. This algorithm, combined with some standard techniques in motion planning, yields a solution to the underlying motion planning problem, within the same asymptotic running time.	FOCS	theory
2071	FOCS	Optimal Bi-Weighted Binary Trees and the Complexity of Maintaining Partial Sums	Haripriyan Hampapuram,Michael L. Fredman	1993	Let A be an array. The partial sum problem concerns the design of a data structure for implementing the following operations. The operation update(j,x) has the effect, A[j]/spl larr/A[j]+x, and the query operation sum(j) returns the partial sum, /spl Sigma//sub i=1//sup j/A[i]. Our interest centers upon the optimal efficiency with which sequences of such operations can be performed, and we derive new upper and lower bounds in the semi-group model of computation. Our analysis relates the optimal complexity of the partial sum problem to optimal binary trees relative to a type of weighting scheme that defines the notion of bi-weighted binary tree.	FOCS	theory
2072	FOCS	Efficient Computation of Euclidean Shortest Paths in the Plane	John Hershberger,Subhash Suri	1993	We propose a new algorithm for a classical problem in plane computational geometry: computing a shortest path between two points in the presence of polygonal obstacles. Our algorithm runs in worst-case time O(nlog/sup 2/ n) and requires O(nlog n) space, where n is the total number of vertices in the obstacle polygons. Our algorithm actually computes a planar map that encodes shortest paths from a fixed source point to all other points of the plane; the map can be used to answer single-source shortest path queries in O(log n) time. The time complexity of our algorithm is a significant improvement over all previous results known for the shortest path problem.	FOCS	theory
2073	FOCS	The shrinkage exponent is 2	Johan Håstad	1993	We prove that if we hit a formula of size L with a random restriction from R/sub p/ then the expected remaining size is at most O(p/sup 2/(log p)/sup 3/2/L). As a corollary we obtain a R(n/sup 3-O(1)/) formula size lower bound for an explicit function in NP.	FOCS	theory
2074	FOCS	Top-Down Lower Bounds for Depth 3 Circuits	Johan Håstad,Stasys Jukna,Pavel Pudlák	1993	We present a top-down lower bound method for depth 3 AND-OR-NOT circuits which is simpler than the previous methods and in some cases gives better lower bounds. In particular we prove that depth 3 AND-OR-NOT circuits that compute PARITY resp. MAJORITY require size at least 2/sup 0.618/ .../spl radic/n/ resp. 2/sup 0.849/.../spl radic/n/. This is the first simple proof of a strong lower bound by a top-down argument for non-monotone circuits.	FOCS	theory
2075	FOCS	Counting Rational Points on Curves over Finite Fields (Extended Abstract)	Ming-Deh A. Huang,Doug Ierardi	1993	Counting Rational Points on Curves over Finite Fields (Extended Abstract)	FOCS	theory
2076	FOCS	On the Value of Information in Coordination Games (preliminary version)	Sandy Irani,Yuval Rabani	1993	On the Value of Information in Coordination Games (preliminary version)	FOCS	theory
2077	FOCS	Simulated Annealing for Graph Bisection	Mark Jerrum,Gregory B. Sorkin	1993	We resolve in the affirmative a question of R.B. Boppana and T. Bui: whether simulated annealing can with high probability and in polynomial time, find the optimal bisection of a random graph an G/sub npr/ when p-r=(/spl Theta/n/sup /spl Delta/-2/) for /spl Delta//spl les/2. (The random graph model G/sub npr/ specifies a planted bisection of density r, separating two n/2-vertex subsets of slightly higher density p.) We show that simulated annealing at an appropriate fixed temperature (i.e., the Metropolis algorithm) finds the unique smallest bisection in O(n/sup 2+/spl epsi//) steps with very high probability, provided /spl Delta/>11/6. (By using a slightly modified neighborhood structure, the number of steps can be reduced to O(n/sup 1+/spl epsi//).) We leave open the question of whether annealing is effective for /spl Delta/ in the range 3/2	FOCS	theory
2078	FOCS	The Complexity and Distribution of Hard Problems (Extended Abstract)	David W. Juedes,Jack H. Lutz	1993	The Complexity and Distribution of Hard Problems (Extended Abstract)	FOCS	theory
2079	FOCS	Universal Emulations with Sublogarithmic Slowdown	Christos Kaklamanis,Danny Krizanc,Satish Rao	1993	The existence of bounded degree networks which can emulate the computation of any bounded degree network of the same size with logarithmic slowdown is well-known. The butterfly is an example of such a universal network. Leiserson was the first to introduce the concept of an area-universal network: a network with VLSI layout area A which can emulate any network of the same size and layout area with logarithmic slowdown. His results imply the existence of an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(log N) slowdown. The main results of this paper are: There exists an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(loglogN) slowdown. The N-node butterfly (and hypercube) can emulate any network with VLSI layout area N/sup 2-/spl epsiv// (/spl epsiv/>0) with O(loglogN) slowdown. We also discuss sublogarithmic bounds for the slowdown of emulations of arbitrary bounded degree networks.	FOCS	theory
2080	FOCS	Random Sampling in Matroids, with Applications to Graph Connectivity and Minimum Spanning Trees	David R. Karger	1993	Random sampling is a powerful way to gather information about a group by considering only a small part of it. We give a paradigm for applying this technique to optimization problems, and demonstrate its effectiveness on matroids. Matroids abstractly model many optimization problems that can be solved by greedy methods, such as the minimum spanning tree (MST) problem. Our results have several applications. We give an algorithm that uses simple data structures to construct an MST in O(m+n log n) time. We give bounds on the connectivity (minimum cut) of a graph suffering random edge failures. We give fast algorithms for packing matroid bases, with particular attention to packing spanning trees in graphs.	FOCS	theory
2081	FOCS	A linear-processor polylog-time algorithm for shortest paths in planar graphs	Philip N. Klein,Sairam Subramanian	1993	We give an algorithm requiring polylog time and a linear number of processors to solve single-source shortest paths in directed planar graphs, bounded-genus graphs, and 2-dimensional overlap graphs. More generally, the algorithm works for any graph provided with a decomposition tree constructed using size-O(/spl radic/n polylog n) separators.	FOCS	theory
2082	FOCS	A Weak Version of the Blum, Shub & Smale model	Pascal Koiran	1993	A Weak Version of the Blum, Shub & Smale model	FOCS	theory
2083	FOCS	On Choosing a Dense Subgraph (Extended Abstract)	Guy Kortsarz,David Peleg	1993	On Choosing a Dense Subgraph (Extended Abstract)	FOCS	theory
2084	FOCS	Breaking the Theta(n log ^2 n) Barrier for Sorting with Faults (Extended Abstract)	Frank Thomson Leighton,Yuan Ma	1993	Breaking the Theta(n log ^2 n) Barrier for Sorting with Faults (Extended Abstract)	FOCS	theory
2085	FOCS	Efficient Out-of-Core Algorithms for Linear Relaxation Using Blocking Covers (Extended Abstract)	Charles E. Leiserson,Satish Rao,Sivan Toledo	1993	Efficient Out-of-Core Algorithms for Linear Relaxation Using Blocking Covers (Extended Abstract)	FOCS	theory
2086	FOCS	A Compact Piecewise-Linear Voronoi Diagram for Convex Sites in the Plane	Michael McAllister,David G. Kirkpatrick,Jack Snoeyink	1993	In the plane, the post-office problem, which asks for the closest site to a query site, and retraction motion planning, which asks for a one-dimensional retract of the free space of a robot, are both classically solved by computing a Voronoi diagram. When the sites are k disjoint convex sets, we give a compact representation of the Voronoi diagram, using O(k) line segments, that is sufficient for logarithmic time post-office location queries and motion planning. If these sets are polygons with n total vertices, we compute this diagram optimally in O(klog n) deterministic time for the Euclidean metric and in O(klog nlog m) deterministic time for the convex distance function defined by a convex m-gon.	FOCS	theory
2087	FOCS	Refining a Triangulation of a Planar Straight-Line Graph to Eliminate Large Angles	Scott A. Mitchell	1993	We show that any planar straight line graph (PSLG) with v vertices can be triangulated with no angle larger than 7/spl pi//8 by adding O(v/sup 2/log v) Steiner points in O(v/sup 2/log/sup 2/ v) time. We first triangulate the PSLG with an arbitrary constrained triangulation and then refine that triangulation by adding additional vertices and edges. We follow a lazy strategy of starting from an obtuse angle and exploring the triangulation in search of a sequence of Steiner points that will satisfy a local angle condition. Explorations may either terminate successfully (for example at a triangle vertex), or merge. Some PSLGs require /spl Omega/(v/sup 2/) Steiner points in any triangulation achieving any largest angle bound less than /spl pi/. Hence the number of Steiner points added by our algorithm is within a log v factor of worst case optimal. For most inputs the number of Steiner points and running time would be considerably smaller than in the worst case.	FOCS	theory
2088	FOCS	Space Bounds for Graph Connectivity Problems on Node-named JAGs and Node-ordered JAGs	C. K. Poon	1993	Two new models, NO-JAG and NN-JAG in order of increasing computation power, are introduced as extensions to the conventional JAG model. A space lower bound of /spl Omega/(log/sup 2/ n/log log n) is proved for the problem of directed st-connectivity on a probabilistic NN-JAG and a space upper bound of O(log n) is proved for the problem of directed st-nonconnectivity on a nondeterministic NO-JAG. It is also shown that a nondeterministic NO-JAG is nearly as powerful as a nondeterministic Turing machine.	FOCS	theory
2089	FOCS	Faster Algorithms for the Generalized Network Flow Problem	Tomasz Radzik	1993	We consider the generalized network flow problem. Each arc e in the network has a gain factor /spl gamma/(e). If f(e) units of flow enter arc e, then f(e)/spl gamma/(e) units arrive at the other end of e. The generalized network flow problem is to maximize the net flow into one specific node, the sink. We give an algorithm which solves this problem in O/spl tilde/(m/sup 2/(m+nloglog B)log B) time, where B is the largest integer used to represent the gain factors, the capacities, and the initial supplies at the nodes. If m is O(n/sup (4/3/-/spl epsiv/) and B is not extremely large, then our bound improves the previous best bound O(m/sup 1.5/n/sup 2/log B) given by P.M. Vaidya (1989). Our algorithm is an approximation scheme which in each iteration reduces by a constant factor the difference between the current net flow into the sink and the optimal one. The solution which is within a factor of 1+/spl xi/ from the optimum can be computed in O/spl tilde/(m/sup 2/n+min{m/sup 2/n, m(m+nloglog B)}log(1//spl xi/)) time. This improves the previous bounds on the approximate generalized flow problem.	FOCS	theory
2090	FOCS	Primal-dual RNC approximation algorithms for (multi)-set (multi)-cover and covering integer programs	Sridhar Rajagopalan,Vijay V. Vazirani	1993	We build on the classical greedy sequential set cover algorithm, in the spirit of the primal-dual schema, to obtain simple parallel approximation algorithms for the set cover problem and its generalizations. Our algorithms use randomization, and our randomized voting lemmas may be of independent interest. Fast parallel approximation algorithms were known before for set cover, though not for any of its generalizations.	FOCS	theory
2091	FOCS	On the ``log rank''-Conjecture in Communication Complexity	Ran Raz,Boris Spieker	1993	We show the existence of a non-constant gap between the communication complexity of a function and the logarithm of the rank of its input matrix. We consider the following problem: each of two players gets a perfect matching between two n-element sets of vertices. Their goal is to decide whether or not the union of the two matchings forms a Hamiltonian cycle. We prove: (1) The rank of the input matrix over the reals for this problem is 2/sup O(n)/. (2) The non-deterministic communication complexity of the problem is /spl Omega/(n log log n). Our result also supplies a superpolynomial gap between the chromatic number of a graph and the rank of its adjacency matrix. Another conclusion from the second result is an /spl Omega/(n log log n). Lower bound for the graph connectivity problem in the non-deterministic case. We make use of the theory of group representations for the first result. The second result is proved by an information theoretic argument.	FOCS	theory
2092	FOCS	An O(n log ^3 n) Algorithm for the Real Root Problem	John H. Reif	1993	An O(n log ^3 n) Algorithm for the Real Root Problem	FOCS	theory
2093	FOCS	The NC Equivalence of Planar Integer Linear Programming and Euclidean GCD	David Shallcross,Victor Y. Pan,Yu Lin-Kriz	1993	We show NC-reduction of integer linear programming with two variables to the evaluation of the remainder sequence arising in the application of the Euclidean algorithm to two positive integers. Due to the previous result of X. Deng (1989), this implies NC-equivalence of both of these problems, whose membership in NC, as well as P-completeness, remain unresolved open problems.	FOCS	theory
2094	FOCS	Almost Tight Upper Bounds for Lower Envelopes in Higher Dimensions	Micha Sharir	1993	We show that the combinatorial complexity of the lower envelope of n surfaces or surface patches in d-space (d/spl ges/3), all algebraic of constant maximum degree, and bounded by algebraic surfaces of constant maximum degree, is O(n/sup d-1+/spl epsi//), for any /spl epsi/>0; the constant of proportionality depends on /spl epsi/, d, and the shape and degree of the surface patches and of their boundaries. This is the first nontrivial general upper bound for this problem, and it almost establishes a long-standing conjecture that the complexity of the envelope is O(n/sup d-2//spl lambda//sub q/(n)) for some constant q depending on the shape and degree of the surfaces (where /spl lambda//sub q/(n) is the maximum length of (n,q) Davenport-Schinzel sequences). We also present a randomized algorithm for computing the envelope in three dimensions, with expected running time O(n/sup 2+/spl epsi//), and give several applications of the new bounds.	FOCS	theory
2095	FOCS	On Representations by Low-Degree Polynomials	Roman Smolensky	1993	In the first part of the paper we show that a subset S of a boolean cube B/sub n/ embedded in the projective space P/sup n/ can be approximated by a subset of B/sub n/ defined by nonzeroes of a low-degree polynomial only if the values of the Hilbert function of S are sufficiently small relative to the size of S. The use of this property provides a simple and direct technique for proving lower bounds on the size of ACC[p/sup r/] circuits. In the second part we look at the problem of computing many-output function by ACC[p/sup r/] circuit and give an example when such a circuit can be correct only at exponentially small fraction of assignments.	FOCS	theory
2096	FOCS	Approximating Shortest Superstrings	Shang-Hua Teng,F. Frances Yao	1993	The Shortest Superstring Problem is to find a shortest possible string that contains every string in a given set as substrings. This problem has applications to data compression and DNA sequencing. As the problem is NP-hard and MAX SNP-hard, approximation algorithms are of interest. We present a new algorithm which always finds a superstring that is at most 2.89 times as long as the shortest superstring. Our result improves the 3-approximation result of Blum, Jiang, Li, Tromp, and Yannakakis (1991).	FOCS	theory
2097	FOCS	Quantum Circuit Complexity	Andrew Chi-Chih Yao	1993	We propose a complexity model of quantum circuits analogous to the standard (acyclic) Boolean circuit model. It is shown that any function computable in polynomial time by a quantum Turing machine has a polynomial-size quantum circuit. This result also enables us to construct a universal quantum computer which can simulate, with a polynomial factor slowdown, a broader class of quantum machines than that considered by E. Bernstein and U. Vazirani (1993), thus answering an open question raised by them. We also develop a theory of quantum communication complexity, and use it as a tool to prove that the majority function does not have a linear-size quantum formula.	FOCS	theory
2098	FOCS	34th Annual Symposium on Foundations of Computer Science, 3-5 November 1993, Palo Alto, California, USA		1993	34th Annual Symposium on Foundations of Computer Science, 3-5 November 1993, Palo Alto, California, USA	FOCS	theory
2099	SODA	Physical Mapping of Chromosomes: A Combinatorial Problem in Molecular Biology.	Farid Alizadeh,Richard M. Karp,Lee Aaron Newberg,Deborah K. Weisser	1993	Physical Mapping of Chromosomes: A Combinatorial Problem in Molecular Biology.	SODA	theory
2100	SODA	Ray Shooting Amidst Convex Polytopes in Three Dimensions.	Pankaj K. Agarwal,Micha Sharir	1993	Ray Shooting Amidst Convex Polytopes in Three Dimensions.	SODA	theory
2101	SODA	Improved Dynamic Dictionary Matching.	Amihood Amir,Martin Farach,Ramana M. Idury,Johannes A. La Poutré,Alejandro A. Schäffer	1993	Improved Dynamic Dictionary Matching.	SODA	theory
2102	SODA	Approximate Nearest Neighbor Queries in Fixed Dimensions.	Sunil Arya,David M. Mount	1993	Approximate Nearest Neighbor Queries in Fixed Dimensions.	SODA	theory
2103	SODA	On-line Choice of On-line Algorithms.	Yossi Azar,Andrei Z. Broder,Mark S. Manasse	1993	On-line Choice of On-line Algorithms.	SODA	theory
2104	SODA	Solving Mixed 0-1 Programs by a Lift-and-Project Method.	Egon Balas,Sebastián Ceria,Gérard Cornuéjols	1993	Solving Mixed 0-1 Programs by a Lift-and-Project Method.	SODA	theory
2105	SODA	On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas.	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1993	On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas.	SODA	theory
2106	SODA	Confluently Persistent Deques via Data Structural Bootstrapping.	Adam L. Buchsbaum,Robert Endre Tarjan	1993	Confluently Persistent Deques via Data Structural Bootstrapping.	SODA	theory
2107	SODA	Faster Algorithms for Some Geometric Graph Problems in Higher Dimensions.	Paul B. Callahan,S. Rao Kosaraju	1993	Faster Algorithms for Some Geometric Graph Problems in Higher Dimensions.	SODA	theory
2108	SODA	On Linear-Time Deterministic Algorithms for Optimization Problems in Fixed Dimensions.	Bernard Chazelle,Jirí Matousek	1993	On Linear-Time Deterministic Algorithms for Optimization Problems in Fixed Dimensions.	SODA	theory
2109	SODA	Random Weighted Laplacians, Lovász Minimum Digraphs and Finding Minimum Separators.	Joseph Cheriyan	1993	Random Weighted Laplacians, Lovász Minimum Digraphs and Finding Minimum Separators.	SODA	theory
2110	SODA	A Unified Approach to Dynamic Point Location, Ray Shooting, and Shortest Paths in Planar Maps.	Yi-Jen Chiang,Franco P. Preparata,Roberto Tamassia	1993	We describe a new technique for dynamically maintaining the trapezoidal decomposition of a connected planar map $\cal M$ with $n$ vertices and apply it to the development of a unified dynamic data structure that supports point-location, ray-shooting, and shortest-path queries in $\cal M$. The space requirement is $O(n\log n)$. Point-location queries take time $O(\log n)$. Ray-shooting and shortest-path queries take time $O(\log^3 n)$ (plus $O(k)$ time if the $k$ edges of the shortest path are reported in addition to its length). Updates consist of insertions and deletions of vertices and edges, and take $O(\log^3 n)$ time (amortized for vertex updates). This is the first polylog-time dynamic data structure for shortest-path and ray-shooting queries. It is also the first dynamic point-location data structure for connected planar maps that achieves optimal query time.	SODA	theory
2111	SODA	Finding Connected Components in O(log n log log n) Time on the EREW PRAM.	Ka Wong Chong,Tak Wah Lam	1993	Finding Connected Components in O(log n log log n) Time on the EREW PRAM.	SODA	theory
2112	SODA	Competitive Implementation of Parallel Programs.	Xiaotie Deng,Elias Koutsoupias	1993	Competitive Implementation of Parallel Programs.	SODA	theory
2113	SODA	Lower Bounds for Set Intersection Queries.	Paul F. Dietz,Kurt Mehlhorn,Rajeev Raman,Christian Uhrig	1993	Lower Bounds for Set Intersection Queries.	SODA	theory
2114	SODA	Iterated Nearest Neighbors and Finding Minimal Polytopes.	David Eppstein,Jeff Erickson	1993	Iterated Nearest Neighbors and Finding Minimal Polytopes.	SODA	theory
2115	SODA	An O(n) Algorithm for Circular-Arc Graph Recognition.	Elaine M. Eschen,Jeremy Spinrad	1993	An O(n) Algorithm for Circular-Arc Graph Recognition.	SODA	theory
2116	SODA	An Efficient Protocol for Unconditionally Secure Secret Key Exchange.	Michael J. Fischer,Rebecca N. Wright	1993	An Efficient Protocol for Unconditionally Secure Secret Key Exchange.	SODA	theory
2117	SODA	A Data Structure for Dynamically Maintaining Rooted Trees.	Greg N. Frederickson	1993	A Data Structure for Dynamically Maintaining Rooted Trees.	SODA	theory
2118	SODA	Data Structures for Traveling Salesmen.	Michael L. Fredman,David S. Johnson,Lyle A. McGeoch,G. Ostheimer	1993	Data Structures for Traveling Salesmen.	SODA	theory
2119	SODA	Analysis of a Simple Greedy Matching Algorithm on Random Cubic Graphs.	Alan M. Frieze,A. J. Radcliffe,Stephen Suen	1993	Analysis of a Simple Greedy Matching Algorithm on Random Cubic Graphs.	SODA	theory
2120	SODA	A Representation for Crossing Set Families with Applications to Submodular Flow Problems.	Harold N. Gabow	1993	A Representation for Crossing Set Families with Applications to Submodular Flow Problems.	SODA	theory
2121	SODA	Scapegoat Trees.	Igal Galperin,Ronald L. Rivest	1993	Scapegoat Trees.	SODA	theory
2122	SODA	Improved Approximation Algorithms for Biconnected Subgraphs via Better Lower Bounding Techniques.	Naveen Garg,Santosh Vempala,Aman Singla	1993	Improved Approximation Algorithms for Biconnected Subgraphs via Better Lower Bounding Techniques.	SODA	theory
2123	SODA	The Suffix of a Square Matrix, with Applications.	Raffaele Giancarlo	1993	The Suffix of a Square Matrix, with Applications.	SODA	theory
2124	SODA	Scaling Algorithms for the Shortest Paths Problem.	Andrew V. Goldberg	1993	We describe a new method for designing scaling algorithms for the single-source shortest paths problem and use this method to obtain an $O(\sqrt n m \log N)$ algorithm for the problem. (Here $n$ and $m$ is the number of nodes and arcs in the input network and $N$ is essentially the absolute value of the most negative arc length, and arc lengths are assumed to be integral.) This improves previous bounds for the problem. The method extends to related problems.	SODA	theory
2125	SODA	Maxima in Convex Regions.	Mordecai J. Golin	1993	Maxima in Convex Regions.	SODA	theory
2126	SODA	Randomized Data Structures for the Dynamic Closest-Pair Problem.	Mordecai J. Golin,Rajeev Raman,Christian Schwarz,Michiel H. M. Smid	1993	We describe a new randomized data structure, the sparse partition, for solving the dynamic closest-pair problem. Using this data structure the closest pair of a set of n points in D-dimensional space, for any fixed D, can be found in constant time. If a frame containing all the points is known in advance, and if the floor function is available at unit cost, then the data structure supports insertions into and deletions from the set in expected O(log n) time and requires expected O(n) space. This method is more efficient than any deterministic algorithm for solving the problem in dimension D > 1. The data structure can be modified to run in O(log2 n) expected time per update in the algebraic computation tree model. Even this version is more efficient than the best currently known deterministic algorithm for D > 2. Both results assume that the sequence of updates is not determined in any way by the random choices made by the algorithm.	SODA	theory
2127	SODA	Fast Deterministic Processor Allocation.	Torben Hagerup	1993	Fast Deterministic Processor Allocation.	SODA	theory
2128	SODA	Efficient Automatic Part Nesting on Irregular and Inhomogeneous Surfaces.	Jörg Heistermann,Thomas Lengauer	1993	Efficient Automatic Part Nesting on Irregular and Inhomogeneous Surfaces.	SODA	theory
2129	SODA	A Pedestrian Approach to Ray Shooting: Shoot a Ray, Take a Walk.	John Hershberger,Subhash Suri	1993	A Pedestrian Approach to Ray Shooting: Shoot a Ray, Take a Walk.	SODA	theory
2130	SODA	Polygonal Approximations that Minimize the Number of Inflections.	John D. Hobby	1993	Polygonal Approximations that Minimize the Number of Inflections.	SODA	theory
2131	SODA	Polynomial Algorithms for Minimum Cost Paths in Periodic Graphs.	Franz Höfting,Egon Wanke	1993	Polynomial Algorithms for Minimum Cost Paths in Periodic Graphs.	SODA	theory
2132	SODA	Searching in an Unknown Environment: An Optimal Randomized Algorithm for the Cow-Path Problem.	Ming-Yang Kao,John H. Reif,Stephen R. Tate	1993	Searching in an Unknown Environment: An Optimal Randomized Algorithm for the Cow-Path Problem.	SODA	theory
2133	SODA	Global Min-cuts in RNC, and Other Ramifications of a Simple Min-Cut Algorithm.	David R. Karger	1993	Global Min-cuts in RNC, and Other Ramifications of a Simple Min-Cut Algorithm.	SODA	theory
2134	SODA	Balancing Minimum Spanning and Shortest Path Trees.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1993	Balancing Minimum Spanning and Shortest Path Trees.	SODA	theory
2135	SODA	Upper and Lower Bounds on Constructing Alphabetic Binary Trees.	Maria M. Klawe,Brendan Mumey	1993	This paper studies the long-standing open question of whether optimal alphabetic binary trees can be constructed in $o(n \lg n)$ time. We show that a class of techniques for finding optimal alphabetic trees which includes all current methods yielding $O(n \lg n)$-time algorithms are at least as hard as sorting in whatever model of computation is used. We also give $O(n)$-time algorithms for the case where all the input weights are within a constant factor of one another and when they are exponentially separated.	SODA	theory
2136	SODA	The Stanford GraphBase: A Platform for Combinatorial Algorithms.	Donald E. Knuth	1993	The Stanford GraphBase: A Platform for Combinatorial Algorithms.	SODA	theory
2137	SODA	Finding Near-Optimal Cuts: An Empirical Evaluation.	Kevin Lang,Satish Rao	1993	Finding Near-Optimal Cuts: An Empirical Evaluation.	SODA	theory
2138	SODA	Non-Clairvoyant Scheduling.	Rajeev Motwani,Steven J. Phillips,Eric Torng	1993	Non-Clairvoyant Scheduling.	SODA	theory
2139	SODA	Dynamic Generation of Discrete Random Variates.	Yossi Matias,Jeffrey Scott Vitter,Wen-Chun Ni	1993	Dynamic Generation of Discrete Random Variates.	SODA	theory
2140	SODA	Efficient Randomized Algorithms for the Repeated Median Line Estimator.	Jirí Matousek,David M. Mount,Nathan S. Netanyahu	1993	Efficient Randomized Algorithms for the Repeated Median Line Estimator.	SODA	theory
2141	SODA	A Linear Time 2+epsilon Approximation Algorithm for Edge Connectivity.	David W. Matula	1993	A Linear Time 2+epsilon Approximation Algorithm for Edge Connectivity.	SODA	theory
2142	SODA	Optimistic Sorting and Information Theoretic Complexity.	Peter M. McIlroy	1993	Optimistic Sorting and Information Theoretic Complexity.	SODA	theory
2143	SODA	Triangulating Vertex Colored Graphs.	Fred R. McMorris,Tandy Warnow,Thomas Wimer	1993	This paper examines the class of vertex-colored graphs that can be triangulated without the introduction of edges between vertices of the same color. This is related to a fundamental and long-standing problem for numerical taxonomists, called the Perfect Phylogeny Problem. These problems are known to be polynomially equivalent and NP-complete. This paper presents a dynamic programming algorithm that can be used to determine whether a given vertex-colored graph can be so triangulated and that runs in $O((n+m(k-2))^{k+1})$ time, where the graph has $n$ vertices, $m$ edges, and $k$ colors. The corresponding algorithm for the Perfect Phylogeny Problem runs in $O(r^{k+1} k^{k+1} + sk^2 )$ time, where $s$ species are defined by $k$ $r$-state characters.	SODA	theory
2144	SODA	The Vertex-Disjoint Menger Problem in Planar Graphs.	Heike Ripphausen-Lipa,Dorothea Wagner,Karsten Weihe	1993	We consider the problem of finding a maximum collection of vertex-disjoint paths in undirected, planar graphs from a vertex $s$ to a vertex $t$. This problem is usually solved using flow techniques, which lead to ${\cal O}(nk)$ and ${\cal O}(n\sqrt{n})$ running times, respectively, where $n$ is the number of vertices and $k$ the maximum number of vertex-disjoint $(s,t)$-paths. The best previously known algorithm is based on a divide-and-conquer approach and has running time ${\cal O}(n\log n)$. The approach presented here is completely different from these methods and yields a linear-time algorithm.	SODA	theory
2145	SODA	A New and Simple Algorithm for Quality 2-Dimensional Mesh Generation.	Jim Ruppert	1993	We present a simple new algorithm for triangulating polygons and planar straightline graphs. It provides shape and size guarantees: -All triangles have a bounded aspect ratio. - The number of Steiner points added is within a constant factor of optimal. Such quality triangulations are desirable as meshes for the finite element method, in which the running time generally increases with the number of triangles, and where the convergence and stability may be hurt by very skinny triangles. The technique we use--successive refinement of the Delaunay triangulation--extends a mesh generation technique of Chew by allowing triangles that vary in size. Previous algorithms with shape and size bounds have all been based on quadtrees. The Delaunay refinement algorithm matches their bounds, but uses a fundamentally different approach. It is much simpler, and hence easier to implement, and it generally produces smaller meshes in practice.	SODA	theory
2146	SODA	Chernoff-Hoeffding Bounds for Applications with Limited Independence.	Jeanette P. Schmidt,Alan Siegel,Aravind Srinivasan	1993	Chernoff-Hoeffding (CH) bounds are fundamental tools used in bounding the tail probabilities of the sums of bounded and independent random variables (r.v.'s). We present a simple technique that gives slightly better bounds than these and that more importantly requires only limited independence among the random variables, thereby importing a variety of standard results to the case of limited independence for free. Additional methods are also presented, and the aggregate results are sharp and provide a better understanding of the proof techniques behind these bounds. These results also yield improved bounds for various tail probability distributions and enable improved approximation algorithms for jobshop scheduling. The limited independence result implies that a reduced amount and weaker sources of randomness are sufficient for randomized algorithms whose analyses use the CH bounds, e.g., the analysis of randomized algorithms for random sampling and oblivious packet routing.	SODA	theory
2147	SODA	Scheduling Unrelated Machines with Costs.	David B. Shmoys,Éva Tardos	1993	Scheduling Unrelated Machines with Costs.	SODA	theory
2148	SODA	On Traversing Layered Graphs On-line.	H. Ramesh	1993	On Traversing Layered Graphs On-line.	SODA	theory
2149	SODA	Fast Construction of Irreducible Polynomials over Finite Fields.	Victor Shoup	1993	Fast Construction of Irreducible Polynomials over Finite Fields.	SODA	theory
2150	SODA	Equidistribution of Point Sets for the Traveling Salesman and Related Problems.	Timothy Law Snyder,J. Michael Steele	1993	Equidistribution of Point Sets for the Traveling Salesman and Related Problems.	SODA	theory
2151	SODA	Optimal Edge Ranking of Trees in Polynomial Time.	Pilar de la Torre,Raymond Greenlaw,Alejandro A. Schäffer	1993	Optimal Edge Ranking of Trees in Polynomial Time.	SODA	theory
2152	SODA	Tree Compatibility and Inferring Evoluationary History.	Tandy Warnow	1993	Tree Compatibility and Inferring Evoluationary History.	SODA	theory
2153	SODA	Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces.	Peter N. Yianilos	1993	Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces.	SODA	theory
2154	SODA	Proceedings of the Fourth Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 25-27 January 1993, Austin, Texas.	Vijaya Ramachandran	1993	Proceedings of the Fourth Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 25-27 January 1993, Austin, Texas.	SODA	theory
2155	STOC	Depth reduction for noncommutative arithmetic circuits.	Eric Allender,Jia Jiao	1993	Depth reduction for noncommutative arithmetic circuits.	STOC	theory
2156	STOC	Routing permutations on graphs via matchings.	Noga Alon,Fan R. K. Chung,Ronald L. Graham	1993	A class of routing problems on connected graphs $G$ is considered. Initially, each vertex $v$ of $G$ is occupied by a ``pebble'' that has a unique destination $\pi (v)$ in $G$ (so that $\pi$ is a permutation of the vertices of $G$). It is required that all the pebbles be routed to their respective destinations by performing a sequence of moves of the following type: A disjoint set of edges is selected, and the pebbles at each edge's endpoints are interchanged. The problem of interest is to minimize the number of steps required for any possible permutation $\pi$. This paper investigates this routing problem for a variety of graphs $G$, including trees, complete graphs, hypercubes, Cartesian products of graphs, expander graphs, and Cayley graphs. In addition, this routing problem is related to certain network flow problems, and to several graph invariants including diameter, eigenvalues, and expansion coefficients.	STOC	theory
2157	STOC	Parametric real-time reasoning.	Rajeev Alur,Thomas A. Henzinger,Moshe Y. Vardi	1993	Parametric real-time reasoning.	STOC	theory
2158	STOC	Approximate load balancing on dynamic and asynchronous networks.	William Aiello,Baruch Awerbuch,Bruce M. Maggs,Satish Rao	1993	Approximate load balancing on dynamic and asynchronous networks.	STOC	theory
2159	STOC	Checking approximate computations over the reals.	Sigal Ar,Manuel Blum,Bruno Codenotti,Peter Gemmell	1993	Checking approximate computations over the reals.	STOC	theory
2160	STOC	On-line load balancing with applications to machine scheduling and virtual circuit routing.	James Aspnes,Yossi Azar,Amos Fiat,Serge A. Plotkin,Orli Waarts	1993	On-line load balancing with applications to machine scheduling and virtual circuit routing.	STOC	theory
2161	STOC	Competitive distributed file allocation.	Baruch Awerbuch,Yair Bartal,Amos Fiat	1993	This paper deals with the file allocation problem [6] concerning the dynamic optimization of communication costs to access data in a distributed environment. We develop a dynamic file re-allocation strategy that adapts on-line to a sequence of read and write requests whose location and relative frequencies are completely unpredictable. This is achieved by replicating the file in response to read requests and migrating the file in response to write requests while paying the associated communications costs, so as to be closer to processors that access it frequently. We develop first explicit deterministic on-line strategy assuming existence of global information about the state of the network; previous (deterministic) solutions were complicated and more expensive. Our solution has (optimal) logarithmic competitive ratio. The paper also contains the first explicit deterministic data migration [7] algorithm achieving the best known competitive ratio for this problem. Using somewhat different technique, we also develop the first deterministic distributed file allocation algorithm (using only local information) with poly-logarithmic competitive ratio against a globally optimized optimal prescient strategy.	STOC	theory
2162	STOC	Time optimal self-stabilizing synchronization.	Baruch Awerbuch,Shay Kutten,Yishay Mansour,Boaz Patt-Shamir,George Varghese	1993	Time optimal self-stabilizing synchronization.	STOC	theory
2163	STOC	A theory of parameterized pattern matching: algorithms and applications.	Brenda S. Baker	1993	A theory of parameterized pattern matching: algorithms and applications.	STOC	theory
2164	STOC	Short random walks on graphs.	Greg Barnes,Uriel Feige	1993	The short-term behavior of random walks on graphs is studied, in particular, the rate at which a random walk discovers new vertices and edges. A conjecture by Linial that the expected time to find $\cal N$ distinct vertices is $O({\cal N}^{3})$ is proved. In addition, upper bounds of $O({\cal M}^{2})$ on the expected time to traverse $\cal M$ edges and of $O(\cal M \cal N)$ on the expected time to either visit $\cal N$ vertices or traverse $\cal M$ edges (whichever comes first) are proved.	STOC	theory
2165	STOC	Proportionate progress: a notion of fairness in resource allocation.	Sanjoy K. Baruah,N. K. Cohen,C. Greg Plaxton,Donald A. Varvel	1993	Proportionate progress: a notion of fairness in resource allocation.	STOC	theory
2166	STOC	Angles of planar triangular graphs.	Giuseppe Di Battista,Luca Vismara	1993	We give a characterization of all the planar drawings of a triangular graph through a system of equations and inequalities relating its angles; we also discuss minimality properties of the characterization. The characterization can be used: (1) to decide in linear time whether a given distribution of angles between the edges of a planar triangular graph can result in a planar drawing; (2) to reduce the problem of maximizing the minimum angle in a planar straight-line drawing of a planar triangular graph to a nonlinear optimization problem purely on a space of angles; (3) to give a characterization of the planar drawings of a triconnected graph through a system of equations and inequalities relating its angles; (4) to give a characterization of Delaunay triangulations through a system of equations and inequalities relating its angles; (5) to give a characterization of all the planar drawings of a triangular graph through a system of equations and inequalities relating the lengths of its edges; in turn, this result allows us to give a new characterization of the disc-packing representations of planar triangular graphs.	STOC	theory
2167	STOC	Efficient probabilistically checkable proofs and applications to approximations.	Mihir Bellare,Shafi Goldwasser,Carsten Lund,A. Russeli	1993	Efficient probabilistically checkable proofs and applications to approximations.	STOC	theory
2168	STOC	Asynchronous secure computation.	Michael Ben-Or,Ran Canetti,Oded Goldreich	1993	Asynchronous secure computation.	STOC	theory
2169	STOC	Space-efficient scheduling of multithreaded computations.	Robert D. Blumofe,Charles E. Leiserson	1993	This paper considers the problem of scheduling dynamic parallel computations to achieve linear speedup without using significantly more space per processor than that required for a single-processor execution. Utilizing a new graph-theoretic model of multithreaded computation, execution efficiency is quantified by three important measures: T1 is the time required for executing the computation on a 1 processor, $T_\infty$ is the time required by an infinite number of processors, and S1 is the space required to execute the computation on a 1 processor. A computation executed on P processors is time-efficient if the time is $O(T_1/P + T_\infty)$, that is, it achieves linear speedup when $P=O(T_1/T_\infty)$, and it is space-efficient if it uses O(S1P) total space, that is, the space per processor is within a constant factor of that required for a 1-processor execution.The first result derived from this model shows that there exist multithreaded computations such that no execution schedule can simultaneously achieve efficient time and efficient space. But by restricting attention to strict computations---those in which all arguments to a procedure must be available before the procedure can be invoked---much more positive results are obtainable. Specifically, for any strict multithreaded computation, a simple online algorithm can compute a schedule that is both time-efficient and space-efficient. Unfortunately, because the algorithm uses a global queue, the overhead of computing the schedule can be substantial. This problem is overcome by a decentralized algorithm that can compute and execute a P-processor schedule online in expected time $O(T_1/P + T_\infty\lg P)$ and worst-case space $O(S_1P\lg P)$, including overhead costs.	STOC	theory
2170	STOC	Thermodynamics of computation and information distance.	Charles H. Bennett,Péter Gács,Ming Li,Paul M. B. Vitányi,Wojciech H. Zurek	1993	Thermodynamics of computation and information distance.	STOC	theory
2171	STOC	A linear time algorithm for finding tree-decompositions of small treewidth.	Hans L. Bodlaender	1993	In this paper, we give for constant $k$ a linear-time algorithm that, given a graph $G=(V,E)$, determines whether the treewidth of $G$ is at most $k$ and, if so, finds a tree-decomposition of $G$ with treewidth at most $k$. A consequence is that every minor-closed class of graphs that does not contain all planar graphs has a linear-time recognition algorithm. Another consequence is that a similar result holds when we look instead for path-decompositions with pathwidth at most some constant $k$.	STOC	theory
2172	STOC	Piecewise linear paths among convex obstacles.	Mark de Berg,Jirí Matousek,Otfried Schwarzkopf	1993	Piecewise linear paths among convex obstacles.	STOC	theory
2173	STOC	On-line algorithms for cache sharing.	Marshall W. Bern,Daniel H. Greene,Arvind Raghunathan	1993	On-line algorithms for cache sharing.	STOC	theory
2174	STOC	Quantum complexity theory.	Ethan Bernstein,Umesh V. Vazirani	1993	In this paper we study quantum computation from a complexity theoretic viewpoint. Our first result is the existence of an efficient universal quantum Turing machine in Deutsch's model of a quantum Turing machine (QTM) [Proc. Roy. Soc. London Ser. A, 400 (1985), pp. 97--117]. This construction is substantially more complicated than the corresponding construction for classical Turing machines (TMs); in fact, even simple primitives such as looping, branching, and composition are not straightforward in the context of quantum Turing machines. We establish how these familiar primitives can be implemented and introduce some new, purely quantum mechanical primitives, such as changing the computational basis and carrying out an arbitrary unitary transformation of polynomially bounded dimension.We also consider the precision to which the transition amplitudes of a quantum Turing machine need to be specified. We prove that $O(\log T)$ bits of precision suffice to support a $T$ step computation. This justifies the claim that the quantum Turing machine model should be regarded as a discrete model of computation and not an analog one. We give the first formal evidence that quantum Turing machines violate the modern (complexity theoretic) formulation of the Church--Turing thesis. We show the existence of a problem, relative to an oracle, that can be solved in polynomial time on a quantum Turing machine, but requires superpolynomial time on a bounded-error probabilistic Turing machine, and thus not in the class $\BPP$. The class $\BQP$ of languages that are efficiently decidable (with small error-probability) on a quantum Turing machine satisfies $\BPP \subseteq \BQP \subseteq \Ptime^{\SP}$. Therefore, there is no possibility of giving a mathematical proof that quantum Turing machines are more powerful than classical probabilistic Turing machines (in the unrelativized setting) unless there is a major breakthrough in complexity theory.	STOC	theory
2175	STOC	The biased coin problem.	Ravi B. Boppana,Babu O. Narayanan	1993	The biased coin problem.	STOC	theory
2176	STOC	Comparison-based search in the presence of errors.	Ryan S. Borgstrom,S. Rao Kosaraju	1993	Comparison-based search in the presence of errors.	STOC	theory
2177	STOC	How much can hardware help routing?	Allan Borodin,Prabhakar Raghavan,Baruch Schieber,Eli Upfal	1993	We study the extent to which complex hardware can speed up routing. Specifically, we consider the following questions. How much does adaptive routing improve over oblivious routing? How much does randomness help? How does it help if each node can have a large number of neighbors? What benefit is available if a node can send packets to several neighbors within a single time step? Some of these features require complex networking hardware, and thus it is important to investigate whether the performance justifies the investment. By varying these hardware parameters, we obtain a hierarchy of time bounds for worst-case permutation routing. We develop a nearly complete taxonomy of the complexity of routing.	STOC	theory
2178	STOC	Generalized FLP impossibility result for t-resilient asynchronous computations.	Elizabeth Borowsky,Eli Gafni	1993	Generalized FLP impossibility result for t-resilient asynchronous computations.	STOC	theory
2179	STOC	Fast asynchronous Byzantine agreement with optimal resilience.	Ran Canetti,Tal Rabin	1993	Fast asynchronous Byzantine agreement with optimal resilience.	STOC	theory
2180	STOC	How to use expert advice.	Nicolò Cesa-Bianchi,Yoav Freund,David P. Helmbold,David Haussler,Robert E. Schapire,Manfred K. Warmuth	1993	We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts''. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes.	STOC	theory
2181	STOC	Randomness-optimal unique element isolation, with applications to perfect matching and related problems.	Suresh Chari,Pankaj Rohatgi,Aravind Srinivasan	1993	Randomness-optimal unique element isolation, with applications to perfect matching and related problems.	STOC	theory
2182	STOC	Improved bounds on weak epsilon-nets for convex sets.	Bernard Chazelle,Herbert Edelsbrunner,Michelangelo Grigni,Leonidas J. Guibas,Micha Sharir,Emo Welzl	1993	Improved bounds on weak epsilon-nets for convex sets.	STOC	theory
2183	STOC	Some complexity issues on the simply connected regions of the two-dimensional plane.	Arthur W. Chou,Ker-I Ko	1993	Some complexity issues on the simply connected regions of the two-dimensional plane.	STOC	theory
2184	STOC	Markov chains, computer proofs, and average-case analysis of best fit bin packing.	Edward G. Coffman Jr.,David S. Johnson,Peter W. Shor,Richard R. Weber	1993	Markov chains, computer proofs, and average-case analysis of best fit bin packing.	STOC	theory
2185	STOC	Reinventing the wheel: an optimal data structure for connectivity queries.	Robert F. Cohen,Giuseppe Di Battista,Arkady Kanevsky,Roberto Tamassia	1993	Reinventing the wheel: an optimal data structure for connectivity queries.	STOC	theory
2186	STOC	Multi-scale self-simulation: a technique for reconfiguring arrays with faults.	Richard Cole,Bruce M. Maggs,Ramesh K. Sitaraman	1993	Multi-scale self-simulation: a technique for reconfiguring arrays with faults.	STOC	theory
2187	STOC	Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions.	Anne Condon,Joan Feigenbaum,Carsten Lund,Peter W. Shor	1993	Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions.	STOC	theory
2188	STOC	Fast perfection-information leader-election protocol with linear immunity.	Jason Cooper,Nathan Linial	1993	Fast perfection-information leader-election protocol with linear immunity.	STOC	theory
2189	STOC	Contention in shared memory algorithms.	Cynthia Dwork,Maurice Herlihy,Orli Waarts	1993	Most complexity measures for concurrent algorithms for asynchronous shared-memory architectures focus on process steps and memory consumption. In practice, however, performance of multiprocessor algorithms is heavily influenced by contention, the extent to which processess access the same location at the same time. Nevertheless, even though contention is one of the principal considerations affecting the performance of real algorithms on real multiprocessors, there are no formal tools for analyzing the contention of asynchronous shared-memory algorithms.This paper introduces the first formal complexity model for contention in shared-memory multiprocessors. We focus on the standard multiprocessor architecture in which n asynchronous processes communicate by applying read, write, and read-modify-write operations to a shared memory. To illustrate the utility of our model, we use it to derive two kinds of results: (1) lower bounds on contention for well-known basic problems such as agreement and mutual exclusion, and (2) trade-offs between the length of the critical path (maximal number of accesses to shared variables performed by a single process in executing the algorithm) and contention for these algorithms. Furthermore, we give the first formal contention analysis of a variety of counting networks, a class of concurrent data structures inplementing shared counters. Experiments indicate that certain counting networks outperform conventional single-variable counters at high levels of contention. Our analysis provides the first formal model explaining this phenomenon.	STOC	theory
2190	STOC	Time-space trade-offs for undirected st-connectivity on a JAG.	Jeff Edmonds	1993	Time-space trade-offs for undirected st-connectivity on a JAG.	STOC	theory
2191	STOC	Separator based sparsification for dynamic planar graph algorithms.	David Eppstein,Zvi Galil,Giuseppe F. Italiano,Thomas H. Spencer	1993	Separator based sparsification for dynamic planar graph algorithms.	STOC	theory
2192	STOC	A robust model for finding optimal evolutionary trees.	Martin Farach,Sampath Kannan,Tandy Warnow	1993	A robust model for finding optimal evolutionary trees.	STOC	theory
2193	STOC	Monotone monadic SNP and constraint satisfaction.	Tomás Feder,Moshe Y. Vardi	1993	Monotone monadic SNP and constraint satisfaction.	STOC	theory
2194	STOC	Optimal online scheduling of parallel jobs with dependencies.	Anja Feldmann,Ming-Yang Kao,Jiri Sgall,Shang-Hua Teng	1993	We study the following general online scheduling problem. Parallel jobs arrive dynamically according to the dependencies between them. Each job requests a certain number of processors with a specific communication configuration, but its running time is not known until it is completed. We present optimal online algorithms for PRAMs, hypercubes and one-dimensional meshes, and obtain optimal tradeoffs between the competitive ratio and the largest number of processors requested by any job. Our work shows that for efficient online scheduling it is necessary to use virtualization, i.e., to schedule parallel jobs on fewer processors than requested while preserving the work. Assume that the largest number of processors requested by a job is lambda(N), where 0 > lambda > 1 and N is the number of processors of - a machine. With virtualization, our algorithm for PRAMs has a competitive __________ ratio of 2 + /4lamba + 1 - 1 . Our lower bound shows that this ratio _______________ 2lambda is optimal. As lambda goes from 0 to 1, the ratio changes from 2 to 2 + Phi, where Phi ~ 0.168 is the golden ratio. For hypercubes and ~ one-dimensional meshes we present Theta (log N ) -competitive algorithms ______ (log log N) as well as matching lower bounds. Without virtualization, no online scheduling algorithm can achieve a competitive ratio smaller than N for lambda = 1. For lambda > 1, the lower bound is 1 + 1 and our _____ 1 - y algorithm for PRAMs achieves this competitive ratio. We prove that tree constraints are complete for the scheduling problem, i.e., any algorithm that solves the scheduling problem if the dependency graph is a tree can be converted to solve the general problem equally efficiently. This shows that the structure of a dependency graph is not as important for online scheduling as it is for offline scheduling, although even simple dependencies make the problem much harder than scheduling independent jobs.	STOC	theory
2195	STOC	Maximum k-chains in planar point sets: combinatorial structure and algorithms.	Stefan Felsner,Lorenz Wernisch	1993	A chain of a set P of n points in the plane is a chain of the dominance order on P. A k-chain is a subset C of P that can be covered by k chains. A k-chain C is a maximum k-chain if no other k-chain contains more elements than C. This paper deals with the problem of finding a maximum k-chain of P in the cardinality and in the weighted case.Using the skeleton S(P) of a point set P introduced by Viennot we describe a fairly simple algorithm that computes maximum k-chains in time O(kn log n) and linear space. The basic idea is that the canonical chain partition of a maximum (k-1)-chain in the skeleton S(P) provides k regions in the plane such that a maximum k-chain for P can be obtained as the union of a maximal chain from each of these regions.By the symmetry between chains and antichains in the dominance order we may use the algorithm for maximum k-chains to compute maximum k-antichains for planar points in time O(kn log n). However, for large k one can do better. We describe an algorithm computing maximum k-antichains (and, by symmetry, k-chains) in time O((n2 k) log n) and linear space. Consequently, a maximum k-chain can be computed in time O(n3/2 log n) for arbitrary k.The background for the algorithms is a geometric approach to the Greene--Kleitman theory for permutations. We include a skeleton-based exposition of this theory and give some hints on connections with the theory of Young tableaux.The concept of the skeleton of a planar point set is extended to the case of a weighted point set. This extension allows to compute maximum weighted k-chains with an algorithm that is similar to the algorithm for the cardinality case. The time and space requirements of the algorithm for weighted k-chains are O(2kn log(2kn)) and O(2kn), respectively.	STOC	theory
2196	STOC	Decision trees: old and new results.	Rudolf Fleischer	1993	Decision trees: old and new results.	STOC	theory
2197	STOC	Efficient learning of typical finite automata from random walks.	Yoav Freund,Michael J. Kearns,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire,Linda Sellie	1993	Efficient learning of typical finite automata from random walks.	STOC	theory
2198	STOC	Fully polynomial Byzantine agreement in t+1 rounds.	Juan A. Garay,Yoram Moses	1993	Fully polynomial Byzantine agreement in t+1 rounds.	STOC	theory
2199	STOC	Approximate max-flow min-(multi)cut theorems and their applications.	Naveen Garg,Vijay V. Vazirani,Mihalis Yannakakis	1993	Consider the multicommodity flow problem in which the object is to maximize the sum of commodities routed. We prove the following approximate max-flow min-multicut theorem: $$ \dst \frac{\mbox{\rm min multicut}}{O(\log k)} \leq \mbox{ \rm max flow } \leq \mbox{ \rm min multicut}, $$ \noindent where $k$ is the number of commodities. Our proof is constructive; it enables us to find a multicut within $O(\log k)$ of the max flow (and hence also the optimal multicut). In addition, the proof technique provides a unified framework in which one can also analyse the case of flows with specified demands of Leighton and Rao and Klein et al. and thereby obtain an improved bound for the latter problem.	STOC	theory
2200	STOC	Counting curves and their projections.	Joachim von zur Gathen,Marek Karpinski,Igor Shparlinski	1993	Counting curves and their projections.	STOC	theory
2201	STOC	Polynomial space polynomial delay algorithms for listing families of graphs.	Leslie Ann Goldberg	1993	Polynomial space polynomial delay algorithms for listing families of graphs.	STOC	theory
2202	STOC	Simulating threshold circuits by majority circuits.	Mikael Goldmann,Marek Karpinski	1993	We prove that a single threshold gate with arbitrary weights can be simulated by an explicit polynomial-size, depth-2 majority circuit. In general we show that a polynomial-size, depth-d threshold circuit can be simulated uniformly by a polynomial-size majority circuit of depth d + 1. Goldmann, Håstad, and Razborov showed in [Comput. Complexity, 2 (1992), pp. 277--300] that a nonuniform simulation exists. Our construction answers two open questions posed by them: we give an explicit construction, whereas they use a randomized existence argument, and we show that such a simulation is possible even if the depth d grows with the number of variables n (their simulation gives polynomial-size circuits only when d is constant).	STOC	theory
2203	STOC	The asynchronous computability theorem for t-resilient tasks.	Maurice Herlihy,Nir Shavit	1993	The asynchronous computability theorem for t-resilient tasks.	STOC	theory
2204	STOC	Matrix searching with the shortest path metric.	John Hershberger,Subhash Suri	1993	We present an O(n) time algorithm for computing row-wise maxima or minima of an implicit, totally monotone $n \times n$ matrix whose entries represent shortest-path distances between pairs of vertices in a simple polygon. We apply this result to derive improved algorithms for several well-known problems in computational geometry. Most prominently, we obtain linear-time algorithms for computing the geodesic diameter, all farthest neighbors, and external farthest neighbors of a simple polygon, improving the previous best result by a factor of O(log n) in each case.	STOC	theory
2205	STOC	Multiple matching of rectangular patterns.	Ramana M. Idury,Alejandro A. Schäffer	1993	Multiple matching of rectangular patterns.	STOC	theory
2206	STOC	Size-depth trade-offs for threshold circuits.	Russell Impagliazzo,Ramamohan Paturi,Michael E. Saks	1993	Size-depth trade-offs for threshold circuits.	STOC	theory
2207	STOC	k one-way heads cannot do string-matching.	Tao Jiang,Ming Li	1993	k one-way heads cannot do string-matching.	STOC	theory
2208	STOC	Constant time factors do matter.	Neil D. Jones	1993	Constant time factors do matter.	STOC	theory
2209	STOC	Characterizing non-deterministic circuit size.	Mauricio Karchmer,Avi Wigderson	1993	Characterizing non-deterministic circuit size.	STOC	theory
2210	STOC	An O~(n) algorithm for minimum cuts.	David R. Karger,Clifford Stein	1993	An O~(n) algorithm for minimum cuts.	STOC	theory
2211	STOC	Mapping the genome: some combinatorial problems arising in molecular biology.	Richard M. Karp	1993	Mapping the genome: some combinatorial problems arising in molecular biology.	STOC	theory
2212	STOC	Efficient noise-tolerant learning from statistical queries.	Michael J. Kearns	1993	In this paper, we study the problem of learning in the presence of classification noise in the probabilistic learning model of Valiant and its variants. In order to identify the class of &ldquo;robust&rdquo; learning algorithms in the most general way, we formalize a new but related model of learning from statistical queries. Intuitively, in this model a learning algorithm is forbidden to examine individual examples of the unknown target function, but is given acess to an oracle providing estimates of probabilities over the sample space of random examples.One of our main results shows that any class of functions learnable from statistical queries is in fact learnable with classification noise in Valiant's model, with a noise rate approaching the information-theoretic barrier of 1/2. We then demonstrate the generality of the statistical query model, showing that practically every class learnable in Valiant's model and its variants can also be learned in the new model (and thus can be learned in the presence of noise). A notable exception to this statement is the class of parity functions, which we prove is not learnable from statistical queries, and for which no noise-tolerant algorithm is known.	STOC	theory
2213	STOC	Matchings in lattice graphs.	Claire Kenyon,Dana Randall,Alistair Sinclair	1993	Matchings in lattice graphs.	STOC	theory
2214	STOC	Cryptographic hardness of distribution-specific learning.	Michael Kharitonov	1993	Cryptographic hardness of distribution-specific learning.	STOC	theory
2215	STOC	Excluded minors, network decomposition, and multicommodity flow.	Philip N. Klein,Serge A. Plotkin,Satish Rao	1993	Excluded minors, network decomposition, and multicommodity flow.	STOC	theory
2216	STOC	Constructing small sample spaces satisfying given constraints.	Daphne Koller,Nimrod Megiddo	1993	The subject of this paper is finding small sample spaces for joint distributions of n discrete random variables. Such distributions are often only required to obey a certain limited set of constraints of the form Pr (Event) = $\pi$. It is shown that the problem of deciding whether there exists any distribution satisfying a given set of constraints is NP-hard. However, if the constraints are consistent, then there exists a distribution satisfying them, which is supported by a small sample space (one whose cardinality is equal to the number of constraints). For the important case of independence constraints, where the constraints have a certain form and are consistent with a joint distribution of independent random variables, a small sample space can be constructed in polynomial time. This last result can be used to derandomize algorithms; this is demonstrated by an application to the problem of finding large independent sets in sparse hypergraphs.	STOC	theory
2217	STOC	Lower bounds for randomized mutual exclusion.	Eyal Kushilevitz,Yishay Mansour,Michael O. Rabin,David Zuckerman	1993	We establish, for the first time, lower bounds for randomized mutual exclusion algorithms (with a read-modify-write operation). Our main result is that a constant-size shared variable cannot guarantee strong fairness, even if randomization is allowed. In fact, we prove a lower bound of $\Omega (\log\log n)$ bits on the size of the shared variable, which is also tight.We investigate weaker fairness conditions and derive tight (upper and lower) bounds for them as well. Surprisingly, it turns out that slightly weakening the fairness condition results in an exponential reduction in the size of the required shared variable. Our lower bounds rely on an analysis of Markov chains that may be of interest on its own and may have applications elsewhere.	STOC	theory
2218	STOC	Efficient construction of a small hitting set for combinatorial rectangles in high dimension.	Nathan Linial,Michael Luby,Michael E. Saks,David Zuckerman	1993	Efficient construction of a small hitting set for combinatorial rectangles in high dimension.	STOC	theory
2219	STOC	A parallel approximation algorithm for positive linear programming.	Michael Luby,Noam Nisan	1993	A parallel approximation algorithm for positive linear programming.	STOC	theory
2220	STOC	On the hardness of approximating minimization problems.	Carsten Lund,Mihalis Yannakakis	1993	On the hardness of approximating minimization problems.	STOC	theory
2221	STOC	Bounds for the computational power and learning complexity of analog neural nets.	Wolfgang Maass	1993	It is shown that high-order feedforward neural nets of constant depth with piecewise-polynomial activation functions and arbitrary real weights can be simulated for Boolean inputs and outputs by neural nets of a somewhat larger size and depth with Heaviside gates and weights from {-1, 0, 1}. This provides the first known upper bound for the computational power of the former type of neural nets. It is also shown that in the case of first-order nets with piecewise-linear activation functions one can replace arbitrary real weights by rational numbers with polynomially many bits without changing the Boolean function that is computed by the neural net. In order to prove these results, we introduce two new methods for reducing nonlinear problems about weights in multilayer neural nets to linear problems for a transformed set of parameters. These transformed parameters can be interpreted as weights in a somewhat larger neural net.As another application of our new proof technique we show that neural nets with piecewise-polynomial activation functions and a constant number of analog inputs are probably approximately correct (PAC) learnable (in Valiant's model for PAC learning [Comm. Assoc. Comput. Mach., 27 (1984), pp. 1134--1142]).	STOC	theory
2222	STOC	Finiteness results for sigmoidal neural networks.	Angus Macintyre,Eduardo D. Sontag	1993	Finiteness results for sigmoidal neural networks.	STOC	theory
2223	STOC	A deterministic algorithm for the three-dimensional diameter problem.	Jirí Matousek,Otfried Schwarzkopf	1993	A deterministic algorithm for the three-dimensional diameter problem.	STOC	theory
2224	STOC	What can be computed locally?	Moni Naor,Larry J. Stockmeyer	1993	The purpose of this paper is a study of computation that can be done locally in a distributed network, where locally means within time (or distance) independent of the size of the network. Locally checkable labeling (LCL) problems are considered, where the legality of a labeling can be checked locally (e.g., coloring). The results include the following: There are nontrivial LCL problems that have local algorithms. There is a variant of the dining philosophers problem that can be solved locally. Randomization cannot make an LCL problem local; i.e., if a problem has a local randomized algorithm then it has a local deterministic algorithm. It is undecidable, in general, whether a given LCL has a local algorithm. However, it is decidable whether a given LCL has an algorithm that operates in a given time $t$. Any LCL problem that has a local algorithm has one that is order-invariant (the algorithm depends only on the order of the processor IDs).	STOC	theory
2225	STOC	More deterministic simulation in logspace.	Noam Nisan,David Zuckerman	1993	More deterministic simulation in logspace.	STOC	theory
2226	STOC	Linear programming without the matrix.	Christos H. Papadimitriou,Mihalis Yannakakis	1993	Linear programming without the matrix.	STOC	theory
2227	STOC	Finding minimum-quotient cuts in planar graphs.	James K. Park,Cynthia A. Phillips	1993	Finding minimum-quotient cuts in planar graphs.	STOC	theory
2228	STOC	The network inhibition problem.	Cynthia A. Phillips	1993	The network inhibition problem.	STOC	theory
2229	STOC	Online load balancing and network flow.	Steven Phillips,Jeffery Westbrook	1993	Online load balancing and network flow.	STOC	theory
2230	STOC	Self-routing superconcentrators.	Nicholas Pippenger	1993	Superconcentrators are switching systems that solve the generic problem of interconnecting clients and servers during sessions, in situations where either the clients or the servers are interchangable (so that it does not matter which client is connected to which server). Previous constructions of superconcentrators have required an external agent to find the interconnections appropriate in each instance. We remedy this shortcoming by constructing superconcentrators that are ``self-routing'''', in the sense that they compute for themselves the required interconnections. Specifically, we show how to construct, for each n, a system S_n with the following properties. (1) The system S_n has n inputs, n outputs, and O(n) components, each of which is of one of a fixed finite number of finite automata, and is connected to a fixed finite number of other components through cables, each of which carries signals from a fixed finite alphabet. (2) When some of the inputs, and an equal number of outputs, are ``marked'''' (by the presentation of a certain signal), then after O(log n) steps (a time proportional to the ``diameter'''' of the network) the system will establish a set of disjoint paths from the marked inputs to the marked outputs.	STOC	theory
2231	STOC	Improved bounds on the max-flow min-cut ratio for multicommodity flows.	Serge A. Plotkin,Éva Tardos	1993	Improved bounds on the max-flow min-cut ratio for multicommodity flows.	STOC	theory
2232	STOC	Modified ranks of tensors and the size of circuits.	Pavel Pudlák,Vojtech Rödl	1993	Modified ranks of tensors and the size of circuits.	STOC	theory
2233	STOC	Cryptographic defense against traffic analysis.	Charles Rackoff,Daniel R. Simon	1993	Cryptographic defense against traffic analysis.	STOC	theory
2234	STOC	Many birds with one stone: multi-objective approximation algorithms.	R. Ravi,Madhav V. Marathe,S. S. Ravi,Daniel J. Rosenkrantz,Harry B. Hunt III	1993	We study network-design problems with multiple design objectives. In particular, we look at two cost measures to be minimized simultaneously: the total cost of the network and the maximum degree of any node in the network. Our main result can be roughly stated as follows: given an integer $b$, we present approximation algorithms for a variety of network-design problems on an $n$-node graph in which the degree of the output network is $O(b \log (\frac{n}{b}))$ and the cost of this network is $O(\log n)$ times that of the minimum-cost degree-$b$-bounded network. These algorithms can handle costs on nodes as well as edges. Moreover, we can construct such networks so as to satisfy a variety of connectivity specifications including spanning trees, Steiner trees and generalized Steiner forests. The performance guarantee on the cost of the output network is nearly best-possible unless $NP = \tilde{P}$. We also address the special case in which the costs obey the triangle inequality. In this case, we obtain a polynomial-time approximation algorithm with a stronger performance guarantee. Given a bound $b$ on the degree, the algorithm finds a degree-$b$-bounded network of cost at most a constant time optimum. There is no algorithm that does as well in the absence of triangle inequality unless $P = NP$. We also show that in the case of spanning networks, we can simultaneously approximate within a constant factor yet another objective: the maximum cost of any edge in the network, also called the bottleneck cost of the network. We extend our algorithms to find TSP tours and $k$-connected spanning networks for any fixed $k$ that simultaneously approximate all these three cost measures.	STOC	theory
2235	STOC	Wait-free k-set agreement is impossible: the topology of public knowledge.	Michael E. Saks,Fotios Zaharoglou	1993	In the classical consensus problem, each of n processors receives a private input value and produces a decision value which is one of the original input values, with the requirement that all processors decide the same value. A central result in distributed computing is that, in several standard models including the asynchronous shared-memory model, this problem has no deterministic solution. The k-set agreement problem is a generalization of the classical consensus proposed by Chaudhuri [ Inform. and Comput., 105 (1993), pp. 132--158], where the agreement condition is weakened so that the decision values produced may be different, as long as the number of distinct values is at most k. For $n>k\geq 2$ it was not known whether this problem is solvable deterministically in the asynchronous shared memory model. In this paper, we resolve this question by showing that for any k < n, there is no deterministic wait-free protocol for n processors that solves the k-set agreement problem. The proof technique is new: it is based on the development of a topological structure on the set of possible processor schedules of a protocol. This topological structure has a natural interpretation in terms of the knowledge of the processors of the state of the system. This structure reveals a close analogy between the impossibility of wait-free k-set agreement and the Brouwer fixed point theorem for the k-dimensional ball.	STOC	theory
2236	STOC	Deterministic coding for interactive communication.	Leonard J. Schulman	1993	Deterministic coding for interactive communication.	STOC	theory
2237	STOC	Locality based graph coloring.	Mario Szegedy,Sundar Vishwanathan	1993	Locality based graph coloring.	STOC	theory
2238	STOC	On the generation of multivariate polynomials which are hard to factor.	Adi Shamir	1993	On the generation of multivariate polynomials which are hard to factor.	STOC	theory
2239	STOC	Expanders that beat the eigenvalue bound: explicit construction and applications.	Avi Wigderson,David Zuckerman	1993	Expanders that beat the eigenvalue bound: explicit construction and applications.	STOC	theory
2240	STOC	A primal-dual approximation algorithm for generalized Steiner network problems.	David P. Williamson,Michel X. Goemans,Milena Mihail,Vijay V. Vazirani	1993	A primal-dual approximation algorithm for generalized Steiner network problems.	STOC	theory
2241	STOC	Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, 1993		1993	Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, 1993	STOC	theory
2242	ICCV	Direct estimation of multiple disparities for transparent multiple surfaces in binocular stereo.	Masahiko Shizawa	1993	Direct estimation of multiple disparities for transparent multiple surfaces in binocular stereo.	ICCV	visu
2243	ICCV	2-D digital curve analysis: A regularity measure.	Bruno Vasselle,Gérard Giraudon	1993	2-D digital curve analysis: A regularity measure.	ICCV	visu
2244	ICCV	Reflectance ratio: A photometric invariant for object recognition.	Shree K. Nayar,Ruud M. Bolle	1993	Reflectance ratio: A photometric invariant for object recognition.	ICCV	visu
2245	ICCV	Renormalization for unbiased estimation.	Kenichi Kanatani	1993	Renormalization for unbiased estimation.	ICCV	visu
2246	ICCV	A modal framework for correspondence and description.	Stan Sclaroff,Alex Pentland	1993	A modal framework for correspondence and description.	ICCV	visu
2247	ICCV	Recovering reflectance and illumination in a world of painted polyhedra.	Pawan Sinha,Edward H. Adelson	1993	Recovering reflectance and illumination in a world of painted polyhedra.	ICCV	visu
2248	ICCV	Learning recognition and segmentation of 3-D objects from 2-D images.	John (Juyang) Weng,Narendra Ahuja,Thomas S. Huang	1993	Learning recognition and segmentation of 3-D objects from 2-D images.	ICCV	visu
2249	ICCV	Relative depth from vergence micromovements.	Antônio Francisco	1993	Relative depth from vergence micromovements.	ICCV	visu
2250	ICCV	Tracking non-rigid objects in complex scenes.	Daniel P. Huttenlocher,Jae J. Noh,William Rucklidge	1993	Tracking non-rigid objects in complex scenes.	ICCV	visu
2251	ICCV	Texture discrimination by local generalized symmetry.	Yoram Bonneh,Daniel Reisfeld,Yehezkel Yeshurun	1993	Texture discrimination by local generalized symmetry.	ICCV	visu
2252	ICCV	Diffuse shading, visibility fields, and the geometry of ambient light.	Michael S. Langer,Steven W. Zucker	1993	Diffuse shading, visibility fields, and the geometry of ambient light.	ICCV	visu
2253	ICCV	Extracting projective structure from single perspective views of 3D point sets.	Charlie Rothwell,David A. Forsyth,Andrew Zisserman,Joseph L. Mundy	1993	Extracting projective structure from single perspective views of 3D point sets.	ICCV	visu
2254	ICCV	Recognizing algebraic surfaces from their outlines.	David A. Forsyth	1993	Recognizing algebraic surfaces from their outlines.	ICCV	visu
2255	ICCV	Cooperation of visually guided behaviors.	Jana Kosecka,Ruzena Bajcsy	1993	Cooperation of visually guided behaviors.	ICCV	visu
2256	ICCV	Integration of quantitative and qualitative techniques for deformable model fitting from orthographic, perspective, and stereo projections.	Dimitris N. Metaxas,Sven J. Dickinson	1993	Integration of quantitative and qualitative techniques for deformable model fitting from orthographic, perspective, and stereo projections.	ICCV	visu
2257	ICCV	Automatic feature point extraction and tracking in image sequences for unknown camera motion.	Qinfen Zheng,Rama Chellappa	1993	Automatic feature point extraction and tracking in image sequences for unknown camera motion.	ICCV	visu
2258	ICCV	Dynamic fixation [active vision].	Kourosh Pahlavan,Tomas Uhlin,Jan-Olof Eklundh	1993	Dynamic fixation [active vision].	ICCV	visu
2259	ICCV	Multiple knowledge sources and evidential reasoning for shape recognition.	B. Besserer,S. Estable,B. Ulmer	1993	Multiple knowledge sources and evidential reasoning for shape recognition.	ICCV	visu
2260	ICCV	Head-centered orientation strategies in animate vision.	Enrico Grosso,Dana H. Ballard	1993	Head-centered orientation strategies in animate vision.	ICCV	visu
2261	ICCV	Optimal estimation of object pose from a single perspective view.	Thai-Quynh Phong,Radu Horaud,Adnan Yassine,Dinh-Tuan Pham	1993	Optimal estimation of object pose from a single perspective view.	ICCV	visu
2262	ICCV	A binocular stereo algorithm for reconstructing sloping, creased, and broken surfaces in the presence of half-occlusion.	Peter N. Belhumeur	1993	A binocular stereo algorithm for reconstructing sloping, creased, and broken surfaces in the presence of half-occlusion.	ICCV	visu
2263	ICCV	Motion segmentation and local structure.	David Sinclair	1993	Motion segmentation and local structure.	ICCV	visu
2264	ICCV	Visual echo analysis.	Esfandiar Bandari,James J. Little	1993	Visual echo analysis.	ICCV	visu
2265	ICCV	Large deformable splines, crest lines and matching.	André Guéziec	1993	Large deformable splines, crest lines and matching.	ICCV	visu
2266	ICCV	Motion detection robust to perturbations: A statistical regularization and temporal integration framework.	Jean-Michel Létang,Veronique Rebuffel,Patrick Bouthemy	1993	Motion detection robust to perturbations: A statistical regularization and temporal integration framework.	ICCV	visu
2267	ICCV	Mathematical morphology: The Hamilton-Jacobi connection.	Alan B. Arehart,Luc Vincent,Benjamin B. Kimia	1993	Mathematical morphology: The Hamilton-Jacobi connection.	ICCV	visu
2268	ICCV	Segmentation and 2D motion estimation by region fragments.	Minoru Etoh,Yoshiaki Shirai	1993	Segmentation and 2D motion estimation by region fragments.	ICCV	visu
2269	ICCV	The reciprocal-wedge transform for space-invariant sensing.	Frank Tong,Ze-Nian Li	1993	The reciprocal-wedge transform for space-invariant sensing.	ICCV	visu
2270	ICCV	Multiscale Markov random field models for parallel image classification.	Zoltan Kato,Marc Berthod,Josiane Zerubia	1993	Multiscale Markov random field models for parallel image classification.	ICCV	visu
2271	ICCV	A quantitative methodology for analyzing the performance of detection algorithms.	Tapas Kanungo,Mysore Y. Jaisimha,John Palmer,Robert M. Haralick	1993	A quantitative methodology for analyzing the performance of detection algorithms.	ICCV	visu
2272	ICCV	Experiments with monocular visual tracking and environment modeling.	Olli Silvén,Tapio Repo	1993	Experiments with monocular visual tracking and environment modeling.	ICCV	visu
2273	ICCV	Robust structure from motion using motion parallax.	Roberto Cipolla,Yasukazu Okamoto,Yoshinori Kuno	1993	Robust structure from motion using motion parallax.	ICCV	visu
2274	ICCV	An improved algorithm for algebraic curve and surface fitting.	Gabriel Taubin	1993	An improved algorithm for algebraic curve and surface fitting.	ICCV	visu
2275	ICCV	A note on existence and uniqueness in shape from shading.	Ryszard Kozera	1993	A note on existence and uniqueness in shape from shading.	ICCV	visu
2276	ICCV	Estimation of the light source distribution and its use in integrated shape recovery from stereo and shading.	Darrell R. Hougen,Narendra Ahuja	1993	Estimation of the light source distribution and its use in integrated shape recovery from stereo and shading.	ICCV	visu
2277	ICCV	Combining stereo and motion analysis for direct estimation of scene structure.	Keith J. Hanna,Neil E. Okamoto	1993	Combining stereo and motion analysis for direct estimation of scene structure.	ICCV	visu
2278	ICCV	A finite element model for 3D shape reconstruction and nonrigid motion tracking.	Tim McInerney,Demetri Terzopoulos	1993	A finite element model for 3D shape reconstruction and nonrigid motion tracking.	ICCV	visu
2279	ICCV	Stereo matching, reconstruction and refinement of 3D curves using deformable contours.	Benedicte Bascle,Rachid Deriche	1993	Stereo matching, reconstruction and refinement of 3D curves using deformable contours.	ICCV	visu
2280	ICCV	Robust 3D-3D pose estimation.	Xinhua Zhuang,Yan Huang	1993	Robust 3D-3D pose estimation.	ICCV	visu
2281	ICCV	Grasping visual symmetry.	Andrew Blake,Michael J. Taylor,Adrian Cox	1993	Grasping visual symmetry.	ICCV	visu
2282	ICCV	The critical sets of lines for camera displacement estimation: A mixed Euclidean-projective and constructive approach.	Nassir Navab,Olivier D. Faugeras,Thierry Viéville	1993	The critical sets of lines for camera displacement estimation: A mixed Euclidean-projective and constructive approach.	ICCV	visu
2283	ICCV	A framework for the robust estimation of optical flow.	Michael J. Black,P. Anandan	1993	A framework for the robust estimation of optical flow.	ICCV	visu
2284	ICCV	Enhanced image capture through fusion.	Peter J. Burt,Raymond J. Kolczynski	1993	Enhanced image capture through fusion.	ICCV	visu
2285	ICCV	Occam algorithms for computing visual motion.	Haim Schweitzer	1993	Occam algorithms for computing visual motion.	ICCV	visu
2286	ICCV	3D object recognition by indexing structural invariants from multiple views.	Rakesh Mohan,Daphna Weinshall,Ramesh R. Sarukkai	1993	3D object recognition by indexing structural invariants from multiple views.	ICCV	visu
2287	ICCV	A computational model of neural contour processing: Figure-ground segregation and illusory contours.	Friedrich Heitger,Rüdiger von der Heydt	1993	A computational model of neural contour processing: Figure-ground segregation and illusory contours.	ICCV	visu
2288	ICCV	A linear complexity procedure for labelling line drawings of polyhedral scenes using vanishing points.	Pietro Parodi,Vincent Torre	1993	A linear complexity procedure for labelling line drawings of polyhedral scenes using vanishing points.	ICCV	visu
2289	ICCV	Robust vergence with concurrent detection of occlusion and specular highlights.	Wee-Soon Ching,Peng-Seng Toh,Kap-Luk Chan,Meng-Hwa Er	1993	Robust vergence with concurrent detection of occlusion and specular highlights.	ICCV	visu
2290	ICCV	Euclidean constraints for uncalibrated reconstruction.	Boubakeur Boufama,Roger Mohr,Francoise Veillon	1993	Euclidean constraints for uncalibrated reconstruction.	ICCV	visu
2291	ICCV	Minimum description length based 2D shape description.	Mengxiang Li	1993	Minimum description length based 2D shape description.	ICCV	visu
2292	ICCV	Probabilistic relaxation for matching problems in computer vision.	Josef Kittler,William J. Christmas,Maria Petrou	1993	Probabilistic relaxation for matching problems in computer vision.	ICCV	visu
2293	ICCV	Active exploration: Knowing when we're wrong.	Peter Whaite,Frank P. Ferrie	1993	Active exploration: Knowing when we're wrong.	ICCV	visu
2294	ICCV	A perceptually plausible model for global symmetry detection.	Francois Labonte,Yerucham Shapira,Paul Cohen	1993	A perceptually plausible model for global symmetry detection.	ICCV	visu
2295	ICCV	Surface discontinuities in range images.	Tomás Pajdla,Václav Hlavác	1993	Surface discontinuities in range images.	ICCV	visu
2296	ICCV	A system for automatic vectorization and interpretation of map-drawings.	Sergey Ablameyko,Vladimir Bereishik,Oleg Frantskevich,Maria Homenko,E. Melnik,Oleg Okun,Nadeshda Paramonova	1993	A system for automatic vectorization and interpretation of map-drawings.	ICCV	visu
2297	ICCV	Learning object recognition models from images.	Arthur R. Pope,David G. Lowe	1993	Learning object recognition models from images.	ICCV	visu
2298	ICCV	Computation of ego-motion and structure from visual and inertial sensors using the vertical cue.	Thierry Viéville,Emmanuelle Clergue,P. E. Dos Santos Facao	1993	Computation of ego-motion and structure from visual and inertial sensors using the vertical cue.	ICCV	visu
2299	ICCV	Projective depth: A geometric invariant for 3D reconstruction from two perspective/orthographic views and for visual recognition.	Amnon Shashua	1993	Projective depth: A geometric invariant for 3D reconstruction from two perspective/orthographic views and for visual recognition.	ICCV	visu
2300	ICCV	Exploiting the generic view assumption to estimate scene parameters.	William T. Freeman	1993	Exploiting the generic view assumption to estimate scene parameters.	ICCV	visu
2301	ICCV	Projectively invariant decomposition and recognition of planar shapes.	Stefan Carlsson	1993	Projectively invariant decomposition and recognition of planar shapes.	ICCV	visu
2302	ICCV	Egomotion analysis based on the Frenet-Serret motion model.	Zoran Duric,Azriel Rosenfeld,Larry S. Davis	1993	Egomotion analysis based on the Frenet-Serret motion model.	ICCV	visu
2303	ICCV	Localization using combinations of model views.	Ronen Basri,Ehud Rivlin	1993	Localization using combinations of model views.	ICCV	visu
2304	ICCV	Reactions to peripheral image motion using a head/eye platform.	David W. Murray,Philip F. McLauchlan,Ian D. Reid,Paul M. Sharkey	1993	Reactions to peripheral image motion using a head/eye platform.	ICCV	visu
2305	ICCV	Relative 3D positioning and 3D convex hull computation from a weakly calibrated stereo pair.	Luc Robert,Olivier D. Faugeras	1993	Relative 3D positioning and 3D convex hull computation from a weakly calibrated stereo pair.	ICCV	visu
2306	ICCV	Looking for trouble: Using causal semantics to direct focus of attention.	Lawrence Birnbaum,Matthew Brand,Paul R. Cooper	1993	Looking for trouble: Using causal semantics to direct focus of attention.	ICCV	visu
2307	ICCV	Ridge-detection for the perceptual organization without edges.	J. Brian Subirana-Vilanova,Kah Kay Sung	1993	Ridge-detection for the perceptual organization without edges.	ICCV	visu
2308	ICCV	Affine-invariant contour tracking with automatic control of spatiotemporal scale.	Andrew Blake,Rupert W. Curwen,Andrew Zisserman	1993	Affine-invariant contour tracking with automatic control of spatiotemporal scale.	ICCV	visu
2309	ICCV	Vision-based construction of CAD models from range images.	Xin Chen,Francis Schmitt	1993	Vision-based construction of CAD models from range images.	ICCV	visu
2310	ICCV	Robust line-based pose enumeration from a single image.	Takeshi Shakunaga	1993	Robust line-based pose enumeration from a single image.	ICCV	visu
2311	ICCV	Interpretation of natural scenes using multi-parameter default models and qualitative constraints.	Michael Hild,Yoshiaki Shirai	1993	Interpretation of natural scenes using multi-parameter default models and qualitative constraints.	ICCV	visu
2312	ICCV	Shape from texture from a multi-scale perspective.	Tony Lindeberg,Jonas Gårding	1993	Shape from texture from a multi-scale perspective.	ICCV	visu
2313	ICCV	Recognizing mice, vegetables and hand printed characters based on implicit polynomials, invariants and Bayesian methods.	Jayashree Subrahmonia,Daniel Keren,David B. Cooper	1993	Recognizing mice, vegetables and hand printed characters based on implicit polynomials, invariants and Bayesian methods.	ICCV	visu
2314	ICCV	Incremental image sequence enhancement with implicit motion compensation.	A. Singh	1993	Incremental image sequence enhancement with implicit motion compensation.	ICCV	visu
2315	ICCV	Robust computation of optical flow in a multi-scale differential framework.	Joseph Weber,Jitendra Malik	1993	Robust computation of optical flow in a multi-scale differential framework.	ICCV	visu
2316	ICCV	Distance accumulation and planar curvature.	Joon Hee Han,Timothy Poston	1993	Distance accumulation and planar curvature.	ICCV	visu
2317	ICCV	Understanding noise: The critical role of motion error in scene reconstruction.	J. Inigo Thomas,Allen R. Hanson,John Oliensis	1993	Understanding noise: The critical role of motion error in scene reconstruction.	ICCV	visu
2318	ICCV	Building and using flexible models incorporating grey-level information.	Timothy F. Cootes,Christopher J. Taylor,Andreas Lanitis,David H. Cooper,Jim Graham	1993	Building and using flexible models incorporating grey-level information.	ICCV	visu
2319	ICCV	Using hyperquadrics for shape recovery from range data.	Song Han,Dmitry B. Goldgof,Kevin W. Bowyer	1993	Using hyperquadrics for shape recovery from range data.	ICCV	visu
2320	ICCV	Recognition of object classes from range data.	Ian D. Reid,J. Michael Brady	1993	Recognition of object classes from range data.	ICCV	visu
2321	ICCV	Silhouette-based object recognition through curvature scale space.	Farzin Mokhtarian,Hiroshi Murase	1993	Silhouette-based object recognition through curvature scale space.	ICCV	visu
2322	ICCV	An all-transputer visual autobahn-autopilot/copilot.	Ernst D. Dickmanns,Reinhold Behringer,C. Brudigam,Dirk Dickmanns,Frank Thomanek,Volker van Holt	1993	An all-transputer visual autobahn-autopilot/copilot.	ICCV	visu
2323	ICCV	A global algorithm for shape from shading.	John Oliensis,Paul Dupuis	1993	A global algorithm for shape from shading.	ICCV	visu
2324	ICCV	Fast segmentation, tracking, and analysis of deformable objects.	Chahab Nastar,Nicholas Ayache	1993	Fast segmentation, tracking, and analysis of deformable objects.	ICCV	visu
2325	ICCV	Quantitative analysis of the viewpoint consistency constraint in model-based vision.	L. Du,Geoffrey D. Sullivan,Keith D. Baker	1993	Quantitative analysis of the viewpoint consistency constraint in model-based vision.	ICCV	visu
2326	ICCV	Active and intelligent sensing of road obstacles: Application to the European Eureka-PROMETHEUS project.	Ming Xie,Laurent Trassoudaine,Joseph Alizon,Monique Thonnat,Jean Gallice	1993	Active and intelligent sensing of road obstacles: Application to the European Eureka-PROMETHEUS project.	ICCV	visu
2327	ICCV	Linear and incremental acquisition of invariant shape models from image sequences.	Daphna Weinshall,Carlo Tomasi	1993	Linear and incremental acquisition of invariant shape models from image sequences.	ICCV	visu
2328	ICCV	Discrete models for energy-minimizing segmentation.	Andrew Ackah-Miezan,André Gagalowicz	1993	Discrete models for energy-minimizing segmentation.	ICCV	visu
2329	ICCV	A complete two-plane camera calibration method and experimental comparisons.	Guo-Qing Wei,Song De Ma	1993	A complete two-plane camera calibration method and experimental comparisons.	ICCV	visu
2330	ICCV	A design for a visual motion transducer.	Andrew Blake,Gabriel Hamid,Lionel Tarassenko	1993	A design for a visual motion transducer.	ICCV	visu
2331	ICCV	Diagonal transforms suffice for color constancy.	Graham D. Finlayson,Mark S. Drew,Brian V. Funt	1993	Diagonal transforms suffice for color constancy.	ICCV	visu
2332	ICCV	Tracking foveated corner clusters using affine structure.	Ian D. Reid,David W. Murray	1993	Tracking foveated corner clusters using affine structure.	ICCV	visu
2333	ICCV	Optical flow from 1D correlation: Application to a simple time-to-crash detector.	Nicola Ancona,Tomaso Poggio	1993	Optical flow from 1D correlation: Application to a simple time-to-crash detector.	ICCV	visu
2334	ICCV	Fourth International Conference on Computer Vision, ICCV 1993, Berlin, Germany, 11-14 May, 1993, Proceedings		1993	Fourth International Conference on Computer Vision, ICCV 1993, Berlin, Germany, 11-14 May, 1993, Proceedings	ICCV	visu
2335	ICCV	A robust active contour model with insensitive parameters.	Gang Xu,Eigo Segawa,Saburo Tsuji	1993	A robust active contour model with insensitive parameters.	ICCV	visu
2336	ICCV	An extension of Marr's signature based edge classification and other methods determining diffuseness and height of edges, and bar edge width.	Wei Zhang,Fredrik Bergholm	1993	An extension of Marr's signature based edge classification and other methods determining diffuseness and height of edges, and bar edge width.	ICCV	visu
2337	ICCV	Eliciting qualitative structure from image curve deformations.	Andrew Zisserman,Andrew Blake,Charlie Rothwell,Luc J. Van Gool,Marc Van Diest	1993	Eliciting qualitative structure from image curve deformations.	ICCV	visu
2338	ICCV	Contextual feature similarities for model-based object recognition.	Detlev Noll,Michael Schwarzinger,Werner von Seelen	1993	Contextual feature similarities for model-based object recognition.	ICCV	visu
2339	ICCV	A generalized brightness change model for computing optical flow.	Shahriar Negahdaripour,Chih-Ho Yu	1993	A generalized brightness change model for computing optical flow.	ICCV	visu
2340	ICCV	Dynamic calibration of an active stereo head.	James L. Crowley,Philippe Bobet,Cordelia Schmid	1993	Dynamic calibration of an active stereo head.	ICCV	visu
2341	ICCV	Accurate line parameters from an optimising Hough Transform for vanishing point detection.	Phil L. Palmer,Maria Petrou,Josef Kittler	1993	Accurate line parameters from an optimising Hough Transform for vanishing point detection.	ICCV	visu
2342	ICCV	A spherical representation for the recognition of curved objects.	Herve Delingette,Martial Hebert,Katsushi Ikeuchi	1993	A spherical representation for the recognition of curved objects.	ICCV	visu
2343	ICCV	Fast and robust 3D recognition by alignment.	Tao Daniel Alter,W. Eric L. Grimson	1993	Fast and robust 3D recognition by alignment.	ICCV	visu
2344	IEEE Visualization	A Climate Simulation Case Study.	P. C. Chen	1993	A Climate Simulation Case Study.	IEEE Visualizat	visu
2345	IEEE Visualization	The Quantum Coulomb Three Body Problem - Visualization of Simulation Results and Numerical Methods.	D. I. Abramov,V. V. Gusev,Stanislav V. Klimenko,L. I. Ponomarev,W. Krueger,W. Renz	1993	Some years ago it was established that the muon catalysed fusion phenomenon could be used for the production of energy. This fact has been causing a rebirth of interest in the universal methods of solving the Quantum Coulomb Three-Body Problem. The Adiabatic Hyperspherical (AHS) approach considered in this joint project has definite advantages in comparison with other methods.The case study proposed will focus on the study of the structure and behavior of the wave function of bound states of quantum three-body system as well as of the basis functions of the AHS approach. Adapted scientific visualization tools such as surface rendering, volume raytracing and texturing will be used. Visualization allows to discover interesting features in the behavior of the basis functions and to analyze the convergence of the AHS-expansion for the wave functions.	IEEE Visualizat	visu
2346	IEEE Visualization	Visualization of Acoustic Lens Data.	A. J. Bladek	1993	3-dimensional data visualization from any input source involves the study and understanding of several steps. These steps include data acquisition. Signal processing, image processing and image generation. Using a forward-looking high frequency sonar system (which focuses sound much like the eye focuses light), standard and non-standard data processing algorithms, and industry standard visualization algorithms, this project produced accurate 3-dimensional representations of several underwater objects.	IEEE Visualizat	visu
2347	IEEE Visualization	3D Simulation of Delivery.	Jean-Daniel Boissonnat,Bernhard Geiger	1993	3D Simulation of Delivery.	IEEE Visualizat	visu
2348	IEEE Visualization	Orientation Maps: Techniques for Visualizing Rotations.	Bowen Alpern,Larry Carter,M. Grayson,C. Pelkie	1993	Orientation Maps: Techniques for Visualizing Rotations.	IEEE Visualizat	visu
2349	IEEE Visualization	GRASPARC: A Problem Solving Environment Integrating Computation and Visualization.	Ken Brodlie,A. Poon,Helen Wright,L. Brankin,G. Banecki,A. Gay	1993	Visualization has proved an effective tool in the understanding of large data sets in computational science and engineering. There is growing interest today in the development of problem solving environments which integrate both visualization and the computational process which generates the data. The GRASPARC project has looked at some of the issues involved in creating such an environment. An architecture is proposed in which tools for computation and visualization can be embedded in a framework which assists in the management of the problem solving process. This framework has an integral data management facility which allows an audit trail of the experiments to be recorded. This design therefore allows not only steering but also backtracking and more complicated problem solving strategies.A number of demonstrator case studies have been implemented.	IEEE Visualizat	visu
2350	IEEE Visualization	Optimal Filter Design for Volume Reconstruction and Visualization.	Ingrid Carlbom	1993	Digital filtering is a crucial operation in volume reconstruction and visualization. Lowpass filters are needed for subsampling and minification. Interpolation filters are needed for registration and magnification, and to compensate for geometric distortions introduced by scanners. Interpolation filters are also needed in volume rendering for ray-casting and slicing. In this paper, we describe a method for digital filter design of interpolation filters based on weighted Chebyshev minimization. The accuracy of the resulting filters are compared with some commonly used filters defined by piecewise cubic polynomials.A significant finding of this paper is that although piecewise cubic interpolation have some computational advantages and may yield visually satisfactory results for some data, other data results in artifacts such as blurring. Furthermore, piecewise cubic filters are inferior for operations such as registration. Better results are obtained by the filters derived in this papers at only small increases in computation.	IEEE Visualizat	visu
2351	IEEE Visualization	Visualization and Modeling of Geophysical Data.	G. Celniker,I. Chakravarty,J. Moorman	1993	We present the visualization and modeling techniques used in a case study to build feature-based computational models from geophysical data. Visualization was used to inspect the quality of the interpretation of the geophysical data. We describe the geophysical data graphical representation used to support rapid rendering and to enhance the perception of differences between the interpretation of the data and the data itself. In addition, we present the modeling techniques used to convert the geophysical data into a feature-based computational model suitable for use by a numerical simulation package.	IEEE Visualizat	visu
2352	IEEE Visualization	Data Shaders.	Brian Corrie,Paul Mackerras	1993	The process of visualizing a scientific data set requires an extensive knowledge of the domain in which the data set is created. Because an in-depth knowledge of all scientific domains is not available to the creator of visualization software, a flexible and extensible visualization system is essential in providing a productive tool to the scientist.This paper presents a shading language, based on the RenderMan shading language, that extends the shading model used to render volume data sets. Data shaders, written in this shading language, give the users of a volume rendering system a means of specifying how a volume data set is to be rendered. This flexibility is useful both as a visualization tool in the scientific community and as a research tool in the visualization community.	IEEE Visualizat	visu
2353	IEEE Visualization	Texture Splats for 3D Scalar and Field Visualization.	Roger Crawfis,Nelson L. Max	1993	Texture Splats for 3D Scalar and Field Visualization.	IEEE Visualizat	visu
2354	IEEE Visualization	Interactive Shading for Surface and Volume Visualization on Graphics Workstations.	Peter A. Fletcher,Philip K. Robertson	1993	Shading is an effective exploratory visualization tool widely used in scientific visualization. Interactive, or close to interactive, shading of images offers significant benefit, but is generally too computationally expensive for graphics workstations. A novel method for providing interactive diffuse and specular shading capability on low-cost graphics workstations is described. Application to digital elevation models, iso-surfaces in volumetric images, and colour-coded aspect maps are illustrated and an analysis of artifacts, and of ways of minimising artifacts, is given.	IEEE Visualizat	visu
2355	IEEE Visualization	The Vision Camera: An Interactive Tool for Volume Data Exploration and Navigation.	Hans-Heino Ehricke,G. Daiber,Wolfgang Straßer	1993	In this paper we focus on one of the key problems of Scientific Visualization, the object recognition dilemma. The necessity to pre-interpret application data in order to classify object surface voxels prior to rendering has prevented many visualization methods from becoming practical. We propose the concept of vision by visualization which integrates Computer Vision methods into the visualization process. Based on this, we present the vision camera, a new tool allowing for interactive object recognition during volume data walkthroughs. This camera model is characterized by a flexible front-plane which, under the control of user-specified parameters and image features elastically matches to object surfaces, while shifted through a data volume. Thus, objects are interactively carved out and can be visualized by standard volume visualization methods. Implementation and application of the model are described. Our results suggest that by the integration of human and machine vision new perspectives for data exploration are opened up.	IEEE Visualizat	visu
2356	IEEE Visualization	Non Conventional Methods for the Visualization of Events from High Energy Physics.	H. Drevermann,D. Kuhm,B. Nilsson	1993	Visualization of events in high energy physics is an important tool to check hard- and software and to generate pictures for presentation purposes. The radial pattern of all events suggests the use of predefined projections, especially p1/Z and Y/X. The representation can be improved by a fish-eye transformation and by angular projections, which produce straight track patterns and allow extensive magnifications. Three dimensional data of radial structure are best displayed in the 3D V-Plot, which has optimal track separation and presents all relevant information in a clear way.	IEEE Visualizat	visu
2357	IEEE Visualization	Navigating Large Networks with Hierarchies.	Stephen G. Eick,Graham J. Wills	1993	This paper is aimed at the exploratory visualization of networks where there is a strength or weight associated with each link, and makes use of any hierarchy present on the nodes to aid the investigation of large networks. It describes a method of placing nodes on the plane that gives meaning to their relative positions. The paper discusses how linking and interaction principles aid the user in the exploration. Two examples are given; one of electronic mail communication over eight months within a department, another concerned with changes to a large section of a computer program.	IEEE Visualizat	visu
2358	IEEE Visualization	Virtual Input Devices for 3D Systems.	Taosong He,Arie E. Kaufman	1993	The device unified interface is a generalized and easily expandable protocol for the communication between applications and input devices. The key idea is to unify various device data into the parameters of a so-called virtual input device. The device information-base, which includes device dependent information, is also incorporated into the virtual input device. Using the device unified interface, system builders are able to design their applications independent of the input devices as well as utilize the capabilities of several devices in the same application.	IEEE Visualizat	visu
2359	IEEE Visualization	Rapid Exploration of Curvilinear Grids Using Direct Volume Rendering.	Allen Van Gelder,Jane Wilhelms	1993	Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described.	IEEE Visualizat	visu
2360	IEEE Visualization	Interactive Visualization Methods for Four Dimensions.	Andrew J. Hanson,Robert A. Cross	1993	Making accurate computer graphics representations of surfaces and volumes (2-manifolds and 3-manifolds) embedded in four-dimensional space typically involves complex and time-consuming computations. In order to make simulated worlds that help develop human intuition about the fourth dimension, we need techniques that permit real-time, interactive manipulation of the most sophisticated depictions available. We propose the following new methods that bring us significantly closer to this goal: an approach to high-speed 4D illuminated surface rendering incorporating 4D shading and occlusion coding; a procedure for rapidly generating 2D screen images of tessellated 3-manifolds illuminated by 4D light. These methods are orders of magnitude faster than previous approaches, enabling the real-time manipulation of high-resolution 4D images on commercial graphics hardware.	IEEE Visualizat	visu
2361	IEEE Visualization	Visualization of Turbulent Flow with Particles.	Andrea J. S. Hin,Frits H. Post	1993	In this paper a new method for visualization of three-dimensional turbulent flow using particle motion animation is presented. The method is based on Reynolds decomposition of a turbulent flow field into a convective and a turbulent motion. At each step of particle path generation a stochastic perturbation is added, resulting in random-walk motions of particles. A physical relation is established between the perturbations and the eddy-diffusivity, which is calculated in a turbulent flow simulation. The flow data used is a mean velocity field, and an eddy-diffusivity field. The erratic particle motions are more than just a visual effect, but represent a real physical phenomenon. An implementation of the method is described, and an example of a turbulent channel flow is given, which clearly shows the random particle motions in their context of general fluid motion patterns.	IEEE Visualizat	visu
2362	IEEE Visualization	Geometric Optimization.	P. A. Hinker,Charles D. Hansen	1993	An algorithm is presented which describes an application independent method for reducing the number of polygonal primitives required to faithfully represent an object. Reducing polygon count without a corresponding reduction in object detail is important for: achieving interactive frame rates in scientific visualization, reducing mass storage requirements, and facilitating the transmission of large, multi-timestep geometric data sets. This paper shows how coplanar and nearly coplanar polygons can be merged into larger complex polygons and re-triangulated into fewer simple polygons than originally required. The notable contributions of this paper are: 1) a method for quickly grouping polygons into nearly coplanar sets, 2) a fast approach for merging coplanar polygon sets and, 3) a simple, robust triangulation method for polygons created by 1 and 2. The central idea of the algorithm is the notion of treating polygonal data as a collection of segments and removing redundant segments to quickly from polygon hulls which represent the merged coplanar sets.	IEEE Visualizat	visu
2363	IEEE Visualization	Visual Feedback in Querying Large Databases.	Daniel A. Keim,Hans-Peter Kriegel,Thomas Seidl	1993	In this paper, we describe a database query system that provides visual relevance feedback in querying large databases. The goal of our system is to support the query specification process by using each pixel of the display to represent one data item of the database. By arranging and coloring the pixels according to their relevance for the query, the user gets a visual impression of the resulting data set. Using sliders for each condition of the query, the user may change the query dynamically and receives immediate feedback by the visual representation of the resulting data set. By using multiple windows for different parts of a complex query, the user gets visual feedback for each part of the query and, therefore, will easier understand the overall result. The system may be used to query any database that contains tens of thousands to millions of data items, but it is especially helpful to explore large data sets with an unknown distribution of values and to find the interesting hot spots in huge amounts of data. The direct feedback allows to visually display the influence of incremental query refinements and, therefore, allows a better, easier and faster query specification.	IEEE Visualizat	visu
2364	IEEE Visualization	Cloud Tracing in Conection-Diffusion Systems.	K. L. Ma,P. J. Smith	1993	This paper describes a highly interactive method for computer visualization of simultaneous three-dimensional vector and scalar flow fields in convection-diffusion systems. This method allows a computational fluid dynamics user to visualize the basic physical process of dispersion and mixing rather than just the vector and scalar values computed by the simulation. It is based on transforming the vector field from a traditionally Eulerian reference frame into a Lagrangian reference frame. Fluid elements are traced through the vector field for the mean path as well as the statistical dispersion of the fluid elements about the mean position by using added scalar information about the root mean square value of the vector field and its Lagrangian time scale. In this way, clouds of fluid elements are traced not just mean paths. We have used this method to visualize the simulation of an industrial incinerator to help identify mechanisms for poor mixing.	IEEE Visualizat	visu
2365	IEEE Visualization	Visualization of Time-Dependent Flow Fields.	David A. Lane	1993	Presently, there are very few visualization systems available for time-dependent flow fields. Although existing visualization systems for instantaneous flow fields may be used to view time-dependent flow fields at discrete points in time, the time variable is usually not considered in the visualization technique. We present a simple and effective approach for visualizing timedependent flow fields using streaklines. A system was developed to demonstrate this approach. The system can process many time frames of flow fields without requiring that all the data be in memory simultaneously, and it also handles flow fields with moving grids. We have used the system to visualize streaklines from several large 3D time-dependent flow fields with moving grids. The system was able to provide useful insights to the physical phenomena in the flow fields.	IEEE Visualizat	visu
2366	IEEE Visualization	Towards Interactive Steering, Visualization and Animation of Unsteady Finite Element Simulations.	G. David Kerlick,E. Kirby	1993	Progress towards interactive steering of the time-accurate, unsteady finite-element simulation program DYNA3D is reported. Rudimentary steering has been demonstrated in a distributed computational environment encompassing a supercomputer, multiple graphics workstations, and a single frame animation recorder. The coroutine facility of AVS (Application Visualization System from AVS Inc.) and software produced in-house has been coordinated to prove the concept. This work also applies to other large batch-oriented FORTRAN simulations (dusty decks) presently in production use.	IEEE Visualizat	visu
2367	IEEE Visualization	An Environment for Telecollaborative Data Exploration.	Gudrun Klinker	1993	This paper presents an environment for telecollaborative data exploration. It provides the following capabilities essential to data exploration: (1) Users can probe the data, defining regions of interest with arbitrary shapes. (2) The selected data can be transformed and displayed in many different ways. (3) Linked cursors can be established between several windows showing data sets with arbitrary relationships. (4) Data can be displayed on any screen across a computer network, allowing for telecollaboration arrangements with linked cursors around the world. (5) Our system is user-extensible, allowing programmers to change any component of it while keeping the remaining functionality. We demonstrate how the system can be used in several applications, such as biomedical imaging, robotics, and wood classification.	IEEE Visualizat	visu
2368	IEEE Visualization	A Probe for Local Flow Field Visualization.	Wim C. de Leeuw,Jarke J. van Wijk	1993	A probe for the interactive visualization of flow fields is presented. The probe can be used to visualize many characteristics of the flow in detail for a small region in the data set. The velocity and the local change of velocity (the velocity gradient tensor) are visualized by a set of geometric primitives. To this end, the velocity gradient tensor is transformed to a local coordinate frame, and decomposed into components parallel with and perpendicular to the flow. These components are visualized as geometric objects with an intuitively meaningful interpretation. An implementation is presented which shows that this probe is a useful tool for flow visualization.	IEEE Visualizat	visu
2369	IEEE Visualization	Bridging the Gap Between Visualization and Data Management: A Simple Visualization Management System.	Peter Kochevar,Zahid Ahmed,J. Shade,Colin Sharp	1993	A prototype visualization management system is described which merges the capabilities of a database management system with any number of existing visualization packages such as AVS or IDL. The prototype uses the Postgres database management system to store and access Earth science data through a simple graphical browser. Data located in the database is visualized by automatically invoking a desired visualization package and downloading an appropriate script or program. The central idea underlying the system is that information on how to visualize a data set is stored in the database with the data set itself.	IEEE Visualizat	visu
2370	IEEE Visualization	Enhancing Reality in the Operating Room.	William E. Lorensen,Harvey E. Cline,C. Nafis,D. Altobelli,L. Gleason	1993	Enhancing Reality in the Operating Room.	IEEE Visualizat	visu
2371	IEEE Visualization	Geometric Clipping Using Boolean Textures.	W. E. Lorenson	1993	Texture mapping is normally used to convey geometric detail without adding geometric complexity. This paper introduces boolean textures, a texture mapping technique that uses implicit functions to generate texture maps and texture coordinates. These boolean textures perform clipping during a renderer's scan conversion step. Any implicit function is a candidate boolean texture clipper. The paper describes how to use quadrics as clippers. Applications from engineering and medicine illustrate the effectiveness of texture as a clipping tool.	IEEE Visualizat	visu
2372	IEEE Visualization	DIVIDE: Distributed Visual Display of the Execution of Asynchronous, Distributed Algorithms on Loosely-Coupled Parallel Processors.	Tom M. Morrow,Sumit Ghosh	1993	The issue of monitoring the execution of asynchronous, distributed algorithms on loosely-coupled parallel processor systems, is important for the purposes of (i) detecting inconsistencies and flaws in the algorithm, (ii) obtaining important performance parameters for the algorithm, and (iii) developing a conceptual understanding of the algorithm's behavior, for given input stimulus, through visualization. For a particular class of asynchronous distributed algorithms [1,5] that may be characterized by independent and concurrent entities that execute asynchronously on multiple processors and interact with one another through explicit messages, the following reasoning applies. Information about the flow of messages and the activity of the processors may contribute significantly towards the conceptual understanding of the algorithm's behavior and the functional correctness of the implementation. The computation and subsequent display of important parameters, based upon the execution of the algorithm, is an important objective of DIVIDE. For instance, the mean and standard deviation values for the propagation delay of ATM cells between any two given Broadband-ISDN (BISDN) nodes in a simulation of BISDN network under stochastic input stimulus[36], as a function of time, are important clues to the degree of congestion in the Broadband-ISDN network. Although the execution of the algorithm typically generates high resolution data, often, a coarse-level visual representation of the data may be useful in facilitating the conceptual understanding of the behavior of the algorithm. DIVIDE permits a user to specify a resolution less than that of the data from the execution of the algorithm, which is then utilized to coalesce the data appropriately. Given that this process requires significant computational power, for efficiency, DIVIDE distributes the overall task of visual display into a number of user specified workstations that are configured as a loosely-coupled parallel processor. DIVIDE has been implemented on a heterogeneous network of SUN sparc 1+, sparc 2, and 3/60 workstations and performance measurements indicate significant improvement over that of a uniprocessor-based visual display.	IEEE Visualizat	visu
2373	IEEE Visualization	Flow Volumes for Interactive Vector Field Visualization.	Nelson L. Max,Barry G. Becker,Roger Crawfis	1993	Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, compositing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing.	IEEE Visualizat	visu
2374	IEEE Visualization	Visualizing Results of Transient Flow Simulations.	H. F. Mayer,B. Tabatabai	1993	Visualizing Results of Transient Flow Simulations.	IEEE Visualizat	visu
2375	IEEE Visualization	Feature Extraction for Oceanographic Data Using a 3D Edge Operator.	R. J. Moorehead,Z. Zhu	1993	Feature Extraction for Oceanographic Data Using a 3D Edge Operator.	IEEE Visualizat	visu
2376	IEEE Visualization	Fast Volume Rendering of Compressed Data.	Paul Ning,Lambertus Hesselink	1993	Volume rendering has been proposed as a useful tool for extracting information from large datasets, where non-visual analysis alone may not be feasible. The scale of these applications implies that data management is an important issue that needs to be addressed. Most volume rendering algorithms, however, process data in raw, uncompressed form. In previous work, we introduced a compressed volume format that may be volume rendered directly with minimal impact on rendering time. In this paper, we extend these ideas to a new volume format that not only reduces storage space and transmission time, but is designed for fast volume rendering as well. The volume dataset is represented as indices into a small codebook of representative blocks. With this data structure, volume shading calculations need only be performed on the codebook and image generation is accelerated by reusing precomputed block projections.	IEEE Visualizat	visu
2377	IEEE Visualization	Unsteady Phenomena, Hypersonic Flows and Co-Operative Flow Visualization.	Hans-Georg Pagendarm	1993	Unsteady Phenomena, Hypersonic Flows and Co-Operative Flow Visualization.	IEEE Visualizat	visu
2378	IEEE Visualization	The Virtual Restoration of the Visir Tomb.	Patrizia Palamidese,M. Betro,G. Muccioli	1993	The Virtual Restoration of the Visir Tomb.	IEEE Visualizat	visu
2379	IEEE Visualization	Spray Rendering: Visualization Using Smart Particles.	Alex Pang,Kyle Smith	1993	We propose a new framework for doing scientific visualization. The basis for this framework is a combination of particle systems and behavioral animation. Here, particles are not only affected by the field that they are in, but can also exhibit different programmed behaviors. An intuitive delivery system, based on virtual cans of spray paint, is also described to introduce the smart particles into the data set. Hence the name spray rendering. Using this metaphor, different types of spray paint are used to highlight different features in the data set. Spray rendering offers several advantages over existing methods: (1) it generalizes the current techniques of surface, volume and flow visualization under one coherent framework; (2) it works with regular and irregular grids as well as sparse and dense data sets; (3) it allows selective progressive refinement; (4) it is modular, extensible and provides scientists with the flexibility for exploring relationships in their data sets in natural and artistic ways.	IEEE Visualizat	visu
2380	IEEE Visualization	Dichromatic Color Representations for Complex Display Systems.	M. S. Peercy,Lambertus Hesselink	1993	New display technologies have begun to provide more innovative and potentially powerful methods to present information to a viewer. However, many of these techniques struggle to deliver accurate full color. In this paper, we address this difficulty by employing the dichromatic theory of color reflection, which implies that many objects can be rendered accurately using only two primaries. Complex display systems with two primaries can be produced with significantly less work than is required for the traditional three primaries. We discuss methods for selecting objects that can be rendered accurately on two-color displays, and we present our experiments with a two-color display using monochromatic primaries.	IEEE Visualizat	visu
2381	IEEE Visualization	MRIVIEW: An Interactive Computational Tool for Investigation of Brain Structure and Function.	D. Ranken,J. George	1993	MRIVIEW is a software system that uses image processing and visualization to provide neuroscience researchers with an integrated environment for combining functional and anatomical information. Key features of the software include semi-automated segmentation of volumetric head data and an interactive coordinate reconciliation method which utilizes surface visualization.The current system is a precursor to a computational brain atlas. We describe features this atlas will incorporate, including methods under development for visualizing brain functional data obtained from several different research modalities.	IEEE Visualizat	visu
2382	IEEE Visualization	Towards a Texture Naming System: Identifying Relevant Dimensions in Texture.	A. Ravishankar Rao,Gerald L. Lohse	1993	Towards a Texture Naming System: Identifying Relevant Dimensions in Texture.	IEEE Visualizat	visu
2383	IEEE Visualization	An Architecute for Rule-Based Visualization.	Bernice E. Rogowitz,Lloyd Treinish	1993	In Rogowitz and Treinish [20] we introduced an architecture for incorporating perceptual rules into the visualization process. In this architecture, higher-level descriptors of the data, metadata, flow to perceptual rules, which constrain visualization operations. In this paper, we develop a deeper analysis of the rules, the prerequisite metadata, and the system for enabling their operation.	IEEE Visualizat	visu
2384	IEEE Visualization	Fine-Grain Visualization Algorithms in Dataflow Environments.	D. Song,Eric J. Golin	1993	Most of the current dataflow visualization systems are based on coarse-grain dataflow computing models. In this paper we propose a fine-grain dataflow model that takes advantage of data locality properties of many visualization algorithms. A fine-grain module works on small chunks of data one at a time by keeping a dynamically adjusted moving window on the input data stream. It is more memory efficient and has the potential of handling very large data sets without taking up all the memory resources. Two popular visualization algorithms, an iso-surface extraction algorithm [1] and a volume rendering algorithm [2], are implemented using the fine-grain model. The performance measurements showed faster speed, reduced memory usage, and improved CPU utilization over a typical coarse-grain system.	IEEE Visualizat	visu
2385	IEEE Visualization	InfoCrystal: A Visual Tool for Information Retrieval.	Anselm Spoerri	1993	This paper introduces a novel representation, called the Info Crystal&trade;, that can be used as a visualization tool as well as a visual query language to help users search for information. The InfoCrystal visualizes all the possible relationships among N concepts. Users can assign relevance weights to the concepts and use thresholding to select relationships of interest. The InfoCrystal allows users to specify Boolean as well as vectorspace queries graphically. Arbitrarily complex queries can be created by using the InfoCrystals as building blocks and organizing them in a hierarchical structure. The InfoCrystal enables users to explore and filter information in a flexible, dynamic and interactive way.	IEEE Visualizat	visu
2386	IEEE Visualization	Applying Observations of Work Activity in Designing Prototype Data Analysis Tools.	R. R. Springmeyer	1993	Designers, implementers, and marketers of data analysis tools typically have different perspectives than end users. Consequently, data analysts often find themselves using tools focused on graphics and programming concepts rather than concepts which reflect their own domain and the context of their work. Some user studies focus on usability tests late in development; others observe work activity, but fail to show how to apply that knowledge in design. This paper describes a methodology for applying observations of data analysis work activity in prototype tool design. The approach can be used both in designing improved data analysis tools, and customizing visualization environments to specific applications. We present an example of user-centered design for a prototype tool to cull large data sets. We revisit the typical graphical approach of animating a large data set from the point of view of an analyst who is culling data. Field evaluations using the prototype tool not only revealed valuable usability information, but initiated in-depth discussions about users' work, tools, technology, and requirements.	IEEE Visualizat	visu
2387	IEEE Visualization	Tioga: A Database-Oriented Visualization Tool.	Michael Stonebraker,Jolly Chen,Nobuko Nathan,Caroline Paxson,Alan Su,Jiang Wu	1993	In this paper we present a new architecture for visualization systems that is based on Data Base Management System (DBMS) technology. By building on the mechanisms present in a next-generation DBMS, rather than merely on the capabilities of a standard file manager, we show that a simpler and more powerful visualization system can be constructed. We retain the popular boxes and arrows programming notation for constructing visualization programs, but add a flight simulator model of movement to navigate the output of such programs. In addition, we provide a means to specify a hierarchy of abstracts of data of different types and resolutions, so that a zoom capability can be supported. The underlying DBMS support for this system, Tioga, is briefly described, as well as the current state of the implementation.	IEEE Visualizat	visu
2388	IEEE Visualization	Developing Modular Applications Builders to Exploit MIMD Parallel Resources.	C. Thornborrow,A. J. S. Wilson,Chris Faigle	1993	Modular application builders (MABs), such as AVS and Iris Explorer[6, 7] are increasingly being used in the visualisation community. Such systems can already place compute intensive modules on supercomputers in order to utilise their power. This paper details two major projects at EPCC which attempted to fully integrate the MAB concept with a distributed memory MIMD (DM-MIMD) environment.The work presented was driven by two goals, efficient use of the resource and ease of use by programmer and end user.We present a model of MABs and describe the major problems faced, giving solutions to them through two case studies.	IEEE Visualizat	visu
2389	IEEE Visualization	Visualization of Stratospheric Ozone Depletion and the Polar Vortex.	Lloyd Treinish	1993	Visualization of Stratospheric Ozone Depletion and the Polar Vortex.	IEEE Visualizat	visu
2390	IEEE Visualization	Visualization of Oil Reservoirs Ovew a Large Range of Scales as a Catalyst for Multi-Disciplinary Integration.	S. Tyson,B. Williams	1993	We discuss a system which provides a single, unified model of oil and gas reservoirs that is used across a range of disciplines from geologists to reservoir engineers. It has to store, manipulate and display reservoir phenomena which are observed over several orders of magnitude from 1mm to 10km.We propose that the current capabilities of visualization, over this range of scales, can remove perception barriers that have existed between disciplines and provide clear insights into the problems of modelling reservoirs from geological and engineering perspectives.	IEEE Visualizat	visu
2391	IEEE Visualization	Fast Analytical Computation of Richard's Smooth Molecular Surface.	Amitabh Varshney,Frederick P. Brooks Jr.	1993	Fast Analytical Computation of Richard's Smooth Molecular Surface.	IEEE Visualizat	visu
2392	IEEE Visualization	Fanel: A Relational Analysis and Visualization Package for High Energy Physics.	H. Videau,P. Mora de Freitas	1993	The package described in this paper has been designed for analysing the data collected in the LEP experiment ALEPH. Its main graphical feature is a deep interplay between the description of the objects manipulated and their relationships, and their graphical representation. The easy access to information through navigation between objects and its display makes possible a thorough study of the events produced by the detector. This has proved to be very powerful in numerous occasions for analysing data and testing programs. The package provides as well statistical analysis tools and a graphic editor. It is based on the PHIGS graphics standard. It will develop towards a more elaborate usage of the data structure in particular in the geometrical representations and towards object oriented languages to overcome some heaviness linked to the use of Fortran.	IEEE Visualizat	visu
2393	IEEE Visualization	Performance Visualization of Parallel Programs.	Abdul Waheed,Diane T. Rover	1993	The user of a parallel computer system would like to know the performance of a program in terms of how optimally it uses the system resources. This task is increasingly performed by program performance visualization. The limitations of conventional performance data analysis techniques necessitate better visual analysis methods that are scalable with the problem and system sizes and extensible. They should represent some physical and logical structure of the parallel system and program. The analysis techniques presented here have been motivated by the use of signal and (two- and three-dimensional) image processing techniques being applied in some areas of scientific visualization. Results of applying selected techniques are shown. These techniques and tools have advantages and disadvantages when applied in this area.	IEEE Visualizat	visu
2394	IEEE Visualization	Volume Sampled Voxelization of Geometric Primitives.	Sidney W. Wang,Arie E. Kaufman	1993	We present a 3D antialiasing algorithm for voxelbased geometric models. The technique band-limits the continuous object before sampling it at the desired 3D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete raytraced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation.	IEEE Visualizat	visu
2395	IEEE Visualization	Implicit Stream Surfaces.	Jarke J. van Wijk	1993	Streamlines and stream surfaces are well known techniques for the visualization of fluid flow. For steady velocity fields, a streamline is the trace of a particle, and a stream surface is the trace of a curve. Here a new method is presented for the construction of stream surfaces. The central concept is the representation of a stream surface as an implicit surface f (x)=C. After the initial calculation off a family of stream surfaces can be generated efficiently by varying C. The shapes of the originating curves as defined by the value off at the boundary. Two techniques are presented for the calculation of f: one based on solving the convection equation, the other on backward tracing of the trajectories of grid points. The flow around objects is discussed separately.With this method irregular topologies of the originating curves and of the stream surfaces can be handled easily. Further, it can also be used for other visualization techniques, such as time surfaces and stream volumes. Finally, an effective method for the automatic placement of originating curves is presented.	IEEE Visualizat	visu
2396	IEEE Visualization	HyperSlice - Visualization of Scalar Functions of Many Variables.	Jarke J. van Wijk,Robert van Liere	1993	HyperSlice is a new method for the visualization of scalar functions of many variables. With this method the multi-dimensional function is presented in a simple and easy to understand way in which all dimensions are treated identically. The central concept is the representation of a multi-dimensional function as a matrix of orthogonal two-dimensional slices. These two-dimensional slices lend themselves very well to interaction via direct manipulation, due to a one to one relation between screen space and variable space. Several interaction techniques, for navigation, the location of maxima, and the use of user-defined paths, are presented.	IEEE Visualizat	visu
2397	IEEE Visualization	Computer Visualization of Long Genomic Sequences.	Dachywan Wu,James Roberge,Douglas J. Cork,Bao Gia Nguyen,Thom Grace	1993	Human beings find it difficult to analyze local and global oligonucleotide patterns in the linear primary sequences of a genome. In this paper, we present a family of iterated function systems (IFS) that can be used to generate a set of visual models of a DNA sequence. A new visualization function, the W-curve, that is derived from this IFS family is introduced. Using W-curves, a user can readily compare subsequences within a long genomic sequence --- or between genomic sequences --- and can visually evaluate the effect of local variations (mutations) upon the global genomic information content.	IEEE Visualizat	visu
2398	IEEE Visualization	Accelerating Volume Animation by Space-Leaping.	Roni Yagel,Z. Shi	1993	In this paper we present a method for speeding the process of volume animation. It exploits coherency between consecutive images to shorten the path rays take through the volume. Rays are provided with the information needed to leap over the empty space and commence volume traversal at the vicinity of meaningful data. The algorithm starts by projecting the volume onto a C-buffer (Coordinates-buffer) which stores the object-space coordinates of the first non-empty voxel visible from a pixel. Following a change in the viewing parameters, the C-buffer is transformed accordingly. Next, coordinates that possibly became hidden are discarded. The remaining values serve as an estimate of the point where the new rays should start their volume traversal. This method does not require 3D preprocessing and does not suffer from any image degradation. It can be combined with existing acceleration techniques and can support any ray traversal algorithm and material modeling scheme.	IEEE Visualizat	visu
2399	IEEE Visualization	Proceedings IEEE Visualization '93	Gregory M. Nielson,R. Daniel Bergeron	1993	Proceedings IEEE Visualization '93	IEEE Visualizat	visu
2400	KDD	Knowledge Discovery in Databases: Papers from the 1994 AAAI Workshop, Seattle, Washington, July 1994. Technical Report WS-94-03	Usama M. Fayyad,Ramasamy Uthurusamy	1994	Knowledge Discovery in Databases: Papers from the 1994 AAAI Workshop, Seattle, Washington, July 1994. Technical Report WS-94-03	KDD	datamining
2401	ICDE	Analysis of Common Subexpression Exploitation Models in Multiple-Query Processing.	Jamal R. Alsabbagh,Vijay V. Raghavan	1994	In multiple-query processing, a subexpression that appears in more than one query is called a common subexpression (CSE). A CSE needs to he evaluated once only to produce a temporary result that can then be used to evaluate all the queries containing the CSE. Therefore, the cost of evaluating the CSE is amortized over the queries requiring its evaluation. Two queries, posed simultaneously to the optimizer, may however contain subexpression that are not equivalent but are, nevertheless related by implication (the extension of one is a proper subset of the other) or intersection (the intersection of the two extensions is a proper subset of both extensions). In order to exploit the opportunity for cost amortization offered by the two latter relationships. the optimizer must rewrite the two queries in such a way that a CSE is induced. This paper compares, empirically and analytically, the performance of the various query execution models that are implied by different approaches to query rewriting	ICDE	database
2402	ICDE	QBISM: Extending a DBMS to Support 3D Medical Images.	Manish Arya,William F. Cody,Christos Faloutsos,Joel E. Richardson,Arthur Toya	1994	Describes the design and implementation of QBlSM (Query By Interactive, Spatial Multimedia), a prototype for querying and visualizing 3D spatial data. The first application is in an area in medical research, in particular, Functional Brain Mapping. The system is built on top of the Starburst DBMS extended to handle spatial data types, specifically, scalar fields and arbitrary regions of space within such fields. The authors list the requirements of the application, discuss the logical and physical database design issues, and present timing results from their prototype. They observed that the DBMS' early spatial filtering results in significant performance savings because the system response time is dominated by the amount of data retrieved, transmitted, and rendered	ICDE	database
2403	ICDE	Title, Message from the General Chairs, Message from the Program Chair, Committees, Reviewers, Author Index.		1994	Title, Message from the General Chairs, Message from the Program Chair, Committees, Reviewers, Author Index.	ICDE	database
2404	ICDE	On the Interaction Between ISA and Cardinality Constraints.	Diego Calvanese,Maurizio Lenzerini	1994	ISA and cardinality constraints are among the most interesting types of constraints in data models. ISA constraints are used to establish several forms of containment among classes, and are receiving great attention in moving to object-oriented data models, where classes are organized in hierarchies based on a generalization/specialization principle. Cardinality constraints impose restrictions on the number of links of a certain type involving every instance of a given class, and can be used for representing several forms of dependencies between classes, including functional and existence dependencies. While the formal properties of each type of constraints are now well understood, little is known of their interaction. We present an effective method for reasoning about a set of ISA and cardinality constraints in the context of a simple data model based on the notions of classes and relationships. In particular, the method allows one both to verify the satisfiability of a schema and to check whether a schema implies a given constraint of any of the two kinds. We prove that the method is sound and complete, thus showing that the reasoning problem for ISA and cardinality constraints is decidable	ICDE	database
2405	ICDE	Distributed Heterogeneous Information Systems (Abstract).	William Carpenter,Gholamreza Emami,Emanuel G. Mamatas,Alok C. Nigam	1994	Distributed Heterogeneous Information Systems (Abstract).	ICDE	database
2406	ICDE	Comparing and Synthesizing Integrity Checking Methods for Deductive Databases.	Matilde Celma,Carlos Garcia,Laura Mota-Herranz,Hendrik Decker	1994	Comparing and Synthesizing Integrity Checking Methods for Deductive Databases.	ICDE	database
2407	ICDE	Implementing Calendars and Temporal Rules in Next Generation Databases.	Rakesh Chandra,Arie Segev,Michael Stonebraker	1994	In applications like financial trading, scheduling, manufacturing and process control, time based predicates in queries and rules are very important. There is also a need to define lists of time points or intervals. The authors refer to these lists as calendars. The authors present a system of calendars that allow specification of natural-language time-based expressions, maintenance of valid time in databases, specification of temporal conditions in database queries and rules, and user-defined semantics for date manipulation. A simple list based language is proposed to define, manipulate and query calendars. The design of the parser and an algorithm for efficient evaluation of calendar expressions is also described. The paper also describes the implementation of time-based rules in POSTGRES using the proposed system of calendars	ICDE	database
2408	ICDE	Papyrus: A History-Based VLSI Design Process Management System.	Tzi-cker Chiueh,Randy H. Katz	1994	This paper describes the design and implementation of a VLSI design process management system called Papyrus, which is built upon a history-based design process model that supports both routine and exploratory VLSI design processes. Emphasis of this paper is put on the descriptions of Papyrus's basic data models, design decisions, and implementation details. The operational prototype features a transparent dynamic load balancing scheme to exploit the computation power of networked workstations, an atomicity-guarantee mechanism to preserve the high-level abstraction of the design task construct, an interactive design-history manipulation facility, and a set of storage management techniques to reduce the storage overhead entailed by the single assignment update semantics, which is crucial to the support of the so-called rework mechanism. This system also embodies an innovative history-based meta-data inference scheme that automates many previously user-responsible design data management functions	ICDE	database
2409	ICDE	On the Selection of Optimal Index Configuration in OO Databases.	Sunil Choenni,Elisa Bertino,Henk M. Blanken,Thiel Chang	1994	An operation in object-oriented databases gives rise to the processing of a path. Several database operations may result into the same path. The authors address the problem of optimal index configuration for a single path. As it is shown an optimal index configuration for a path can be achieved by splitting the path into subpaths and by indexing each subpath with the optimal index organization. The authors present an algorithm which is able to select an optimal index configuration for a given path. The authors consider a limited number of existing indexing techniques (simple index, inherited index, nested inherited index, multi-index, and multi-inherited index) but the principles of the algorithm remain the same adding more indexing techniques	ICDE	database
2410	ICDE	Semantics-Based Multilevel Transaction Management in Federated Systems.	Andrew Deacon,Hans-Jörg Schek,Gerhard Weikum	1994	A federated database management system (FDBMS) is a special type of distributed database system that enables existing local databases, in a heterogeneous environment, to maintain a high degree of autonomy. One of the key problems in this setting is the coexistence of local transactions and global transactions, where the latter access and manipulate data of multiple local databases. In modeling FDBMS transaction executions the authors propose a more realistic model than the traditional read/write model; in their model a local database exports high-level operations which are the only operations distributed global transactions can execute to access data in the shared local databases. Such restrictions are not unusual in practice as, for example, no airline or bank would ever permit foreign users to execute ad hoc queries against their databases for fear of compromising autonomy. The proposed architecture can be elegantly modeled using the multilevel nested transaction model for which a sound theoretical foundation exists to prove concurrent executions correct. A multilevel scheduler that is able to exploit the semantics of exported operations can significantly increase concurrency by ignoring pseudo conflicts. A practical scheduling mechanism for FDBMSs is described that offers the potential for greater performance and more flexibility than previous approaches based on the read/write model	ICDE	database
2411	ICDE	Transactional Workflow Management in Distributed Object Computing Environments.	Dimitrios Georgakopoulos	1994	Focuses on transactional workflows, i.e., the advanced transaction technology required to (i) ensure the reliability of tasks in a workflow, and the correctness and reliability of concurrent workflows, and (ii) support the specification and management of extended transactions models. In addition, the author discusses research and development at GTE Laboratories to produce a Transaction Specification and Management Environment (TSME) that can satisfy such requirements. He also discusses the integration of DOM and TSME technologies	ICDE	database
2412	ICDE	Specification and Management of Extended Transactions in a Programmable Transaction Environment.	Dimitrios Georgakopoulos,Mark F. Hornick,Piotr Krychniak,Frank Manola	1994	A Transaction Specification and Management Environment (TSME) is a transaction processing system toolkit that supports the definition and construction of application-specific extended transaction models (ETMs). The TSME provides a transaction specification language that allows a transaction model designer to create implementation-independent specifications of extended transactions. In addition, the TSME provides a programmable transaction management mechanism that assembles and configures a run-time environment to support specified ETMs. The authors discuss the TSME in the context of a distributed object management system (DOMS), and describe specifications of extended transactions and corresponding configurations of transaction management mechanisms	ICDE	database
2413	ICDE	Object Placement in Parallel Object-Oriented Database Systems.	Shahram Ghandeharizadeh,David Wilhite,Kai-Ming Lin,Xiaoming Zhao	1994	Parallelism is a viable solution to constructing high performance object-oriented database systems. In parallel systems based on a shared-nothing architecture, the database is horizontally declustered across multiple processors, enabling the system to employ multiple processors to speedup the execution time of a query. The placement of objects across the processors has a significant impact on the performance of queries that traverse a few objects. The paper describes and evaluates a greedy algorithm for the placement of objects across the processors of a system. Moreover, it describes two alternative availability strategies and quantifies their performance tradeoff using a trace-driven simulation study	ICDE	database
2414	ICDE	Sort-Merge-Join: An Idea Whose Time Has(h) Passed?	Goetz Graefe	1994	Matching two sets of data items is a fundamental operation required in relational, extensible, and object-oriented database systems alike. However, the pros and cons of sort- and hash-based query evaluation techniques in modern query processing systems are still not fully understood. After our earlier research clarified strengths and weaknesses of sort- and hash-based query processing techniques and suggested remedies for the shortcomings of hash-based algorithms, the present paper outlines a number of further differences between sort-merge-join and hybrid hash join that traditionally have been ignored in such comparisons and render sort-merge-join mostly obsolete. We consolidate old and raise new issues pertinent to the comparison of sort- and hash-based query evaluation techniques and stir some thought and discussion among both academic and industrial database system builders	ICDE	database
2415	ICDE	A Multi-Set Extended Relational Algebra - A Formal Approach to a Practical Issue.	Paul W. P. J. Grefen,Rolf A. de By	1994	A Multi-Set Extended Relational Algebra - A Formal Approach to a Practical Issue.	ICDE	database
2416	ICDE	Approximate Analysis of Real-Time Database Systems.	Jayant R. Haritsa	1994	During the past few years, several studies have been made on the performance of real-time database systems with respect to the number of transactions that miss their deadlines. These studies have used either simulation models or database testbeds as their performance evaluation tools. We present a preliminary analytical performance study of real-time transaction processing. Using a series of approximations, we derive simple closed-form solutions to reduced real-time database models. Although quantitatively approximate, the solutions accurately capture system sensitivity to workload parameters and indicate conditions under which performance bounds are achieved	ICDE	database
2417	ICDE	Performance Evaluation of Grid Based Multi-Attibute Record Declustering Methods.	Bhaskar Himatsingka,Jaideep Srivastava	1994	Performance Evaluation of Grid Based Multi-Attibute Record Declustering Methods.	ICDE	database
2418	ICDE	Data Management in Delayed Conferencing (Abstract).	Arding Hsu	1994	Data Management in Delayed Conferencing (Abstract).	ICDE	database
2419	ICDE	Object Allocation in Distributed Databases and Mobile Computers.	Yixiu Huang,Ouri Wolfson	1994	This paper makes two contributions. First, we introduce a model for evaluating the performance of data allocation and replication algorithms in distributed databases. The model is comprehensive in the sense that it accounts for I/O cost, for communication cost, and for limits on the minimum number of copies of the object (to ensure availability). The second contribution of this paper is the introduction and analysis of an algorithm for automatic dynamic allocation of replicas to processors. Using the new model, we compare the performance of the traditional read-one-write-all static allocation algorithm, to the performance of the dynamic allocation algorithm. As a result, we obtain the relationship between the communication cost and I/O cost for which static allocation is superior to dynamic allocation, and the relationships for which dynamic allocation is superior	ICDE	database
2420	ICDE	Object Skeletons: An Efficient Navigation Structure for Object-Oriented Database Systems.	Kien A. Hua,Chinmoy Tripathy	1994	One common requirement of object-oriented applications is the efficient support of complex objects. This requirement is one salient feature of object orientation. Access to a complex object involves true basic steps: (1) The predicate is evaluated to identify the complex object. (2) The qualified complex object is traversed to retrieve the required components. Over the past few years, several indexing schemes have been developed to support step 1. However, support structures for the efficient execution of step 2 has received little attention. To address this problem, we propose, in this paper, using networks of unique object identifiers (Object Skeletons) as a navigational structure to aid query processing of complex objects. In this approach, skeletons of complex objects contain only the semantic information. Once a skeleton has been loaded into memory, navigation along the complex object can be done with no further disk access. Furthermore, since the descriptive information of an object is stored separately from its object identifier, it is free to migrate anywhere in the database. To assess the efficiency of this approach, we built a prototype and compared its performance to some recently proposed indexing schemes. The results of our study indicate that this technique can provide very impressive savings of both space and time	ICDE	database
2421	ICDE	Active Databases for Active Repositories.	Heinrich Jasper	1994	The various activities necessary for constructing a software product are described by software process models. Many of the actions mentioned there are supported by tools that use a repository in order to create, manipulate, generate, etc. the deliverables. The process is tailored for each project to necessary work and planned with respect to existing resources. This results in a schedule for each project that is manually compared with ongoing work. We introduce the idea of active repositories that partially automate scheduling and controlling of the activities described within a process model. The notion of active repositories is based on active database technology that allows for detecting events and triggering the corresponding actions. Events are state changes in the repository or raised by external components, e.g. a clock or CASE tool. Actions manipulate the repository, trigger CASE tools, signal external systems or notify the user	ICDE	database
2422	ICDE	Supporting Data Mining of Large Databases by Visual Feedback Queries.	Daniel A. Keim,Hans-Peter Kriegel,Thomas Seidl	1994	Describes a query system that provides visual relevance feedback in querying large databases. The goal is to support the process of data mining by representing as many data items as possible on the display. By arranging and coloring the data items as pixels according to their relevance for the query, the user gets a visual impression of the resulting data set. Using an interactive query interface, the user may change the query dynamically and receives immediate feedback by the visual representation of the resulting data set. Furthermore, by using multiple windows for different parts of a complex query, the user gets visual feedback for each part of the query and, therefore, may easier understand the overall result. The system allows one to represent the largest amount of data that can be visualized on current display technology, provides valuable feedback in querying the database, and allows the user to find results which would otherwise remain hidden in the database	ICDE	database
2423	ICDE	A Method for Transforming Relational Schemas Into Conceptual Schemas.	Paul Johannesson	1994	A major problem with currently existing database systems is that there often does not exist a conceptual understanding of the data. Such an understanding can be obtained by describing the data using a semantic data model, such as the ER model. Consequently, there is a need for methods that translate a schema in a traditional data model into a conceptual schema. We present a method for translating a schema in the relational model into a schema in a conceptual model. We also show that the schema produced has the same information capacity as the original schema. The conceptual model used is a formalization of an extended ER model, which also includes the subtype concept	ICDE	database
2424	ICDE	Query Optimization Strategies for Browsing Sessions.	Martin L. Kersten,M. F. N. de Boer	1994	This paper describes techniques and experimental results to obtain response time improvement for a browsing session, i.e. a sequence of interrelated queries to locate a subset of interest. The optimization technique exploits symbolic analysis of the query interdependencies and retention of (partial) query answers. A prototype browsing session optimizer (BSO) has been constructed that runs as a front-end to the Ingres relational system. Based on the experiments reported, we propose to extend (existing) DBMSs with a mechanism to keep and reuse small answers by default. Such investments quickly pay off in sessions with interrelated queries	ICDE	database
2425	ICDE	Cooperative Problem Solving Using Database Conversations.	Thomas Kirsche,Richard Lenz,Thomas Ruf,Hartmut Wedekind	1994	Cooperative problem solving is a joint style of producing and consuming data. Unfortunately, most database mechanisms developed so far; are more appropriate for competitive usage than for a cooperative working style. They mostly adopt an operational point of view which binds data to applications. Data-oriented mechanisms like check-in/out avoid this binding but do not improve synchronization towards concurrent usage of data. Conversations are an application-independent, tight framework for jointly modifying common data. The idea is to create transaction-spanning conversational working stages that organize different contributions instead of serializing accesses. To illustrate the conversation concept, an extended query language with conversational operations is presented	ICDE	database
2426	ICDE	Declustering Techniques for Parallelizing Temporal Access Structures.	Vram Kouramajian,Ramez Elmasri,Anurag Chaudhry	1994	This paper addresses the issues of declustering temporal index and access structures for a single processor multiple independent disk architecture. The temporal index is the Monotonic B+-Tree which uses the time index temporal access structure. We devise a new algorithm, called multi-level round robin, for assigning tree nodes to multiple disks. The multi-level round robin declustering technique takes advantage of the append-only nature of temporal databases to achieve uniform load distribution, decrease response time, and increase the fanout of the tree by eliminating the need to store disk numbers within the tree nodes. We propose two declustering techniques for the time index access structures; one considers only time proximity while declustering, whereas the other considers both time proximity and data size. We investigate their performance over different types of temporal queries and show that various temporal queries have conflicting allocation criteria for the time index buckets. In addition, we devise two disk partition techniques for the time index buckets. The mutually exclusive technique partitions the disks into disjoint groups, whereas the shared disk technique allows the different types of buckets to share all disks	ICDE	database
2427	ICDE	Knowledge-Based Handling of Design Expertise.	Pierre Morizet-Mahoudeaux,Einoshin Suzuki,Setsuo Ohsuga	1994	Research issues in the domain of AI for design can be organized in three categories: decision making, representation and knowledge handling. In the area of knowledge handling, this paper addresses issues concerning the management of design experience to guide a priori the generation of candidate solutions. The approach is based on keeping the trace of a previous design experience as a hierarchical knowledge base. A level in the hierarchy can be viewed as a level of granularity of the description of the design process. A general framework for defining a partial order function between the granularity levels in the knowledge bases of design expertise is proposed. It is then possible to compute the sets of the elements belonging to smaller granularity levels, which are linked to any component of the hierarchy. Thus, it makes it possible to compute the level in the hierarchy that can be reused without modification for the design of a new product. Computation of the appropriate level is mainly based on matching the data corresponding to the new requirements with these sets. The approach has been tested by using a multiple expert systems structure based on using interactively two systems, an expert system development tool for design, KAUS, and an expert system development tool for diagnosing engineering processes, SUPER. The intrinsic properties of SUPER have also been used for improving the design procedure when qualitative and quantitative knowledge is involved	ICDE	database
2428	ICDE	Discovering Database Summaries through Refinements of Fuzzy Hypotheses.	Doheon Lee,Myoung-Ho Kim	1994	Recently, many applications such as scientific databases and decision supporting systems that require comprehensive analysis of a very large amount of data, have been evolved. Summary discovery techniques, which extract compact representations grasping the meanings of large databases, can play a major role in those applications. We present an effective and robust method to discover simple linguistic summaries. We first propose a hypothesis refinement algorithm that is a key technique for our summary discovery method. Using the algorithm, a formal procedure for summary discovery is presented together with an illustrative example. Our discovery method can handle both rigid concepts and fuzzy concepts that occur frequently in practice. Discovered summaries can also be regarded as high-level interattribute dependencies	ICDE	database
2429	ICDE	Resolving Attribute Incompatibility in Database Integration: An Evidential Reasoning Approach.	Ee-Peng Lim,Jaideep Srivastava,Shashi Shekhar	1994	Resolving domain incompatibility among independently developed databases often involves uncertain information. DeMichiel (1989) showed that uncertain information can be generated by the mapping of conflicting attributes to a common domain, based on some domain knowledge. The authors show that uncertain information can also arise when the database integration process requires information not directly represented in the component databases, but can be obtained through some summary of data. They therefore propose an extended relational model based on Dempster-Shafer theory of evidence (1976) to incorporate such uncertain knowledge about the source databases. They also develop a full set of extended relational operations over the extended relations. In particular, an extended union operation has been formalized to combine two extended relations using Dempster's rule of combination. The closure and boundedness properties of the proposed extended operations are formulated	ICDE	database
2430	ICDE	Polymorphic Reuse Mechanisms for Object-Oriented Database Specifications.	Ling Liu,Roberto Zicari,Walter L. Hürsch,Karl J. Lieberherr	1994	A polymorphic approach to the incremental design and reuse of object-oriented methods and query specifications is presented. Using this approach, the effort required for manually reprogramming methods and queries due to schema modifications can be avoided or minimized. The salient features of of our approach are the use of propagation patterns and a mechanism for propagation pattern refinement. Propagation patterns can be employed as an interesting specification formalism for modeling operational requirements in object-oriented database systems. They encourage the reuse of operational specifications against the structural modification of an object-oriented schema. Propagation pattern refinement is suited for the specification of reusable operational modules, and for achieving reusability of propagation patterns towards the operational requirement changes	ICDE	database
2431	ICDE	Fast Ranking in Limited Space.	Alistair Moffat,Justin Zobel	1994	Ranking techniques have long been suggested as alternatives to conventional Boolean methods for searching document collections. The cost of computing a ranking is, however, greater than the cost of performing a Boolean search, in terms of both memory space and processing time. The authors consider the resources required by the cosine method of ranking, and show that, with a careful application of indexing and selection techniques, both the space and the time required by ranking can be substantially reduced. The methods described in the paper have been used to build a retrieval system with which it is possible to process ranked queries of 40 terms in about 5% of the space required by previous implementations; in as little as 25% of the time; and without measurable degradation in retrieval effectiveness	ICDE	database
2432	ICDE	Exploiting Uniqueness in Query Optimization.	G. N. Paulley,Per-Åke Larson	1994	Consider an SQL query that specifies duplicate elimination via a DISTINCT clause. Because duplicate elimination often requires an expensive sort of the query result, it is often worthwhile to identify unnecessary DISTINCT clauses and avoid the sort altogether. We prove a necessary and sufficient condition for deciding if a query requires duplicate elimination. The condition exploits knowledge about keys, table constraints, and query predicates. Because the condition cannot always be tested efficiently, we offer a practical algorithm that tests a simpler, sufficient condition. We consider applications of this condition for various types of queries, and show that we can exploit this condition in both relational and nonregulation database systems	ICDE	database
2433	ICDE	Efficient Support for Partial Write Operations in Replicated Databases.	Michael Rabinovich,Edward D. Lazowska	1994	We present a new replica control technique targeted at replicated systems in which write operations update a portion of the information in the data item rather than replacing it entirely. The existing protocols capable of supporting partial writes must either perform the writes on all accessible replicas of the data item, or always apply the writes to the same group (quorum set) of replicas. In the former case, the system incurs high message overhead. In the latter case, if any of the replicas in this group fail, additional replicas must be synchronously brought up-to-date during the write operation causing delay to the operation. Also, in both cases, the system loses the advantage of load sharing provided by replication. Our protocol avoids performing the write on all nodes while preserving load sharing and reducing greatly the risk of having to propagate updates synchronously. We describe the protocol, prove it correct, and present a comparative performance study of our protocol and the existing alternatives	ICDE	database
2434	ICDE	Parallel Approaches to Database Management (Abstract).	David S. Reiner	1994	Parallel Approaches to Database Management (Abstract).	ICDE	database
2435	ICDE	Capturing Design Dynamics the Concord Approach.	Norbert Ritter,Bernhard Mitschang,Theo Härder,Michael Gesmann,Harald Schöning	1994	Capturing Design Dynamics the Concord Approach.	ICDE	database
2436	ICDE	Analysis of Reorganization Overhead in Log-Structured File Systems.	John T. Robinson,Peter A. Franaszek	1994	In a log-structured file system (LFS), in general each block written to disk causes another disk block to become invalid data, resulting in one block of free space. Over time free disk space becomes highly fragmented, and a high level of dynamic reorganization may be required to coalesce free blocks into physically contiguous areas that subsequently can be used for logs. By consuming available disk bandwidth, this reorganization can degrade system performance. In a segmented disk LFS organization, the copy-and-compact reorganization method reads entire segments and then writes back all valid blocks. Other methods, suggested by earlier work on reduction of storage fragmentation for non-LFS disks, may access far fewer blocks (at the cost of increased CPU time). An analytic model is used to evaluate the effects on available disk bandwidth of dynamic reorganization, as a function of the read/write ratio, storage utilization, and degree of data movement required by dynamic reorganization for steady-state operation. It is shown that decreasing reorganization overhead can have dramatic effects on available disk bandwidth	ICDE	database
2437	ICDE	The TP-Index: A Dynamic and Efficient Indexing Mechanism for Temporal Databases.	Han Shen,Beng Chin Ooi,Hongjun Lu	1994	To support temporal operators efficiently, indexing based on temporal attributes must be supported. The authors propose a dynamic and efficient index scheme called the time polygon (TP-index) for temporal databases. In the scheme, temporal data are mapped into a two-dimensional temporal space, where the data can be clustered based on time. The date space is then partitioned into time polygons where each polygon corresponds to a data page. The time polygon directory can be organized as a hierarchical index. The index handles long duration temporal data elegantly and efficiently. The performance analysis indicates that the time polygon index is efficient both in storage utilization and query search	ICDE	database
2438	ICDE	Efficient Organization of Large Multidimensional Arrays.	Sunita Sarawagi,Michael Stonebraker	1994	Large multidimensional arrays are widely used in scientific and engineering database applications. The authors present methods of organizing arrays to make their access on secondary and tertiary memory devices fast and efficient. They have developed four techniques for doing this: (1) storing the array in multidimensional &ldquo;chunks&rdquo; to minimize the number of blocks fetched, (2) reordering the chunked array to minimize seek distance between accessed blocks, (3) maintaining redundant copies of the array, each organized for a different chunk size and ordering and (4) partitioning the array onto platters of a tertiary memory device so as to minimize the number of platter switches. The measurements on real data obtained from global change scientists show that accesses on arrays organized using these techniques are often an order of magnitude faster than on the unoptimized data	ICDE	database
2439	ICDE	Transactional Workflows: Research, Enabling Technologies, and Applications (Abstract).	Amit P. Sheth	1994	Transactional Workflows: Research, Enabling Technologies, and Applications (Abstract).	ICDE	database
2440	ICDE	Managing Change in the Rufus System.	Peter M. Schwarz,Kurt A. Shoens	1994	Rufus is an information system that models user data with objects taken from a class system. Due to the importance of coping with changes to the schema, Rufus has adopted the conformity-based model of Melampus. This model enables Rufus to cope with schema changes more easily than traditional class- and inheritance-based data models. The paper reviews the Melampus data model and describes how it was implemented in the Rufus system. The authors show how changes to the schema can be accommodated with minimum disruption. They also review design decisions that contributed to streamlined schema evolution and compare this approach with those proposed in the literature	ICDE	database
2441	ICDE	X-500 Directory Schema Management.	Daniel L. Silver,James W. Hong,Michael A. Bauer	1994	X-500 Directory Schema Management.	ICDE	database
2442	ICDE	Efficient Evaluation of the Valid-Time Natural Join.	Michael D. Soo,Richard T. Snodgrass,Christian S. Jensen	1994	Joins are arguably the most important relational operators. Poor implementations are tantamount to computing the Cartesian product of the input relations. In a temporal database, the problem is more acute for two reasons. First, conventional techniques are designed for the optimization of joins with equality predicates, rather than the inequality predicates prevalent in valid-time queries. Second, the presence of temporally-varying data dramatically increases the size of the database. These factors require new techniques to efficiently evaluate valid-time joins. The authors address this need for efficient join evaluation in databases supporting valid-time. A new temporal-join algorithm based on tuple partitioning is introduced. This algorithm avoids the quadratic cost of nested-loop evaluation methods; it also avoids sorting. Performance comparisons between the partition-based algorithm and other evaluation methods are provided. While the paper focuses on the important valid-time natural join, the techniques presented are also applicable to other valid-time joins	ICDE	database
2443	ICDE	Mariposa: A New Architecture for Distributed Data.	Michael Stonebraker,Paul M. Aoki,Robert Devine,Witold Litwin,Michael A. Olson	1994	We describe the design of Mariposa, an experimental distributed data management system that provides high performance in an environment of high data mobility and heterogeneous host capabilities. The Mariposa design unifies the approaches taken by distributed file systems and distributed databases. In addition, Mariposa provides a general, flexible platform for the development of new algorithms for distributed query optimization, storage management, and scalable data storage structures. This flexibility is primarily due to a unique rule-based design that permits autonomous, local-knowledge decisions to be made regarding data placement, query execution location, and storage management	ICDE	database
2444	ICDE	An Efficient Relational Implementation of Recursive Relationships using Path Signatures.	Jukka Teuhola	1994	The `parts explosion' is a classical problem, which is hard for relational database systems, due to recursion. A simple solution is suggested, which packs information of an ancestor path of a tuple into a fixed-length code, called signature. The coding technique is carefully adjusted to enable an efficient retrieval of the transitive closure, in terms of both disk accesses and DBMS calls. The code is lossy, and its purpose is to define a reasonably small superset of the closure, as well as establish an effective order of clustering. The method performs best for tree-structured hierarchies, where the processing time typically decreases by a factor of more than ten, compared to the trivial method. Also general directed graphs, both acyclic and cyclic, can be handled more efficiently	ICDE	database
2445	ICDE	On a More Realistic Lock Contention Model and Its Analysis.	Alexander Thomasian	1994	Most performance modeling studies of lock contention in transaction processing systems are deficient in that they postulate a homogeneous database access model. The non-homogeneous database access model described in this paper allows multiple transaction classes with different access patterns to the database regions. The performance of the system from the viewpoint of lock contention is analyzed in the context of the standard two-phase locking concurrency control method with the general waiting policy. The approximate analysis is based on mean values of parameters and derives expressions for the probability of lock conflict (usually leading to transaction blocking) and the mean blocking time. The latter requires estimating the distribution of the effective wait-depth encountered by blocked transactions and the mean waiting time associated with different blocking levels. The accuracy of the analysis is validated against simulation results and also shown to be more accurate than analytic solutions considering only two levels of transaction blocking. Previously proposed metrics for load control have limited applicability for the model under consideration	ICDE	database
2446	ICDE	Performance Analysis of RAID5 Disk Arrays with a Vacationing Server Model for Rebuild Mode Operation.	Alexander Thomasian,Jai Menon	1994	Performance Analysis of RAID5 Disk Arrays with a Vacationing Server Model for Rebuild Mode Operation.	ICDE	database
2447	ICDE	Supporting Partial Data Accesses to Replicated Data.	Peter Triantafillou,Feng Xiao	1994	Partial data access operations occur frequently in distributed systems. This paper presents new approaches for efficiently supporting partial data access operations to replicated data. We propose the replica modularization (RM) technique which suggests partitioning replicas into modules, which now become the minimum unit of data access. RM is shown to increase the availability of both partial read and write operations and improves performance by reducing access delays and the size of data transfers occurring during operation execution on replicated data. In addition, we develop a new module-based protocol (MB) in which different replication protocols are used to access different sets of replicas, with each replica storing different modules. The instance of MB we discuss here is a hybrid of the ROWA (Read One Write All) protocol and the MQ (Majority Quorum) protocol. MB allows a trade-off between storage costs and availability. We show that MB can achieve almost as high availability as the MQ protocol, but with considerably smaller storage costs	ICDE	database
2448	ICDE	Supporting High-Bandwidth Navigation in Object-Bases.	Venu Vasudevan	1994	Magritte is an attempt to construct a high-bandwidth front-end to an object-base containing meta-data about SCAD designs. SCAD is a small part of a family of visualization applications where the end-user concurrently manipulates large collections of active data. Such end-user interfaces require a different paradigm of interaction than the object-at-a-time interfaces of current databases. Proposals here can be divided into mechanisms for scene creation and those for scene integration. The former allow a user to create a single scene with ease. The latter help in desktop management by allowing scenes to be combined and correlated. The implementation experience points out a number of shortcomings in current database offerings that need to be solved so as to ease the design of high-bandwidth front-ends	ICDE	database
2449	ICDE	Data Placement and Buffer Management for Concurrent Mergesorts with Parallel Prefetching.	Kun-Lung Wu,Philip S. Yu,James Z. Teng	1994	Various data placement policies are studied for the merge phase of concurrent mergesorts using parallel prefetching, where initial sorted runs (input) of a merge and its final sorted run (output) are stored on multiple disks but each run resides only on a single disk. Since the merge phase involves only sequential references, parallel prefetching can be attractive an reducing the average response time for concurrent merges. However, without careful buffer control, severe thrashing may develop under certain run placement policies, reducing the benefits of prefetching. The authors examine through detailed simulations three different run placement policies. The results show that even though buffer thrashing can be almost avoided by placing the output run of a job on the same disk with at least one of its input runs, this thrashing-avoiding run placement policy can be substantially outperformed by other policies that use buffer thrashing control. With buffer thrashing avoidance, the best performance as achieved by a run placement policy that uses a proper subset of disks dedicated for writing the output runs while the rest of the disks are used for prefetching the input runs in parallel	ICDE	database
2450	ICDE	Index Structures for Information Filtering Under the Vector Space Model.	Tak W. Yan,Hector Garcia-Molina	1994	With the ever increasing volumes of information generation, users of information systems are facing an information overload. It is desirable to support information filtering as a complement to traditional retrieval mechanism. The number of users, and thus profiles (representing users'' long-term interests), handled by an information filtering system is potentially huge, and the system has to process a constant stream of incoming information in a timely fashion. The efficiency of the filtering process is thus an important issue. In this paper, we study what data structures and algorithms can be used to efficiently perform large-scale information filtering under the vector space model, a retrieval model established as being effective. We apply the idea of the standard inverted index to index user profiles. We devise an alternative to the standard inverted index, in which we, instead of indexing every term in a profile, select only the significant ones to index. We evaluate their performance and show that the indexing methods require orders of magnitude fewer I/Os to process a document than when no index is used. We also show that the proposed alternative performs better in terms of I/O and CPU processing time in many cases.	ICDE	database
2451	ICDE	Performing Group-By before Join.	Weipeng P. Yan,Per-Åke Larson	1994	Performing Group-By before Join.	ICDE	database
2452	ICDE	A Hybrid Transitive Closure Algorithm for Sequential and Parallel Processing.	Qi Yang,Clement T. Yu,Chengwen Liu,Son Dao,Gaoming Wang,Tracy Pham	1994	A new hybrid algorithm is proposed for well-formed path problems including the transitive closure problem. The CPU time for computation is O(ne), and blocking technique is incorporated to reduce the disk I/O cost in disk-resident environment. The new features of the new algorithm are that only parents sets instead of descendant sets are loaded in from disk, and the computation can be parallelized efficiently. Simulation results show that our algorithm is superior to other existing algorithms in sequential computation, and that linear speedup is achieved in parallel computation	ICDE	database
2453	ICDE	Disk Allocation Methods for Parallelizing Grid Files.	Yvonne Zhou,Shashi Shekhar,Mark Coyle	1994	Disk Allocation Methods for Parallelizing Grid Files.	ICDE	database
2454	ICDE	A Query Sampling Method of Estimating Local Cost Parameters in a Multidatabase System.	Qiang Zhu,Per-Åke Larson	1994	A Query Sampling Method of Estimating Local Cost Parameters in a Multidatabase System.	ICDE	database
2455	ICDE	Applying Signatures for Forward Traversal Query Processing in Object-Oriented Databases.	Hwan-Seung Yong,Sukho Lee,Hyoung-Joo Kim	1994	Forward traversal methods are used to process queries having nested predicates in object-oriented databases. To expedite the forward traversal, a signature replication technique is proposed. Object signature is a signature formed by values of all atomic attributes defined in the object. When an object refers to other objects through its attribute, the object signature of the referred object is stored into the referring object. Using object signatures, nested predicates can be checked without inspecting referred objects	ICDE	database
2456	ICDE	Storage Reclamation and Reorganization in Client-Server Persistent Object Stores.	Voon-Fee Yong,Jeffrey F. Naughton,Jie-Bing Yu	1994	The authors develop and evaluate a number of storage reclamation algorithms for client-server persistent object stores. Experience with a detailed simulation and a prototype implementation in the Exodus storage manager shows that one of the proposed algorithms, the Incremental Partitioned Collector, is complete, maintains transaction semantics, and can be run incrementally and concurrently with client applications. Furthermore, it can significantly improve subsequent system performance by reclustering data, rendering it attractive even for systems that choose not to support automatic storage reclamation	ICDE	database
2457	SIGMOD Conference	Quest: A Project on Database Mining.	Rakesh Agrawal,Michael J. Carey,Christos Faloutsos,Sakti P. Ghosh,Maurice A. W. Houtsma,Tomasz Imielinski,Balakrishna R. Iyer,A. Mahboob,H. Miranda,Ramakrishnan Srikant,Arun N. Swami	1994	Quest: A Project on Database Mining.	SIGMOD Conferen	database
2458	SIGMOD Conference	Database Issues in Telecommunications Network Management.	Ilsoo Ahn	1994	Database Issues in Telecommunications Network Management.	SIGMOD Conferen	database
2459	SIGMOD Conference	UniSQL/X Unified Relational and Object-Oriented Database System.	Won Kim	1994	UniSQL/X Unified Relational and Object-Oriented Database System.	SIGMOD Conferen	database
2460	SIGMOD Conference	Evolving Teradata Decision Support for Massively Parallel Processing with UNIX.	Carrie Ballinger	1994	Evolving Teradata Decision Support for Massively Parallel Processing with UNIX.	SIGMOD Conferen	database
2461	SIGMOD Conference	Staggered Striping in Multimedia Information Systems.	Steven Berson,Shahram Ghandeharizadeh,Richard R. Muntz,Xiangyu Ju	1994	Multimedia information systems have emerged as an essential component of many application domains ranging from library information systems to entertainment technology. However, most implementations of these systems cannot support the continuous display of multimedia objects and suffer from frequent disruptions and delays termed hiccups. This is due to the low I/O bandwidth of the current disk technology, the high bandwidth requirement of multimedia objects, and the large size of these objects that almost always requires them to be disk resident. One approach to resolve this limitation is to decluster a multimedia object across multiple disk drives in order to employ the aggregate bandwidth of several disks to support the continuous retrieval (and display) of objects. This paper describes staggered striping as a novel technique to provide effective support for multiple users accessing the different objects in the database. Detailed simulations confirm the superiority of staggered striping.	SIGMOD Conferen	database
2462	SIGMOD Conference	Sleepers and Workaholics: Caching Strategies in Mobile Environments.	Daniel Barbará,Tomasz Imielinski	1994	In the mobile wireless computing environment of the future a large number of users equipped with low powered palm-top machines will query databases over the wireless communication channels. Palmtop based units will often be disconnected for prolonged periods of time due to the battery power saving measures; palmtops will also frequencly relocate between different cells and connect to different data servers at different times. Caching of frequently accessed data items will be an important technique that will reduce contention on the narrow bandwidth wireless channel. However, cache invalidation strategies will be severely affected by the disconnection and mobility of the clients. The server may no longer know which clients are currently residing under its cell and which of them are currently on. We propose a taxonomy of different cache invalidation strategies and study the impact of client's disconnection times on their performance. We determine that for the units which are often disconnected (sleepers) the best cache invalidation strategy is based on signatures previously used for efficient file comparison. On the other hand, for units which are connected most of the time (workaholics), the best cache invalidation strategy is based on the periodic broadcast of changed data items.	SIGMOD Conferen	database
2463	SIGMOD Conference	ASSET: A System for Supporting Extended Transactions.	Alexandros Biliris,Shaul Dar,Narain H. Gehani,H. V. Jagadish,Krithi Ramamritham	1994	Extended transaction models in databases were motivated by the needs of complex applications such as CAD and software engineering. Transactions in such applications have diverse needs, for example, they may be long lived and they may need to cooperate. We describe ASSET, a system for supporting extended transactions. ASSET consists of a set of transaction primitives that allow users to define custom transaction semantics to match the needs of specific applications. We show how the transaction primitives can be used to specify a variety of transaction models, including nested transactions, split transactions, and sagas. Application-specific transaction models with relaxed correctness criteria, and computations involving workflows, can also be specified using the primitives. We describe the implementation of the ASSET primitives in the context of the Ode database.	SIGMOD Conferen	database
2464	SIGMOD Conference	EOS: An Extensible Object Store.	Alexandros Biliris,Euthimios Panagos	1994	EOS: An Extensible Object Store.	SIGMOD Conferen	database
2465	SIGMOD Conference	Open Object Database Management Systems.	José A. Blakeley	1994	Open Object Database Management Systems.	SIGMOD Conferen	database
2466	SIGMOD Conference	Multi-Step Processing of Spatial Joins.	Thomas Brinkhoff,Hans-Peter Kriegel,Ralf Schneider,Bernhard Seeger	1994	Spatial joins are one of the most important operations for combining spatial objects of several relations. In this paper, spatial join processing is studied in detail for extended spatial objects in two-dimensional data space. We present an approach for spatial join processing that is based on three steps. First, a spatial join is performed on the minimum bounding rectangles of the objects returning a set of candidates. Various approaches for accelerating this step of join processing have been examined at the last year's conference [BKS 93a]. In this paper, we focus on the problem how to compute the answers from the set of candidate which is handled by the following two steps. First of all, sophisticated approximations are used to identify answers as well as to filter out false hits from the set of candidates. For this purpose, we investigate various types of conservative and progressive approximations. In the last step, the exact geometry of the remaining candidates has to be tested against the join predicate. The time required for computing spatial join predicates can essentially be reduced when objects are adequately organized in main memory. In our approach, objects are first decomposed into simple components which are exclusively organized by a main-memory resident spatial data structure. Overall, we present a complete approach of spatial join processing on complex spatial objects. The performance of the individual steps of our approach is evaluated with data sets from real cartographic applications. The results show that our approach reduces the total execution time of the spatial join by factors.	SIGMOD Conferen	database
2467	SIGMOD Conference	GENESYS: A System for Efficient Spatial Query Processing.	Thomas Brinkhoff,Hans-Peter Kriegel,Ralf Schneider,Bernhard Seeger	1994	GENESYS: A System for Efficient Spatial Query Processing.	SIGMOD Conferen	database
2468	SIGMOD Conference	The MEDUSA Project: Autonomous Data Management in a Shared-Nothing Parallel Database Machine.	George M. Bryan,Wayne E. Moore,B. J. Curry,K. W. Lodge,J. Geyer	1994	The MEDUSA Project: Autonomous Data Management in a Shared-Nothing Parallel Database Machine.	SIGMOD Conferen	database
2469	SIGMOD Conference	Parallel Database Systems in the 1990's.	Michael J. Carey	1994	Parallel Database Systems in the 1990's.	SIGMOD Conferen	database
2470	SIGMOD Conference	Shoring Up Persistent Applications.	Michael J. Carey,David J. DeWitt,Michael J. Franklin,Nancy E. Hall,Mark L. McAuliffe,Jeffrey F. Naughton,Daniel T. Schuh,Marvin H. Solomon,C. K. Tan,Odysseas G. Tsatalos,Seth J. White,Michael J. Zwilling	1994	SHORE (Scalable Heterogeneous Object REpository) is a persistent object system under development at the University of Wisconsin. SHORE represents a merger of object-oriented database and file system technologies. In this paper we give the goals and motivation for SHORE, and describe how SHORE provides features of both technologies. We also describe some novel aspects of the SHORE architecture, including a symmetric peer-to-peer server architecture, server customization through an extensible value-added server facility, and support for scalability on multiprocessor systems. An initial version of SHORE is already operational, and we expect a release of Version 1 in mid-1994.	SIGMOD Conferen	database
2471	SIGMOD Conference	Fine-Grained Sharing in a Page Server OODBMS.	Michael J. Carey,Michael J. Franklin,Markos Zaharioudakis	1994	For reasons of simplicity and communication efficiency, a number of existing object-oriented database management systems are based on page server architectures; data pages are their minimum unit of transfer and client caching. Despite their efficiency, page servers are often criticized as being too restrictive when it comes to concurrency, as existing systems use pages as the minimum locking unit as well. In this paper we show how to support object-level locking in a page server context. Several approaches are described, including an adaptive granularity approach that uses page-level locking for most pages but switches to object-level locking when finer-grained sharing is demanded. We study the performance of these approaches, comparing them to both a pure page server and a pure object server. For the range of workloads that we have examined, our results indicate that a page server is clearly preferable to an object server. Moreover, the adaptive page server is shown to provide very good performance, generally outperforming the pure page server, the pure object server, and the other alternatives as well.	SIGMOD Conferen	database
2472	SIGMOD Conference	Query by Diagram: A Graphical Environment for Querying Databases.	Tiziana Catarci,Giuseppe Santucci	1994	Query by Diagram: A Graphical Environment for Querying Databases.	SIGMOD Conferen	database
2473	SIGMOD Conference	ODMG-93: A Standard for Object-Oriented DBMSs.	R. G. G. Cattell	1994	ODMG-93: A Standard for Object-Oriented DBMSs.	SIGMOD Conferen	database
2474	SIGMOD Conference	Adaptive Selectivity Estimation Using Query Feedback.	Chung-Min Chen,Nick Roussopoulos	1994	In this paper, we propose a novel approach for estimating the record selectivities of database queries. The real attribute value distribution is adaptively approximated by a curve-fitting function using a query feedback mechanism. This approach has the advantage of requiring no extra database access overhead for gathering statistics and of being able to continuously adapt the value distribution through queries and updates. Experimental results show that the estimation accuracy of this approach is comparable to traditional methods based on statistics gathering.	SIGMOD Conferen	database
2475	SIGMOD Conference	From Structured Documents to Novel Query Facilities.	Vassilis Christophides,Serge Abiteboul,Sophie Cluet,Michel Scholl	1994	Structured documents (e.g., SGML) can benefit a lot from database support and more specifically from object-oriented database (OODB) management systems. This paper describes a natural mapping from SGML documents into OODB's and a formal extension of two OODB query languages (one SQL-like and the other calculus) in order to deal with SGML document retrieval.Although motivated by structured documents, the extensions of query languages that we present are general and useful for a variety of other OODB applications. A key element is the introduction of paths as first class citizens. The new features allow to query data (and to some extent schema) without exact knowledge of the schema in a simple and homogeneous fashion.	SIGMOD Conferen	database
2476	SIGMOD Conference	Optimization of Dynamic Query Evaluation Plans.	Richard L. Cole,Goetz Graefe	1994	Traditional query optimizers assume accurate knowledge of run-time parameters such as selectivities and resource availability during plan optimization, i.e., at compile time. In reality, however, this assumption is often not justified. Therefore, the &ldquo;static&rdquo; plans produced by traditional optimizers may not be optimal for many of their actual run-time invocations. Instead, we propose a novel optimization model that assigns the bulk of the optimization effort to compile-time and delays carefully selected optimization decisions until run-time. Our previous work defined the run-time primitives, &ldquo;dynamic plans&rdquo; using &ldquo;choose-plan&rdquo; operators, for executing such delayed decisions, but did not solve the problem of constructing dynamic plans at compile-time. The present paper introduces techniques that solve this problem. Experience with a working prototype optimizer demonstrates (i) that the additional optimization and start-up overhead of dynamic plans compared to static plans is dominated by their advantage at run-time, (ii) that dynamic plans are as robust as the &ldquo;brute-force&rdquo; remedy of run-time optimization, i.e., dynamic plans maintain their optimality even if parameters change between compile-time and run-time, and (iii) that the start-up overhead of dynamic plans is significantly less than the time required for complete optimization at run-time. In other words, our proposed techniques are superior to both techniques considered to-date, namely compile-time optimization into a single static plan as well as run-time optimization. Finally, we believe that the concepts and technology described can be transferred to commercial query optimizers in order to improve the performance of embedded queries with host variables in the query predicate and to adapt to run-time system loads unpredictable at compile time.	SIGMOD Conferen	database
2477	SIGMOD Conference	Optimizing Queries on Files.	Mariano P. Consens,Tova Milo	1994	We present a framework which allows the user to access and manipulate data uniformly, regardless of whether it resides in a database or in the file system (or in both). A key issue is the performance of the system. We show that text indexing, combined with newly developed optimization techniques, can be used to provide an efficient high level interface to information stored in files. Furthermore, using these techniques, some queries can be evaluated significantly faster than in standard database implementations. We also study the tradeoff between efficiency and the amount of indexing.	SIGMOD Conferen	database
2478	SIGMOD Conference	Partition Selection Policies in Object Database Garbage Collection.	Jonathan E. Cook,Alexander L. Wolf,Benjamin G. Zorn	1994	The automatic reclamation of storage for unreferenced objects is very important in object databases. Existing language system algorithms for automatic storage reclamation have been shown to be inappropriate. In this paper, we investigate methods to improve the performance of algorithms for automatic for automatic storage reclamation of object databases. These algorithms are based on a technique called partitioned garbage collection, in which a subset of the entire database is collected independently of the rest. Specifically, we investigate the policy that is used to select what partition in the database should be collected. The policies that we propose and investigate are based on the intuition that the values of overwritten pointers provide good hints about where to find garbage. Using trace-driven simulation, we show that one of our policies requires less I/O to collect more garbage than any existing implementable policy and performs close to a near-optimal policy over a wide range of database sizes and object connectivities.	SIGMOD Conferen	database
2479	SIGMOD Conference	Oracle's Symmetric Replication Technology and Implications for Application Design.	Dean Daniels,Lip Boon Doo,Alan Downing,Curtis Elsbernd,Gary Hallmark,Sandeep Jain,Bob Jenkins,Peter Lim,Gordon Smith,Benny Souder,Jim Stamos	1994	Oracle's Symmetric Replication Technology and Implications for Application Design.	SIGMOD Conferen	database
2480	SIGMOD Conference	A Performance Study of Transitive Closure Algorithms.	Shaul Dar,Raghu Ramakrishnan	1994	We present a comprehensive performance evaluation of transitive closure (reachability) algorithms for databases. The study is based upon careful implementations of the algorithms, measures page I/O, and covers algorithms for full transitive closure as well as partial transitive closure (finding all successors of each node in a set of given source nodes). We examine a wide range of acyclic graphs with varying density and &ldquo;locality&rdquo; of arcs in the graph. We also consider query parameters such as the selectivity of the query, and system parameters such as the buffer size and the page and successor list replacement policies. We show that significant cost tradeoffs exist between the algorithms in this spectrum and identify the factors that influence the performance of the algorithms.An important aspect of our work is that we measure a number of different cost metrics, giving us a good understanding of the predictive power of these metrics with respect to I/O cost. This is especially significant since metrics such as number of tuples generated or number of successor list operations have been widely used to compare transitive closure algorithms in the literature. Our results strongly suggest that these other metrics cannot be reliability used to predict I/O cost of transitive closure evaluation.	SIGMOD Conferen	database
2481	SIGMOD Conference	Predictive Dynamic Load Balancing of Parallel and Distributed Rule and Query Processing.	Hasanat M. Dewan,Salvatore J. Stolfo,Mauricio A. Hernández,Jae-Jun Hwang	1994	Expert Databases are environments that support the processing of rule programs against a disk resident database. They occupy a position intermediate between active and deductive databases, with respect to the level of abstraction of the underlying rule language. The operational semantics of the rule language influences the problem solving strategy, while the architecture of the processing environment determines efficiency and scalability.In this paper, we present elements of the PARADISER architecture and its kernel rule language, PARULEL. The PARADISER environment provides support for parallel and distributed evaluation of rule programs, as well as static and dynamic load balancing protocols that predictively balance a computation at runtime. This combination of features results in a scalable database rule and complex query processing architecture. We validate our claims by analyzing the performance of the system for two realistic test cases. In particular, we show how the performance of a parallel implementation of transitive closure is significantly improved by predictive dynamic load balancing.	SIGMOD Conferen	database
2482	SIGMOD Conference	DEC Data Distributor: for Data Replication and Data Warehousing.	Daniel J. Dietterich	1994	DEC Data Distributor: for Data Replication and Data Warehousing.	SIGMOD Conferen	database
2483	SIGMOD Conference	METU Object-Oriented DBMS.	Asuman Dogac,Ismailcem Budak Arpinar,Cem Evrendilek,Cetin Ozkan,Ilker Altintas,Ilker Durusoy,Mehmet Altinel,Tansel Okay,Yuksel Saygin	1994	METU Object-Oriented DBMS.	SIGMOD Conferen	database
2484	SIGMOD Conference	NonStop SQL: Scalability and Availability for Decision Support.	Susanne Englert	1994	NonStop SQL: Scalability and Availability for Decision Support.	SIGMOD Conferen	database
2485	SIGMOD Conference	The IMPRESS DDT: A Database Design Toolbox Based on a Formal Specification Language.	Jan Flokstra,Maurice van Keulen,Jacek Skowronek	1994	The IMPRESS DDT: A Database Design Toolbox Based on a Formal Specification Language.	SIGMOD Conferen	database
2486	SIGMOD Conference	Fast Subsequence Matching in Time-Series Databases.	Christos Faloutsos,M. Ranganathan,Yannis Manolopoulos	1994	We present an efficient indexing method to locate 1-dimensional subsequences within a collection of sequences, such that the subsequences match a given (query) pattern within a specified tolerance. The idea is to map each data sequences into a small set of multidimensional rectangles in feature space. Then, these rectangles can be readily indexed using traditional spatial access methods, like the R*-tree [9]. In more detail, we use a sliding window over the data sequence and extract its features; the result is a trail in feature space. We propose an efficient and effective algorithm to divide such trails into sub-trails, which are subsequently represented by their Minimum Bounding Rectangles (MBRs). We also examine queries of varying lengths, and we show how to handle each case efficiently. We implemented our method and carried out experiments on synthetic and real data (stock price movements). We compared the method to sequential scanning, which is the only obvious competitor. The results were excellent: our method accelerated the search time from 3 times up to 100 times.	SIGMOD Conferen	database
2487	SIGMOD Conference	Red Brick Warehouse: A Read-Mostly RDBMS for Open SMP Platforms.	Phillip M. Fernandez	1994	Red Brick Warehouse: A Read-Mostly RDBMS for Open SMP Platforms.	SIGMOD Conferen	database
2488	SIGMOD Conference	Spatial Joins Using Seeded Trees.	Ming-Ling Lo,Chinya V. Ravishankar	1994	Existing methods for spatial joins assume the existence of indices for the participating data sets. This assumption is not realistic for applications involving multiple map layer overlays or for queries involving non-spatial selections. In this paper, we explore a spatial join method that dynamically constructs index trees called seeded trees at join time. This methods uses knowledge of the data sets involved in the join process.Seeded trees are R-tree like structures, and are divided into the seed levels and the grown levels. The nodes in the seed levels are used to guide tree growth during tree construction. The seed levels can also be used to filter out some input data during construction, thereby reducing tree size. We develop a technique that uses intermediate linked lists during tree construction and significantly speeds up the tree construction process. The technique allows a large number of random disk accesses during tree construction to be replaced by smaller numbers of sequential accesses.Our performance studies show that spatial joins using seeded trees outperform those using other methods significantly in terms of disk I/O. The CPU penalties incurred are also lower except when seed-level filtering is used.	SIGMOD Conferen	database
2489	SIGMOD Conference	Outerjoins as Disjunctions.	César A. Galindo-Legaria	1994	The outerjoin operator is currently available in the query language of several major DBMSs, and it is included in the proposed SQL2 standard draft. However, &ldquo;associativity problems&rdquo; of the operator have been pointed out since its introduction. In this paper we propose a shift in the intuition behind outerjoin: Instead of computing the join while also preserving its arguments, outerjoin delivers tuples that come either from the join or from the arguments. Queries with joins and outerjoins deliver tuples that come from one out of several joins, where a single relation is a trivial join. An advantage of this view is that, in contrast to preservation, disjunction is commutative and associative, which is a significant property for intuition, formalisms, and generation of execution plans.Based on a disjunctive normal form, we show that some data merging queries cannot be evaluated by means of binary outerjoins, and give alternative procedures to evaluate those queries. We also explore several evaluation strategies for outerjoin queries, including the use of semijoin programs to reduce base relations.	SIGMOD Conferen	database
2490	SIGMOD Conference	The Effectiveness of GlOSS for the Text Database Discovery Problem.	Luis Gravano,Hector Garcia-Molina,Anthony Tomasic	1994	The popularity of on-line document databases has led to a new problem: finding which text databases (out of many candidate choices) are the most relevant to a user. Identifying the relevant databases for a given query is the text database discovery problem. The first part of this paper presents a practical solution based on estimating the result size of a query and a database. The method is termed GlOSS&mdash;Glossary of Servers Server. The second part of this paper evaluates the effectiveness of GlOSS based on a trace of real user queries. In addition, we analyze the storage cost of our approach.	SIGMOD Conferen	database
2491	SIGMOD Conference	Sybase Replication Server.	Alex Gorelik,Yongdong Wang,Mark Deppe	1994	Sybase Replication Server.	SIGMOD Conferen	database
2492	SIGMOD Conference	Quickly Generating Billion-Record Synthetic Databases.	Jim Gray,Prakash Sundaresan,Susanne Englert,Kenneth Baclawski,Peter J. Weinberger	1994	Evaluating database system performance often requires generating synthetic databases&mdash;ones having certain statistical properties but filled with dummy information. When evaluating different database designs, it is often necessary to generate several databases and evaluate each design. As database sizes grow to terabytes, generation often takes longer than evaluation. This paper presents several database generation techniques. In particular it discusses: (1) Parallelism to get generation speedup and scaleup. (2) Congruential generators to get dense unique uniform distributions. (3) Special-case discrete logarithms to generate indices concurrent to the base table generation. (4) Modification of (2) to get exponential, normal, and self-similar distributions.The discussion is in terms of generating billion-record SQL databases using C programs running on a shared-nothing computer system consisting of a hundred processors, with a thousand discs. The ideas apply to smaller databases, but large databases present the more difficult problems.	SIGMOD Conferen	database
2493	SIGMOD Conference	Ptool: A Scalable Persistent Object Manager.	Robert L. Grossman,Xiao Qin	1994	Ptool: A Scalable Persistent Object Manager.	SIGMOD Conferen	database
2494	SIGMOD Conference	Data Modeling of Time-Based Media.	Simon J. Gibbs,Christian Breiteneder,Dennis Tsichritzis	1994	Many aspects of time-based media&mdash;complex data encoding, compression, &ldquo;quality factors,&rdquo; timing&mdash;appear problematic from a data modeling standpoint. This paper proposes timed streams as the basic abstraction for modeling time-based media. Several media-independent structuring mechanisms are introduced and a data model is presented which, rather than leaving the interpretation of multimedia data to applications, addresses the complex organization and relationships present in multimedia.	SIGMOD Conferen	database
2495	SIGMOD Conference	DBLearn: A System Prototype for Knowledge Discovery in Relational Databases.	Jiawei Han,Yongjian Fu,Yue Huang,Yandong Cai,Nick Cercone	1994	A prototyped data mining system, DBLearn, has been developed, which efficiently and effectively extracts different kinds of knowledge rules from relational databases. It has the following features: high level learning interfaces, tightly integrated with commercial relational database systems, automatic refinement of concept hierarchies, efficient discovery algorithms and good performance. Substantial extensions of its knowledge discovery power towards knowledge mining in object-oriented, deductive and spatial databases are under research and development.	SIGMOD Conferen	database
2496	SIGMOD Conference	Practical Predicate Placement.	Joseph M. Hellerstein	1994	Recent work in query optimization has addressed the issue of placing expensive predicates in a query plan. In this paper we explore the predicate placement options considered in the Montage DBMS, presenting a family of algorithms that form successively more complex and effective optimization solutions. Through analysis and performance measurements of Montage SQL queries, we classify queries and highlight the simplest solution that will optimize each class correctly. We demonstrate limitations of previously published algorithms, and discuss the challenges and feasibility of implementing the various algorithms in a commercial-grade system.	SIGMOD Conferen	database
2497	SIGMOD Conference	On Parallel Execution of Multiple Pipelined Hash Joins.	Hui-I Hsiao,Ming-Syan Chen,Philip S. Yu	1994	In this paper we study parallel execution of multiple pipelined hash joins. Specifically, we deal with two issues, processor allocation and the use of hash filters, to improve parallel execution of hash joins. We first present a scheme to transform a bushy execution tree to an allocation tree, where each node denotes a pipeline. Then, processors are allocated to the nodes in the allocation tree based on the concept of synchronous execution time such that inner relations (i.e., hash tables) in a pipeline can be made available approximately the same time. In addition, the approach of hash filtering is investigated to further improve the overall performance. Performance studies are conducted via simulation to demonstrate the importance of processor allocation and to evaluate various schemes using hash filters. Simulation results indicate that processor allocation based on the allocation tree significantly outperforms that based on the original bushy tree, and that the effect of hash filtering becomes prominent as the number of relations in a query increases.	SIGMOD Conferen	database
2498	SIGMOD Conference	Data Replication for Mobile Computers.	Yixiu Huang,A. Prasad Sistla,Ouri Wolfson	1994	Users of mobile computers will soon have online access to a large number of databases via wireless networks. Because of limited bandwidth, wireless communication is more expensive than wire communication. In this paper we present and analyze various static and dynamic data allocation methods. The objective is to optimize the communication cost between a mobile computer and the stationary computer that stores the online database. Analysis is performed in two cost models. One is connection (or time) based, as in cellular telephones, where the user is charged per minute of connection. The other is message based, as in packet radio networks, where the user is charged per message. Our analysis addresses both, the average case and the worst case for determining the best allocation method.	SIGMOD Conferen	database
2499	SIGMOD Conference	The MYRIAD Federated Database Prototype.	San-Yih Hwang,Ee-Peng Lim,H.-R. Yang,S. Musukula,K. Mediratta,M. Ganesh,Dave Clements,J. Stenoien,Jaideep Srivastava	1994	The MYRIAD Federated Database Prototype.	SIGMOD Conferen	database
2500	SIGMOD Conference	Energy Efficient Indexing on Air.	Tomasz Imielinski,S. Viswanathan,B. R. Badrinath	1994	We consider wireless broadcasting of data as a way of disseminating information to a massive number of users. Organizing and accessing information on wireless communication channels is different from the problem of organizing and accessing data on the disk. We describe two methods, (1,m) Indexing and Distributed Indexing, for organizing and accessing broadcast data. We demonstrate that the proposed algorithms lead to significant improvement of battery life, while retaining a low access time.	SIGMOD Conferen	database
2501	SIGMOD Conference	Incomplete Path Expressions and their Disambiguation.	Yannis E. Ioannidis,Yezdi Lashkari	1994	When we, humans, talk to each other we have no trouble disambiguating what another person means, although our statements are almost never meticulously specified down to very last detail. We &ldquo;fill in the gaps&rdquo; using our common-sense knowledge about the world. We present a powerful mechanism that allows users of object-oriented database systems to specify certain types of ad-hoc queries in a manner closer to the way we pose questions to each other. Specifically, the system accepts as input queries with incomplete, and therefore ambiguous, path expressions. From them, it generates queries with fully-specified path expressions that are consistent with those given as input and capture what the user most likely meant by them. This is achieved by mapping the problem of path expression disambiguation to an optimal path computation (in the transitive closure sense) over a directed graph that represents the schema. Our method works by exploiting the semantics of the kinds of relationships in the schema and requires no special knowledge about the contents of the underlying database, i.e., it is domain independent. In a limited set of experiments with human subjects, the proposed mechanism was very successful in disambiguating incomplete path expressions.	SIGMOD Conferen	database
2502	SIGMOD Conference	Databases for Networks.	H. V. Jagadish	1994	Databases for Networks.	SIGMOD Conferen	database
2503	SIGMOD Conference	Optimizing Disjunctive Queries with Expensive Predicates.	Alfons Kemper,Guido Moerkotte,Klaus Peithner,Michael Steinbrunn	1994	In this work, we propose and assess a technique called bypass processing for optimizing the evaluation of disjunctive queries with expensive predicates. The technique is particularly useful for optimizing selection predicates that contain terms whose evaluation costs vary tremendously; e.g., the evaluation of a nested subquery or the invocation of a user-defined function in an object-oriented or extended relational model may be orders of magnitude more expensive than an attribute access (and comparison). The idea of bypass processing consists of avoiding the evaluation of such expensive terms whenever the outcome of the entire selection predicate can already be induced by testing other, less expensive terms. In order to validate the viability of bypass evaluation, we extend a previously developed optimizer architecture and incorporate three alternative optimization algorithms for generating bypass processing plans.	SIGMOD Conferen	database
2504	SIGMOD Conference	Distributing a Search Tree Among a Growing Number of Processors.	Brigitte Kröll,Peter Widmayer	1994	Databases are growing steadily, and distributed computer systems are more and more easily available. This provides an opportunity to satisfy the increasingly tighter efficiency requirements by means of distributed data structures. The design and analysis of these structures under efficiency aspects, however, has not yet been studied sufficiently. To our knowledge, a single scalable, distributed data structure has been proposed so far. It is a distributed variant of linear hashing with uncontrolled splits, and, as a consequence, performs efficiently for data distributions that are close to uniform, but not necessarily for others. In addition, it does not support queries that refer to the linear order of keys, such as nearest neighbor or range queries. We propose a distributed search tree that avoids these problems, since it inherits desirable properties from non-distributed trees. Our experiments show that our structure does indeed combine a guarantee for good storage space utilization with high query efficiency. Nevertheless, we feel that further research in the area of scalable, distributed data structures is dearly needed; it should eventually lead to a body of knowledge that is comparable with the non-distributed, classical data structures field.	SIGMOD Conferen	database
2505	SIGMOD Conference	A Language Based Multidatabase System.	eva Kühn,Thomas Tschernko,Konrad Schwarz	1994	A Language Based Multidatabase System.	SIGMOD Conferen	database
2506	SIGMOD Conference	Object-Oriented Extensions in SQL3: A Status Report.	Krishna G. Kulkarni	1994	Object-Oriented Extensions in SQL3: A Status Report.	SIGMOD Conferen	database
2507	SIGMOD Conference	Oracle Media Server: Providing Consumer Based Interactive Access to Multimedia Data.	Andrew Laursen,Jeffrey Olkin,Mark Porter	1994	Currently, most data accessed on large servers is structured data stored in traditional databases. Networks are LAN based and clients range from simple terminals to powerful workstations. The user is corporate and the application developer is an MIS professional.With the introduction of broadband communications to the home and better than 100-to-1 compression techniques, a new form of network-based computing is emerging. Structured data is still important, but the bulk of data becomes unstructured: audio, video, news feeds, etc. The predominant user becomes the consumer. The predominant client device becomes the television set. The application developer becomes the storyboard developer, director, or the video production engineer.The Oracle Media Server supports access to all types of conventional data stored in Oracle relational and text databases. In addition, we have developed a real-time stream server that supports storage and playback of real-time audio and video data. The Media Server also provides access to data stored in file systems or as binary large objects (images, executables, etc.)The Oracle Media Server provides a platform for distributed client-server computing and access to data over asymmetric real-time networks. A service mechanism allows applications to be split such that client devices (set-top boxes, personal digital assistants, etc.) can focus on presentation, while backend services running in a distributed server complex, provide access to data via messaging or lightweight RPC (Remote Procedure Call).	SIGMOD Conferen	database
2508	SIGMOD Conference	COSS: The Common Object Services Specifications.	Bruce E. Martin	1994	COSS: The Common Object Services Specifications.	SIGMOD Conferen	database
2509	SIGMOD Conference	Self-Adaptive, On-Line Reclustering of Complex Object Data.	William J. McIver Jr.,Roger King	1994	A likely trend in the development of future CAD, CASE and office information systems will be the use of object-oriented database systems to manage their internal data stores. The entities that these applications will retrieve, such as electronic parts and their connections or customer service records, are typically large complex objects composed of many interconnected heterogeneous objects, not thousands of tuples. These applications may exhibit widely shifting usage patterns due to their interactive mode of operation. Such a class of applications would demand clustering methods that are appropriate for clustering large complex objects and that can adapt on-line to the shifting usage patterns. While most object-oriented clustering methods allow grouping of heterogeneous objects, they are usually static and can only be changed off-line. We present one possible architecture for performing complex object reclustering in an on-line manner that is adaptive to changing usage patterns. Our architecture involves the decomposition of a clustering method into concurrently operating components that each handle one of the fundamental tasks involved in reclustering, namely statistics collection, cluster analysis, and reorganization. We present the results of an experiment performed to evaluate its behavior. These results show that the average miss rate for object accesses can be effectively reduced using a combination of rules that we have developed for deciding when cluster analyses and reorganizations should be performed.	SIGMOD Conferen	database
2510	SIGMOD Conference	Enterprise Information Architectures -- They're Finally Changing.	Wesley P. Melling	1994	Enterprise Information Architectures -- They're Finally Changing.	SIGMOD Conferen	database
2511	SIGMOD Conference	MOSAICO - A System for Conceptual Modeling and Rapid Prototyping of Object-Oriented Database Application.	Michele Missikoff,M. Toiati	1994	MOSAICO - A System for Conceptual Modeling and Rapid Prototyping of Object-Oriented Database Application.	SIGMOD Conferen	database
2512	SIGMOD Conference	A Survey and Critique of Advanced Transaction Models.	C. Mohan	1994	A Survey and Critique of Advanced Transaction Models.	SIGMOD Conferen	database
2513	SIGMOD Conference	ARIES/CSA: A Method for Database Recovery in Client-Server Architectures.	C. Mohan,Inderpal Narang	1994	This paper presents an algorithm, called ARIES/CSA (Algorithm for Recovery and Isolation Exploiting Semantics for Client-Server Architectures), for performing recovery correctly in client-server (CS) architectures. In CS, the server manages the disk version of the database. The clients, after obtaining database pages from the server, cache them in their buffer pools. Clients perform their updates on the cached pages and produce log records. The log records are buffered locally in virtual storage and later sent to the single log at the server. ARIES/CSA supports a write-ahead logging (WAL), fine-granularity (e.g., record) locking, partial rollbacks and flexible buffer management policies like steal and no-force. It does not require that the clocks on the clients and the server be synchronized. Checkpointing by the server and the clients allows for flexible and easier recovery.	SIGMOD Conferen	database
2514	SIGMOD Conference	Implementation of Magic-sets in a Relational Database System.	Inderpal Singh Mumick,Hamid Pirahesh	1994	We describe the implementation of the magic-sets transformation in the Starburst extensible relational database system. To our knowledge this is the first implementation of the magic-sets transformation in a relational database system. The Starburst implementation has many novel features that make our implementation especially interesting to database practitioners (in addition to database researchers). (1) We use a cost-based heuristic for determining join orders (sips) before applying magic. (2) We push all equality and non-equality predicates using magic, replacing traditional predicate pushdown optimizations. (3) We apply magic to full SQL with duplicates, aggregation, null values, and subqueries. (4) We integrate magic with other relational optimization techniques. (5) The implementation is extensible.Our implementation demonstrates the feasibility of the magic-sets transformation for commercial relational systems, and provides a mechanism to implement magic as an integral part of a new database system, or as an add-on to an existing database system.	SIGMOD Conferen	database
2515	SIGMOD Conference	AlphaSort: A RISC Machine Sort.	Chris Nyberg,Tom Barclay,Zarka Cvetanovic,Jim Gray,David B. Lomet	1994	A new sort algorithm, called AlphaSort, demonstrates that commodity processors and disks can handle commercial batch workloads. Using Alpha AXP processors, commodity memory, and arrays of SCSI disks, AlphaSort runs the industry-standard sort benchmark in seven seconds. This beats the best published record on a 32-cpu 32-disk Hypercube by 8:1. On another benchmark, AlphaSort sorted more than a gigabyte in a minute.AlphaSort is a cache-sensitive memory-intensive sort algorithm. It uses file striping to get high disk bandwidth. It uses QuickSort to generate runs and uses replacement-selection to merge the runs. It uses shared memory multiprocessors to break the sort into subsort chores.Because startup times are becoming a significant part of the total time, we propose two new benchmarks: (1) Minutesort: how much can you sort in a minute, and (2) DollarSort: how much can you sort for a dollar.	SIGMOD Conferen	database
2516	SIGMOD Conference	Managing Memory for Real-Time Queries.	HweeHwa Pang,Michael J. Carey,Miron Livny	1994	The demanding performance objectives that real-time database systems (RTDBS) face necessitate the use of priority resource scheduling. This paper introduces a Priority Memory Management (PMM) algorithm that is designed to schedule queries in RTDBS. PMM attempts to minimize the number of missed deadlines by adapting both its multiprogramming level and its memory allocation strategy to the characteristics of the offered workload. A series of simulation experiments confirms that PMM's admission control and memory allocation mechanisms are very effective for real-time query scheduling.	SIGMOD Conferen	database
2517	SIGMOD Conference	Object-Oriented Features of DB2 Client/Server.	Hamid Pirahesh	1994	Object-Oriented Features of DB2 Client/Server.	SIGMOD Conferen	database
2518	SIGMOD Conference	Sequence Query Processing.	Praveen Seshadri,Miron Livny,Raghu Ramakrishnan	1994	Many applications require the ability to manipulate sequences of data. We motivate the importance of sequence query processing, and present a framework for the optimization of sequence queries based on several novel techniques. These include query transformations, optimizations that utilize meta-data, and caching of intermediate results. We present a bottom-up algorithm that generates an efficient query evaluation plan based on cost estimates. This work also identifies a number of directions in which future research can be directed.	SIGMOD Conferen	database
2519	SIGMOD Conference	XSB as an Efficient Deductive Database Engine.	Konstantinos F. Sagonas,Terrance Swift,David Scott Warren	1994	This paper describes the XSB system, and its use as an in-memory deductive database engine. XSB began from a Prolog foundation, and traditional Prolog systems are known to have serious deficiencies when used as database systems. Accordingly, XSB has a fundamental bottom-up extension, introduced through tabling (or memoing)[4], which makes it appropriate as an underlying query engine for deductive database systems. Because it eliminates redundant computation, the tabling extension makes XSB able to compute all modularly stratified datalog programs finitely and with polynomial data complexity. For non-stratified programs, a meta-interpreter with the same properties is provided. In addition XSB significantly extends and improves the indexing capabilities over those of standard Prolog. Finally, its syntactic basis in HiLog [2], lends it flexibility for data modelling.The implementation of XSB derives from the WAM [25], the most common Prolog engine. XSB inherits the WAM's efficiency and can take advantage of extensive compiler technology developed for Prolog. As a result, performance comparisons indicate that XSB is significantly faster than other deductive database systems for a wide range of queries and stratified rule sets. XSB is under continuous development, and version 1.3 is available through anonymous ftp.	SIGMOD Conferen	database
2520	SIGMOD Conference	XSB as a Deductive Database.	Konstantinos F. Sagonas,Terrance Swift,David Scott Warren	1994	XSB as a Deductive Database.	SIGMOD Conferen	database
2521	SIGMOD Conference	Estimating Page Fetches for Index Scans with Finite LRU Buffers.	Arun N. Swami,K. Bernhard Schiefer	1994	We describe an algorithm for estimating the number of page fetches for a partial or complete scan of a B-tree index. The algorithm obtains estimates for the number of page fetches for an index scan when given the number of tuples selected and the number of LRU buffers currently available. The algorithm has an initial phase that is performed exactly once before any estimates are calculated. This initial phase, involving LRU buffer modeling, requires a scan of all the index entries and calculates the number of page fetches for different buffer sizes. An approximate empirical model is obtained from this data. Subsequently, an inexpensive estimation procedure is called by the query optimizer whenever it needs an estimate of the page fetches for the index scan. This procedure utilizes the empirical model obtained in the initial phase.	SIGMOD Conferen	database
2522	SIGMOD Conference	Relaxed Transaction Processing.	Munindar P. Singh,Christine Tomlinson,Darrell Woelk	1994	Relaxed Transaction Processing.	SIGMOD Conferen	database
2523	SIGMOD Conference	The ORES Temporal Database Management System.	Babis Theodoulidis,Aziz Ait-Braham,George Andrianopoulos,Jayant Chaudhary,George Karvelis,Simon Sou	1994	The ORES Temporal Database Management System.	SIGMOD Conferen	database
2524	SIGMOD Conference	Incremental Updates of Inverted Lists for Text Document Retrieval.	Anthony Tomasic,Hector Garcia-Molina,Kurt A. Shoens	1994	With the proliferation of the world's &ldquo;information highways&rdquo; a renewed interest in efficient document indexing techniques has come about. In this paper, the problem of incremental updates of inverted lists is addressed using a new dual-structure index. The index dynamically separates long and short inverted lists and optimizes retrieval, update, and storage of each type of list. To study the behavior of the index, a space of engineering trade-offs which range from optimizing update time to optimizing query performance is described. We quantitatively explore this space by using actual data and hardware in combination with a simulation of an information retrieval system. We then describe the best algorithm for a variety of criteria.	SIGMOD Conferen	database
2525	SIGMOD Conference	The Montage Extensible DataBlade Achitecture.	Michael Ubell	1994	The Montage Extensible DataBlade Achitecture.	SIGMOD Conferen	database
2526	SIGMOD Conference	Database in Crisis and Transition: A Technical Agenda for the Year 2001.	David Vaskevitch	1994	The current paper outlines a number of important changes that face the database community and presents an agenda for how some of these challenges can be met. This database agenda is currently being addressed in the Enterprise Group at Microsoft Corporation. The paper concludes with a scenario for 2001 which reflects the Microsoft vision of &ldquo;Information at your fingertips.&rdquo;	SIGMOD Conferen	database
2527	SIGMOD Conference	Distributed File Organization with Scalable Cost/Performance.	Radek Vingralek,Yuri Breitbart,Gerhard Weikum	1994	This paper presents a distributed file organization for record-structured, disk-resident files with key-based exact-match access. The file is organized into buckets that are spread across multiple servers, where a server may hold multiple buckets. Client requests are serviced by mapping keys onto buckets and looking up the corresponding server in an address table. Dynamic growth in terms of file size and access load is supported by bucket splits and migration onto other existing or newly acquired servers.The significant and challenging problem addressed here is how to achieve scalability so that both the file size and the client throughput can be scaled up by linearly increasing the number of servers and dynamically redistributing data. Unlike previous work with similar objectives, our data redistribution considers explicitly the cost/performance ratio of the system by aiming to minimize the number of servers that are acquired to provide the required performance. A new server is acquired only if the overall server utilization in the system does not drop below a specified threshold. Preliminary simulation results show that the goal of scalability with controlled cost/performance is indeed achieved to a large extent.	SIGMOD Conferen	database
2528	SIGMOD Conference	Combinatorial Pattern Discovery for Scientific Data: Some Preliminary Results.	Jason Tsong-Li Wang,Gung-Wei Chirn,Thomas G. Marr,Bruce A. Shapiro,Dennis Shasha,Kaizhong Zhang	1994	Suppose you are given a set of natural entities (e.g., proteins, organisms, weather patterns, etc.) that possess some important common externally observable properties. You also have a structural description of the entities (e.g., sequence, topological, or geometrical data) and a distance metric. Combinatorial pattern discovery is the activity of finding patterns in the structural data that might explain these common properties based on the metric.This paper presents an example of combinatorial pattern discovery: the discovery of patterns in protein databases. The structural representation we consider are strings and the distance metric is string edit distance permitting variable length don't cares. Our techniques incorporate string matching algorithms and novel heuristics for discovery and optimization, most of which generalize to other combinatorial structures. Experimental results of applying the techniques to both generated data and functionally related protein families obtained from the Cold Spring Harbor Laboratory show the effectiveness of the proposed techniques. When we apply the discovered patterns to perform protein classification, they give information that is complementary to the best protein classifier available today.	SIGMOD Conferen	database
2529	SIGMOD Conference	QuickStore: A High Performance Mapped Object Store.	Seth J. White,David J. DeWitt	1994	QuickStore is a memory-mapped storage system for persistent C++, built on top of the EXODUS Storage Manager. QuickStore provides fast access to in-memory objects by allowing application programs to access objects via normal virtual memory pointers. This article presents the results of a detailed performance study using the OO7 benchmark. The study compares the performance of QuickStore with the latest implementation of the E programming language. The QuickStore and E systems exemplify the two basic approaches (hardware and software) that have been used to implement persistence in object-oriented database systems. In addition, both systems use the same underlying storage manager and compiler, allowing us to make a truly apples-to-apples comparison of the hardware and software techniques.	SIGMOD Conferen	database
2530	SIGMOD Conference	Ensuring Relaxed Atomicity for Flexible Transactions in Multidatabase Systems.	Aidong Zhang,Marian H. Nodine,Bharat K. Bhargava,Omran A. Bukhres	1994	Global transaction management requires cooperation from local sites to ensure the consistent and reliable execution of global transactions in a distributed database system. In a heterogeneous distributed database (or multidatabase) environment, various local sites make conflicting assertions of autonomy over the execution of global transactions. A flexible transaction model for the specification of global transactions makes it possible to deal robustly with these conflicting requirements. This paper presents an approach that preserves the semi-atomicity (a weaker form of atomicity) of flexible transactions, allowing local sites to autonomously maintain serializability and recoverability. We offer a fundamental characterization of the flexible transaction model and precisely define the semi-atomicity. We investigate the commit dependencies among the subtransactions of a flexible transaction. These dependencies are used to control the commitment order of the subtransactions. We next identify those restrictions that must be placed upon a flexible transaction to ensure the maintenance of its semi-atomicity. As atomicity is a restrictive criterion, semi-atomicity enhances the class of executable global transactions.	SIGMOD Conferen	database
2531	VLDB	Supporting Exceptions to Schema Consistency to Ease Schema Evolution in OODBMS.	Eric Amiel,Marie-Jo Bellosta,Eric Dujardin,Eric Simon	1994	Supporting Exceptions to Schema Consistency to Ease Schema Evolution in OODBMS.	VLDB	database
2532	VLDB	An Empirical Performance Study of the Ingres Search Accelerator for a Large Property Management Database System.	Sarabjot S. Anand,David A. Bell,John G. Hughes	1994	An Empirical Performance Study of the Ingres Search Accelerator for a Large Property Management Database System.	VLDB	database
2533	VLDB	Fast Algorithms for Mining Association Rules in Large Databases.	Rakesh Agrawal,Ramakrishnan Srikant	1994	Fast Algorithms for Mining Association Rules in Large Databases.	VLDB	database
2534	VLDB	A Transaction Replication Scheme for a Replicated Database with Node Autonomy.	Ada Wai-Chee Fu,David Wai-Lok Cheung	1994	A Transaction Replication Scheme for a Replicated Database with Node Autonomy.	VLDB	database
2535	VLDB	An Algebraic Approach to Rule Analysis in Expert Database Systems.	Elena Baralis,Jennifer Widom	1994	Expert database systems extend the functionality of conventional database systems by providing a facility for creating and automatically executing Condition-Action rules. While Condition-Action rules in database systems are very powerful, they also can be very difficult to program, due to the unstructured and unpredictable nature of rule processing. We provide methods for static analysis of Condition-Action rules; our methods determine whether a given rule set is guaranteed to terminate, and whether rule execution is confluent (has a guaranteed unique final state). Our methods are based on previous methods for analyzing rules in active database systems. We improve considerably on the previous methods by providing analysis criteria that are much less conservative: our methods often determine that a rule set will terminate or is confluent when previous methods could not. Our improved analysis is based on a ``propagation'''' algorithm, which uses a formal approach based on an extended relational algebra to accurately determine when the action of one rule can affect the condition of another. Our algebraic approach yields methods that are applicable to a broad class of expert database rule languages.	VLDB	database
2536	VLDB	An Effective Deductive Object-Oriented Database Through Language Integration.	Maria L. Barja,Norman W. Paton,Alvaro A. A. Fernandes,M. Howard Williams,Andrew Dinn	1994	An Effective Deductive Object-Oriented Database Through Language Integration.	VLDB	database
2537	VLDB	An Overview of Repository Technology.	Philip A. Bernstein,Umeshwar Dayal	1994	An Overview of Repository Technology.	VLDB	database
2538	VLDB	PC Database Systems - Present and Future.	Philip A. Bernstein	1994	PC Database Systems - Present and Future.	VLDB	database
2539	VLDB	Semantic Integration in Heterogeneous Databases Using Neural Networks.	Wen-Syan Li,Chris Clifton	1994	Semantic Integration in Heterogeneous Databases Using Neural Networks.	VLDB	database
2540	VLDB	The Impact of Global Clustering on Spatial Database Systems.	Thomas Brinkhoff,Hans-Peter Kriegel	1994	The Impact of Global Clustering on Spatial Database Systems.	VLDB	database
2541	VLDB	Fast Incremental Indexing for Full-Text Information Retrieval.	Eric W. Brown,James P. Callan,W. Bruce Croft	1994	Fast Incremental Indexing for Full-Text Information Retrieval.	VLDB	database
2542	VLDB	Towards Automated Performance Tuning for Complex Workloads.	Kurt P. Brown,Manish Mehta,Michael J. Carey,Miron Livny	1994	Towards Automated Performance Tuning for Complex Workloads.	VLDB	database
2543	VLDB	Efficient and Effective Clustering Methods for Spatial Data Mining.	Raymond T. Ng,Jiawei Han	1994	Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also develop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms. Furthermore, experiments conducted to compare the performance of CLARANS with that of existing clustering methods show that CLARANS is the most efficient.	VLDB	database
2544	VLDB	Maximizing Buffer and Disk Utilizations for News On-Demand.	Raymond T. Ng,Jinhai Yang	1994	Maximizing Buffer and Disk Utilizations for News On-Demand.	VLDB	database
2545	VLDB	Composite Events for Active Databases: Semantics, Contexts and Detection.	Sharma Chakravarthy,V. Krishnaprasad,Eman Anwar,S.-K. Kim	1994	Composite Events for Active Databases: Semantics, Contexts and Detection.	VLDB	database
2546	VLDB	Content-Based Image Indexing.	Tzi-cker Chiueh	1994	Content-Based Image Indexing.	VLDB	database
2547	VLDB	Including Group-By in Query Optimization.	Surajit Chaudhuri,Kyuseok Shim	1994	Including Group-By in Query Optimization.	VLDB	database
2548	VLDB	On Index Selection Schemes for Nested Object Hierarchies.	Sudarshan S. Chawathe,Ming-Syan Chen,Philip S. Yu	1994	On Index Selection Schemes for Nested Object Hierarchies.	VLDB	database
2549	VLDB	A Multidatabase System for Tracking and Retrieval of Financial Data.	Munir Cochinwala,John Bradley	1994	A Multidatabase System for Tracking and Retrieval of Financial Data.	VLDB	database
2550	VLDB	NAOS - Efficient and Modular Reactive Capabilities in an Object-Oriented Database System.	Christine Collet,Thierry Coupaye,T. Svensen	1994	NAOS - Efficient and Modular Reactive Capabilities in an Object-Oriented Database System.	VLDB	database
2551	VLDB	Memory-Contention Responsive Hash Joins.	Diane L. Davison,Goetz Graefe	1994	Memory-Contention Responsive Hash Joins.	VLDB	database
2552	VLDB	Client-Server Paradise.	David J. DeWitt,Navin Kabra,Jun Luo,Jignesh M. Patel,Jie-Bing Yu	1994	Client-Server Paradise.	VLDB	database
2553	VLDB	Implementing Lazy Database Updates for an Object Database System.	Fabrizio Ferrandina,Thorsten Meyer,Roberto Zicari	1994	Implementing Lazy Database Updates for an Object Database System.	VLDB	database
2554	VLDB	OdeFS: A File System Interface to an Object-Oriented Database.	Narain H. Gehani,H. V. Jagadish,William D. Roome	1994	OdeFS: A File System Interface to an Object-Oriented Database.	VLDB	database
2555	VLDB	Access to Objects by Path Expressions and Rules.	Jürgen Frohn,Georg Lausen,Heinz Uphoff	1994	Object oriented databases provide rich structuring capabilities to organize the objects being relevant for a given application. Due to the possible complexity of object structures, path expressions have become accepted as a concise syntactical means to reference objects. Even though known approaches to path expressions provide quite elegant access to objects, there seems to be still a need for more generality. To this end, the rule-language PathLog is introduced. A first contribution of PathLog is to add a second dimension to path expressions in order to increase conciseness. In addition, a path expression can also be used to reference virtual objects. Both enhancements give rise to interesting semantic implications.	VLDB	database
2556	VLDB	Qualified Answers That Reflect User Needs and Preferences.	Terry Gaasterland,Jorge Lobo	1994	Qualified Answers That Reflect User Needs and Preferences.	VLDB	database
2557	VLDB	Fast, Randomized Join-Order Selection - Why Use Transformations?	César A. Galindo-Legaria,Arjan Pellenkoft,Martin L. Kersten	1994	Fast, Randomized Join-Order Selection - Why Use Transformations?	VLDB	database
2558	VLDB	Building a Laboratory Information System Around a C++-Based Object-Oriented DBMS.	Nathan Goodman,Steve Rozen,Lincoln Stein	1994	Building a Laboratory Information System Around a C++-Based Object-Oriented DBMS.	VLDB	database
2559	VLDB	Database Graph Views: A Practical Model to Manage Persistent Graphs.	Alejandro Gutiérrez,Philippe Pucheral,Hermann Steffen,Jean-Marc Thévenin	1994	Database Graph Views: A Practical Model to Manage Persistent Graphs.	VLDB	database
2560	VLDB	GraphDB: Modeling and Querying Graphs in Databases.	Ralf Hartmut Güting	1994	GraphDB: Modeling and Querying Graphs in Databases.	VLDB	database
2561	VLDB	Optimization Algorithms for Exploiting the Parallelism-Communication Tradeoff in Pipelined Parallelism.	Waqar Hasan,Rajeev Motwani	1994	Optimization Algorithms for Exploiting the Parallelism-Communication Tradeoff in Pipelined Parallelism.	VLDB	database
2562	VLDB	Modelling and Querying Video Data.	Rune Hjelsvold,Roger Midtstraum	1994	Modelling and Querying Video Data.	VLDB	database
2563	VLDB	Performance of Data-Parallel Spatial Operations.	Erik G. Hoel,Hanan Samet	1994	Performance of Data-Parallel Spatial Operations.	VLDB	database
2564	VLDB	Providing Dynamic Security Control in a Federated Database.	Norbik Bashah Idris,W. A. Gray,R. F. Churchhouse	1994	Providing Dynamic Security Control in a Federated Database.	VLDB	database
2565	VLDB	Data Compression Support in Databases.	Balakrishna R. Iyer,David Wilhite	1994	Data Compression Support in Databases.	VLDB	database
2566	VLDB	Dalí: A High Performance Main Memory Storage Manager.	H. V. Jagadish,Daniel F. Lieuwen,Rajeev Rastogi,Abraham Silberschatz,S. Sudarshan	1994	Dalí: A High Performance Main Memory Storage Manager.	VLDB	database
2567	VLDB	2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm.	Theodore Johnson,Dennis Shasha	1994	2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm.	VLDB	database
2568	VLDB	An Approach for Building Secure Database Federations.	Dirk Jonscher,Klaus R. Dittrich	1994	An Approach for Building Secure Database Federations.	VLDB	database
2569	VLDB	Hilbert R-tree: An Improved R-tree using Fractals.	Ibrahim Kamel,Christos Faloutsos	1994	Hilbert R-tree: An Improved R-tree using Fractals.	VLDB	database
2570	VLDB	Dual-Buffering Strategies in Object Bases.	Alfons Kemper,Donald Kossmann	1994	Dual-Buffering Strategies in Object Bases.	VLDB	database
2571	VLDB	Indexing Multiple Sets.	Christoph Kilger,Guido Moerkotte	1994	Indexing Multiple Sets.	VLDB	database
2572	VLDB	Experiments on Access to Digital Libraries: How can Images and Text be Used Together.	Michael Lesk	1994	Experiments on Access to Digital Libraries: How can Images and Text be Used Together.	VLDB	database
2573	VLDB	Query Optimization by Predicate Move-Around.	Alon Y. Levy,Inderpal Singh Mumick,Yehoshua Sagiv	1994	Query Optimization by Predicate Move-Around.	VLDB	database
2574	VLDB	Challenges for Global Information Systems.	Alon Y. Levy,Abraham Silberschatz,Divesh Srivastava,Maria Zemankova	1994	Challenges for Global Information Systems.	VLDB	database
2575	VLDB	RP*: A Family of Order Preserving Scalable Distributed Data Structures.	Witold Litwin,Marie-Anne Neimat,Donovan A. Schneider	1994	RP*: A Family of Order Preserving Scalable Distributed Data Structures.	VLDB	database
2576	VLDB	On Spatially Partitioned Temporal Join.	Hongjun Lu,Beng Chin Ooi,Kian-Lee Tan	1994	On Spatially Partitioned Temporal Join.	VLDB	database
2577	VLDB	Relating Distributed Objects.	Bruce E. Martin,R. G. G. Cattell	1994	Relating Distributed Objects.	VLDB	database
2578	VLDB	Persistent Threads.	Florian Matthes,Joachim W. Schmidt	1994	Persistent Threads.	VLDB	database
2579	VLDB	V-Trees - A Storage Method for Long Vector Data.	Maurício R. Mediano,Marco A. Casanova,Marcelo Dreux	1994	V-Trees - A Storage Method for Long Vector Data.	VLDB	database
2580	VLDB	Some Issues in Design of Distributed Deductive Databases.	Mukesh K. Mohania,Nandlal L. Sarda	1994	Some Issues in Design of Distributed Deductive Databases.	VLDB	database
2581	VLDB	A Requirement-Based Approach to Data Modeling and Re-Engineering.	Alice H. Muntz,Christian T. Ramiller	1994	A Requirement-Based Approach to Data Modeling and Re-Engineering.	VLDB	database
2582	VLDB	A Top-Down Approach for Two Level Serializability.	Mourad Ouzzani,M. A. Atroun,N. L. Belkhodja	1994	A Top-Down Approach for Two Level Serializability.	VLDB	database
2583	VLDB	A Low-Cost Storage Server for Movie on Demand Databases.	Banu Özden,Alexandros Biliris,Rajeev Rastogi,Abraham Silberschatz	1994	A Low-Cost Storage Server for Movie on Demand Databases.	VLDB	database
2584	VLDB	Materialization: A Powerful and Ubiquitous Abstraction Pattern.	Alain Pirotte,Esteban Zimányi,David Massart,Tatiana Yakusheva	1994	Materialization: A Powerful and Ubiquitous Abstraction Pattern.	VLDB	database
2585	VLDB	Investigation of Algebraic Query Optimisation Techniques for Database Programming Languages.	Alexandra Poulovassilis,Carol Small	1994	Investigation of Algebraic Query Optimisation Techniques for Database Programming Languages.	VLDB	database
2586	VLDB	Data Integration in the Large: The Challenge of Reuse.	Arnon Rosenthal,Leonard J. Seligman	1994	Data Integration in the Large: The Challenge of Reuse.	VLDB	database
2587	VLDB	New Concurrency Control Algorithms for Accessing and Compacting B-Trees.	V. W. Setzer,Andrea Zisman	1994	New Concurrency Control Algorithms for Accessing and Compacting B-Trees.	VLDB	database
2588	VLDB	Cache Conscious Algorithms for Relational Query Processing.	Ambuj Shatdal,Chander Kant,Jeffrey F. Naughton	1994	Cache Conscious Algorithms for Relational Query Processing.	VLDB	database
2589	VLDB	Reasoning About Spatial Relationships in Picture Retrieval Systems.	A. Prasad Sistla,Clement T. Yu,R. Haddad	1994	Reasoning About Spatial Relationships in Picture Retrieval Systems.	VLDB	database
2590	VLDB	User Interfaces; Who Cares?	Stefano Spaccapietra	1994	User Interfaces; Who Cares?	VLDB	database
2591	VLDB	The hcC-tree: An Efficient Index Structure for Object Oriented Databases.	B. Sreenath,S. Seshadri	1994	The hcC-tree: An Efficient Index Structure for Object Oriented Databases.	VLDB	database
2592	VLDB	Cumulative Updates.	Suryanarayana M. Sripada,Beat Wüthrich	1994	Cumulative Updates.	VLDB	database
2593	VLDB	From Nested-Loop to Join Queries in OODB.	Hennie J. Steenhagen,Peter M. G. Apers,Henk M. Blanken,Rolf A. de By	1994	From Nested-Loop to Join Queries in OODB.	VLDB	database
2594	VLDB	Towards Event-Driven Modelling for Database Design.	Maguelonne Teisseire,Pascal Poncelet,Rosine Cicchetti	1994	Towards Event-Driven Modelling for Database Design.	VLDB	database
2595	VLDB	The GMAP: A Versatile Tool for Physical Data Independence.	Odysseas G. Tsatalos,Marvin H. Solomon,Yannis E. Ioannidis	1994	Physical data independence is touted as a central feature of modern database systems. It allows users to frame queries in terms of the logical structure of the data, letting a query processor automatically translate them into optimal plans that access physical storage structures. Both relational and object-oriented systems, however, force users to frame their queries in terms of a logical schema that is directly tied to physical structures. We present an approach that eliminates this dependence. All storage structures are defined in a declarative language based on relational algebra as functions of a logical schema. We present an algorithm, integrated with a conventional query optimizer, that translates queries over this logical schema into plans that access the storage structures. We also show how to compile update requests into plans that update all relevant storage structures consistently and optimally. Finally, we report on experiments with a prototype implementation of our approach that demonstrate how it allows storage structures to be tuned to the expected or observed workload to achieve significantly better performance than is possible with conventional techniques.	VLDB	database
2596	VLDB	Bulk Loading into an OODB: A Performance Study.	Janet L. Wiener,Jeffrey F. Naughton	1994	Bulk Loading into an OODB: A Performance Study.	VLDB	database
2597	VLDB	Join Index Hierarchies for Supporting Efficient Navigations in Object-Oriented Databases.	Zhaohui Xie,Jiawei Han	1994	Join Index Hierarchies for Supporting Efficient Navigations in Object-Oriented Databases.	VLDB	database
2598	VLDB	Integrating a Structured-Text Retrieval System with an Object-Oriented Database System.	Tak W. Yan,Jurgen Annevelink	1994	Integrating a Structured-Text Retrieval System with an Object-Oriented Database System.	VLDB	database
2599	VLDB	Scientific Databases - State of the Art and Future Directions.	Maria Zemankova,Yannis E. Ioannidis	1994	Scientific Databases - State of the Art and Future Directions.	VLDB	database
2600	SIGMOD Record	Loading Databases Using Dataflow Parallelism.	Tom Barclay,Robert Barnes,Jim Gray,Prakash Sundaresan	1994	This paper describes a parallel database load prototype for Digital's Rdb database product. The prototype takes a dataflow approach to database parallelism. It includes an explorer that discovers and records the cluster configuration in a database, a client CUI interface that gathers the load job description from the user and from the Rdb catalogs, and an optimizer that picks the best parallel execution plan and records it in a web data structure. The web describes the data operators, the dataflow rivers among them, the binding of operators to processes, processes to processors, and files to discs and tapes. This paper describes the optimizer's cost-based hierarchical optimization strategy in some detail. The prototype executes the web's plan by spawning a web manager process at each node of the cluster. The managers create the local executor processes, and orchestrate startup, phasing, checkpoint, and shutdown. The execution processes perform one or more operators. Data flows among the operators are via memory-to-memory streams within a node, and via web-manager multiplexed tcp/ip streams among nodes. The design of the transaction and checkpoint/restart mechanisms are also described. Preliminary measurements indicate that this design will give excellent scaleups.	SIGMOD Record	database
2601	SIGMOD Record	Data Modelling in the Large.	Martin Bertram	1994	Data Modelling in the Large.	SIGMOD Record	database
2602	SIGMOD Record	Trade Press News.	Rafael Alonso	1994	Trade Press News.	SIGMOD Record	database
2603	SIGMOD Record	Trade Press News.	Rafael Alonso	1994	Trade Press News.	SIGMOD Record	database
2604	SIGMOD Record	Trade Press News - Announcement and Preface.	Rafael Alonso	1994	Trade Press News - Announcement and Preface.	SIGMOD Record	database
2605	SIGMOD Record	SEQUOIA 2000 Metadata Schema for Satellite Images.	Jean T. Anderson,Michael Stonebraker	1994	Sequoia 2000 schema development is based on emerging geospatial standards to accelerate development and facilitate data exchange. This paper focuses on the metadata schema for digital satellite images. We examine how satellite metadata are defined, used, and maintained. We discuss the geospatial standards we are using, and describe a SQL prototype that is based on the Spatial Archive and Interchange Format (SAIF) standard and implemented in the Illustra object-relational database.	SIGMOD Record	database
2606	SIGMOD Record	The Impact of Database Research on Industrial Products (Panel Summary).	Daniel Barbará,José A. Blakeley,Daniel H. Fishman,David B. Lomet,Michael Stonebraker	1994	The Impact of Database Research on Industrial Products (Panel Summary).	SIGMOD Record	database
2607	SIGMOD Record	Metadata for Multimedia Documents.	Klemens Böhm,Thomas C. Rakow	1994	In this article metadata for mulimedia documents are classified in conformity with their nature, and the different kinds of metadata are brought into relation with the different purposes intended. We describe how metadata may be organized in accordance with the ISO standards SGML, which facilitates the handling of structured documents, and DFR, which supports the storage of collections of documents. Finally, we outline the impact of our observations on future developments.	SIGMOD Record	database
2608	SIGMOD Record	Comprehension Syntax.	Peter Buneman,Leonid Libkin,Dan Suciu,Val Tannen,Limsoon Wong	1994	The syntax of comprehensions is very close to the syntax of a number of practical database query languages and is, we believe, a better starting point than first-order logic for the development of database languages. We give an informal account of a language based on comprehension syntax that deals uniformly with a variety of collection types; it also includes pattern matching, variant types and function definition. We show, again informally, how comprehension syntax is a natural fragment of structural recursion, a much more powerful programming paradigm for collection types. We also show that a very small abstract syntax language can serve as a basis for the implementation and optimization of comprehension syntax.	SIGMOD Record	database
2609	SIGMOD Record	Database Research at NTHU and ITRI.	Arbee L. P. Chen	1994	Database Research at NTHU and ITRI.	SIGMOD Record	database
2610	SIGMOD Record	Metadata for Mixed-Media Access.	Francine Chen,Marti A. Hearst,Julian Kupiec,Jan O. Pedersen,Lynn Wilcox	1994	In this paper, we discuss mixed-media access, an information access paradigm for multimedia data in which the media type of a query may differ from that of the data. The types of media considered in this paper are speech, images of text, and full-length text. Some examples of metadata for mixed-media access are locations of keywords in speech and images, identification of speakers, locations of emphasized regions in speech, and locations of topic boundaries in text. Algorithms for automatically generating this metadata are described, including word spotting, speaker segmentation, emphatic speech detection, and subtopic boundary location. We illustrate queries composed of diverse media types in an example of access to recorded meetings, via speaker and keyword location.	SIGMOD Record	database
2611	SIGMOD Record	Research Issues in Databases for ARCS: Active Rapidly Changing Data Systems.	Anindya Datta	1994	We identify an emergent class of database systems that has not been dealt with extensively in the literature that we call ARCS (Active, Rapidly Changing data Systems) databases. These systems impose certain unique requirements on databases that monitor and control them. These requirements are such that traditional data and transaction management models appear inadequate. We present an analysis of data and transaction characteristics in ARCS systems and identify relevant research issues.	SIGMOD Record	database
2612	SIGMOD Record	Supporting Dynamic Displays Using Active Rules.	Oscar Díaz,Arturo Jaime,Norman W. Paton,Ghassan al-Qaimari	1994	In a graphical interface which is used to display database objects, dynamic displays are updated automatically as modifications occur to the database objects being visualised. Approaches based on enlarging either the database system or the interface code to provide the appropriate communication, complicates the interaction between the two systems, as well as making later updates cumbersome. In this paper, an approach based on active rules is presented. The declarative and modular description of active rules enables active displays to be supported with minimal changes to the database or its graphical interface. Although this approach has been used to support the link between a database system and its graphical interface, it can easily be adapted to support dynamic interaction between an active database system and other external systems.	SIGMOD Record	database
2613	SIGMOD Record	Research Perspectives for Time Series Management Systems.	Werner Dreyer,Angelika Kotz Dittrich,Duri Schmidt	1994	Empirical research based on time series is a data intensive activity that needs a data base management system (DBMS). We investigate the special properties a time series management system (TSMS) should have. We then show that currently available solutions and related research directions are not well suited to handle the existing problems. Therefore, we propose the development of a special purpose TSMS, which will offer particular modeling, retrieval, and computation capabilities. It will be suitable for end users, offer direct manipulation interfaces, and allow data exchange with a variety of data sources, including other databases and application packages. We intend to build such a system on top of an off-the-shelf object-oriented DBMS.	SIGMOD Record	database
2614	SIGMOD Record	Influencing Database Language Standards.	Leonard Gallagher	1994	In this first article of the regular column on data base standardization activities, I give an overview of topic areas under active development in the formal national and international standardization bodies. I solicit contributions on these active topics so that standardizers and researchers can cooperate in the near term, before irreversible decisions are made, to produce the most useful and highest quality database standards.	SIGMOD Record	database
2615	SIGMOD Record	Constructing the Next 100 Database Management Systems.	Andreas Geppert,Klaus R. Dittrich	1994	Constructing the Next 100 Database Management Systems.	SIGMOD Record	database
2616	SIGMOD Record	Metadata for Integrating Speech Documents in a Text Retrieval System.	Ulrike Glavitsch,Peter Schäuble,Martin Wechsler	1994	We present an information retrieval system that simultaneously allows to search for text and speech documents. The retrieval system accepts vague queries and performs a best-match search to find those documents that are relevant to the query. The output of the retrieval system is a list of ranked documents where the documents on the top of the list satisfy best the user's information need. The relevance of the documents is estimated by means of metadata (document description vectors). The metadata is automatically generated and it is organized such that queries can be processed efficiently. We introduce a controlled indexing vocabulary for both speech and text documents. The size of the new indexing vocabulary is small (1000 features) compared with the sizes of indexing vocabularies of conventional text retrieval (10000 - 100000 features). We show that the retrieval effectiveness based on such a small indexing vocabulary is similar to the retrieval effectiveness of a Boolean retrieval system.	SIGMOD Record	database
2617	SIGMOD Record	Using Metadata for the Intelligent Browsing of Structured Media Objects.	William I. Grosky,Farshad Fotouhi,Ishwar K. Sethi	1994	Using Metadata for the Intelligent Browsing of Structured Media Objects.	SIGMOD Record	database
2618	SIGMOD Record	Response to the March 1994 ODMG-93 Commentary Written by Dr. Won Kim of UniSQL, Inc.	Object Database Management Group	1994	Response to the March 1994 ODMG-93 Commentary Written by Dr. Won Kim of UniSQL, Inc.	SIGMOD Record	database
2619	SIGMOD Record	Metadata in Video Databases.	Ramesh Jain,Arun Hampapur	1994	Video is composed of audio-visual information. Providing content based access to video data is essential for the sucessful integration of video into computers. Organizing video for content based access requires the use of video metadata. This paper explores the nature video metadata. A data model for video databases is presented based on a study of the applications of video, the nature of video retrieval requests, and the features of video. The data model is used in the architectural framework of a video database. The current state of technology in video databases is summarized and research issues are highlighted.	SIGMOD Record	database
2620	SIGMOD Record	A Consensus Glossary of Temporal Database Concepts.	Christian S. Jensen,James Clifford,Ramez Elmasri,Shashi K. Gadia,Patrick J. Hayes,Sushil Jajodia	1994	A Consensus Glossary of Temporal Database Concepts.	SIGMOD Record	database
2621	SIGMOD Record	Observations on the ODMG-93 Proposal.	Won Kim	1994	Observations on the ODMG-93 Proposal.	SIGMOD Record	database
2622	SIGMOD Record	A Metadatabase System for Semantic Image Search by a Mathematical Model of Meaning.	Yasushi Kiyoki,Takashi Kitagawa,Takanari Hayama	1994	In the design of multimedia database systems, one of the most important issues is to extract images dynamically according to the user's impression and the image's contents. In this paper, we present a metadatabase system which realizes the semantic associative search for images by giving keywords representing the user's impression and the image's contents.This metadatabase system provides several functions for performing the semantic associative search for images by using the metadata representing the features of images. These functions are realized by using our proposed mathematical model of meaning. The mathematical model of meaning is extended to compute specific meanings of keywords which are used for retrieving images unambiguously and dynamically. The main feature of this model is that the semantic associative search is performed in the orthogonal semantic space. This space is created for dynamically computing semantic equivalence or similarity between the metadata items of the images and keywords.	SIGMOD Record	database
2623	SIGMOD Record	Metadata for Digital Media: Introduction to the Special Issue.	Wolfgang Klas,Amit P. Sheth	1994	Metadata for Digital Media: Introduction to the Special Issue.	SIGMOD Record	database
2624	SIGMOD Record	How to Modify SQL Queries in Order to Guarantee Sure Answers.	Hans-Joachim Klein	1994	Some problems connected with the handling of null values in SQL are discussed. A definition of sure answers to SQL queries is proposed which takes care of the &ldquo;no information&rdquo; meaning of null values in SQL. An algorithm is presented for modifying SQL queries such that answers are not changed for databases without null values but sure answers are obtained for arbitrary databases with standard SQL semantics.	SIGMOD Record	database
2625	SIGMOD Record	Text Databases: A Survey of Text Models and Systems.	Arjan Loeffen	1994	Text models focus on the manipulation of textual data. They describe texts by their structure, operations on the texts, and constraints on both structure and operations. In this article common characteristics of machine readable texts in general are outlined. Subsequently, ten text models are introduced. They are described in terms of the datatypes that they support, and the operations defined by these datatypes. Finally, the models are compared.	SIGMOD Record	database
2626	SIGMOD Record	Recent Design Trade-offs in SQL3.	Nelson Mendonça Mattos,Linda G. DeMichiel	1994	Recent Design Trade-offs in SQL3.	SIGMOD Record	database
2627	SIGMOD Record	Databases for GIS.	Claudia Bauzer Medeiros,Fatima Pires	1994	Databases for GIS.	SIGMOD Record	database
2628	SIGMOD Record	The Database Research Group at ETH Zurich.	Moira C. Norrie,Stephen Blott,Hans-Jörg Schek,Gerhard Weikum	1994	The Database Research Group at ETH Zurich.	SIGMOD Record	database
2629	SIGMOD Record	Towards an Infrastructure for Temporal Databases: Report of an Invitational ARPA/NSF Workshop.	Niki Pissinou,Richard T. Snodgrass,Ramez Elmasri,Inderpal Singh Mumick,M. Tamer Özsu,Barbara Pernici,Arie Segev,Babis Theodoulidis,Umeshwar Dayal	1994	Towards an Infrastructure for Temporal Databases: Report of an Invitational ARPA/NSF Workshop.	SIGMOD Record	database
2630	SIGMOD Record	Jumping on the NII Bandwagon.	Xiaolei Qian	1994	Many requests for proposals have been issued since the last issue of this column appeared six months ago. We first briefly touch upon some recent developments along the policy/legislation front concerning NSF, ARPA, and HPCC. We then recap the recent requests for proposals from ARPA, NSF, Air Force, NASA, and Army.	SIGMOD Record	database
2631	SIGMOD Record	Announcements from NSF, NASA, and Elsewhere.	Xiaolei Qian	1994	Announcements from NSF, NASA, and Elsewhere.	SIGMOD Record	database
2632	SIGMOD Record	Medical Information Systems: Characterization and Challenges.	Jorge C. G. Ramirez,Lon A. Smith,Lynn L. Peterson	1994	This paper examines the characteristics and challenges presented by medical databases and medical information systems. It begins with a survey of medical databases/information systems. This is followed by a list of challenges for database management systems generated by the needs of these systems. It concludes with a look at some systems which address these challenges. In the context of this background information, the database community is asked to consider whether the results of database research are reaching those who are making day-to-day decisions regarding design and implementation of medical information systems.	SIGMOD Record	database
2633	SIGMOD Record	Unix RDBMS: The Next Generation.	Bill Rosneblatt	1994	Unix RDBMS: The Next Generation.	SIGMOD Record	database
2634	SIGMOD Record	Editor's Notes.	Arie Segev	1994	Editor's Notes.	SIGMOD Record	database
2635	SIGMOD Record	Editor's Notes.	Arie Segev	1994	Editor's Notes.	SIGMOD Record	database
2636	SIGMOD Record	Editor's Notes and Erratum.	Arie Segev	1994	Editor's Notes and Erratum.	SIGMOD Record	database
2637	SIGMOD Record	A New Join Algorithm.	Dong Keun Shin,Arnold Charles Meltzer	1994	This paper introduces a new efficient join algorithm to increase the speed of the join relational operation. Using a divide and conquer strategy, stack oriented filter technique in the new join algorithm filters unwanted tuples as early as possible while none of the currently existing join algorithms takes advantage of any filtering concept. Other join algorithms may carry the unnecessary tuples up to the last moment of join attribute comparisons.Four join algorithms are described and discussed in this paper: the nested-loop join algorithm, the sort-merge join algorithm, the hash join algorithm, and the new join algorithm.	SIGMOD Record	database
2638	SIGMOD Record	In Memory of Bob Kooi (1951-1993).	Michael Stonebraker	1994	In Memory of Bob Kooi (1951-1993).	SIGMOD Record	database
2639	SIGMOD Record	Overview of the Special Section on Temporal Database Infrastructure.	Richard T. Snodgrass	1994	Overview of the Special Section on Temporal Database Infrastructure.	SIGMOD Record	database
2640	SIGMOD Record	TSQL2 Language Specification.	Richard T. Snodgrass,Ilsoo Ahn,Gad Ariav,Don S. Batory,James Clifford,Curtis E. Dyreson,Ramez Elmasri,Fabio Grandi,Christian S. Jensen,Wolfgang Käfer,Nick Kline,Krishna G. Kulkarni,T. Y. Cliff Leung,Nikos A. Lorentzos,John F. Roddick,Arie Segev,Michael D. Soo,Suryanarayana M. Sripada	1994	TSQL2 Language Specification.	SIGMOD Record	database
2641	SIGMOD Record	A TSQL2 Tutorial.	Richard T. Snodgrass,Ilsoo Ahn,Gad Ariav,Don S. Batory,James Clifford,Curtis E. Dyreson,Ramez Elmasri,Fabio Grandi,Christian S. Jensen,Wolfgang Käfer,Nick Kline,Krishna G. Kulkarni,T. Y. Cliff Leung,Nikos A. Lorentzos,John F. Roddick,Arie Segev,Michael D. Soo,Suryanarayana M. Sripada	1994	A TSQL2 Tutorial.	SIGMOD Record	database
2642	SIGMOD Record	Are the Terms Version and Variant Orthogonal to One Another? A Critical Assessment of the STEP Standardization.	Hartmut Wedekind	1994	Are the Terms Version and Variant Orthogonal to One Another? A Critical Assessment of the STEP Standardization.	SIGMOD Record	database
2643	SIGMOD Record	Research Issues in Active Database Systems: Report from the Closing Panel at RIDE-ADS '94.	Jennifer Widom	1994	The discussions during the panel stayed largely but not entirely focused on the question of active database research issues from the application perspective. There were nine panelists. Each panelist was asked to prepare brief answers to a set of questions. The sets of answers were discussed by all participants, and finally a number of more general issues were discussed. The questions asked of the panelists were: Name an application that will certainly be supported by active database systems in the not-too-distant future. Name an application that will certainly not be supported by active database systems in the near future. Name an area of active database systems in which you are not working but that is crucial to meet the needs of applications. Name an area of active database systems that is not on the critical path to supporting applications. Name an area of active database systems that should have been discussed in the course of the workshop but was not.	SIGMOD Record	database
2644	SIGMOD Record	Progress on HPCC and NII.	Marianne Winslett	1994	In this issue we briefly touch on the continuing turmoil over NSF, ARPA, and HPCC, and the brighter news regarding the US National Information Infrastructure plan. We then describe funding opportunities from NSF, ARPA, the National Security Agency, the National Center for Automated Information Research, the Air Force, and NASA.	SIGMOD Record	database
2645	SIGMOD Record	The TSQL2 Final Language Definition Announcement.		1994	The TSQL2 Final Language Definition Announcement.	SIGMOD Record	database
2646	SIGMOD Record	Calls for Papers / Announcements.		1994	Calls for Papers / Announcements.	SIGMOD Record	database
2647	SIGMOD Record	Calls for Papers / Announcements.		1994	Calls for Papers / Announcements.	SIGMOD Record	database
2648	SIGMOD Record	A Hypertext Query Language for Images.	Li Yang	1994	HYPERQUERY is a hypertext query language for object-oriented pictorial database systems. First, we discuss object calculus based on term rewriting. Then, example queries are used to illustrate language facilities. This query language has been designed with a flavor similar to QBE as the highly nonprocedural and conversational language for object-oriented pictorial database management system OISDBS.	SIGMOD Record	database
2649	SIGMOD Record	Performance Evaluation of a New Distributed Deadlock Detection Algorithm.	Chim-fu Yeung,Sheung-lun Hung,Kam-yiu Lam	1994	In this paper, a new probe-based distributed deadlock detection algorithm is proposed. It is an enhanced version of the algorithm originally proposed by Chandy's et al. [5,6]. The new algorithm has proven to be error free and suffers very little performance degradation from the additional deadlock detection overhead. The algorithm has been compared with the modified probe-based and timeout methods. It is found that under high data contention, it has the best performance. Results also indicate that the rate of probe initiation is significantly reduced in the new algorithm.	SIGMOD Record	database
2650	Artificial Intelligence in Medicine	Polygenic trait analysis by neural network learning.	L. Fu	1994	Polygenic trait analysis by neural network learning.	Artificial Inte	medical
2651	Artificial Intelligence in Medicine	Removing the assumption of conditional independence from Bayesian decision models by using artificial neural networks: some practical techniques and a case study.	Y. C. Wu,D. H. Gustafson	1994	Removing the assumption of conditional independence from Bayesian decision models by using artificial neural networks: some practical techniques and a case study.	Artificial Inte	medical
2652	Artificial Intelligence in Medicine	A neural model of cortical map reorganization following a focal lesion.	Steven L. Armentrout,James A. Reggia,Michael Weinrich	1994	A neural model of cortical map reorganization following a focal lesion.	Artificial Inte	medical
2653	Artificial Intelligence in Medicine	A methodology for evaluation of knowledge-based systems in medicine.	K. Clarke,R. O'Moore,R. Smeets,Jan L. Talmon,Jytte Brender,Peter McNair,Pirkko Nykänen,Jane Grimson,B. Barber	1994	A methodology for evaluation of knowledge-based systems in medicine.	Artificial Inte	medical
2654	Artificial Intelligence in Medicine	A causal and temporal reasoning model and its use in drug therapy applications.	Pedro Barahona	1994	A causal and temporal reasoning model and its use in drug therapy applications.	Artificial Inte	medical
2655	Artificial Intelligence in Medicine	Reusable influence diagrams.	Riccardo Bellazzi,Silvana Quaglini	1994	Reusable influence diagrams.	Artificial Inte	medical
2656	Artificial Intelligence in Medicine	A support for decision-making: cost-sensitive learning system.	Ivan Bruha,Sylva Kocková	1994	A support for decision-making: cost-sensitive learning system.	Artificial Inte	medical
2657	Artificial Intelligence in Medicine	On using feedforward neural networks for clinical diagnostic tasks.	Georg Dorffner,Gerold Porenta	1994	On using feedforward neural networks for clinical diagnostic tasks.	Artificial Inte	medical
2658	Artificial Intelligence in Medicine	On the quality of neural net classifiers.	Michael Egmont-Petersen,Jan L. Talmon,Jytte Brender,Peter McNair	1994	On the quality of neural net classifiers.	Artificial Inte	medical
2659	Artificial Intelligence in Medicine	A resource guide to VR in medicine.	T. Emerson,J. Prothero,Suzanne Weghorst	1994	A resource guide to VR in medicine.	Artificial Inte	medical
2660	Artificial Intelligence in Medicine	An object-oriented approach to knowledge representation in a biomedical domain.	Marco Ensing,Ray Paton,Piet-Hein Speel,Roy Rada	1994	An object-oriented approach to knowledge representation in a biomedical domain.	Artificial Inte	medical
2661	Artificial Intelligence in Medicine	Neural computing in medicine.	Norberto Ezquerra,A. Pazos	1994	Neural computing in medicine.	Artificial Inte	medical
2662	Artificial Intelligence in Medicine	Integrating consultation and semi-automatic knowledge acquisition in a prototype-based architecture: experiences with dysmorphic syndromes.	Lothar Gierl,S. Stengel-Rutkowski	1994	Integrating consultation and semi-automatic knowledge acquisition in a prototype-based architecture: experiences with dysmorphic syndromes.	Artificial Inte	medical
2663	Artificial Intelligence in Medicine	Augmenting reality in rehabilitation medicine.	Walter J. Greenleaf,Maria A. Tovar	1994	Augmenting reality in rehabilitation medicine.	Artificial Inte	medical
2664	Artificial Intelligence in Medicine	Dynamic force feedback in a virtual knee palpation.	Noshir A. Langrana,Grigore C. Burdea,K. Lange,Daniel Gomez,Sonal Deshpande	1994	Dynamic force feedback in a virtual knee palpation.	Artificial Inte	medical
2665	Artificial Intelligence in Medicine	Combining rule-based reasoning and mathematical modelling in diabetes care.	E. D. Lehmann,T. Deutsch,Ewart R. Carson,P. H. Sönksen	1994	Combining rule-based reasoning and mathematical modelling in diabetes care.	Artificial Inte	medical
2666	Artificial Intelligence in Medicine	Methodological issues in validating decision-support systems for insulin dosage adjustment.	H. J. Leicester,Abdul V. Roudsari,E. D. Lehmann,Ewart R. Carson	1994	Methodological issues in validating decision-support systems for insulin dosage adjustment.	Artificial Inte	medical
2667	Artificial Intelligence in Medicine	Identifying the measurement noise in glaucomatous testing: an artificial neural network approach.	Xiaohui Liu,Gongxian Cheng,John Xingwang Wu	1994	Identifying the measurement noise in glaucomatous testing: an artificial neural network approach.	Artificial Inte	medical
2668	Artificial Intelligence in Medicine	Refinement of the HEPAR expert system: tools and techniques.	Peter J. F. Lucas	1994	Refinement of the HEPAR expert system: tools and techniques.	Artificial Inte	medical
2669	Artificial Intelligence in Medicine	Effective retrieval in Hospital Information Systems: the use of context in answering queries to Patient Discharge Summaries.	Brenda Nangle,Mark T. Keane	1994	Effective retrieval in Hospital Information Systems: the use of context in answering queries to Patient Discharge Summaries.	Artificial Inte	medical
2670	Artificial Intelligence in Medicine	The evaluation of expert diagnostic systems. How to assess outcomes and quality parameters?	C. Nohr	1994	The evaluation of expert diagnostic systems. How to assess outcomes and quality parameters?	Artificial Inte	medical
2671	Artificial Intelligence in Medicine	Fundamentals of clinical methodology: 1. Differential indication.	Kazem Sadegh-Zadeh	1994	Fundamentals of clinical methodology: 1. Differential indication.	Artificial Inte	medical
2672	Artificial Intelligence in Medicine	Emerging medical applications of virtual reality: a surgeon's perspective.	Richard M. Satava	1994	Emerging medical applications of virtual reality: a surgeon's perspective.	Artificial Inte	medical
2673	Artificial Intelligence in Medicine	Information technology factors in transferability of knowledge based systems in medicine.	T. Schioler,Jan L. Talmon,J. Nolan,Peter McNair	1994	Information technology factors in transferability of knowledge based systems in medicine.	Artificial Inte	medical
2674	Artificial Intelligence in Medicine	Methods in the Virtual Wetlab I: rule-based reasoning driven by nearest-neighbor lattice dynamics.	Hans B. Sieburg	1994	Methods in the Virtual Wetlab I: rule-based reasoning driven by nearest-neighbor lattice dynamics.	Artificial Inte	medical
2675	Artificial Intelligence in Medicine	Learning and discovery from a clinical database: an incremental concept formation approach.	Von-Wun Soo,Jan-Sin Wang,Shih-Pu Wang	1994	Learning and discovery from a clinical database: an incremental concept formation approach.	Artificial Inte	medical
2676	Artificial Intelligence in Medicine	Towards productive Knowledge-Based Systems in clinical organizations: a methods perspective.	Toomas Timpka,E. Rauch,James M. Nyce	1994	Towards productive Knowledge-Based Systems in clinical organizations: a methods perspective.	Artificial Inte	medical
2677	Artificial Intelligence in Medicine	High-specificity neurological localization using a connectionist model.	Stanley Tuhrim,James A. Reggia,Yun Peng	1994	High-specificity neurological localization using a connectionist model.	Artificial Inte	medical
2678	Artificial Intelligence in Medicine	Integration of quantitative and qualitative reasoning: an expert system for cardiosurgical patients.	Mauro Ursino,E. Artioli,G. Avanzolini,V. Potuto	1994	Integration of quantitative and qualitative reasoning: an expert system for cardiosurgical patients.	Artificial Inte	medical
2679	Artificial Intelligence in Medicine	Finding temporal patterns - a set-based approach.	T. D. Wade,P. J. Byrns,J. F. Steiner,J. Bondy	1994	Finding temporal patterns - a set-based approach.	Artificial Inte	medical
2680	Artificial Intelligence in Medicine	Virtual reality in medicine.	Suzanne Weghorst	1994	Virtual reality in medicine.	Artificial Inte	medical
2681	FOCS	Priority Encoding Transmission	Andres Albanese,Johannes Blömer,Jeff Edmonds,Michael Luby,Madhu Sudan	1994	We introduce a novel approach for sending messages over lossy packet-based networks. The new method, called Priority Encoding Transmission, allows a user to specify a different priority on each segment of the message. Based on the priorities, the sender uses the system to encode the segments into packets for transmission. The system ensures recovery of the segments in order of their priority. The priority of a segment determines the minimum number of packets sufficient to recover the segment. We define a measure for a set of priorities, called the rate, which dictates how much information about the message must be contained in each bit of the encoding. We develop systems for implementing any set of priorities with rate equal to one. We also give an information-theoretic proof that there is no system that implements a set of priorities with rate greater than one. This work has applications to multi-media and high speed networks applications, especially in those with bursty sources and multiple receivers with heterogeneous capabilities.	FOCS	theory
2682	FOCS	``Go With the Winners'' Algorithms	David Aldous,Umesh V. Vazirani	1994	We can view certain randomized optimization algorithms as rules for randomly moving a particle around in a state space; each state might correspond to a distinct solution to the optimization problem, or more generally, the state space might express some other structure underlying the optimization algorithm. In this setting, a general paradigm for designing heuristics is to run several simulations of the algorithm simultaneously, and every so often classify the particles as doing well or doing badly, and move each particle that is doing badly to the position of one that is doing well. In this paper, we give a rigorous analysis of such a go with the winners scheme in the concrete setting of searching for a deep leaf in a tree. There are two relevant parameters of the tree: its depth d, and another parameter /spl kappa/ which is a measure of the imbalance of the tree. We prove that the running time of the go with the winners scheme (to achieve 99% probability of success) is bounded by a polynomial in d and /spl kappa/. By contrast, the simple restart scheme: run several independent simulations and pick the deepest leaf encountered takes time exponential in /spl kappa/ and d in the worst-case. We also show that any algorithm that guarantees a constant probability of success must have worst case running time at least /spl kappa/d.	FOCS	theory
2683	FOCS	Algorithmic Number Theory-The Complexity Contribution	Leonard M. Adleman	1994	Though algorithmic number theory is one of man's oldest intellectual pursuits, its current vitality is perhaps unrivalled in history. This is due in part to the injection of new ideas from computational complexity. In this paper, a brief history of the symbiotic relationship between number theory and complexity theory will be presented. In addition, some of the technical aspects underlying 'modern' methods of primality testing and factoring will be described. Finally, an extensive lists of open problems in algorithmic number theory will be provided.	FOCS	theory
2684	FOCS	Measure on Small Complexity Classes, with Applications for BPP	Eric Allender,Martin Strauss	1994	We present a notion of resource-bounded measure for P and other subexponential-time classes. This generalization is based on Lutz's notion of measure, but overcomes the limitations that cause Lutz's definitions to apply only to classes at least as large as E. We present many of the basic properties of this measure, and use it to explore the class of sets that are hard for BPP. Bennett and Gill showed that almost all sets are hard for BPP; Lutz improved this from Lebesgue measure to measure on ESPACE. We use our measure to improve this still further, showing that for all /spl epsiv/>0, almost every set in E/sub /spl epsiv// is hard for BPP, where E/sub /spl epsiv//=/spl cup//sub /spl delta/	FOCS	theory
2685	FOCS	A Theory of Competitive Analysis for Distributed Algorithms	Miklós Ajtai,James Aspnes,Cynthia Dwork,Orli Waarts	1994	We introduce a theory of competitive analysis for distributed algorithms. The first steps in this direction were made in the seminal papers of Y. Bartal et al. (1992), and of B. Awerbuch et al. (1992), in the context of data management and job scheduling. In these papers, as well as in other subsequent sequent work, the cost of a distributed algorithm is compared to the cost of an optimal global-control algorithm. In this paper we introduce a more refined notion of competitiveness for distributed algorithms, one that reflects the performance of distributed algorithms more accurately. In particular, our theory allows one to compare the cost of a distributed on-line algorithm to the cost of an optimal distributed algorithm. We demonstrate our method by studying the cooperative collect primitive, first abstracted by M. Saks, N. Shavit, and H. Woll (1991). We provide the first algorithms that allow processes to cooperate to finish their work in fewer steps. Specifically, we present two algorithms (with different strengths), and provide a competitive analysis for each one.	FOCS	theory
2686	FOCS	Polynomial time randomised approxmiation schemes for the Tutte polynomial of dense graphs	Noga Alon,Alan M. Frieze,Dominic Welsh	1994	The Tutte-Grothendieck polynomial T(G; x, y) of a graph G encodes numerous interesting combinatorial quantities associated with the graph. Its evaluation in various points in the (x,y) plane gave the number of spanning forests of the graph, the number of its strongly connected orientations, the number of its proper k-colorings, the (all terminal) reliability probability of the graph, and various other invariants the exact computation of each of which is well known to be P-hard. Here we develop a general technique that supplies fully polynomial randomised approximation schemes for approximating the valve of T(G; x,, y) for any dense graph G, that is, any graph on n vertices whose minimum degree is /spl Omega/(n), whenever x/spl ges/1 and y/spl ges/1, and in various additional points. This region includes evaluations of reliability and partition functions of the ferromagnetic Q-state Potts model. Extensions to linear matroids where T specialises to the weight enumerator of linear codes are considered as well.	FOCS	theory
2687	FOCS	Parallel Algorithms for Higher-Dimensional Convex Hulls	Nancy M. Amato,Michael T. Goodrich,Edgar A. Ramos	1994	We give fast randomized and deterministic parallel methods for constructing convex hulls in R/sup d/, for any fixed d. Our methods are for the weakest shared-memory model, the EREW PRAM, and have optimal work bounds (with high probability for the randomized methods). In particular, we show that the convex hull of n points in R/sup d/ can be constructed in O(log n) time using O(n log n+n/sup [d/2]/) work, with high probability. We also show that it can be constructed deterministically in O(log/sup 2/ n) time using O(n log n) work for d=3 and in O(log n) time using O(n/sup [d/2]/ log/sup c([d/2]-[d/2]/) n) work for d/spl ges/4, where c>0 is a constant which is optimal for even d/spl ges/4. We also show how to make our 3-dimensional methods output-sensitive with only a small increase in running time. These methods can be applied to other problems as well.	FOCS	theory
2688	FOCS	A New Efficient Radix Sort	Arne Andersson,Stefan Nilsson	1994	We present new improved algorithms for the sorting problem. The algorithms are not only efficient but also clear and simple. First, we introduce Forward Radix Sort which combines the advantages of traditional left-to-right and right-to-left radix sort in a simple manner. We argue that this algorithm will work very well in practice. Adding a preprocessing step, we obtain an algorithm with attractive theoretical properties. For example, n binary strings can be sorted in /spl Theta/ (n log(B/(n log n)+2)) time, where B is the minimum number of bits that have to be inspected to distinguish the strings. This is an improvement over the previously best known result by Paige and Tarjan (1987). The complexity may also be expressed in terms of H, the entropy of the input: n strings from a stationary ergodic process can be sorted in /spl Theta/ (n log(1/H+1)) time an improvement over the result recently presented by Chen and Reif (1993).	FOCS	theory
2689	FOCS	Randomized and deterministic algorithms for geometric spanners of small diameter	Sunil Arya,David M. Mount,Michiel H. M. Smid	1994	Let S be a set of n points in IR/sup d/ and let t>1 be a real number. A t-spanner for S is a directed graph having the points of S as its vertices, such that for any pair p and q of points there is a path from p to q of length at most t times the Euclidean distance between p and p. Such a path is called a t-spanner path. The spanner diameter of such a spanner is defined as the smallest integer D such that for any pair p and q of points there is a t-spanner path from p to q containing at most D edges. Randomized and deterministic algorithms are given for constructing t-spanners consisting of O(n) edges and having O(log n) diameter. Also, it is shown how to maintain the randomized t-spanner under random insertions and deletions. Previously, no results were known for spanners with low spanner diameter and for maintaining spanners under insertions and deletions.	FOCS	theory
2690	FOCS	Local Optimization of Global Objectives: Competitive Distributed Deadlock Resolution and Resource Allocation	Baruch Awerbuch,Yossi Azar	1994	The work is motivated by deadlock resolution and resource allocation problems, occurring in distributed server-client architectures. We consider a very general setting which includes, as special cases, distributed bandwidth management in communication networks, as well as variations of classical problems in distributed computing and communication networking such as deadlock: resolution and dining philosophers. In the current paper, we exhibit first local solutions with globally-optimum performance guarantees. An application of our method is distributed bandwidth management in communication networks. In this setting, deadlock resolution (and maximum fractional independent set) corresponds to admission control maximizing network throughput. Job scheduling (and minimum fractional coloring) corresponds to route selection that minimizes load.	FOCS	theory
2691	FOCS	On-line Admission Control and Circuit Routing for High Performance Computing and Communication	Baruch Awerbuch,Rainer Gawlick,Frank Thomson Leighton,Yuval Rabani	1994	This paper considers the problems of admission control and virtual circuit routing in high performance computing and communication systems. Admission control and virtual circuit routing problems arise in numerous applications, including video-servers, real-lime database servers, and the provision of permanent virtual channel in large-scale communications networks. The paper describes both upper and lower bounds on the competitive ratio of algorithms for admission control and virtual circuit routing in trees, arrays, and hypercubes (the networks most commonly used in conjunction with nigh performance computing and communication). Our results include optimal algorithms for admission control and virtual circuit routing in trees, as well as the first competitive algorithms for these problems on non-tree networks. A key result of our research is the development of on-line algorithms that substantially outperform the greedy-based approaches that are used in practice.	FOCS	theory
2692	FOCS	On the Combinatorial and Algebraic Complexity of Quantifier Elimination	Saugata Basu,Richard Pollack,Marie-Françoise Roy	1994	In this paper we give a new algorithm for performing quantifier elimination from first order formulae over real closed fields. This algorithm improves the complexity of the asymptotically fastest algorithm for this problem, known to this date. A new feature of our algorithm is that the role of the algebraic part (the dependence on the degrees of the input polynomials) and the combinatorial part (the dependence on the number of polynomials) are separated, making possible our improved complexity bound. Another new feature is that the degrees of the polynomials in the equivalent quantifier-free formula that we output, are independent of the number of input polynomials. As special cases of this algorithm, we obtain new and improved algorithms for deciding a sentence in the first order theory over real closed fields, and also for solving the existential problem in the first order theory over real closed fields. Using the theory developed in this paper, we also give an improved bound on the radius of a ball centered at the origin, which is guaranteed to intersect every connected component of the sign partition induced by a family of polynomials. We also use our methods to obtain algorithms for solving certain decision problems in real and complex geometry which improves the complexity of the currently known algorithms for these problems.	FOCS	theory
2693	FOCS	Lower Bound on Hilbert's Nullstellensatz and propositional proofs	Paul Beame,Russell Impagliazzo,Jan Krajícek,Toniann Pitassi,Pavel Pudlák	1994	The weak form of the Hilbert's Nullstellensatz says that a system of algebraic equations over a field, Q/sub i/(x~)=0, does not have a solution in the algebraic closure iff 1 is in the ideal generated by the polynomials Q/sub i/(x~). We shall prove a lower bound on the degrees of polynomials P/sub i/(x~) such that /spl Sigma//sub i/ P/sub i/(x~)Q/sub i/(x~)=1. This result has the following application. The modular counting principle states that no finite set whose cardinality is not divisible by q can be partitioned into q-element classes. For each fixed cardinality N, this principle can be expressed as a propositional formula Count/sub q//sup N/. Ajtai (1988) proved recently that, whenever p, q are two different primes, the propositional formulas Count/sub q//sup qn+1/ do not have polynomial size, constant-depth Frege proofs from instances of Count/sub p//sup m/, m/spl ne/0 (mod p). We give a new proof of this theorem based on the lower bound for the Hilbert's Nullstellensatz. Furthermore our technique enables us to extend the independence results for counting principles to composite numbers p and q. This results in an exact characterization of when Count/sub q/ can be proven efficiently from Count/sub p/, for all p and q.	FOCS	theory
2694	FOCS	Randomness-Efficient Oblivious Sampling	Mihir Bellare,John Rompel	1994	We introduce a natural notion of obliviousness of a sampling procedure, and construct a randomness-efficient oblivious sampler. Our sampler uses O(l+log /spl delta//sup -1//spl middot/log l) coins to output m=poly(/spl epsiv//sup -1/, log /spl delta//sup -1/, log l) sample points x/sub 1/, ..., x/sub m/, /spl isin/ {0, 1}/sup 1/ such that Pr[|1/m/spl Sigma//sub i=1//sup m/f(x/sub i/)-E[f]|	FOCS	theory
2695	FOCS	Algebraic Computation Trees in Characteristi p>0 (Extended Abstract)	Michael Ben-Or	1994	Algebraic Computation Trees in Characteristi p>0 (Extended Abstract)	FOCS	theory
2696	FOCS	The Power of Team Exploration: Two Robots Can Learn Unlabeled Directed Graphs	Michael A. Bender,Donna K. Slonim	1994	We show that two cooperating robots can learn exactly any strongly-connected directed graph with n indistinguishable nodes in expected time polynomial in n. We introduce a new type of homing sequence for two robots which helps the robots recognize certain previously-seen nodes. We then present an algorithm in which the robots learn the graph and the homing sequence simultaneously by wandering actively through the graph. Unlike most previous learning results using homing sequences, our algorithm does not require a teacher to provide counterexamples. Furthermore, the algorithm can use efficiently any additional information available that distinguishes nodes. We also present an algorithm in which the robots learn by taking random walks. The rate at which a random walk converges to the stationary distribution is characterized by the conductance of the graph. Our random-walk algorithm learns in expected time polynomial in n and in the inverse of the conductance and is more efficient than the homing-sequence algorithm for high-conductance graphs.	FOCS	theory
2697	FOCS	Program Result-Checking: A Theory of Testing Meets a Test of Theory	Manuel Blum,Hal Wasserman	1994	We review the field of result-checking, discussing simple checkers and self-correctors. We argue that such checkers could profitably be incorporated in software as an aid to efficient debugging and reliable functionality. We consider how to modify traditional checking methodologies to make them more appropriate for use in real-time, real-number computer systems. In particular, we suggest that checkers should be allowed to use stored randomness: i.e., that they should be allowed to generate, pre-process, and store random bits prior to run-time, and then to use this information repeatedly in a series of run-time checks. In a case study of checking a general real-number linear transformation (for example, a Fourier Transform), we present a simple checker which uses stored randomness, and a self-corrector which is particularly efficient if stored randomness is allowed.	FOCS	theory
2698	FOCS	Scheduling Multithreaded Computations by Work Stealing	Robert D. Blumofe	1994	Scheduling Multithreaded Computations by Work Stealing	FOCS	theory
2699	FOCS	On Learning Discretized Geometric Concepts (Extended Abstract)	Nader H. Bshouty,Zhixiang Chen,Steven Homer	1994	On Learning Discretized Geometric Concepts (Extended Abstract)	FOCS	theory
2700	FOCS	A Spectral Approach to Lower Bounds	Bernard Chazelle	1994	We establish a nonlinear lower bound for halfplane range searching over a group. Specifically, we show that summing up the weights of n (weighted) points within n halfplanes requires /spl Omega/(n log n) additions and subtractions. This is the first nontrivial lower bound for range searching over a group. By constrast, range searching over a semigroup (which forbids subtractions) is almost completely understood. Our proof has two parts: First, we develop a general, entropy-based, method for relating the linear circuit complexity of a linear map A to the spectrum of A/sup T/A. In the second part of the proof, we design a high-spectrum geometric set system and, using techniques from discrepancy theory, we estimate the median eigenvalue of its associated map. Interestingly, the method also shows that using up to a linear number of help gates cannot help; these are gates that can compute any bivariate function. The best feature of our method is that it is very general. With any instance of range searching we associate a quadratic form: any lower bound on the mid-range of its spectrum implies a lower bound on the complexity of that range searching problem. The main drawback of our approach is that it (probably) yields weak lower bounds. Another shortcoming is that the method does not seem to generalize to range searching over rings or fields.	FOCS	theory
2701	FOCS	Efficient Average-Case Algorithms for the Modular Group	Jin-yi Cai,Wolfgang H. J. Fuchs,Dexter Kozen,Zicheng Liu	1994	The modular group occupies a central position in many branches of mathematical sciences. In this paper we give average polynomial-time algorithms for the unbounded and bounded membership problems for finitely generated subgroups of the modular group. The latter result affirms a conjecture of Y. Gurevich (1990).	FOCS	theory
2702	FOCS	The Complexity of the Membership Problem for 2-generated Commutative Semigroups of Rational Matrices	Jin-yi Cai,Richard J. Lipton,Yechezkel Zalcstein	1994	We present a deterministic polynomial-time algorithm for the ABC problem, which is the membership problem for 2-generated commutative linear semigroups over an algebraic number field. We also obtain a polynomial time algorithm, for the (easier) membership problem, for 2-generated abelian linear groups. Furthermore, we provide a polynomial-sized encoding for the set of all solutions.	FOCS	theory
2703	FOCS	Set constraints with projections are in NEXPTIME	Witold Charatonik,Leszek Pacholski	1994	Systems of set constraints describe relations between sets of ground terms. They have been successfully used in program analysis and type inference. In this paper we prove that the problem of existence of a solution of a system of set constraints with projections is in NEXPTIME, and thus that it is NEXPTIME-complete. This extends the result of A. Aiken, D. Kozen, and E.L. Wimmers (1993) and R. Gilleron, S. Tison, and M. Tommasi (1990) on decidability of negated set constraints and solves a problem that was open for several years.	FOCS	theory
2704	FOCS	More Output-Sensitive Geometric Algorithms (Extended Abstract)	Kenneth L. Clarkson	1994	More Output-Sensitive Geometric Algorithms (Extended Abstract)	FOCS	theory
2705	FOCS	Estimating the Size of the Transitive Closure in Linear Time	Edith Cohen	1994	Computing transitive closure and reachability information in directed graphs is a fundamental graph problem with many applications. The fastest known algorithms run in O(sm) time for computing all nodes reachable from each of 1/spl les/s/spl les/n source nodes, or, using fast matrix multiplication, in O(n/sup 2.38/) time for computing the transitive closure, where n is the number of nodes and m the number of edges in the graph. In query optimization in database applications it is often the case that only estimates on the size of the transitive closure and on the number of nodes reachable from certain nodes are needed. We present an O(m) time randomized algorithm that estimates the number of nodes reachable from every node and the size of the transitive closure. We also obtain a O/spl tilde/(m) time algorithm for estimating sizes of neighborhoods in directed graphs with nonnegative weights, avoiding the O/spl tilde/(mn) time bound of explicitly computing these neighborhoods. Our size-estimation algorithms are much faster than performing the actual computations and improve significantly over previous estimation methods.	FOCS	theory
2706	FOCS	PAC Learning with Irrelevant Attributes	Aditi Dhagat,Lisa Hellerstein	1994	We consider the problem of learning in the presence of irrelevant attributes in Valiant's PAC model (1984). In the PAC model, the goal of the learner is to produce an approximately correct hypothesis from random sample data. If the number of relevant attributes in the target function is small, it may be desirable to produce a hypothesis that also depends on only a small number of variables. Haussler (1988) previously considered the problem of learning monomials of a small number of variables. He showed that the greedy set cover approximation algorithm can be used as a polynomial-time Occam algorithm for learning monomials on r of n variables. A outputs a monomial on r(ln q+1) variables, where q is the number of negative examples in the sample. We extend this result by showing that there is a polynomial-time Occam algorithm for learning k-term DNF formulas depending on r of n variables that outputs a DNF formula depending on O(r/sup k/log/sup k/q) variables, where q is the number of negative examples in the sample. We also give a polynomial-time Occam algorithm for learning decision lists (sometimes called 1-decision lists) with k alternations.	FOCS	theory
2707	FOCS	Finding the k Shortest Paths	David Eppstein	1994	We give algorithms for finding the k shortest paths (not required to be simple) connecting a pair of vertices in a digraph. Our algorithms output an implicit representation of these paths in a digraph with n vertices and m edges, in time O(m+n log n+k). We can also find the k shortest paths from a given source s to each vertex in the graph, in total time O(m+n log n+kn). We describe applications to dynamic programming problems including the knapsack problem, sequence alignment, and maximum inscribed polygons.	FOCS	theory
2708	FOCS	Optimizing Static Calendar Queues	K. Bruce Erickson,Richard E. Ladner,Anthony LaMarca	1994	The calendar queue is an important implementation of a priority queue which is particularly useful in discrete event simulators. In this paper we present an analysis of the static calendar queue which maintains N active events. A step of the discrete event simulator removes and processes the event with the smallest associated time and inserts a new event whose associated time is the time of the removed event plus a random increment with mean /spl mu/. We demonstrate that for the infinite bucket calendar queue the optimal bucket width is approximately /spl delta//sub opt/=/spl radic/(2b/c)/spl mu//N where b is the time to process an empty bucket and c the incremental time to process a list element. With bucket width chosen to be /spl delta//sub opt/, the expected time to process an event is approximately minimized at the constant c+/spl radic/(2bc)+d, where d is the fixed time to process an event. We show that choosing the number of buckets to be O(N) yields a calendar queue with performance equal to or almost equal to the performance of the infinite bucket calendar queue.	FOCS	theory
2709	FOCS	Optimal Evolutionary Tree Comparison by Sparse Dynamic Programming (Extended Abstract)	Martin Farach,Mikkel Thorup	1994	Optimal Evolutionary Tree Comparison by Sparse Dynamic Programming (Extended Abstract)	FOCS	theory
2710	FOCS	Finding separator cuts in planar graphs within twice the optimal	Naveen Garg,Huzur Saran,Vijay V. Vazirani	1994	Building on the works of S.B. Rao (1987, 1992) and J.K. Park and C.A. Phillips (1993), we present a factor 2 approximation algorithm for the problem of finding a minimum cost b-balanced cut in planar graphs, for b/spl les/1/3, if the vertex weights are given in unary (using scaling, a psuedo-approximation algorithm is also presented for the case of binary vertex weights). This problem is of considerable practical significance, especially in VLSI design.	FOCS	theory
2711	FOCS	Randomized Simplex Algorithms on Klee-Mintny Cubes	Bernd Gärtner,Günter M. Ziegler	1994	We investigate the behavior of randomized simplex algorithms on special linear programs. For this, we develop combinatorial models for the Klee-Minty cubes (1972) and similar linear programs with exponential decreasing paths. The analysis of two most natural randomized pivot rules on the Klee-Minty cubes leads to (nearly) quadratic lower bounds for the complexity of linear programming with random pivots. Thus we disprove two bounds conjectured in the literature. At the same lime, we establish quadratic upper bounds for random pivots on the linear programs under investigation. This motivates the question whether some randomized pivot rules possibly have quadratic worst-case behavior on general linear programs.	FOCS	theory
2712	FOCS	Multi-Index Hashing for Information Retrieval	Daniel H. Greene,Michal Parnas,F. Frances Yao	1994	We describe a technique for building hash indices for a large dictionary of strings. This technique permits robust retrieval of strings from the dictionary even when the query pattern has a significant number of errors. This technique is closely related to the classical Turan problem for hypergraphs. We propose a general method of multi-index construction by generalizing certain Turan hypergraphs. We also develop an accompanying theory for analyzing such hashing schemes. The resulting algorithms have been implemented and can be applied to a wide variety of recognition and retrieval problems.	FOCS	theory
2713	FOCS	Complexity Lower Bounds for Computation Trees with Elementary Transcendental Function Gates	Dima Grigoriev,Nicolai Vorobjov	1994	We consider computation trees which admit as gate functions along with the usual arithmetic operations also algebraic or transcendental functions like exp, log, sin, square root (defined in the relevant domains) or much more general, Pfaffian functions. A new method for proving lower bounds on the depth of these trees is developed which allows to prove a lower bound /spl Omega/(/spl radic/(log N)) for testing membership to a convex polyhedron with N facets of all dimensions, provided that N is large enough. This method differs essentially from the previous approaches adopted for algebraic computation trees.	FOCS	theory
2714	FOCS	Fully Dynamic Cycle-Equivalence in Graphs	Monika Rauch Henzinger	1994	Two edges e/sub 1/ and e/sub 2/ of an undirected graph are cycle-equivalent iff all cycles that contain e/sub 1/ also contain e/sub 2/, i.e., iff e/sub 1/ and e/sub 2/ are a cut-edge pair. The cycle-equivalence classes of the control-flow graph are used in optimizing compilers to speed up existing control-flow and data-flow algorithms. While the cycle-equivalence classes can be computed in linear time, we present the first fully dynamic algorithm for maintaining the cycle-equivalence relation. In an n-node graph our data structure executes an edge insertion or deletion in O(/spl radic/n log n) time and answers the query whether two given edges are cycle-equivalent in O(log/sup 2/ n) time. We also present an algorithm for plane graphs with O(log n) update and query time and for planar graphs with O(log n) insertion time and O(log/sup 2/ n) query and deletion time. Additionally, we show a lower bound of /spl Omega/(log n/log log n) for the amortized time per operation for the dynamic cycle-equivalence problem in the cell probe model.	FOCS	theory
2715	FOCS	A Polynomial-time Algorithm for Deciding Equivalence of Normed Context-free Processes	Yoram Hirshfeld,Mark Jerrum,Faron Moller	1994	A polynomial-time procedure is presented for deciding bisimilarity of normed context-free processes. It follows as a corollary that language equivalence of simple context-free grammars is decidable in polynomial time.	FOCS	theory
2716	FOCS	Fast and Lean Self-Stabilizing Asynchronous Protocols	Gene Itkis,Leonid A. Levin	1994	We consider asynchronous general topology dynamic networks of identical nameless nodes with worst-case transient faults. Starting from any faulty configuration, our protocols self-stabilize any computation in time polynomial in the (unknown) network diameter. This version sacrifices some diversity of tasks and efficiency for simplicity and clarity of details. Appendix gives more efficient procedures in less detail.	FOCS	theory
2717	FOCS	An Efficient Membership-Query Algorithm for Learning DNF with Respect to the Uniform Distribution	Jeffrey C. Jackson	1994	We present a membership-query algorithm for efficiently learning DNF with respect to the uniform distribution. In fact, the algorithm properly learns the more general class of functions that are computable as a majority of polynomially-many parity functions. We also describe extensions of this algorithm for learning DNF over certain nonuniform distributions and from noisy examples as well as for learning a class of geometric concepts that generalizes DNF. The algorithm utilizes one of Freund's boosting techniques and relies on the fact that boosting does not require a completely distribution-independent weak learner. The boosted weak learner is a nonuniform extension of a Fourier-based algorithm due to Kushilevitz and Mansour (1991).	FOCS	theory
2718	FOCS	Tail Bounds for Occupancy and the Satisfiability Threshold Conjecture	Anil Kamath,Rajeev Motwani,Krishna V. Palem,Paul G. Spirakis	1994	The classical occupancy problem is concerned with studying the number of empty bins resulting from a random allocation of m balls to n bins. We provide a series of tail bounds on the distribution of the number of empty bins. These tail bounds should find application in randomized algorithms and probabilistic analysis. Our motivating application is the following well-known conjecture on threshold phenomenon for the satisfiability problem. Consider random 3-SAT formulas with cn clauses over n variables, where each clause is chosen uniformly and independently from the space of all clauses of size 3. It has been conjectured that there is a sharp threshold for satisfiability at c*/spl ap/4.2. We provide the first non-trivial upper bound on the value of c*, showing that for c>4.758 a random 3-SAT formula is unsatisfiable with high probability. This result is based on a structural property, possibly of independent interest, whose proof needs several applications of the occupancy tail bounds.	FOCS	theory
2719	FOCS	Markov Chains and Polynomial Time Algorithms	Ravi Kannan	1994	This paper outlines the use of rapidly mixing Markov Chains in randomized polynomial time algorithms to solve approximately certain counting problems. They fall into two classes: combinatorial problems like counting the number of perfect matchings in certain graphs and geometric ones like computing the volumes of convex sets.	FOCS	theory
2720	FOCS	Tractability of parameterized completion problems on chordal and interval graphs: Minimum Fill-in and Physical Mapping	Haim Kaplan,Ron Shamir,Robert Endre Tarjan	1994	We study the parameterized complexity of several NP-Hard graph completion problems: The minimum fill-in problem is to decide if a graph can be triangulated by adding at most k edges. We develop an O(k/sup 5/ mn+f(K)) algorithm for the problem on a graph with n vertices and m edges. In particular, this implies that the problem is fixed parameter tractable (FPT). proper interval graph completion problems, motivated by molecular biology, ask for adding edges in order to obtain a proper interval graph, so that a parameter in that graph does not exceed k. We show that the problem is FPT when k is the number of added edges. For the problem where k is the clique size, we give an O(f(k)n/sup k-1/) algorithm, so it is polynomial for fixed k. On the other hand, we prove its hardness in the parameterized hierarchy, so it is probably not FPT. Those results are obtained even when a set of edges which should not be added is given. That set can be given either explicitly or by a proper vertex coloring which the added edges should respect.	FOCS	theory
2721	FOCS	(De)randomized Construction of Small Sample Spaces in \calNC	David R. Karger,Daphne Koller	1994	(De)randomized Construction of Small Sample Spaces in \calNC	FOCS	theory
2722	FOCS	Approximate Graph Coloring by Semidefinite Programming	David R. Karger,Rajeev Motwani,Madhu Sudan	1994	We consider the problem of coloring k-colorable graphs with the fewest possible colors. We give a randomized polynomial time algorithm which colors a 3-colorable graph on n vertices with min {O(/spl Delta//sup 1/3/log/sup 4/3//spl Delta/), O(n/sup 1/4/ log n)} colors where /spl Delta/ is the maximum degree of any vertex. Besides giving the best known approximation ratio in terms of n, this marks the first non-trivial approximation result as a function of the maximum degree /spl Delta/. This result can be generalized to k-colorable graphs to obtain a coloring using min {O/spl tilde/(/spl Delta//sup 1-2/k/), O/spl tilde/(n/sup 1-3/(k+1/))} colors. Our results are inspired by the recent work of Goemans and Williamson who used an algorithm for semidefinite optimization problems, which generalize linear programs, to obtain improved approximations for the MAX CUT and MAX 2-SAT problems. An intriguing outcome of our work is a duality relationship established between the value of the optimum solution to our semidefinite program and the Lovasz /spl thetav/-function. We show lower bounds on the gap between the optimum solution of our semidefinite program and the actual chromatic number; by duality this also demonstrates interesting new facts about the /spl thetav/-function.	FOCS	theory
2723	FOCS	Maximum Agreement Subtree in a Set of Evolutionary Trees-Metrics and Efficient Algorithms	Dmitry Keselman,Amihood Amir	1994	In this paper we prove that the maximum homeomorphic agreement subtree problem is /spl Nscr//spl Pscr/-complete for three trees with unbounded degrees. We then show an approximation algorithm of time O(kn/sup 5/) for choosing the species that are not in a maximum agreement subtree of a set of k trees. Our approximation is guaranteed to provide a set that is no more than 4 times the optimum solution. While the set of evolutionary trees may be large in practice, the trees usually have very small degrees, typically no larger than three. We develop a new method for finding a maximum agreement subtree of k trees, of which one has degree bounded by d. This new method enables us to find a maximum agreement subtree in time O(kn/sup d+1/).	FOCS	theory
2724	FOCS	On Syntactic versus Computational Views of Approximability	Sanjeev Khanna,Rajeev Motwani,Madhu Sudan,Umesh V. Vazirani	1994	We attempt to reconcile the two distinct views of approximation classes: syntactic and computational. Syntactic classes such as MAX SNP permit structural results and have natural complete problems, while computational classes such as APX allow us to work with classes of problems whose approximability is well-understood. Our results provide a syntactic characterization of computational classes, and give a computational framework for syntactic classes.	FOCS	theory
2725	FOCS	On the complexity of Bounded-Interaction and Noninteractive Zero-Knowledge Proofs	Joe Kilian	1994	We consider the basic cryptographic primitive known as zero-knowledge proofs on committed bits. In this primitive, a prover P commits to a set of bits, and then at a later time convinces a verifier V that some property /spl Pscr/ holds for a subset of these bits. It is known how to implement this primitive based on an ordinary bit-committal primitive, but the standard implementations involve a great deal of interaction between the prover and the verifier. We introduce new implementations that require markedly less interaction. We implement bounded-interaction proofs on committed bits, generalizing a model of A. De Micali et al. (1988). For all security parameters, our implementations require only a lg/sup 2/ (n) overhead over the best known circuit-based interactive implementations; for sufficiently large security parameters this gap drops to a lg(n) factor.	FOCS	theory
2726	FOCS	The Localization Problem for Mobile Robots	Jon M. Kleinberg	1994	A fundamental task for an autonomous mobile robot is that of localization-determining its location in a known environment. This problem arises in settings that range from the computer analysis of aerial photographs to the design of autonomous Mars rovers. L. Guibas et al. ((1992) have given geometric algorithms for the problem of enumerating locations for a robot consistent with a given view of the environment. We provide an on-line algorithm for a robot to move within its environment so as to uniquely determine its location. The algorithm improves asymptotically on strategies based purely on the spiral search technique of R. Baeza-Yates et al. (1993); an interesting feature of our approach is the way in which the robot is able to identify critical directions in the environment which allow it to perform late stages of the search more efficiently.	FOCS	theory
2727	FOCS	On the Design of Reliable Boolean Circuits that Contain Partially Unreliable Gates	Daniel J. Kleitman,Frank Thomson Leighton,Yuan Ma	1994	We investigate a model of gate failure for Boolean circuits in which a faulty gate is restricted to output one of its input values. For some types of gates, the model (which we call the short-circuit model of gate failure) is weaker than the traditional von Neumann model where faulty gates always output precisely the wrong value. Our model has the advantage that it allows us to design Boolean circuits that can tolerate worst-case faults, as well as circuits that have arbitrarily high success probability in the case of random faults. Moreover, the short-circuit model captures a particular type of fault that commonly appears in practice, and it suggests a simple method for performing post-test alterations to circuits that have more severe types of faults. A variety of bounds on the size of fault-tolerant circuits are proved in the paper. Perhaps, the most important is a proof that any k-fault-tolerant circuit for any input-sensitive function using any type of gates (even arbitrarily powerful, multiple-input gates) must have size at least /spl Omega/(k log k/log log k). Obtaining a tight bound on the size of a circuit for computing the AND of two values if up to k of the gates are faulty is one of the central questions left open in the paper.	FOCS	theory
2728	FOCS	Reducibility and Completeness in Multi-Party Private Computations	Eyal Kushilevitz,Silvio Micali,Rafail Ostrovsky	1994	We define the notions of reducibility and completeness in multi-party private computations. Let g be an n-argument function. We say that a function f is reducible to g if n honest-but-curious players can compute the function f n-privately, given a black-box for g (for which they secretly give inputs and get the result of operating g on these inputs). We say that g is complete (for multi-party private computations) if every function f is reducible to g. In this paper, we characterize the complete Boolean functions: we show that a Boolean function g is complete if and only if g itself cannot be computed n-privately (when there is no black-box available). Namely, for Boolean functions, the notions of completeness and n-privacy are complementary. This characterization gives a huge collection of complete functions (any non-private Boolean function!) compared to very few examples given (implicitly) in previous work. On the other hand, for non-Boolean functions, we show that these two notions are not complementary. Our results can be viewed as a generalization (for multi-party protocols and for (n/spl ges/2)-argument functions) of the two-party case, where it was known that Oblivious Transfer protocol (and its variants) are complete.	FOCS	theory
2729	FOCS	Fast and Feasible Periodic Sorting Networks of Constant Depth	Miroslaw Kutylowski,Krzysztof Lorys,Brigitte Oesterdiekhoff,Rolf Wanka	1994	A periodic comparator network has depth (or period) k, if for every t>k, the compare-exchange operations performed at step t are executed between exactly the same registers as at step t-k. We introduce a general method that converts an arbitrary comparator network that sorts n items in time T(n) and that has layout area A into a periodic sorting network of depth 5 that sorts /spl Theta/(n/spl middot/T(n)) items in time O(T(n)/spl middot/log n) and has layout area O(A/spl middot/T(n)). This scheme applied to the AKS network yields a depth 5 periodic comparator network that sorts in time O(log/sup 2/ n). More practical networks with runtime O(log/sup 3/ n) can be obtained from Batcher's networks. Developing the techniques for the main result, we improve some previous results: Let us fix a d/spl isin/N. Then we can construct a network of depth 3 based on a d-dimensional mesh sorting n items in time O(n/sup 1/d//spl middot/log/sup O(d/) n).	FOCS	theory
2730	FOCS	Long Tours and Short Superstrings (Preliminary Version)	S. Rao Kosaraju,James K. Park,Clifford Stein	1994	Long Tours and Short Superstrings (Preliminary Version)	FOCS	theory
2731	FOCS	Beyond Competitive Analysis	Elias Koutsoupias,Christos H. Papadimitriou	1994	The competitive analysis of online algorithms has been criticized as being too crude and unrealistic. We propose refinements of competitive analysis in two directions: The first restricts the power of the adversary by allowing only certain input distributions, while the other allows for comparisons between information regimes for online decision-making. We illustrate the first with an application to the paging problem; as a byproduct we characterize completely the work functions of this important special case of the k-server problem. We use the second refinement to explore the power of lookahead in server and task systems.	FOCS	theory
2732	FOCS	The geometry of graphs and some of its algorithmic applications	Nathan Linial,Eran London,Yuri Rabinovich	1994	We explore some implications of viewing graphs as geometric objects. This approach offers a new perspective on a number of graph-theoretic and algorithmic problems. There are several ways to model graphs geometrically and our main concern here is with geometric representations that respect the metric of the (possibly weighted) graph. Given a graph G we map its vertices to a normed space in an attempt to (i) Keep down the dimension of the host space and (ii) Guarantee a small distortion, i.e., make sure that distances between vertices in G closely match the distances between their geometric images. We develop efficient algorithms for embedding graphs low-dimensionally with a small distortion.	FOCS	theory
2733	FOCS	IP over connection-oriented networks and distributional paging	Carsten Lund,Steven Phillips,Nick Reingold	1994	Next generation wide area network are very likely to use connection-oriented protocols such as Asynchronous Transfer Mode (ATM). For the huge existing investment in current IP networks such as the Internet to remain useful, me must devise mechanisms to carry IP traffic over connection-oriented networks. A basic issue is to devise holding policies for virtual circuits carrying datagrams. In this paper we consider two variants of the paging problem that arise in the design of such holding policies. In the IP-paging problem the page inter-request times are chosen according to independent distributions. For this model we construct a very simple deterministic algorithm whose page fault rate is at most 5 times that of the best online algorithm (that knows the inter-request time distributions). We also show that some natural algorithms for this problem do not have constant competitive ratio. In distributional paging the inter-request time distributions may be dependent, and hence any probabilistic model of page request sequences can be represented. We construct a simple randomized algorithm whose page fault rate is at most 4 times that of the best online algorithm.	FOCS	theory
2734	FOCS	CS Proofs (Extended Abstracts)	Silvio Micali	1994	CS Proofs (Extended Abstracts)	FOCS	theory
2735	FOCS	On Rank vs. Communication Complexity	Noam Nisan,Avi Wigderson	1994	This paper concerns the open problem of Lovasz and Saks (1988) regarding the relationship between the communication complexity of a Boolean function and the rank of the associated matrix. We first give an example exhibiting the largest gap known. We then prove two related theorems.	FOCS	theory
2736	FOCS	Motion Planning on a Graph (Extended Abstract)	Christos H. Papadimitriou,Prabhakar Raghavan,Madhu Sudan,Hisao Tamaki	1994	Motion Planning on a Graph (Extended Abstract)	FOCS	theory
2737	FOCS	The Load, Capacity and Availability of Quorum Systems	Moni Naor,Avishai Wool	1994	A quorum system is a collection of sets (quorums) every two of which have a nonempty intersection. Quorum systems have been used for a number of applications in the area of distributed systems. We investigate the load, capacity and availability of quorum systems. We present four novel constructions of quorum system, all featuring optimal or near optimal load, and high availability. These desirable properties of the constructions translate into improvements of any protocol using them: a low work load on the processors and a high resilience to processor failures. The best construction, based on paths in a grid, has a load of O(1//spl radic/n), and a failure probability of exp(-O(/spl radic/n)) when the elements fail with probability p	FOCS	theory
2738	FOCS	An O(n^1+epsilon log b) Algorithm for the Complex Roots Problem	C. Andrew Neff,John H. Reif	1994	An O(n^1+epsilon log b) Algorithm for the Complex Roots Problem	FOCS	theory
2739	FOCS	Products and Help Bits in Decision Trees	Noam Nisan,Steven Rudich,Michael E. Saks	1994	We investigate two problems concerning the complexity of evaluating a function f at k-tuple of unrelated inputs by k parallel decision tree algorithms. In the product problem, for some fixed depth bound d, we seek to maximize the fraction of input k-tuples for which all k decision trees are correct. Assume that for a single input to f, the best decision tree algorithm of depth d is correct on a fraction p of inputs. We prove that the maximum fraction of k-tuples on which k depth d algorithms are all correct is at most p/sup k/, which is the trivial lower bound. We show that if we replace the depth d restriction by expected depth d, then this result fails. In the help-bit problem, we are permitted to ask k-1 arbitrary binary questions about the k-tuple of inputs. For each possible k-1-tuple of answers to these queries we will have a k-tuple of decision trees which are supposed to correctly compute all functions on k-tuples that are consistent with the particular answers. The complexity here is the maximum depth of any of the trees in the algorithm. We show that for all k sufficiently large, this complexity is equal to deg/sup s/(f) which is the minimum degree of a multivariate polynomial whose sign is equal to f. Finally, we give a brief discussion of these problems in the context of other complexity models.	FOCS	theory
2740	FOCS	On the robustness of functional equations	Ronitt Rubinfeld	1994	Given a functional equation, such as /spl forall/x, y f(x)+f(y)=f(x+y), we study the following general question: When can the for all quantifiers be replaced by for most quantifiers without essentially changing the functions that are characterized by the property? When for most quantifiers are sufficient, we say that the functional equation is robust. We show conditions on functional equations of the form /spl forall/x, y F[f(x-y), f(x+y), f(x), f(y)]=0, where F is an algebraic function, that imply robustness. We then initiate a general study aimed at characterizing properties of functional equations that determine whether or not they are robust. Our results have applications to the area of self-testing/correcting programs-this paper provides results which show that the concept of self-testing/correcting has much broader applications than we previously understood. We show that self-testers and self-correctors can be found for many functions satisfying robust functional equations, including tan x, 1/1+cot x, Ax/1-Ax', cosh x.	FOCS	theory
2741	FOCS	Nearly Tight Bounds for Wormhole Routing	Abhiram G. Ranade,Saul Schleimer,Daniel Shawcross Wilkerson	1994	We present nearly tight bounds for wormhole muting on Butterfly networks which indicate it is fundamentally different from store-and-forward packet routing. For instance, consider the problem of routing N log N (randomly generated) log N length messages from the inputs to the outputs of an N input Butterfly. We show that with high probability that this must take time at least /spl Omega/(log/sup 3/N/(log log N)/sup 2/). The best lower bound known earlier was /spl Omega/(log/sup 2/ N), which is simply the flit congestion an each link. Thus our lower bound shows that wormhole routing (unlike store-and-forward-routing) is very ineffective in utilizing communication links. We also give a routing algorithm which nearly matches our lower bound. That is, we show that with high probability the time is O(log/sup 3/ N log log N), which improves upon, the previous best bound of O(log/sup 4/ N). Our method also extends to other networks such as the two-dimensional mesh, where it is nearly optimal. Finally, we consider the problem of offline wormhole routing, where we give optimal algorithms for trees and multidimensional meshes.	FOCS	theory
2742	FOCS	Rapid Rumor Ramification: Approximating the minimum broadcast time (Extended Abstract)	R. Ravi	1994	Rapid Rumor Ramification: Approximating the minimum broadcast time (Extended Abstract)	FOCS	theory
2743	FOCS	On Monotone Formula Closure of SZK	Alfredo De Santis,Giovanni Di Crescenzo,Giuseppe Persiano,Moti Yung	1994	We investigate structural properties of statistical zero knowledge (SZK) both in the interactive and in the non-interactive model. Specifically, we look into the closure properties of SZK languages under monotone logical formula composition. This gives rise to new protocol techniques. We show that interactive SZK for random self reducible languages (RSR) (and for co-RSR) is closed under monotone Boolean operations. Namely, we give SZK proofs for monotone Boolean formulae whose atoms are statements about an SZK language which is RSR (or a complement of RSR). All previously known languages in SZK are in these classes. We then show that if a language L has a non-interactive SZK proof system then honest-verifier interactive SZK proof systems exist for all monotone Boolean formulae whose atoms are statements about the complement of L. We also discuss extensions and generalizations.	FOCS	theory
2744	FOCS	Graph Connectivity and Monadic NP	Thomas Schwentick	1994	Ehrenfeucht games are a useful tool in proving that certain properties of finite structures are not expressible by formulas of a certain type. In this paper a new method is introduced that allows the extension of a local winning strategy for Duplicator, one of the two players in Ehrenfeucht games, to a global winning strategy. As an application it is shown that graph connectivity cannot be expressed by existential second-order formulas, where the second-order quantification is restricted to unary relations (monadic NP), even, in the presence of a built-in linear order. As a second application it is stated, that, on the other hand, the presence of a linear order increases the power of monadic NP more than the presence of a successor relation.	FOCS	theory
2745	FOCS	Algorithms for Quantum Computation: Discrete Logarithms and Factoring	Peter W. Shor	1994	A computer is generally considered to be a universal computational device; i.e., it is believed able to simulate any physical computational device with a cost in computation time of at most a polynomial factor: It is not clear whether this is still true when quantum mechanics is taken into consideration. Several researchers, starting with David Deutsch, have developed models for quantum mechanical computers and have investigated their computational properties. This paper gives Las Vegas algorithms for finding discrete logarithms and factoring integers on a quantum computer that take a number of steps which is polynomial in the input size, e.g., the number of digits of the integer to be factored. These two problems are generally considered hard on a classical computer and have been used as the basis of several proposed cryptosystems. We thus give the first examples of quantum cryptanalysis.	FOCS	theory
2746	FOCS	On the Power of Quantum Cryptography	Daniel R. Simon	1994	The quantum model of computation is a probabilistic model, similar to the probabilistic Turing Machine, in which the laws of chance are those obeyed by particles on a quantum mechanical scale, rather than the rules familiar to us from the macroscopic world. We present here a problem of distinguishing between two fairly natural classes of function, which can provably be solved exponentially faster in the quantum model than in the classical probabilistic one, when the function is given as an oracle drawn equiprobably from the uniform distribution on either class. We thus offer compelling evidence that the quantum model may have significantly more complexity theoretic power than the probabilistic Turing Machine. In fact, drawing on this work, Shor (1994) has recently developed remarkable new quantum polynomial-time algorithms for the discrete logarithm and integer factoring problems.	FOCS	theory
2747	FOCS	Efficient Oblivious Branching Programs for Threshold Functions	Rakesh K. Sinha,Jayram S. Thathachar	1994	In his survey paper on branching programs, A.A. Razborov (1991) asked the following question: Does every rectifier-switching network computing the majority of n bits have size n/sup 1+/spl Omega/(1/)? We answer this question in the negative by constructing a simple oblivious branching program of size O(n log/sup 3/ n/log log n log log log n) for computing any threshold function. This improves the previously best known upper bound of O(n/sup 3/2/) due to O.B. Lupanov (1965).	FOCS	theory
2748	FOCS	Expander Codes	Michael Sipser,Daniel A. Spielman	1994	We present a new class of asymptotically good, linear error-correcting codes based upon expander graphs. These codes have linear time sequential decoding algorithms, logarithmic time parallel decoding algorithms with a linear number of processors, and are simple to understand. We present both randomized and explicit constructions for some of these codes. Experimental results demonstrate the extremely good performance of the randomly chosen codes.	FOCS	theory
2749	FOCS	Computing with Very Weak Random Sources	Aravind Srinivasan,David Zuckerman	1994	For any fixed /spl epsiv/>0, we show how to simulate RP algorithms in time n/sup O(log n/) using the output of a /spl delta/-source with min-entropy R(/spl epsiv/). Such a weak random source is asked once for R(/spl epsiv/) bits; it outputs an R-bit string such that any string has probability at most 2/sup -R/(/spl epsiv//). If /spl epsiv/>1-1/(k+1), our BPP simulations take time n/sup O(log(k/ n)) (log/sup (k/) is the logarithm iterated k times). We also give a polynomial-time BPP simulation using Chor-Goldreich sources of min-entropy R/sup /spl Omega/(1/), which is optimal. We present applications to time-space tradeoffs, expander constructions, and the hardness of approximation. Also of interest is our randomness-efficient Leftover Hash Lemma, found independently by Goldreich and Wigderson.	FOCS	theory
2750	FOCS	A note on the Theta number of Lovász and the generalized Delsarte bound	Mario Szegedy	1994	A note on the Theta number of Lovász and the generalized Delsarte bound	FOCS	theory
2751	FOCS	On the Computation of Boolean Functions by Analog Circuits of Bounded Fan-in (Extended Abstract)	György Turán,Farrokh Vatan	1994	On the Computation of Boolean Functions by Analog Circuits of Bounded Fan-in (Extended Abstract)	FOCS	theory
2752	FOCS	Maximum (s, t)-Flows in Planar Networks in O(|V| log |V|) Time	Karsten Weihe	1994	Let G=(V, A) be a directed, planar graph, let s, t /spl isin/ V, s/spl ne/t, and let c/sub a/>0 be the capacity of an arc a/spl isin/A. The problem is to find a maximum flow from s to t in G: subject to these capacities. The fastest algorithm known so far requires /spl Oscr/(|V|/spl middot//sup 3//spl radic/|V|/spl middot/log|V|) time, whereas the algorithm introduced in this paper requires only /spl Oscr/(|V|log|V|) time.	FOCS	theory
2753	FOCS	A Lower Bound for the Monotone Depth of Connectivity	Andrew Chi-Chih Yao	1994	We show that any monotone circuit for computing graph connectivity must have a depth greater than /spl Omega/((log n)/sup 3/2// log log n). This proves that UCONN/sub n/ is not in monotone NC/sup 1/. The proof technique, which is an adaptation of Razborov's approximation method, is also used to derive lower bounds for a general class of graph problems.	FOCS	theory
2754	FOCS	35th Annual Symposium on Foundations of Computer Science, 20-22 November 1994, Santa Fe, New Mexico, USA		1994	35th Annual Symposium on Foundations of Computer Science, 20-22 November 1994, Santa Fe, New Mexico, USA	FOCS	theory
2755	SODA	Reliable Benchmarks Using Numerical Instability.	Sigal Ar,Jin-yi Cai	1994	Reliable Benchmarks Using Numerical Instability.	SODA	theory
2756	SODA	Physical Mapping of Chromosomes Using Unique Probes.	Farid Alizadeh,Richard M. Karp,Deborah K. Weisser,Geoffrey Zweig	1994	Physical Mapping of Chromosomes Using Unique Probes.	SODA	theory
2757	SODA	Matching Nuts and Bolts.	Noga Alon,Manuel Blum,Amos Fiat,Sampath Kannan,Moni Naor,Rafail Ostrovsky	1994	Matching Nuts and Bolts.	SODA	theory
2758	SODA	Selection in the Presence of Noise: The Design of Playoff Systems.	Micah Adler,Peter Gemmell,Mor Harchol-Balter,Richard M. Karp,Claire Kenyon	1994	Selection in the Presence of Noise: The Design of Playoff Systems.	SODA	theory
2759	SODA	Surface Approximation and Geometric Partitions.	Pankaj K. Agarwal,Subhash Suri	1994	Motivated by applications in computer graphics, visualization, and scientific computation, we study the computational complexity of the following problem: given a set S of n points sampled from a bivariate function f(x,y) and an input parameter $\eps > 0$, compute a piecewise-linear function $\Sigma(x,y)$ of minimum complexity (that is, an xy-monotone polyhedral surface, with a minimum number of vertices, edges, or faces) such that $| \Sigma(x_p, y_p) \; - \; z_p | \:\:\leq\:\: \eps$ for all $(x_p, y_p, z_p) \in S$. We give hardness evidence for this problem, by showing that a closely related problem is NP-hard. The main result of our paper is a polynomial-time approximation algorithm that computes a piecewise-linear surface of size O(Ko log Ko), where Ko is the complexity of an optimal surface satisfying the constraints of the problem.The technique developed in our paper is more general and applies to several other problems that deal with partitioning of points (or other objects) subject to certain geometric constraints. For instance, we get the same approximation bound for the following problem arising in machine learning: given n red and m blue points in the plane, find a minimum number of pairwise disjoint triangles such that each blue point is covered by some triangle and no red point lies in any of the triangles.	SODA	theory
2760	SODA	Let Sleeping Files Lie: Pattern Matching in Z-compressed Files.	Amihood Amir,Gary Benson,Martin Farach	1994	Let Sleeping Files Lie: Pattern Matching in Z-compressed Files.	SODA	theory
2761	SODA	Efficient Routing and Scheduling Algorithms for Optical Networks.	Alok Aggarwal,Amotz Bar-Noy,Don Coppersmith,Rajiv Ramaswami,Baruch Schieber,Madhu Sudan	1994	Efficient Routing and Scheduling Algorithms for Optical Networks.	SODA	theory
2762	SODA	A Scaling Technique for Better Network Design.	Manica Aggarwal,Naveen Garg	1994	A Scaling Technique for Better Network Design.	SODA	theory
2763	SODA	Optimal Parallel Sorting in Multi-Level Storage.	Alok Aggarwal,C. Greg Plaxton	1994	We adapt the Sharesort algorithm of Cypher and Plaxton to run on various parallel models of multi-level storage, and analyze its resulting performance. Sharesort was originally defined in the context of sorting n records on an n-processor hypercubic network. In that context, it is not known whether Sharesort is asymptotically optimal. Nonetheless, we find that Sharesort achieves optimal time bounds for parallel sorting in multi-level storage, under a variety of models that have been defined in the literature.	SODA	theory
2764	SODA	On the Greedy Heuristic for Matchings.	Jonathan Aronson,Martin E. Dyer,Alan M. Frieze,Stephen Suen	1994	On the Greedy Heuristic for Matchings.	SODA	theory
2765	SODA	An Optimal Algorithm for Approximate Nearest Neighbor Searching.	Sunil Arya,David M. Mount,Nathan S. Netanyahu,Ruth Silverman,Angela Y. Wu	1994	An Optimal Algorithm for Approximate Nearest Neighbor Searching.	SODA	theory
2766	SODA	Competitive Routing of Virtual Circuits with Unknown Duration.	Baruch Awerbuch,Yossi Azar,Serge A. Plotkin,Orli Waarts	1994	Competitive Routing of Virtual Circuits with Unknown Duration.	SODA	theory
2767	SODA	Competitive Non-Preemptive Call Control.	Baruch Awerbuch,Yair Bartal,Amos Fiat,Adi Rosén	1994	Competitive Non-Preemptive Call Control.	SODA	theory
2768	SODA	Exact Analysis of a Priority Queue Algorithm for Random Variate Generation.	Eric Bach	1994	Exact Analysis of a Priority Queue Algorithm for Random Variate Generation.	SODA	theory
2769	SODA	Approximation Algorithms for the Vertex Feedback Set Problem with Applications to Constraint Satisfaction and Bayesian Inference.	Reuven Bar-Yehuda,Dan Geiger,Joseph Naor,Ron M. Roth	1994	Approximation Algorithms for the Vertex Feedback Set Problem with Applications to Constraint Satisfaction and Bayesian Inference.	SODA	theory
2770	SODA	The Subtree Max Gap Problem with Application to Parallel String Covering.	Amir M. Ben-Amram,Omer Berkman,Costas S. Iliopoulos,Kunsoo Park	1994	The Subtree Max Gap Problem with Application to Parallel String Covering.	SODA	theory
2771	SODA	Approximating Maximum Independent Set in Bounded Degree Graphs.	Piotr Berman,Martin Fürer	1994	Approximating Maximum Independent Set in Bounded Degree Graphs.	SODA	theory
2772	SODA	Optimal Construction of Edge-Disjoint Paths in Random Graphs.	Andrei Z. Broder,Alan M. Frieze,Stephen Suen,Eli Upfal	1994	Given a graph G=(V,E) with n vertices, m edges, and a family of $\kappa$ pairs of vertices in $V$, we are interested in finding for each pair (ai, bi) a path connecting ai to bi such that the set of $\kappa$ paths so found is edge disjoint. (For arbitrary graphs the problem is ${\cal NP}$-complete, although it is in ${\cal P}$ if $\kappa$ is fixed.)We present a polynomial time randomized algorithm for finding the optimal number of edge disjoint paths (up to constant factors) in the random graph Gn,m for all edge densities above the connectivity threshold. (The graph is chosen first; then an adversary chooses the pairs of endpoints.) Our results give the first tight bounds for the edge-disjoint paths problem for any nontrivial class of graphs.	SODA	theory
2773	SODA	On Degeneracy in Geometric Computations.	Christoph Burnikel,Kurt Mehlhorn,Stefan Schirra	1994	On Degeneracy in Geometric Computations.	SODA	theory
2774	SODA	Linear and O(n log n) Time Minimum-Cost Matching Algorithms for Quasi-Convex Tours.	Samuel R. Buss,Peter N. Yianilos	1994	Linear and O(n log n) Time Minimum-Cost Matching Algorithms for Quasi-Convex Tours.	SODA	theory
2775	SODA	New Results on the Old k-Opt Algorithm for the TSP.	Barun Chandra,Howard J. Karloff,Craig A. Tovey	1994	New Results on the Old k-Opt Algorithm for the TSP.	SODA	theory
2776	SODA	A Las Vegas O(n) Algorithm for the Cardinality of a Maximum Matching.	Joseph Cheriyan	1994	A Las Vegas O(n) Algorithm for the Cardinality of a Maximum Matching.	SODA	theory
2777	SODA	Shortest Paths Algorithms: Theory and Experimental Evaluation.	Boris V. Cherkassky,Andrew V. Goldberg,Tomasz Radzik	1994	Shortest Paths Algorithms: Theory and Experimental Evaluation.	SODA	theory
2778	SODA	Recognizing Balanced 0, +/- Matrices.	Michele Conforti,Gérard Cornuéjols,Ajai Kapoor,Kristina Vuskovic	1994	Recognizing Balanced 0, +/- Matrices.	SODA	theory
2779	SODA	Roots of a Polynomial and its Derivatives.	Don Coppersmith,C. Andrew Neff	1994	Roots of a Polynomial and its Derivatives.	SODA	theory
2780	SODA	Neighborhood Preserving Hashing and Approximate Queries.	Danny Dolev,Yuval Harari,Nathan Linial,Noam Nisan,Michal Parnas	1994	Let $D \subseteq \Sigma^n$ be a dictionary. We look for efficient data structures and algorithms to solve the following approximate query problem: Given a query $u \in \Sigma^n$ list all words $v \in D$ that are close to u in Hamming distance.The problem reduces to the following combinatorial problem: Hash the vertices of the n-dimensional hypercube into buckets so that (1) the c-neighborhood of each vertex is mapped into at most k buckets and (2) no bucket is too large.Lower and upper bounds are given for the tradeoff between k and the size of the largest bucket. These results are used to derive bounds for the approximate query problem.	SODA	theory
2781	SODA	Maximal Empty Ellipsoids.	Rex A. Dwyer,William F. Eddy	1994	Maximal Empty Ellipsoids.	SODA	theory
2782	SODA	Approximately Counting Hamilton Cycles in Dense Graphs.	Martin E. Dyer,Alan M. Frieze,Mark Jerrum	1994	Approximately Counting Hamilton Cycles in Dense Graphs.	SODA	theory
2783	SODA	A Near-Linear Algorithm for the Planar Segment Center Problem.	Alon Efrat,Micha Sharir	1994	A Near-Linear Algorithm for the Planar Segment Center Problem.	SODA	theory
2784	SODA	Average Case Analysis of Dynamic Geometric Optimization.	David Eppstein	1994	Average Case Analysis of Dynamic Geometric Optimization.	SODA	theory
2785	SODA	Clustering for Faster Network Simplex Pivots.	David Eppstein	1994	Clustering for Faster Network Simplex Pivots.	SODA	theory
2786	SODA	Fast Comparison of Evolutionary Trees.	Martin Farach,Mikkel Thorup	1994	Fast Comparison of Evolutionary Trees.	SODA	theory
2787	SODA	A Sublinear Parallel Algorithm for Stable Matching.	Tomás Feder,Nimrod Megiddo,Serge A. Plotkin	1994	A Sublinear Parallel Algorithm for Stable Matching.	SODA	theory
2788	SODA	Low-degree Tests.	Katalin Friedl,Zsolt Hátsági,Alexander Shen	1994	Low-degree Tests.	SODA	theory
2789	SODA	The Complexity of Resolvent Resolved.	Giovanni Gallo,Bhubaneswar Mishra	1994	The Complexity of Resolvent Resolved.	SODA	theory
2790	SODA	The QRQW PRAM: Accounting for Contention in Parallel Algorithms.	Phillip B. Gibbons,Yossi Matias,Vijaya Ramachandran	1994	The QRQW PRAM: Accounting for Contention in Parallel Algorithms.	SODA	theory
2791	SODA	Improved Approximation Algorithms for Network Design Problems.	Michel X. Goemans,Andrew V. Goldberg,Serge A. Plotkin,David B. Shmoys,Éva Tardos,David P. Williamson	1994	Improved Approximation Algorithms for Network Design Problems.	SODA	theory
2792	SODA	Path Problems in Skew-Symmetric Graphs.	Andrew V. Goldberg,Alexander V. Karzanov	1994	Path Problems in Skew-Symmetric Graphs.	SODA	theory
2793	SODA	Optimal Parallel Approximation for Prefix Sums and Integer Sorting.	Michael T. Goodrich,Yossi Matias,Uzi Vishkin	1994	Optimal Parallel Approximation for Prefix Sums and Integer Sorting.	SODA	theory
2794	SODA	Moments of Inertia and Graph Separators.	Keith D. Gremban,Gary L. Miller,Shang-Hua Teng	1994	Moments of Inertia and Graph Separators.	SODA	theory
2795	SODA	An Efficient Algorithm for Dynamic Text Indexing.	Ming Gu,Martin Farach,Richard Beigel	1994	An Efficient Algorithm for Dynamic Text Indexing.	SODA	theory
2796	SODA	Queueing Analysis of Oblivious Packet-Routing Networks.	Mor Harchol-Balter,Paul E. Black	1994	Queueing Analysis of Oblivious Packet-Routing Networks.	SODA	theory
2797	SODA	Learning Binary Matroid Ports.	Lisa Hellerstein,Collette R. Coullard	1994	Learning Binary Matroid Ports.	SODA	theory
2798	SODA	Polynomial Time Algorithms for Some Evacuation Problems.	Bruce Hoppe,Éva Tardos	1994	Polynomial Time Algorithms for Some Evacuation Problems.	SODA	theory
2799	SODA	Comparing Point Sets Under Projection.	Daniel P. Huttenlocher,Jon M. Kleinberg	1994	Comparing Point Sets Under Projection.	SODA	theory
2800	SODA	Minimizing Channel Density by Lateral Shifting of Components.	David S. Johnson,Andrea S. LaPaugh,Ron Y. Pinter	1994	Minimizing Channel Density by Lateral Shifting of Components.	SODA	theory
2801	SODA	Optimal Constructions of Hybrid Algorithms.	Ming-Yang Kao,Yuan Ma,Michael Sipser,Yiqun Lisa Yin	1994	Optimal Constructions of Hybrid Algorithms.	SODA	theory
2802	SODA	Using Randomized Sparsification to Approximate Minimum Cuts.	David R. Karger	1994	Using Randomized Sparsification to Approximate Minimum Cuts.	SODA	theory
2803	SODA	A Better Algorithm for an Ancient Scheduling Problem.	David R. Karger,Steven J. Phillips,Eric Torng	1994	A Better Algorithm for an Ancient Scheduling Problem.	SODA	theory
2804	SODA	Two and Higher Dimensional Pattern Matching in Optimal Expected Time.	Juha Kärkkäinen,Esko Ukkonen	1994	Algorithms with optimal expected running time are presented for searching the occurrences of a two-dimensional m X m pattern P in a two-dimensional n X n text T over an alphabet of size c. The algorithms are based on placing in the text a static grid of test points, determined only by n, m, and c (not dynamically by earlier test results). Using test strings read from the test points the algorithms eliminate as many potential occurrences of P as possible. The remaining potential occurrences are separately checked for actual occurrences. A suitable choice of the test point set leads to algorithms with expected running time O(n2logc m2/m2) using the uniform Bernoulli model of randomness. This is shown to be optimal by a generalization of a one-dimensional lower bound result by Yao. Experimental results show that the algorithms are efficient in practice, too. The method is also generalized for the k mismatches problem. The resulting algorithm has expected running time O(kn2logc m2/m2), provided that $k\leq(m\lfloor m/\lceil\log_c m^2\rceil\rfloor-1)/2$.\ All algorithms need preprocessing of P which takes time and space O(m2). The text processing can be done on-line, using a rather small window. The algorithms easily generalize to d-dimensional matching for any d.	SODA	theory
2805	SODA	Derandomizing Algorithms for Routing and Sorting on Meshes.	Michael Kaufmann,Jop F. Sibeyn,Torsten Suel	1994	Derandomizing Algorithms for Routing and Sorting on Meshes.	SODA	theory
2806	SODA	Reconstructing a History of Recombinations from a Set of Sequences.	John D. Kececioglu,Dan Gusfield	1994	Reconstructing a History of Recombinations from a Set of Sequences.	SODA	theory
2807	SODA	Approximating the Minimum Equivalent Diagraph.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1994	The MEG (minimum equivalent graph) problem is the following: Given a directed graph, find a smallest subset of the edges that maintains all reachability relations between nodes. This problem is NP-hard; this paper gives an approximation algorithm achieving a performance guarantee of about 1.64 in polynomial time. The algorithm achieves a performance guarantee of 1.75 in the time required for transitive closure. The heart of the MEG problem is the minimum SCSS (strongly connected spanning subgraph) problem --- the MEG problem restricted to strongly connected digraphs. For the minimum SCSS problem, the paper gives a practical, nearly linear-time implementation achieving a performance guarantee of 1.75. The algorithm and its analysis are based on the simple idea of contracting long cycles. The analysis applies directly to $2$-\Exchange, a general local improvement algorithm, showing that its performance guarantee is 1.75.	SODA	theory
2808	SODA	Optimal Prediction for Prefetching in the Worst Case.	P. Krishnan,Jeffrey Scott Vitter	1994	Response time delays caused by I/O are a major problem in many systems and database applications. Prefetching and cache replacement methods are attracting renewed attention because of their success in avoiding costly I/Os. Prefetching can be looked upon as a type of online sequential prediction, where the predictions must be accurate as well as made in a computationally efficient way. Unlike other online problems, prefetching cannot admit a competitive analysis, since the optimal offline prefetcher incurs no cost when it knows the future page requests. Previous analytical work on prefetching [. Vitter Krishnan 1991.] [J. Assoc. Comput. Mach., 143 (1996), pp. 771--793] consisted of modeling the user as a probabilistic Markov source. In this paper, we look at the much stronger form of worst-case analysis and derive a randomized algorithm for pure prefetching. We compare our algorithm for every page request sequence with the important class of finite state prefetchers, making no assumptions as to how the sequence of page requests is generated. We prove analytically that the fault rate of our online prefetching algorithm converges almost surely for every page request sequence to the fault rate of the optimal finite state prefetcher for the sequence. This analysis model can be looked upon as a generalization of the competitive framework, in that it compares an online algorithm in a worst-case manner over all sequences with a powerful yet nonclairvoyant opponent. We simultaneously achieve the computational goal of implementing our prefetcher in optimal constant expected time per prefetched page using the optimal dynamic discrete random variate generator of [. Matias Matias, Vitter, and Ni [Proc. 4th Annual SIAM/ACM Symposium on Discrete Algorithms, Austin, TX, January 1993].	SODA	theory
2809	SODA	On-line Search in a Simple Polygon.	Jon M. Kleinberg	1994	On-line Search in a Simple Polygon.	SODA	theory
2810	SODA	An Effective Additive Basis for the Integers.	Mihail N. Kolountzakis	1994	An Effective Additive Basis for the Integers.	SODA	theory
2811	SODA	Generating Low-Degree 2-Spanners.	Guy Kortsarz,David Peleg	1994	A k-spanner of a connected graph G = (V,E) is a subgraph G\spr consisting of all the vertices of V and a subset of the edges, with the additional property that the distance between any two vertices in G\spr is larger than that distance in G by no more than a factor of k. This paper concerns the problem of finding a 2-spanner in a given graph, with minimum maximum degree. A randomized approximation algorithm is provided for this problem, with approximation ration of [O\tilde](D1/4).	SODA	theory
2812	SODA	An Optimal RAM Implementation of Catenable Min Double-ended Queues.	S. Rao Kosaraju	1994	An Optimal RAM Implementation of Catenable Min Double-ended Queues.	SODA	theory
2813	SODA	Online Interval Scheduling.	Richard J. Lipton,Andrew Tomkins	1994	Online Interval Scheduling.	SODA	theory
2814	SODA	Tight Bounds for Dynamic Storage Allocation.	Michael Luby,Joseph Naor,Ariel Orda	1994	Tight Bounds for Dynamic Storage Allocation.	SODA	theory
2815	SODA	Scheduling Malleable and Nonmalleable Parallel Tasks.	Walter Ludwig,Prasoon Tiwari	1994	Scheduling Malleable and Nonmalleable Parallel Tasks.	SODA	theory
2816	SODA	Linear Programs for Randomized On-Line Algorithms.	Carsten Lund,Nick Reingold	1994	Linear Programs for Randomized On-Line Algorithms.	SODA	theory
2817	SODA	Computing the Covers of a String in Linear Time.	Dennis Moore,William F. Smyth	1994	Computing the Covers of a String in Linear Time.	SODA	theory
2818	SODA	Optimum Parallel Computations with Banded Matrices.	Victor Y. Pan,Isdor Sobze,Antoine Atinkpahoun	1994	Optimum Parallel Computations with Banded Matrices.	SODA	theory
2819	SODA	New Techniques for Approximating Complex Polynomial Zeros.	Victor Y. Pan	1994	New Techniques for Approximating Complex Polynomial Zeros.	SODA	theory
2820	SODA	On Optimal Strategies for Searching in Presence of Errors.	S. Muthukrishnan	1994	On Optimal Strategies for Searching in Presence of Errors.	SODA	theory
2821	SODA	Approximate Data Structures with Applications.	Yossi Matias,Jeffrey Scott Vitter,Neal E. Young	1994	Approximate Data Structures with Applications.	SODA	theory
2822	SODA	Linear-Time Modular Decomposition and Efficient Transitive Orientation of Comparability Graphs.	Ross M. McConnell,Jeremy Spinrad	1994	Linear-Time Modular Decomposition and Efficient Transitive Orientation of Comparability Graphs.	SODA	theory
2823	SODA	Maintaining Dynamic Sequences Under Equality-Tests in Polylogarithmic Time.	Kurt Mehlhorn,R. Sundar,Christian Uhrig	1994	Maintaining Dynamic Sequences Under Equality-Tests in Polylogarithmic Time.	SODA	theory
2824	SODA	Shallow Excluded Minors and Improved Graph Decompositions.	Serge A. Plotkin,Satish Rao,Warren D. Smith	1994	Shallow Excluded Minors and Improved Graph Decompositions.	SODA	theory
2825	SODA	Dynamic Two-Connectivity with Backtracking.	Johannes A. La Poutré,Jeffery Westbrook	1994	Dynamic Two-Connectivity with Backtracking.	SODA	theory
2826	SODA	An Efficient Parallel Algorithm for the General Planar Monotone Circuit Value Problem.	Vijaya Ramachandran,Honghua Yang	1994	An Efficient Parallel Algorithm for the General Planar Monotone Circuit Value Problem.	SODA	theory
2827	SODA	Optimal Randomized Parallel Algorithms for Computing the Row Maxima of a Totally Monotone Matrix.	Rajeev Raman,Uzi Vishkin	1994	Optimal Randomized Parallel Algorithms for Computing the Row Maxima of a Totally Monotone Matrix.	SODA	theory
2828	SODA	Testable Algorithms for Self-Avoiding Walks.	Dana Randall,Alistair Sinclair	1994	Testable Algorithms for Self-Avoiding Walks.	SODA	theory
2829	SODA	Spanning Trees Short or Small.	R. Ravi,Ravi Sundaram,Madhav V. Marathe,Daniel J. Rosenkrantz,S. S. Ravi	1994	We study the problem of finding small trees. Classical network design problems are considered with the additional constraint that only a specified number $k$ of nodes are required to be connected in the solution. A prototypical example is the $k$MST problem in which we require a tree of minimum weight spanning at least $k$ nodes in an edge-weighted graph. We show that the $k$MST problem is NP-hard even for points in the Euclidean plane. We provide approximation algorithms with performance ratio $2\sqrt{k}$ for the general edge-weighted case and $O(k^{1/4})$ for the case of points in the plane. Polynomial-time exact solutions are also presented for the class of treewidth-bounded graphs, which includes trees, series-parallel graphs, and bounded bandwidth graphs, and for points on the boundary of a convex region in the Euclidean plane. We also investigate the problem of finding short trees and, more generally, that of finding networks with minimum diameter. A simple technique is used to provide a polynomial-time solution for finding $k$-trees of minimum diameter. We identify easy and hard problems arising in finding short networks using a framework due to T. C. Hu.	SODA	theory
2830	SODA	Dynamic Algebraic Algorithms.	John H. Reif,Stephen R. Tate	1994	Dynamic Algebraic Algorithms.	SODA	theory
2831	SODA	Design of On-line Algorithms Using Hitting Times.	Prasad Tetali	1994	Random walks are well known for playing a crucial role in the design of randomized off-line as well as on-line algorithms. In this work we prove some basic identities for ergodic Markov chains (e.g., an interesting characterization of reversibility in Markov chains is obtained in terms of first passage times). Besides providing new insight into random walks on weighted graphs, we show how these identities give us a way of designing competitive randomized on-line algorithms for certain well-known problems.	SODA	theory
2832	SODA	Scheduling Parallel Tasks to Minimize Average Response Time.	John Turek,Uwe Schwiegelshohn,Joel L. Wolf,Philip S. Yu	1994	Scheduling Parallel Tasks to Minimize Average Response Time.	SODA	theory
2833	SODA	Computational Experience with an Approximation Algorithm on Large-Scale Euclidean Matching Instances.	David P. Williamson,Michel X. Goemans	1994	Computational Experience with an Approximation Algorithm on Large-Scale Euclidean Matching Instances.	SODA	theory
2834	SODA	Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms. 23-25 January 1994, Arlington, Virginia.	Daniel Dominic Sleator	1994	Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms. 23-25 January 1994, Arlington, Virginia.	SODA	theory
2835	STOC	A spectral technique for coloring random 3-colorable graphs (preliminary version).	Noga Alon,Nabil Kahale	1994	A spectral technique for coloring random 3-colorable graphs (preliminary version).	STOC	theory
2836	STOC	Color-coding: a new method for finding simple paths, cycles and other small subgraphs within large graphs.	Noga Alon,Raphael Yuster,Uri Zwick	1994	Color-coding: a new method for finding simple paths, cycles and other small subgraphs within large graphs.	STOC	theory
2837	STOC	Time-adaptive algorithms for synchronization.	Rajeev Alur,Hagit Attiya,Gadi Taubenfeld	1994	We consider concurrent systems in which there is an unknown upper bound on memory access time. Such a model is inherently different from the asynchronous model, where no such bound exists, and also from timing-based models, where such a bound exists and is known a priori. The appeal of our model lies in the fact that while it abstracts from implementation details, it is a better approximation of real concurrent systems than the asynchronous model. Furthermore, it is stronger than the asynchronous model, enabling us to design algorithms for problems that are unsolvable in the asynchronous model.Two basic synchronization problems, consensus and mutual exclusion, are investigated in a shared-memory environment that supports atomic read/write registers. We show that $\Theta(\Delta\frac{\log \Delta}{\log\log \Delta})$ is an upper and lower bound on the time complexity of consensus, where $\Delta$ is the (unknown) upper bound on memory access time. For the mutual exclusion problem, we design an efficient algorithm that takes advantage of the fact that some upper bound on memory access time exists. The solutions for both problems are even more efficient in the absence of contention, in which case their time complexity is a constant.	STOC	theory
2838	STOC	The complexity of searching a sorted array of strings.	Arne Andersson,Torben Hagerup,Johan Håstad,Ola Petersson	1994	The complexity of searching a sorted array of strings.	STOC	theory
2839	STOC	Choosing a learning team: a topological approach.	Kalvis Apsitis,Rusins Freivalds,Carl H. Smith	1994	Choosing a learning team: a topological approach.	STOC	theory
2840	STOC	Simulating quadratic dynamical systems is PSPACE-complete (preliminary version).	Sanjeev Arora,Yuval Rabani,Umesh V. Vazirani	1994	Simulating quadratic dynamical systems is PSPACE-complete (preliminary version).	STOC	theory
2841	STOC	Simulating access to hidden information while learning.	Peter Auer,Philip M. Long	1994	Simulating access to hidden information while learning.	STOC	theory
2842	STOC	Efficient asynchronous distributed symmetry breaking.	Baruch Awerbuch,Lenore Cowen,Mark A. Smith	1994	Efficient asynchronous distributed symmetry breaking.	STOC	theory
2843	STOC	Improved approximation algorithms for the multi-commodity flow problem and local competitive routing in dynamic networks.	Baruch Awerbuch,Tom Leighton	1994	Improved approximation algorithms for the multi-commodity flow problem and local competitive routing in dynamic networks.	STOC	theory
2844	STOC	Balanced allocations (extended abstract).	Yossi Azar,Andrei Z. Broder,Anna R. Karlin,Eli Upfal	1994	Suppose that we sequentially place n balls into n boxes by putting each ball into a randomly chosen box. It is well known that when we are done, the fullest box has with high probability lnn/lnlnn(1 + o(1)) balls in it. Suppose instead, that for each ball we choose two boxes at random and place the ball into the one which is less full at the time of placement. We show that with high probability, the fullest box contains only lnlnn/ln2 + O(1) balls - exponentially less than before. Furthermore, we show that a similar gap exists in the infinite process, where at each step one ball, chosen uniformly at random, is deleted, and one ball is added in the manner above. We discuss consequences of this and related theorems for dynamic resource allocation, hashing, and on-line load balancing.	STOC	theory
2845	STOC	Efficient probabilistic checkable proofs and applications to approximation.	Mihir Bellare,Shafi Goldwasser,Carsten Lund,Alexander Russell	1994	Efficient probabilistic checkable proofs and applications to approximation.	STOC	theory
2846	STOC	Improved non-approximability results.	Mihir Bellare,Madhu Sudan	1994	Improved non-approximability results.	STOC	theory
2847	STOC	The minimum latency problem.	Avrim Blum,Prasad Chalasani,Don Coppersmith,William R. Pulleyblank,Prabhakar Raghavan,Madhu Sudan	1994	The minimum latency problem.	STOC	theory
2848	STOC	Weakly learning DNF and characterizing statistical query learning using Fourier analysis.	Avrim Blum,Merrick L. Furst,Jeffrey C. Jackson,Michael J. Kearns,Yishay Mansour,Steven Rudich	1994	Weakly learning DNF and characterizing statistical query learning using Fourier analysis.	STOC	theory
2849	STOC	Receipt-free secret-ballot elections (extended abstract).	Josh Cohen Benaloh,Dwight Tuinstra	1994	Receipt-free secret-ballot elections (extended abstract).	STOC	theory
2850	STOC	On lazy randomized incremental construction.	Mark de Berg,Katrin Dobrindt,Otfried Schwarzkopf	1994	On lazy randomized incremental construction.	STOC	theory
2851	STOC	Scalable expanders: exploiting hierarchical random wiring.	Eric A. Brewer,Frederic T. Chong,Tom Leighton	1994	Scalable expanders: exploiting hierarchical random wiring.	STOC	theory
2852	STOC	Improved algorithms via approximations of probability distributions (extended abstract).	Suresh Chari,Pankaj Rohatgi,Aravind Srinivasan	1994	Improved algorithms via approximations of probability distributions (extended abstract).	STOC	theory
2853	STOC	Computational geometry: a retrospective.	Bernard Chazelle	1994	Computational geometry: a retrospective.	STOC	theory
2854	STOC	A near optimal algorithm for edge separators (preliminary version).	Fan R. K. Chung,S.-T. Yau	1994	A near optimal algorithm for edge separators (preliminary version).	STOC	theory
2855	STOC	Polylog-time and near-linear work approximation scheme for undirected shortest paths.	Edith Cohen	1994	Shortest paths computations constitute one of the most fundamental network problems. Nonetheless, known parallel shortest-paths algorithms are generally inefficient: they perform significantly more work (product of time and processors) than their sequential counterparts. This gap, known in the literature as the &ldquo;transitive closure bottleneck,&rdquo; poses a long-standing open problem. Our main result is an Omne0+s m+n1+e0 work polylog-time randomized algorithm that computes paths within (1 + O(1/polylog n) of shortest from s source nodes to all other nodes in weighted undirected networks with n nodes and m edges (for any fixed &egr;0>0). This work bound nearly matches the O&d5;sm sequential time. In contrast, previous polylog-time algorithms required nearly minO&d5; n3,O&d5; m2 work (even when s=1), and previous near-linear work algorithms required near-O(n) time. We also present faster sequential algorithms that provide good approximate distances only between &ldquo;distant&rdquo; vertices: We obtain an Om+snne 0 time algorithm that computes paths of weight (1+O(1/polylog n) dist + O(wmax polylog n), where dist is the corresponding distance and wmax is the maximum edge weight. Our chief instrument, which is of independent interest, are efficient constructions of sparse hop sets. A (d,&egr;)-hop set of a network G=(V,E) is a set E* of new weighted edges such that mimimum-weight d-edge paths in V,E&cup;E* have weight within (1+&egr;) of the respective distances in G. We construct hop sets of size On1+e0 where &egr;=O(1/polylog n) and d=O(polylog n).	STOC	theory
2856	STOC	On the power of finite automata with both nondeterministic and probabilistic states (preliminary version).	Anne Condon,Lisa Hellerstein,Samuel Pottle,Avi Wigderson	1994	On the power of finite automata with both nondeterministic and probabilistic states (preliminary version).	STOC	theory
2857	STOC	The connectivity carcass of a vertex subset in a graph and its incremental maintenance.	Yefim Dinitz,Alek Vainshtein	1994	The connectivity carcass of a vertex subset in a graph and its incremental maintenance.	STOC	theory
2858	STOC	Two prover protocols: low error at affordable rates.	Uriel Feige,Joe Kilian	1994	We introduce the miss-match form for two-prover one-round proof systems. Any two-prover one-round proof system can be easily modified so as to be in miss-match form. Proof systems in miss-match form have the projection property that is important for deriving hardness of approximation results for NP-hard combinatorial optimization problems.Our main result is an upper bound on the number of parallel repetitions that suffice in order to reduce the error of miss-match proof systems from p to $\epsilon$. This upper bound depends only on p and on $\epsilon$ (polynomial in 1/(1-p) and in $1/\epsilon$). Based on previous work, it follows that for any $\epsilon >0,$ NP has two-prover one-round proof systems with logarithmic-sized questions, constant-sized answers, and error at most $\epsilon$.As part of our proof we prove upper bounds on the influence of random variables on multivariate functions, which may be of independent interest.	STOC	theory
2859	STOC	A minimal model for secure computation (extended abstract).	Uriel Feige,Joe Kilian,Moni Naor	1994	A minimal model for secure computation (extended abstract).	STOC	theory
2860	STOC	Optimality and domination in repeated games with bounded players.	Lance Fortnow,Duke Whang	1994	Optimality and domination in repeated games with bounded players.	STOC	theory
2861	STOC	Efficient splitting off algorithms for graphs.	Harold N. Gabow	1994	Efficient splitting off algorithms for graphs.	STOC	theory
2862	STOC	.879-approximation algorithms for MAX CUT and MAX 2SAT.	Michel X. Goemans,David P. Williamson	1994	.879-approximation algorithms for MAX CUT and MAX 2SAT.	STOC	theory
2863	STOC	Computational complexity and knowledge complexity (extended abstract).	Oded Goldreich,Rafail Ostrovsky,Erez Petrank	1994	Computational complexity and knowledge complexity (extended abstract).	STOC	theory
2864	STOC	Tiny families of functions with random properties (preliminary version): a quality-size trade-off for hashing.	Oded Goldreich,Avi Wigderson	1994	Tiny families of functions with random properties (preliminary version): a quality-size trade-off for hashing.	STOC	theory
2865	STOC	Lower bounds on testing membership to a polyhedron by algebraic decision trees.	Dima Grigoriev,Marek Karpinski,Nicolai Vorobjov	1994	Lower bounds on testing membership to a polyhedron by algebraic decision trees.	STOC	theory
2866	STOC	A weight-size trade-off for circuits with MOD m gates.	Vince Grolmusz	1994	A weight-size trade-off for circuits with MOD m gates.	STOC	theory
2867	STOC	Optimal parallel string algorithms: sorting, merging and computing the minimum.	Torben Hagerup	1994	Optimal parallel string algorithms: sorting, merging and computing the minimum.	STOC	theory
2868	STOC	Greed is good: approximating independent sets in sparse and bounded-degree graphs.	Magnús M. Halldórsson,Jaikumar Radhakrishnan	1994	Greed is good: approximating independent sets in sparse and bounded-degree graphs.	STOC	theory
2869	STOC	The computational complexity of recognizing permutation functions.	Keju Ma,Joachim von zur Gathen	1994	The computational complexity of recognizing permutation functions.	STOC	theory
2870	STOC	Optimal parallel suffix tree construction.	Ramesh Hariharan	1994	Optimal parallel suffix tree construction.	STOC	theory
2871	STOC	A simple constructive computability theorem for wait-free computation.	Maurice Herlihy,Nir Shavit	1994	A simple constructive computability theorem for wait-free computation.	STOC	theory
2872	STOC	Pseudorandomness for network algorithms.	Russell Impagliazzo,Noam Nisan,Avi Wigderson	1994	Pseudorandomness for network algorithms.	STOC	theory
2873	STOC	A functional equation often arising in the analysis of algorithms (extended abstract).	Philippe Jacquet,Wojciech Szpankowski	1994	A functional equation often arising in the analysis of algorithms (extended abstract).	STOC	theory
2874	STOC	Circuit complexity: from the worst case to the average case.	Andreas Jakoby,Rüdiger Reischuk,Christian Schindelhauer	1994	Circuit complexity: from the worst case to the average case.	STOC	theory
2875	STOC	Aligning sequences via an evolutionary tree: complexity and approximation.	Tao Jiang,Eugene L. Lawler,Lusheng Wang	1994	Aligning sequences via an evolutionary tree: complexity and approximation.	STOC	theory
2876	STOC	Two heads are better than two tapes.	Tao Jiang,Joel I. Seiferas,Paul M. B. Vitányi	1994	We show that a Turing machine with two single-head one-dimensional tapes cannot recognize the set.	STOC	theory
2877	STOC	Fault-tolerant scheduling.	Bala Kalyanasundaram,Kirk Pruhs	1994	We study fault-tolerant multiprocessor scheduling under the realistic assumption that the occurrence of faults cannot be predicted. The goal in these problems is to minimize the delay incurred by the jobs. Since this is an online problem we use competitive analysis to evaluate possible algorithms. For the problems of minimizing the makespan and minimizing the average completion time (for static release times), we give nonclairvoyant algorithms (both deterministic and randomized) that have provably asymptotically optimal competitive ratios. The main tool used by these algorithms to combat faults is redundancy. We also show that randomization has the same effect as redundancy.	STOC	theory
2878	STOC	Random sampling in cut, flow, and network design problems.	David R. Karger	1994	Random sampling in cut, flow, and network design problems.	STOC	theory
2879	STOC	On the fault tolerance of the butterfly.	Anna R. Karlin,Greg Nelson,Hisao Tamaki	1994	On the fault tolerance of the butterfly.	STOC	theory
2880	STOC	On the learnability of discrete distributions.	Michael J. Kearns,Yishay Mansour,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire,Linda Sellie	1994	On the learnability of discrete distributions.	STOC	theory
2881	STOC	Low degree spanning trees of small weight.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1994	Given $n$ points in the plane, the degree-$K$ spanning-tree problem asks for a spanning tree of minimum weight in which the degree of each vertex is at most $K$. This paper addresses the problem of computing low-weight degree-$K$ spanning trees for $K>2$. It is shown that for an arbitrary collection of $n$ points in the plane, there exists a spanning tree of degree 3 whose weight is at most 1.5 times the weight of a minimum spanning tree. It is shown that there exists a spanning tree of degree 4 whose weight is at most 1.25 times the weight of a minimum spanning tree. These results solve open problems posed by Papadimitriou and Vazirani. Moreover, if a minimum spanning tree is given as part of the input, the trees can be computed in $O(n)$ time. The results are generalized to points in higher dimensions. It is shown that for any $d \ge 3$, an arbitrary collection of points in $\Re^d$ contains a spanning tree of degree 3 whose weight is at most 5/3 times the weight of a minimum spanning tree. This is the first paper that achieves factors better than 2 for these problems.	STOC	theory
2882	STOC	Faster shortest-path algorithms for planar graphs.	Philip N. Klein,Satish Rao,Monika Rauch Henzinger,Sairam Subramanian	1994	We give a linear-time algorithm for single-source shortest paths in planar graphs with nonnegative edge-lengths. Our algorithm also yields a linear-time algorithm for maximum flow in a planar graph with the source and sink on the same face. The previous best algorithms for these problems required $\Omega(n \sqrt{\log n})$ time where $n$ is the number of nodes in the input graph. For the case where negative edge-lengths are allowed, we give an algorithm requiring $O(n^{4/3} \log nL)$ time, where $L$ is the absolute value of the most negative length. Previous algorithms for shortest paths with negative edge-lengths required $\Omega(n^{3/2})$ time. Our shortest-path algorithm yields an $O(n^{4/3} \log n)$-time algorithm for finding a perfect matching in a planar bipartite graph. A similar improvement is obtained for maximum flow in a directed planar graph.	STOC	theory
2883	STOC	A randomized linear-time algorithm for finding minimum spanning trees.	Philip N. Klein,Robert Endre Tarjan	1994	We present a randomized linear-time algorithm for finding a minimum spanning tree in a connected graph with edge weights. The algorithm is a modification of one proposed by Karger and uses random sampling in combination with a recently discovered linear-time algorithm for verifying a minimum spanning tree. Our computational model is a unit-cost random-access machine with the restriction that the only operations allowed on edge weights are binary comparisons.	STOC	theory
2884	STOC	Fast algorithms for finding randomized strategies in game trees.	Daphne Koller,Nimrod Megiddo,Bernhard von Stengel	1994	Fast algorithms for finding randomized strategies in game trees.	STOC	theory
2885	STOC	Real-time pattern matching and quasi-real-time construction of suffix trees (preliminary version).	S. Rao Kosaraju	1994	Real-time pattern matching and quasi-real-time construction of suffix trees (preliminary version).	STOC	theory
2886	STOC	On the computational power of depth 2 circuits with threshold and modulo gates.	Matthias Krause,Pavel Pudlák	1994	On the computational power of depth 2 circuits with threshold and modulo gates.	STOC	theory
2887	STOC	The complexity of verification.	Robert P. Kurshan	1994	The complexity of verification.	STOC	theory
2888	STOC	Simple strategies for large zero-sum games with applications to complexity theory.	Richard J. Lipton,Neal E. Young	1994	Simple strategies for large zero-sum games with applications to complexity theory.	STOC	theory
2889	STOC	On contention resolution protocols and associated probabilistic phenomena.	Philip D. MacKenzie,C. Greg Plaxton,Rajmohan Rajaraman	1994	Consider an on-line scheduling problem in which a set of abstract processes are competing for the use of a number of resources. Further assume that it is either prohibitively expensive or impossible for any two of the processes to directly communicate with one another. If several processes simultaneously attempt to allocate a particular resource (as may be expected to occur, since the processes cannot easily coordinate their allocations), then none succeed. In such a framework, it is a challenge to design efficient contention resolution protocols.Two recently-proposed approaches to the problem of PRAM emulation give rise to scheduling problems of the above kind. In one approach, the resources (in this case, the shared memory cells) are duplicated and distributed randomly. We analyze a simple and efficient deterministic algorithm for accessing some subset of the duplicated resources. In the other approach, we analyze how quickly we can access the given (nonduplicated) resource using a simple randomized strategy. We obtain precise bounds on the performance of both strategies. We anticipate that our results with find other applications.	STOC	theory
2890	STOC	Trade-offs between communication throughput and parallel time.	Yishay Mansour,Noam Nisan,Uzi Vishkin	1994	Trade-offs between communication throughput and parallel time.	STOC	theory
2891	STOC	Approximation schemes for PSPACE-complete problems for succinct specifications (preliminary version).	Madhav V. Marathe,Harry B. Hunt III,Richard Edwin Stearns,Venkatesh Radhakrishnan	1994	Approximation schemes for PSPACE-complete problems for succinct specifications (preliminary version).	STOC	theory
2892	STOC	Lower bounds for union-split-find related problems on random access machines.	Peter Bro Miltersen	1994	We prove =(Clog logn ) lower bounds on the random access machine complexity of several dynamic, partially dynamic and static data structure problems, including the union-split-find problem, dynamic prefix problems and one-dimensional range query problems. The proof techniques include a general technique using perfect hashing for reducing static data structure problems (with a restriction of the size of the structure) into partially dynamic data structure problems (with no such restriction), thus providing a way to transfer lower bounds. We use a generalization of a method due to Ajtai for proving the lower bounds on the static problems, but describe the proof in terms of communication complexity, revealing a striking similarity to the proof used by Karchmer and Wigderson for proving lower bounds on the monotone circuit depth of connectivity.	STOC	theory
2893	STOC	Lower bounds for parallel linear programming and other problems.	Ketan Mulmuley	1994	Lower bounds for parallel linear programming and other problems.	STOC	theory
2894	STOC	Non-standard stringology: algorithms and complexity.	S. Muthukrishnan,Krishna V. Palem	1994	Non-standard stringology: algorithms and complexity.	STOC	theory
2895	STOC	Search for the maximum of a random walk.	Andrew M. Odlyzko	1994	Search for the maximum of a random walk.	STOC	theory
2896	STOC	Simple and efficient leader election in the full information model.	Rafail Ostrovsky,Sridhar Rajagopalan,Umesh V. Vazirani	1994	In this paper, we study the leader election problem in the full information model. We show two results in this context. First, we exhibit a constructive $O(\log N)$ round protocol that is resilient against linear size coalitions. That is, our protocol is resilient against any coalition of size less then $\beta N$ for some constant (but small) value of $\beta$. Second, we provide an easy, non-constructive probabilistic argument that shows the existence of $O(\log N)$ round protocol in which $\beta$ can be made as large as $\half - \epsilon$ for any positive $\epsilon$. Our protocols are extremely simple.	STOC	theory
2897	STOC	On complexity as bounded rationality (extended abstract).	Christos H. Papadimitriou,Mihalis Yannakakis	1994	On complexity as bounded rationality (extended abstract).	STOC	theory
2898	STOC	A theory of clock synchronization (extended abstract).	Boaz Patt-Shamir,Sergio Rajsbaum	1994	A theory of clock synchronization (extended abstract).	STOC	theory
2899	STOC	On point location and motion planning among simplices.	Marco Pellegrini	1994	Let $\SS$ be a set of $n$ possibly intersecting $(d-1)$-simplices in $d$-space for $d \geq 2$, and let ${\cal A}(\SS)$ be the arrangement of $\SS$. Let $K = |{\cal A}(\SS)|$ be the number of faces of any dimension in the arrangement of $\SS$. A data structure is described that uses storage $O(n^{d-1+\eps} +K)$ and is built {\em deterministically} in time $O(n^{d-1+\eps} +K\log n)$, where $\eps >0$ is an arbitrarily small constant, such that the face of ${\cal A}(\SS)$ containing a query point is located in time $O(\log^3 n)$. If two query points are in the same cell of ${\cal A}(\SS)$, a collision-free path connecting them is produced. This result is obtained by exploiting powerful and so far overlooked properties of sparse nets introduced by Chazelle [{\em Discrete Comput. Geom.}, 9 (1993), pp. 145--158]. If the $(d-1)$-simplices in $\SS$ have pairwise-disjoint interiors and $d \geq 3$, improved bounds are obtained. A data structure is described that uses $O(n^{d-1})$ storage and is built deterministically in time $O(n^{d-1})$ such that point-location queries are solved in time $O(\log n)$. Also, as a by-product, this method gives the first optimal worst-case algorithm for triangulating a nonsimple polyhedron in 3-space.	STOC	theory
2900	STOC	Nearly-linear size holographic proofs.	Alexander Polishchuk,Daniel A. Spielman	1994	Nearly-linear size holographic proofs.	STOC	theory
2901	STOC	Alpha-algorithms for incremental planarity testing (preliminary version).	Johannes A. La Poutré	1994	Alpha-algorithms for incremental planarity testing (preliminary version).	STOC	theory
2902	STOC	Efficient routing in all-optical networks.	Prabhakar Raghavan,Eli Upfal	1994	Communication in all-optical networks requires novel routing paradigms. The high bandwidth of the optic fiber is utilized through wavelength-division multiplexing : A single physical optical link can carry several logical signals, provided that they are transmitted on different wavelengths. We study the problem of routing a set of requests (each of which is a pair of nodes to be connected by a path) on sparse networks using a limited number of wavelengths, ensuring that different paths using the same wavelength never use the same physical link.	STOC	theory
2903	STOC	A coding theorem for distributed computation.	Sridhar Rajagopalan,Leonard J. Schulman	1994	A coding theorem for distributed computation.	STOC	theory
2904	STOC	Improved data structures for fully dynamic biconnectivity.	Monika Rauch	1994	We present fully dynamic algorithms for maintaining the biconnected components in general and plane graphs. A fully dynamic algorithm maintains a graph during a sequence of insertions and and deletions of edges or isolated vertices. Let $m$ be the number of edges and $n$ be the number of vertices in a graph. The time per operation of the best known algorithms are $O(\sqrt{n})$ in general graphs and $O(\log n)$ in plane graphs for fully dynamic connectivity and $O(\min\{m^{2/3}, n\})$ in general graphs and $O(\sqrt{n})$ in plane graphs for fully dynamic biconnectivity. We improve the later running times to $(\min\{\sqrt{m}\log n, n \})$ in general graphs and $O(\log^{2}n)$ in plane graphs. Our algorithm for general graphs can also find the biconnected components of all vertices in time $O(n)$. The update times in general graphs are amortized. This shows that the biconnected components of a graph can be dynamically maintained almost as efficiently as the connected components.	STOC	theory
2905	STOC	Natural proofs.	Alexander A. Razborov,Steven Rudich	1994	Natural proofs.	STOC	theory
2906	STOC	Pseudorandom generators and learning algorithms for AC.	Meera Sitharam	1994	Pseudorandom generators and learning algorithms for AC.	STOC	theory
2907	STOC	Symmetry breaking for suffix tree construction.	Süleyman Cenk Sahinalp,Uzi Vishkin	1994	Symmetry breaking for suffix tree construction.	STOC	theory
2908	STOC	How to share a function securely.	Alfredo De Santis,Yvo Desmedt,Yair Frankel,Moti Yung	1994	How to share a function securely.	STOC	theory
2909	STOC	On the complexity of negation-limited Boolean networks.	Keisuke Tanaka,Tetsuro Nishino	1994	On the complexity of negation-limited Boolean networks.	STOC	theory
2910	STOC	An accelerated interior point method whose running time depends only on A (extended abstract).	Stephen A. Vavasis,Yinyu Ye	1994	An accelerated interior point method whose running time depends only on A (extended abstract).	STOC	theory
2911	STOC	The amazing power of pairwise independence (abstract).	Avi Wigderson	1994	The amazing power of pairwise independence (abstract).	STOC	theory
2912	STOC	Time bounds for mutual exclusion and related problems.	Jae-Heon Yang,James H. Anderson	1994	Time bounds for mutual exclusion and related problems.	STOC	theory
2913	STOC	Decision tree complexity and Betti numbers.	Andrew Chi-Chih Yao	1994	Decision tree complexity and Betti numbers.	STOC	theory
2914	STOC	An O(log k) approximation algorithm for the k minimum spanning tree problem in the plane.	Naveen Garg,Dorit S. Hochbaum	1994	An O(log k) approximation algorithm for the k minimum spanning tree problem in the plane.	STOC	theory
2915	STOC	Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, 23-25 May 1994, Montréal, Québec, Canada		1994	Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, 23-25 May 1994, Montréal, Québec, Canada	STOC	theory
2916	IEEE Visualization	Case Study: New Techniques in the Design of Healthcare Facilities.	Tarek K. Alameldin,Mardelle Shepley	1994	The recent advent of computer graphics techniques has helped to bridge the gap between architectural concepts and actual buildings. Closing this gap is especially critical in healthcare facilities. In this paper, we present new techniques to support the design decision process and apply them to the design of a neonatal intensive care unit. Two issues are addressed: ergonometric accessibility and visual supervision of spaces. These two issues can be investigated utilizing new technologies that demonstrate that computers are more than a medium of communication in the field of architecture; the computer can make a significant contribution as a proactive design tool.	IEEE Visualizat	visu
2917	IEEE Visualization	Interactive Visualization via 3D User Interfaces.	Andries van Dam	1994	Interactive Visualization via 3D User Interfaces.	IEEE Visualizat	visu
2918	IEEE Visualization	Challenges and Opportunities in Visualization for NASA's EOS Mission to Planet Earth - Panel.	Mike E. Botts,Jon D. Dykstra,Lee S. Elson,Steven J. Goodman,Meemong Lee	1994	Challenges and Opportunities in Visualization for NASA's EOS Mission to Planet Earth - Panel.	IEEE Visualizat	visu
2919	IEEE Visualization	Integrated Control of Distributed Volume Visualization Through the World-Wide-Web.	Cheong S. Ang,David C. Martin,Michael D. Doyle	1994	The World-Wide-Web (WWW) has created a new paradigm for online information retrieval by providing immediate and ubiquitous access to digital information of any type from data repositories located throughout the world. The web's development enables not only effective access for the generic user, but also more efficient and timely information exchange among scientists and researchers. We have extended the capabilities of the web to include access to three-dimensional volume data sets with integrated control of a distributed client-server volume visualization system. This paper provides a brief background on the World-Wide-Web, an overview of the extensions necessary to support these new data types and a description of an implementation of this approach in a WWW-compliant distributed visualization system	IEEE Visualizat	visu
2920	IEEE Visualization	VolVis: A Diversified Volume Visualization System.	Ricardo S. Avila,Taosong He,Lichan Hong,Arie E. Kaufman,Hanspeter Pfister,Cláudio T. Silva,Lisa M. Sobierajski,Sidney W. Wang	1994	VolVis is a diversified, easy to use, extensible, high performance, and portable volume visualization system for scientists and engineers as well as for visualization developers and researchers. VolVis accepts as input 3D scalar volumetric data as well as 3D volume-sampled and classical geometric models. Interaction with the data is controlled by a variety of 3D input devices in an input device-independent environment. VolVis output includes navigation preview, static images, and animation sequences. A variety of volume rendering algorithms are supported, ranging from fast rough approximations, to compression-domain rendering, to accurate volumetric ray tracing and radiosity, and irregular grid rendering.	IEEE Visualizat	visu
2921	IEEE Visualization	Streamball Techniques for Flow Visualization.	Manfred Brill,Hans Hagen,Hans-Christian Rodrian,Wladimir Djatschin,Stanislav V. Klimenko	1994	We introduce the concept of streamballs for flow visualization. Streamballs are based upon implicit surface generation techniques adopted from the well-known metaballs. Their property to split or merge automatically in areas of significant divergence or convergence makes them an ideal tool for the visualization of arbitrary complex flow fields. Using convolution surfaces generated by continuous skeletons for streamball construction offers the possibility to visualize even tensor fields.	IEEE Visualizat	visu
2922	IEEE Visualization	Triangulation and Display of Rational Parametric Surfaces.	Chandrajit L. Bajaj,Andrew V. Royappa	1994	We present a comprehensive algorithm to construct a topologically correct triangulation of the real affine part of a rational parametric surface with few restrictions on the defining rational functions. The rational functions are allowed to be undefined on domain curves (pole curves) and at certain special points (base points), and the surface is allowed to have nodal or cuspidal self-intersections. We also recognize that for a complete display some real points on the parametric surface may be generated only by complex parameter values, and that some finite points on the surface may be generated only by infinite parameter values; we show how to compensate for these conditions. Our techniques for handling these problems have applications in scientific visualization, rendering non-standard NURBS, and in finite-element mesh generation.	IEEE Visualizat	visu
2923	IEEE Visualization	The Design and Implementation of the Cortex Visualization System.	Deb Banerjee,Chris Morley,Wayne Smith	1994	Cortex has been designed for interactive analysis and display of simulation data generated by CFD applications based on unstructured-grid solvers. Unlike post-processing visualization environments, Cortex is designed to work in co-processing mode with the CFD application. This significantly reduces data storage and data movement requirements for visualization and also allows users to interactively steer the application. Further, Cortex supports high-performance by running on massively parallel computers and workstation clusters.An important goal for Cortex is to provide visualization to a variety of solvers which differ in their solution methodologies and supported flow models. Coupled with the co-processing requirement, this has required the development of a well defined programming interface to the CFD solver that lets the the visualization system communicate efficiently with the solver, and requires minimal programming effort for porting to new solvers. Further, the requirement for targeting multiple solvers and application niches demands that the visualization system be rapidly and easily modifiable. Such flexibility is attained in Cortex by using the high-level, interpreted language Scheme for implementing user-interfaces and high-level visualization functions. By making the Scheme interpreter available from the Cortex text interface, the user can also customize and extend the visualization system.	IEEE Visualizat	visu
2924	IEEE Visualization	Vortex Tubes in Turbulent Flows: Identification, Representation, Reconstruction.	David C. Banks,Bart A. Singer	1994	A new algorithm for identifying vortices in complex flows is presented. The scheme uses both the vorticity and pressure fields. A skelton line along the center of a vortex is produced by a two-step predictor-corrector scheme. The technique uses the vector field to move in the direction of the skeleton line and the scalar field to correct the location in the plane perpendicular to the skelton line. With an economical description of the vortex tube's cross-section, the skeleton compresses the representation of the flow by a factor of 4000 or more. We show how the reconstructed geometry of vortex tubes can be enhanced to help visualize helical motion.	IEEE Visualizat	visu
2925	IEEE Visualization	Information Workspaces for Large Scale Cognition.	Stuart K. Card	1994	Information Workspaces for Large Scale Cognition.	IEEE Visualizat	visu
2926	IEEE Visualization	Virtual Reality Performance for Virtual Geometry.	Robert A. Cross,Andrew J. Hanson	1994	We describe the theoretical and practical visualization issues solved in the implementation of an interactive real-time four-dimensional geometry interface for the CAVE, an immersive virtual reality environment. While our specific task is to produce a virtual geometry experience by approximating physically correct rendering of manifolds embedded in four dimensions, the general principles exploited by our approach reflect requirements common to many immersive virtual reality applications, especially those involving volume rendering. Among the issues we address are the classification of rendering tasks, the specialized hardware support required to attain interactivity, specific techniques required to render 4D objects, and interactive methods appropriate for our 4D virtual world application.	IEEE Visualizat	visu
2927	IEEE Visualization	The Topology of Symmetric, Second-Order Tensor Fields.	Thierry Delmarcelle,Lambertus Hesselink	1994	We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data.The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities---such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields.Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Pointcar&eacute;-Hopf theorem for vector fields.	IEEE Visualizat	visu
2928	IEEE Visualization	An Object Oriented Design for the Visualization of Multi-Variable Data Objects.	Jean-Marie Favre,James K. Hahn	1994	This paper presents an object-oriented system design supporting the composition of scientific data visualization techniques based on the definition of hierarchies of typed data objects and tools. Traditional visualization systems focus on creating graphical objects which often cannot be re-used for further processing. Our approach provides objects of different topological dimension to offer a natural way of describing the results of visualization mappings. Serial composition of data extraction tools is allowed, while each intermediate visualization object shares a common description and behavior. Visualization objects can be re-used, facilitating the data exploration process by expanding the available analysis and correlation functions provided. This design offers an open-ended architecture for the development of new visualization techniques. It promotes data and software re-use, eliminates the need for writing special purpose software and reduces processing requirements during interactive visualization sessions.	IEEE Visualizat	visu
2929	IEEE Visualization	User Modeling for Adaptive Visualization Systems.	Gitta Domik,Bernd Gutkauf	1994	Meaningful scientific visualizations benefit the interpretation of scientific data, concepts and processes. To ensure meaningful visualizations, the visualization system needs to adapt to desires, disabilities and abilities of the user, interpretation aim, resources (hardware, software) available, and the form and content of the data to be visualized. We suggest to describe these characteristics by four models: user model, problem domain/task model, resource model and data model. This paper makes suggestions for the generation of a user model as a basis for an adaptive visualization system.We propose to extract information about the user by involving the user in interactive computer tests and games. Relevant abilities tested are color preception, color memory, color ranking, mental rotation, and fine motor coordination.	IEEE Visualizat	visu
2930	IEEE Visualization	A Case Study on Visualization for Boundary Value Problems.	Gábor Domokos,Randy C. Paffenroth	1994	In this paper we present a method, and a software based on this method, making highly inter-active visualization possible for computational results on nonlinear BVPs associated with ODEs. The program PCR relies partly on computer graphics tools and partly on real-time computations, the combination of which not only helps the understanding of complex problems, it also permits the reduction of stored data by orders of magnitude. The method has been implemented on PCs (running on DOS) and on the Application Visualization System (AVS) for UNIX machines, this paper provides a brief introduction to the latter version besides describing the mathematical background of the method.	IEEE Visualizat	visu
2931	IEEE Visualization	Visualizing Flow Over Curvilinear Grid Surfaces Using Line Integral Convolution.	Lisa K. Forssell	1994	Line Integral Convolution (LIC), introduced by Cabral and Leedom in Siggraph '93, is a powerful technique for imaging and animating vector fields. We extend the LIC paradigm in three ways:1. The existing technique is limited to vector fields over a regular Cartesian grid. We extend it to vector fields over parametric surfaces, specifically those found in curvilinear grids, used in computational fluid dynamics simulations.2. Periodic motion filters can be used to animate the flow visualization. When the flow lies on a parametric surface, however, the motion appears misleading. We explain why this problem arises and show how to adjust the LIC algorithm to handle it.3. We introduce a technique to visualize vector magnitude as well as vector direction. Cabral and Leedom have suggested a method for variable-speed animation, which is based on varying the frequency of the filter function. We develop a different technique based on kernel phase shifts which we have found to show substantially better results.Our implementation of these algorithms utilizes texture-mapping hardware to run in real time, which allows them to be included in interactive applications.	IEEE Visualizat	visu
2932	IEEE Visualization	Spiders: A New User Interface for Rotation and Visualization of N-dimensional Point Sets.	Kirk L. Duffin,William A. Barrett	1994	We present a new method for creating n-dimensional rotation matrices from manipulating the projections of n-dimensional data coordinate axes onto a viewing plane. A user interface for n-dimensional rotation is implemented. The interface is shown to have no rotational hysteresis.	IEEE Visualizat	visu
2933	IEEE Visualization	Nonpolygonal Isosurface Rendering for Large Volume Datasets.	James W. Durkin,John F. Hughes	1994	Surface-based rendering techniques, particularly those that extract a polygonal approximation of an isosurface, are widely used in volume visualization. As dataset size increases though, the computational demands of these methods can overwhelm typically available computing resources. Recent work on accelerating such techniques has focused on preprocessing the volume data or postprocessing the extracted polygonization. Our new algorithm concentrates instead on streamlining the surface extraction process itself so as to accelerate the rendering of large volumes. The technique shortens the conventional isosurface visualization pipeline by eliminating the intermediate polygonization. We compute the contribution of the isosurface within a volume cell to the resulting image directly from a simplified numerical description of the cell/surface intersection. Our approach also reduces the work in the remaining stages of the visualization process. By quantizing the volume data, we exploit precomputed and cached data at key processing steps to improve rendering efficiency. The resulting implementation provides comparatively fast renderings with reasonable image quality.	IEEE Visualizat	visu
2934	IEEE Visualization	Volume Rendering Methods for Computational Fluid Dynamics Visualization.	David S. Ebert,Roni Yagel,James N. Scott,Yair Kurzion	1994	This paper describes three alternative volume rendering approaches to visualizing computational fluid dynamics (CFD) data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations from scalar CFD data. The second uses ray casting that is based on a simpler illumination model and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple illumination model and rapid rendering mechanisms to provide efficient preview capabilities. These tools provide a large range of volume rendering capabilities to be used by the CFD explorer to render rapidly for navigation through the data, to emphasize data features (e.g., shock waves) with a specific transfer function, or to present a realistic rendition of the model.	IEEE Visualizat	visu
2935	IEEE Visualization	Wavelet-Based Volume Morphing.	Taosong He,Sidney W. Wang,Arie E. Kaufman	1994	This paper presents a technique for performing volume morphing between two volumetric datasets in the wavelet domain. The idea is to decompose the volumetric datasets into a set of frequency bands, apply smooth interpolation to each band, and reconstruct to form the morphed model. In addition, a technique for establishing a suitable correspondence among object voxels is presented. The combination of these two techniques results in a smooth transition between the two datasets and produces morphed volume with fewer high frequency distortions than those obtained from spatial domain volume morphing.	IEEE Visualizat	visu
2936	IEEE Visualization	Visualization in the Information Highway.	Nahum D. Gershon	1994	Visualization in the Information Highway.	IEEE Visualizat	visu
2937	IEEE Visualization	Visualizing Flow with Quaternion Frames.	Andrew J. Hanson,Hui Ma	1994	Flow fields, geodesics, and deformed volumes are natural sources of families of space curves that can be characterized by intrinsic geometric properties such as curvature, torsion, and Frenet frames. By expressing a curve's moving Frenet coordinate frame as an equivalent unit quaternion, we reduce the number of components that must be displayed from nine with six constraints to four with one constraint. We can then assign a color to each curve point by dotting its quaternion frame with a 4D light vector, or we can plot the frame values separately as a curve in the threesphere. As example, we examine twisted volumes used in topology to construct knots and tangles, a spherical volume deformation known as the Dirac string trick, and streamlines of 3D vector flow fields.	IEEE Visualizat	visu
2938	IEEE Visualization	A Lattice Model for Data Display.	William L. Hibbard,Charles R. Dyer,Brian E. Paul	1994	In order to develop a foundation for visualization, we develop lattice models for data objects and displays that focus on the fact that data objects are approximations to mathematical objects and real displays are approximations to ideal displays. These lattice models give us a way to quantize the information content of data and displays and to define conditions on the visualization mappings from data to displays. Mappings satisfy these conditions if and only if they are lattice isomorphisms. We show how to apply this result to scientific data and display models, and discuss how it might be applied to recursively defined data types appropriate for complex information processing.	IEEE Visualizat	visu
2939	IEEE Visualization	Visualizing multidimensional (multivariate) data and relations (Panel).	Alfred Inselberg,Georges G. Grinstein,Ted Mihalisin,Hans Hinterberger	1994	Visualizing multidimensional (multivariate) data and relations (Panel).	IEEE Visualizat	visu
2940	IEEE Visualization	Isosurface Generation by Using Extrema Graphs.	Takayuki Itoh,Koji Koyamada	1994	A high-performance algorithm for generating isosurfaces is presented. In this algorithm, extrema points in a scalar field are first extracted. A graph is then generated in which the extrema points are taken as nodes. Each arc of the graph has a list of IDs of the cells that are intersected by the arc. A boundary cell list ordered according to cells' values is also generated. The graph and the list generated in this pre-process are used as a guide in searching for seed cells. Isosurfaces are generated from seed cells that are found in arcs of the graph. In this process isosurfaces appear to propagate themselves. The algorithm visits only cells that are intersected by an isosurface and cells whose IDs are included in cell lists. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described in this paper show the efficiency of the algorithm.	IEEE Visualizat	visu
2941	IEEE Visualization	Case Study: Visualization of Mesoscale Flow Features in Ocean Basins.	Andreas Johannsen,Robert J. Moorhead	1994	Environmental issues such as global warming are an active area of international research and concern today. This case study describes various visualization paradigms that have been developed and applied in an attempt to elucidate the information provided by environmental models and observations. The ultimate goal is to accurately measure the existence of any long term climatological change. The global ocean is the starting point, since it is a major source and sink of heat within our global environment.	IEEE Visualizat	visu
2942	IEEE Visualization	The Crucial Difference Between Human and Machine Vision: Focal Attention.	Bela Julesz	1994	The Crucial Difference Between Human and Machine Vision: Focal Attention.	IEEE Visualizat	visu
2943	IEEE Visualization	UFAT - A Particle Tracer for Time-Dependent Flow Fields.	David A. Lane	1994	Time-dependent (unsteady) flow fields are commonly generated in Computational Fluid Dynamics (CFD) simulations; however, there are very few flow visualization systems that generate particle traces in unsteady flow fields. Most existing systems generate particle traces in time-independent flow fields. A particle tracing system has been developed to generate particle traces in unsteady flow fields. The system was used to visualize several 3D unsteady flow fields from real-world problems, and it has provided useful insights into the time-varying phenomena in the flow fields. In this paper, the design requirements and the architecture of the system are described. Some examples of particle traces computed by the system are also shown.	IEEE Visualizat	visu
2944	IEEE Visualization	Strata-Various: Multi-Layer Visualization of Dynamics in Software System Behavior.	Doug Kimelman,Bryan S. Rosenburg,Tova Roth	1994	Current software visualization tools are inadequate for understanding, debugging, and tuning realistically complex applications. These tools often present only static structure, or they present dynamics from only a few of the many layers of a program and its underlying system. This paper introduces PV, a prototype program visualization system which provides concurrent visual presentation of behavior from all layers, including: the program itself, user-level libraries, the operating system, and the hardware, as this behavior unfolds over time. PV juxtaposes views from different layers in order to facilitate visual correlation, and allows these views to be navigated in a coordinated fashion. This results in an extremely powerful mechanism for exploring application behavior. Experience is presented from actual use of PV in production settings with programmers facing real deadlines and serious performance problems.	IEEE Visualizat	visu
2945	IEEE Visualization	3D Visualization of Unsteady 2D Airplane Wake Vortices.	Kwan-Liu Ma,Z. C. Zheng	1994	Air flowing around the wing tips of an airplane forms horizontal tornado-like vortices that can be dangerous to following aircraft. The dynamics of such vortices, including ground and atmospheric effects, can be predicted by numerical simulation, allowing the safety and capacity of airports to be improved. In this payer, we introduce three-dimensional techniques for visualizing time-dependent, two-dimensional wake vorte computations, and the hazard strength of such vortices near the ground. We describe a vortex core tracing algorithm and a local tiling method to visualize the vortex evolution. The tiling method converts time-dependent, two-dimensional vortex cores into three-dimensional vortex tubes. Finally, a novel approach is used to calculate the induced rolling moment on the following airplane at each grid point within a region near the vortex tubes and thus allows three-dimensional visualization of the hazard strength of the vortices.	IEEE Visualizat	visu
2946	IEEE Visualization	An Annotation System for 3D Fluid Flow Visualization.	Maria M. Loughlin,John F. Hughes	1994	Annotation is a key activity of data analysis. However, current data analysis systems focus almost exclusively on visualization. We propose a system which integrates annotations into a visualization system. Annotations are embedded in 3D data space, using the Post-it1 metaphor. This embedding allows contextual-based information storage and retrieval, and facilitates information sharing in collaborative environments. We provide a traditional database filter and a Magic Lens2 filter to create specialized views of the data. The system is customized for fluid flow applications, with features which allow users to store parameters of visualization tools and sketch 3D volumes.	IEEE Visualizat	visu
2947	IEEE Visualization	Introducing Alpha Shapes for the Analysis of Path Integral Monte Carlo Results.	Patrick J. Moran,Marcus Wagner	1994	We present a new technique for the visualization and analysis of the results from Monte Carlo simulations based on &alpha;-complexes and &alpha;-shapes. The specific application we present in this article is the analysis of the quantum-mechanical behavior of hydrogen molecules and helium atoms on a surface at very low temperatures. Our technique is an improvement over existing techniques in two respects. First, our approach allows one to visualize the points on a random walk at varying levels of detail and interactively select the level of detail that is most appropriate. Second using &alpha;-shapes one can obtain quantitative measures of spatial properties of the system, such as the boundary length and interior area of clusters, that would be difficult to obtain otherwise.	IEEE Visualizat	visu
2948	IEEE Visualization	Case Study: Visualization of an Electric Power Transmission System.	Pramod M. Mahadev,Richard D. Christie	1994	Visualization techniques are applied to an electric power system transmission network to create a graphical picture of network power flows and voltages. A geographic data map is used. Apparent power flow is encoded as the width of an arrow, with direction from real power flow. Flows are superposed on flow limits. Contour plots and color coding failed for representing bus voltages. A two-color thermometer encoding worked well. The resulting visualization is a significant improvement over current user interface practice in the power industry.	IEEE Visualizat	visu
2949	IEEE Visualization	Case Study: Visualization and Data Analysis in Space and Atmospheric Science.	A. Mankofsky,E. P. Szuszczewicz,P. Blanchard,C. Goodrich,D. McNabb,R. Kulkarni,D. Kamins	1994	In this paper we show how SAVS, a tool for visualization and data analysis in space and atmospheric science, can be used to quickly and easily address problems that would previously have been far more laborious to solve. Based on the popular AVS package, SAVS presents the user with an environment tailored specifically for the physical scientist. Thus there is minimal startup time, and the scientist can immediately concentrate on his science problem. The SAVS concept readily generalizes to many other fields of science and engineering.	IEEE Visualizat	visu
2950	IEEE Visualization	Piecewise-Linear Surface Approximation From Noisy Scattered Samples.	Michael Margaliot,Craig Gotsman	1994	We consider the problem of approximating a smooth surface f(x,y), based on n scattered samples {(xi, yi, zi)ni=1} where the sample values {zi} are contaminated with noise: zi = f(xi, yi) + &epsilon;i. We present an algorithm that generates a PLS (Piecewise Linear Surface) f1, defined on a triangulation of the sample locations V = {(xi, yi)ni=1}, approximating f well. Constructing the PLS involves specifying both the triangulation of V and the values of f1 at the points of V. We demonstrate that even when the sampling process is not noisy, a better approximation for f is obtained using our algorithm, compared to existing methods. This algorithm is useful for DTM (Digital Terrain Map) manipulation by polygon-based graphics engines for visualization applications.	IEEE Visualizat	visu
2951	IEEE Visualization	An Evaluation of Reconstruction Filters for Volume Rendering.	Stephen R. Marschner,Richard Lobb	1994	To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation.We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the intrpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter.	IEEE Visualizat	visu
2952	IEEE Visualization	Approximation of Isosurface in the Marching Cube: Ambiguity Problem.	Sergey V. Matveyev	1994	The purpose of the present article is the consideration of the problem of ambiguity over the faces arising in the Marching Cube algorithm. The article shows that for unambiguous choice of the sequence of the points of intersection of the isosurface with edges confining the face it is sufficient to sort them along one of the coordinates. It also presents the solution of this problem inside the cube. The graph theory methods are used to approximate the isosurface inside the cell.	IEEE Visualizat	visu
2953	IEEE Visualization	A Library for Visualizing Combinatorial Structures.	Marc Najork,Marc H. Brown	1994	This paper describes ANIM3D, a 3D animation library targeted at visualizing combinatorial structures. In particular, we are interested in algorithm animation. Constructing a new view for an algorithm typically takes dozens of design iterations, and can be very time-consuming. Our library eases the programmer's burden by providing high-level constructs for performing animations, and by offering an interpretive environment that eliminates the need for recompilations. This paper also illustrates ANIM3D's expressiveness by developing a 3D animation of Dijkstra's shortest-path algorithm in just 70 lines of code.	IEEE Visualizat	visu
2954	IEEE Visualization	Visualizing 3D Velocity Fields Near Contour Surfaces.	Nelson L. Max,Roger Crawfis,Charles Grant	1994	Vector field rendering is difficult in 3D because the vector icons overlap and hide each other. We propose four different techniques for visualizing vector fields only near surfaces. The first uses motion blurred particles in a thickened region around the surface. The second uses a voxel grid to contain integral curves of the vector field. The third uses many antialiased lines through the surface, and the fourth uses hairs sprouting from the surface and then bending in the direction of the vector field. All the methods use the graphics pipeline, allowing real time rotation and interaction, and the first two methods can animate the texture to move in the flow determined by the velocity field.	IEEE Visualizat	visu
2955	IEEE Visualization	Feature Detection from Vector Quantities in a Numerically Simulated Hypersonic Flow Field in Combination with Experimental Flow Visualization.	Hans-Georg Pagendarm,Birgit Walter	1994	In computational fluid dynamics visualization is a frequently used tool for data evaluation, understanding of flow characteristics, and qualitative comparison to flow visualizations originating from experiments. Building on an existing visualization software system, that allows for a careful selection of state-of-the-art visualization techniques and some extensions, it became possible to present various features of the data in a single image. The visualizations show vortex position and rotation as well as skin-friction lines, experimental oil-flow traces, and shock-wave positions. By adding experimental flow visualization, a comparison between numerical simulation and wind-tunnel flow becomes possible up to a high level of detail. Since some of the underlying algorithms are not yet described in detail in the visualization literature, some experiences gained from the implementation are illustrated.	IEEE Visualizat	visu
2956	IEEE Visualization	Mix&Match: A Construction Kit for Visualization.	Alex Pang,Naim Alper	1994	Mix&Match: A Construction Kit for Visualization.	IEEE Visualizat	visu
2957	IEEE Visualization	Case Study: Tokamak Plasma Turbulence Visualization.	Scott E. Parker,Ravi Samtaney	1994	One of the most fundamental issue in magnetic fusion research is the understanding of turbulent transport observed in present-day tokamak experiments. Plasma turbulence is very challenging from a theoretical point of view due to the nonlinearity and high dimensionality of the governing equations. Recent developments in algorithms along with the astounding advances in high performance computing now make first-principle particle simulations an important tool for improved understanding of such phenomena. Due to the five dimensional phase space (3 spatial, 2 velocity) and complex toroidal geometry, visualization is crucial for interpreting such simulation data. This paper discusses how visualization tools are currently used and what new physics has been elucidated, along with what can be learned about tokamak turbulence through the interplay between theory, simulation and visualization.	IEEE Visualizat	visu
2958	IEEE Visualization	Case Study: Integrating Spatial Data Display with Virtual Reconstruction.	Philip Peterson,Brian Hayden,F. David Fracchia	1994	In the process of archaeological excavation, a vast amount of data, much of it three-dimensional in nature, is recorded. In recent years, computer graphics techniques have been applied to the task of visualizing such data. In particular, data visualization has been used to accomplish the virtual reconstruction of site architecture and to enable the display of spatial data distributions using three-dimensional models of site terrain. In the case we present here, these two approaches are integrated in the modeling of a prehistoric pithouse. In order to better visualize artifact distributions in the context of site architecture, surface data is displayed as a layer in a virtual reconstruction viewable at interactive rates. This integration of data display with the architectural model has proven valuable in identifying correlations between distributions of different artifact categories and their spatial proximity to significant architectural features.	IEEE Visualizat	visu
2959	IEEE Visualization	Visualization and Geographic Information System Integration: What are the needs and the requirements, if any? (Panel).	Theresa-Marie Rhyne,William Ivey,Loey Knapp,Peter Kochevar,Tom Mace	1994	Visualization and Geographic Information System Integration: What are the needs and the requirements, if any? (Panel).	IEEE Visualizat	visu
2960	IEEE Visualization	A Visualization System on Every Desk - Keeping it Simple.	Steven F. Roth	1994	A Visualization System on Every Desk - Keeping it Simple.	IEEE Visualizat	visu
2961	IEEE Visualization	Case Study: Visualization of Volcanic Ash Clouds.	Mitchell Roth,Rick Guritz	1994	Ash clouds resulting from volcanic eruptions are a serious hazard to aviation safety. In Alaska alone, there are over 40 active volcanoes whose eruptions may affect more than 40,000 flights using the great circle polar routes each year. The clouds are especially problematic because they are invisible to radar and nearly impossible to distinguish from weather clouds. The Arctic Region Supercomputing Center and the Alaska Volcano Observatory have collaborated to develop a system for predicting and visualizing the movement of volcanic ash clouds when an eruption occurs. The output from the model is combined with a digtal elevation model to produce a realistic view of the ash cloud which may be examined interactively from any desired point of view at any time during the prediction period. This paper describes the visualization techniques employed in the system and includes a video animation of the 1989 Mount Redoubt eruption which caused complete engine failure on a 747 passenger jet.	IEEE Visualizat	visu
2962	IEEE Visualization	Visualization in Medicine: VIRTUAL Reality or ACTUAL Reality? (Panel).	Christian Roux,Jean-Louis Coatrieux,Jean-Louis Dillenseger,Elliot K. Fishman,Murray H. Loew,Hans-Peter Meinzer,Justin D. Pearlman	1994	Visualization in Medicine: VIRTUAL Reality or ACTUAL Reality? (Panel).	IEEE Visualizat	visu
2963	IEEE Visualization	A distributed, parallel, interactive volume rendering package.	John S. Rowlan,G. Edward Lent,Nihar Gokhale,Shannon Bradshaw	1994	This paper presents a parallel ray-casting volume rendering algorithm and its implementation on the massively parallel IBM SP-1 computer using the Chameleon message passing library. Though this algorithm takes advantage of many of the unique features of the SP-1 (e.g. high-speed switch, large memory per node, high-speed disk array, HIPPI display, et al), the use of Chameleon allows the code to be executed on any collection of workstations.The algorithm is image-ordered and distributes the data and the computational load to individual processors. After the volume data is distributed, all processors then perform local raytracing of their respective subvolumes concurrently. No interprocess communication takes place during the ray tracing process. After a subimage is generated by each processor, the final image is obtained by composing subimages between all the processers.The program itself is implemented as an interactive process through a GUI residing on a graphics work-station which is coupled to the parallel rendering algorithm via sockets. The paper highlights the Chameleon implementation, the GUI, some optimization improvements, static load balancing, and direct parallel display to a HIPPI framebuffer.	IEEE Visualizat	visu
2964	IEEE Visualization	Case Study: Volume Rendering of Pool Fire Data.	Holly E. Rushmeier,A. Hamins,M.-Y. Choi	1994	We describe how techniques from computer graphics are used to visualize pool fire data and computer radiative effects from pool fires. The basic tools are ray casting and accurate line integration using the RADCAL program. Example images in the visible and infrared band are shown which give qualitative insights about the fire data. Examples are given of irradiation calculations and novel methods to visualize the results of irradiation calculations.	IEEE Visualizat	visu
2965	IEEE Visualization	Case Study: Visualization of 3D Ultrasonic Data.	Georgios Sakas,Lars-Arne Schreyer,Marcus Grimm	1994	3D Ultrasound is one of the most interesting non-invasive, non-radiative tomographic techniques. Rendering 3D modells from such data is not straight-forward due to the noisy, fuzzy nature of ultrasound imaging containing a lot of artefacts. In this paper we first apply speckle, median and gaussian prefiltering to improve the image quality. Using several semi-automatic segmentation tools we isolate interesting features within a few minutes. Our improved surface-extraction procedure enables volume rendering of high quality within a few seconds on a normal work-station, thus making the complete system suitable for routine clinical applications.	IEEE Visualizat	visu
2966	IEEE Visualization	Implicit Modeling of Swept Surfaces and Volumes.	William J. Schroeder,William E. Lorensen,Steve Linthicum	1994	Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning.	IEEE Visualizat	visu
2967	IEEE Visualization	Differential Volume Rendering: A Fast Volume Visualization Technique for Flow Animation.	Han-Wei Shen,Christopher R. Johnson	1994	We present a direct volume rendering algorithm to speed up volume animation for flow visualizations. Data coherency between consecutive simulation time steps is used to avoid casting rays from those pixels retaining color values assigned to the previous image. The algorithm calculates the differential information among a sequence of 3D volumetric simulation data. At each time step the differential information is used to compute the locations of pixels that need updating and a ray-casting method is utilized to produce the updated image. We illustrate the utility and speed of the differential volume rendering algorithm with simulatin data from computational bioelectric and fluid dynamics applications. We can achieve considerable disk-space savings and nearly real-time rendering of 3D flows using low-cost, single processor workstations* for models which contain hundreds of thousands of data points.	IEEE Visualizat	visu
2968	IEEE Visualization	The Future of Graphic User Interfaces.	Ben Shneiderman	1994	The Future of Graphic User Interfaces.	IEEE Visualizat	visu
2969	IEEE Visualization	Parallel Performance Measures for Volume Ray Casting.	Cláudio T. Silva,Arie E. Kaufman	1994	We describe a technique for achieving fast volume ray casting on parallel machines, using a load balancing scheme and an efficient pipelined approach to compositing. We propose a new model for measuring the amount of work one needs to perform in order to render a given volume, and use this model to obtain a better load balancing scheme for distributed memory machines. We also discuss in detail the design tradeoffs of our technique. In order to validate our model we have implemented it on the Intel iPSC/860 and the Intel Paragon, and conducted a detailed performance analysis.	IEEE Visualizat	visu
2970	IEEE Visualization	Fast Surface Rendering from Raster Data by Voxel Traversal Using Chessboard Distance.	Milos Srámek	1994	Fast Surface Rendering from Raster Data by Voxel Traversal Using Chessboard Distance.	IEEE Visualizat	visu
2971	IEEE Visualization	Case Study: Observing a Volume Rendered Fetus within a Pregnant Patient.	Andrei State,David T. Chen,Chris Tector,Andrew Brandt,Hong Chen,Ryutarou Ohbuchi,Michael Bajura,Henry Fuchs	1994	Augmented reality systems with see-through head-mounted displays have been used primarily for applications that are possible with today's computational capabilities. We explore possibilities for a particular application---in-place, real-time 3D ultrasound visualization---without concern for such limitations. The question is not How well could we currently visualize the fetus in real time, but How well could we see the fetus if we had sufficient compute power?Our video sequence shows a 3D fetus within a pregnant woman's abdomen---the way this would look to a HMD user. Technical problems in making the sequence are discussed. This experience exposed limitations of current augmented reality systems; it may help define the capabilities of future systems needed for applications as demanding as real-time medical visualization.	IEEE Visualizat	visu
2972	IEEE Visualization	Visualizing Data: Is Virtual Reality the Key? (Panel).	Linda M. Stone,Thomas Erickson,Benjamin B. Bederson,Peter Rothman,Raymond Muzzy	1994	Visualizing Data: Is Virtual Reality the Key? (Panel).	IEEE Visualizat	visu
2973	IEEE Visualization	GASP - A System for Visualizing Geometric Algorithms.	Ayellet Tal,David P. Dobkin	1994	This paper describes a system, GASP, that facilitates the visualization of geometric algorithms. The user need not have any knowledge of computer graphics in order to quickly generate a visualization. The system is also intended to facilitate the task of implementing and debugging geometric algorithms. The viewer is provided with a comfortable user interface enhancing the exploration of an algorithm's functionality. We describe the underlying concepts of the system as well as a variety of examples which illustrate its use.	IEEE Visualizat	visu
2974	IEEE Visualization	Progressive Transmission of Scientific Data Using Biorthogonal Wavelet Transform.	Hai Tao,Robert J. Moorhead	1994	An important issue in scientific visualization systems is the management of data sets. Most data sets in scientific visualization, whether created by measurement or simulation, are usually voluminous. The goal of data management is to reduce the storage space and the access time of these data sets to speed up the visualization process. A new progressive transmission scheme using spline biorthogonal wavelet bases is proposed in this paper. By exploiting the properties of this set of wavelet bases, a fast algorithm involving only additions and subtractions is developed. Due to the multiresolutional nature of the wavelet transform, this scheme is compatible with hierarchical-structured rendering algorithms. The formula for reconstructing the functional values in a continuous volume space is given in a simple polynomial form. Lossless compression is possible, even when using floating-point numbers. This algorithm has been applied to data from a global ocean model. The lossless compression ratio is about 1.5:1. With a compression ratio of 50:1, the reconstructed data is still of good quality. Several other wavelet bases are compared with the spline biorthogonal wavelet bases. Finally, the reconstructed data is visualized using various algorithms and the results are demonstrated.	IEEE Visualizat	visu
2975	IEEE Visualization	Case Study: Severe Rainfall Events in Northwestern Peru (Visualization of Scattered Meteorological Data).	Lloyd Treinish	1994	The ordinarily arid climate of coastal Peru is disturbed every few years by a phenomenon called El Ni&ntilde;o, characterized by a warming in the Pacific Ocean. Severe rainstorms are one of the consequences of El Ni&ntilde;o, which cause great damage. An examination of daily data from 66 rainfall stations in the Chiura-Piura region of north-western Peru from late 1982 through mid-1983 (associated with an El Ni&ntilde;o episode) yields information on the mesoscale structure of these storms. These observational data are typical of a class that are scattered at irregular locations in two dimensions. The use of continuous realization techniques for qualitative visualization (e.g., surface deformation or contouring) requires an intermediate step to define a topological relationship between the locations of data to form a mesh structure. Several common methods are considered, and the results of their application to the study of the rainfall events are analyzed.	IEEE Visualizat	visu
2976	IEEE Visualization	Restorer: A Visualization Technique for Handling Missing Data.	Ray Twiddy,John Cavallo,Shahram M. Shiri	1994	Pseudocoloring is a frequently used technique in scientific visualization for mapping a color to a data value. When using pseudocolor and animation to visualize data that contain missing regions displayed as black or transparent, the missing regions popping in and out can distract the viewer from the more relevant information. Filling these gaps with interpolated data could lead to a misinterpretation of the data. This paper presents a method for combining pseudocoloring and grayscale in the same colormap. Valid data are mapped to colors in the colormap. The luminance values of the colors bounding areas of missing data are used in interpolating over these regions. The missing data are mapped to the grayscale portion of the colormap. This approach has the advantages of eliminating distracting gaps caused by missing data and distinguishing between those areas that represent valid data and those areas that do not. This approach was inspired by a technique used in the restoration of paintings.	IEEE Visualizat	visu
2977	IEEE Visualization	Validation, verification and evaluation (Panel).	Samuel P. Uselton,Geoff Dorn,Charbel Farhat,Michael W. Vannier,Kim Esbensen,Al Globus	1994	Validation, verification and evaluation (Panel).	IEEE Visualizat	visu
2978	IEEE Visualization	XmdvTool: Integrating Multiple Methods for Visualizing Multivariate Data.	Matthew O. Ward	1994	Much of the attention in visualization research has focussed on data rooted in physical phenomena, which is generally limited to three or four dimensions. However, many sources of data do not share this dimensional restriction. A critical problem in the analysis of such data is providing researchers with tools to gain insights into characteristics of the data, such as anomalies and patterns. Several visualization methods have been developed to address this problem, and each has its strengths and weaknesses. This paper describes a system named XmdvTool which integrates several of the most common methods for projecting multivariate data onto a two-dimensional screen. This integration allows users to explore their data in a variety of formats with ease. A view enhancement mechanism called an N-dimensional brush is also described. The brush allows users to gain insights into spatial relationships over N dimensions by highlighting data which falls within a user-specified subspace.	IEEE Visualizat	visu
2979	IEEE Visualization	Visualizing Polycrystalline Orientation Microstructures with Spherical Color Maps.	Boris Yamrom,John A. Sutliff,Andrew P. Woodfield	1994	Spherical color maps can be an effective tool in the microstructure visualization of polycrystals. Electron backscatter diffraction pattern analysis provides large arrays of the orientation data that can be visualized easily using the technique described in this paper. A combination of this technique with the traditional black and white scanning electron microscopy imaging will enable scientists to better understand the correlation between material properties and their polycrystalline structure.	IEEE Visualizat	visu
2980	IEEE Visualization	Proceedings IEEE Visualization '94, Washington, DC, USA, October 17-21, 1994	R. Daniel Bergeron,Arie E. Kaufman	1994	Proceedings IEEE Visualization '94, Washington, DC, USA, October 17-21, 1994	IEEE Visualizat	visu
2981	KDD	STAR: A General Architecture for the Support of Distortion Oriented Displays.	Paul Anderson,Ray Smith,Zhongwei Zhang	1995	STAR: A General Architecture for the Support of Distortion Oriented Displays.	KDD	datamining
2982	KDD	Learning First Order Logic Rules with a Genetic Algorithm.	Sébastien Augier,Gilles Venturini,Yves Kodratoff	1995	Learning First Order Logic Rules with a Genetic Algorithm.	KDD	datamining
2983	KDD	Discovery and Maintenance of Functional Dependencies by Independencies.	Siegfried Bell	1995	Discovery and Maintenance of Functional Dependencies by Independencies.	KDD	datamining
2984	KDD	Active Data Mining.	Rakesh Agrawal,Giuseppe Psaila	1995	Active Data Mining.	KDD	datamining
2985	KDD	Capacity and Complexity Control in Predicting the Spread Between Borrowing and Lending Interest Rates.	Corinna Cortes,Harris Drucker,Dennis Hoover,Vladimir Vapnik	1995	Capacity and Complexity Control in Predicting the Spread Between Borrowing and Lending Interest Rates.	KDD	datamining
2986	KDD	Limits on Learning Machine Accuracy Imposed by Data Quality.	Corinna Cortes,Lawrence D. Jackel,Wan-Ping Chiang	1995	Limits on Learning Machine Accuracy Imposed by Data Quality.	KDD	datamining
2987	KDD	Intelligent Instruments: Discovering How to Turn Spectral Data into Information.	Wray L. Buntine,Tarang Patel	1995	Intelligent Instruments: Discovering How to Turn Spectral Data into Information.	KDD	datamining
2988	KDD	Applying a Data Miner To Heterogeneous Schema Integration.	Son Dao,Brad Perry	1995	Applying a Data Miner To Heterogeneous Schema Integration.	KDD	datamining
2989	KDD	Rough Sets Similarity-Based Learning from Databases.	Xiaohua Hu,Nick Cercone	1995	Rough Sets Similarity-Based Learning from Databases.	KDD	datamining
2990	KDD	Learning Arbiter and Combiner Trees from Partitioned Data for Scaling Machine Learning.	Philip K. Chan,Salvatore J. Stolfo	1995	Learning Arbiter and Combiner Trees from Partitioned Data for Scaling Machine Learning.	KDD	datamining
2991	KDD	Exploiting Upper Approximation in the Rough Set Methodology.	Jitender S. Deogun,Vijay V. Raghavan,Hayri Sever	1995	Exploiting Upper Approximation in the Rough Set Methodology.	KDD	datamining
2992	KDD	Analyzing the Benefits of Domain Knowledge in Substructure Discovery.	Surnjani Djoko,Diane J. Cook,Lawrence B. Holder	1995	Analyzing the Benefits of Domain Knowledge in Substructure Discovery.	KDD	datamining
2993	KDD	Designing Neural Networks from Statistical Models: A New Approach to Data Exploration.	Antonio Ciampi,Yves Lechevallier	1995	Designing Neural Networks from Statistical Models: A New Approach to Data Exploration.	KDD	datamining
2994	KDD	Knowledge-Based Scientific Discovery in Geological Databases.	Cen Li,Gautam Biswas	1995	Knowledge-Based Scientific Discovery in Geological Databases.	KDD	datamining
2995	KDD	Knowledge Discovery in a Water Quality Database.	Saso Dzeroski	1995	Knowledge Discovery in a Water Quality Database.	KDD	datamining
2996	KDD	Structured and Unstructured Induction with EDAGs.	Brian R. Gaines	1995	Structured and Unstructured Induction with EDAGs.	KDD	datamining
2997	KDD	A Statistical Perspective On Knowledge Discovery In Databases.	John F. Elder IV,Daryl Pregibon	1995	A Statistical Perspective On Knowledge Discovery In Databases.	KDD	datamining
2998	KDD	A Database Interface for Clustering in Large Spatial Databases.	Martin Ester,Hans-Peter Kriegel,Xiaowei Xu	1995	A Database Interface for Clustering in Large Spatial Databases.	KDD	datamining
2999	KDD	Knowledge Discovery in Telecommunication Services Data Using Bayesian Network Models.	Kazuo J. Ezawa,Steven W. Norton	1995	Knowledge Discovery in Telecommunication Services Data Using Bayesian Network Models.	KDD	datamining
3000	KDD	Available Technology for Discovering Causal Models, Building Bayes Nets, and Selecting Predictors: The TETRAD II Program.	Clark Glymour	1995	Available Technology for Discovering Causal Models, Building Bayes Nets, and Selecting Predictors: The TETRAD II Program.	KDD	datamining
3001	KDD	Restructuring Databases for Knowledge Discovery by Consolidation and Link Formation.	Henry G. Goldberg,Ted E. Senator	1995	Restructuring Databases for Knowledge Discovery by Consolidation and Link Formation.	KDD	datamining
3002	KDD	Data Mining for Loan Evaluation at ABN AMRO: A Case Study.	A. J. Feelders,A. J. F. le Loux,J. W. van't Zand	1995	Data Mining for Loan Evaluation at ABN AMRO: A Case Study.	KDD	datamining
3003	KDD	Knowledge Discovery in Textual Databases (KDT).	Ronen Feldman,Ido Dagan	1995	Knowledge Discovery in Textual Databases (KDT).	KDD	datamining
3004	KDD	Optimization and Simplification of Hierarchical Clusterings.	Douglas Fisher	1995	Optimization and Simplification of Hierarchical Clusterings.	KDD	datamining
3005	KDD	An Assessment of PrIL.	Özden Gür-Ali,William A. Wallace	1995	An Assessment of PrIL.	KDD	datamining
3006	KDD	Discriminant Adaptive Nearest Neighbor Classification.	Trevor Hastie,Robert Tibshirani	1995	Nearest neighbor classification expects the class conditional probabilities to be locally constant, and suffers from bias in high dimensions. We propose a locally adaptive form of nearest neighbor classification to try to ameliorate this curse of dimensionality. We use a local linear discriminant analysis to estimate an effective metric for computing neighborhoods. We determine the local decision boundaries from centroid information, and then shrink neighborhoods in directions orthogonal to these local decision boundaries, and elongate them parallel to the boundaries. Thereafter, any neighborhood-based classifier can be employed, using the modified neighborhoods. The posterior probabilities tend to be more homogeneous in the modified neighborhoods. We also propose a method for global dimension reduction, that combines local dimension information. In a number of examples, the methods demonstrate the potential for substantial improvements over nearest neighbor classification.	KDD	datamining
3007	KDD	A Perspective on Databases and Data Mining.	Marcel Holsheimer,Martin L. Kersten,Heikki Mannila,Hannu Toivonen	1995	We discuss the use of database methods for data mining. Recently impressive results have been achieved for some data mining problems using highly specialized and clever data structures. We study how well one can manage by using general purpose database management systems. We illustrate our ideas by investigating the use of a dbms for a well-researched area: the discovery of association rules. We present a simple algorithm, consisting of only union and intersection operations, and show that it achieves quite good performance on an efficient dbms. Our method can incorporate inheritance hierarchies to the association rule algorithm easily. We also present a technique that effectively reduces the number of database operations when searching large search spaces that contain only few interesting items. Our work shows that database techniques are promising for data mining: general architectures can achieve reasonable results.	KDD	datamining
3008	KDD	Estimating the Robustness of Discovered Knowledge.	Chun-Nan Hsu,Craig A. Knoblock	1995	Estimating the Robustness of Discovered Knowledge.	KDD	datamining
3009	KDD	Efficient Algorithms for Attribute-Oriented Induction.	Hoi-Yee Hwang,Ada Wai-Chee Fu	1995	Efficient Algorithms for Attribute-Oriented Induction.	KDD	datamining
3010	KDD	Robust Decision Trees: Removing Outliers from Databases.	George H. John	1995	Robust Decision Trees: Removing Outliers from Databases.	KDD	datamining
3011	KDD	Conceptual Clustering in Structured Databases: A Practical Approach.	A. Ketterlin,Pierre Gançarski,Jerzy J. Korczak	1995	Conceptual Clustering in Structured Databases: A Practical Approach.	KDD	datamining
3012	KDD	Anonymization Techniques for Knowledge Discovery in Databases.	Willi Klösgen	1995	Anonymization Techniques for Knowledge Discovery in Databases.	KDD	datamining
3013	KDD	Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology.	Ron Kohavi,Dan Sommerfield	1995	Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology.	KDD	datamining
3014	KDD	Exploiting Visualization in Knowledge Discovery.	Hing-Yan Lee,Hwee-Leng Ong,Lee-Hian Quek	1995	Exploiting Visualization in Knowledge Discovery.	KDD	datamining
3015	KDD	MDL-Based Decision Tree Pruning.	Manish Mehta,Jorma Rissanen,Rakesh Agrawal	1995	MDL-Based Decision Tree Pruning.	KDD	datamining
3016	KDD	Discovering Frequent Episodes in Sequences.	Heikki Mannila,Hannu Toivonen,A. Inkeri Verkamo	1995	Discovering Frequent Episodes in Sequences.	KDD	datamining
3017	KDD	Decision Tree Induction: How Effective is the Greedy Heuristic?	Sreerama K. Murthy,Steven Salzberg	1995	Decision Tree Induction: How Effective is the Greedy Heuristic?	KDD	datamining
3018	KDD	An Iterative Improvement Approach for the Discretization of Numeric Attributes in Bayesian Classifiers.	Michael J. Pazzani	1995	An Iterative Improvement Approach for the Discretization of Numeric Attributes in Bayesian Classifiers.	KDD	datamining
3019	KDD	Compression-Based Evaluation of Partial Determinations.	Bernhard Pfahringer,Stefan Kramer	1995	Compression-Based Evaluation of Partial Determinations.	KDD	datamining
3020	KDD	Fuzzy Interpretation of Induction Results.	Xindong Wu,Petter Måhlén	1995	Fuzzy Interpretation of Induction Results.	KDD	datamining
3021	KDD	Discovering Enrollment Knowledge in University Databases.	Arun P. Sanjeev,Jan M. Zytkow	1995	Discovering Enrollment Knowledge in University Databases.	KDD	datamining
3022	KDD	Extracting Support Data for a Given Task.	Bernhard Schölkopf,Chris Burges,Vladimir Vapnik	1995	Extracting Support Data for a Given Task.	KDD	datamining
3023	KDD	Knowledge Discovery from Multiple Databases.	James S. Ribeiro,Kenneth A. Kaufman,Larry Kerschberg	1995	Knowledge Discovery from Multiple Databases.	KDD	datamining
3024	KDD	Feature Extraction for Massive Data Mining.	V. Seshadri,Raguram Sasisekharan,Sholom M. Weiss	1995	Feature Extraction for Massive Data Mining.	KDD	datamining
3025	KDD	Using Rough Sets as Tools for Knowledge Discovery.	Ning Shan,Wojciech Ziarko,Howard J. Hamilton,Nick Cercone	1995	Using Rough Sets as Tools for Knowledge Discovery.	KDD	datamining
3026	KDD	Data Surveying: Foundations of an Inductive Query Language.	Arno Siebes	1995	Data Surveying: Foundations of an Inductive Query Language.	KDD	datamining
3027	KDD	On Subjective Measures of Interestingness in Knowledge Discovery.	Abraham Silberschatz,Alexander Tuzhilin	1995	On Subjective Measures of Interestingness in Knowledge Discovery.	KDD	datamining
3028	KDD	Using Recon for Data Cleaning.	Evangelos Simoudis,Brian Livezey,Randy Kerber	1995	Using Recon for Data Cleaning.	KDD	datamining
3029	KDD	Discovery of Concurrent Data Models from Experimental Tables: A Rough Set Approach.	Andrzej Skowron,Zbigniew Suraj	1995	Discovery of Concurrent Data Models from Experimental Tables: A Rough Set Approach.	KDD	datamining
3030	KDD	Learning Bayesian Networks with Discrete Variables from Data.	Peter Spirtes,Christopher Meek	1995	Learning Bayesian Networks with Discrete Variables from Data.	KDD	datamining
3031	KDD	Fast Spatio-Temporal Data Mining of Large Geophysical Datasets.	Paul E. Stolorz,Hisashi Nakamura,Edmond Mesrobian,Richard R. Muntz,Eddie C. Shek,Jose Renato Santos,J. Yi,Kenneth W. Ng,S.-Y. Chien,Carlos R. Mechoso,John D. Farrara	1995	Fast Spatio-Temporal Data Mining of Large Geophysical Datasets.	KDD	datamining
3032	KDD	Accelerated Quantification of Bayesian Networks with Incomplete Data.	Bo Thiesson	1995	Accelerated Quantification of Bayesian Networks with Incomplete Data.	KDD	datamining
3033	KDD	Automated Selection of Rule Induction Methods Based on Recursive Iteration of Resampling Methods and Multiple Statistical Testing.	Shusaku Tsumoto,Hiroshi Tanaka	1995	Automated Selection of Rule Induction Methods Based on Recursive Iteration of Resampling Methods and Multiple Statistical Testing.	KDD	datamining
3034	KDD	Automated Discovery of Functional Components of Proteins from Amino-Acid Sequences Based on Rough Sets and Change of Representation.	Shusaku Tsumoto,Hiroshi Tanaka	1995	Automated Discovery of Functional Components of Proteins from Amino-Acid Sequences Based on Rough Sets and Change of Representation.	KDD	datamining
3035	KDD	Toward a Multi-Strategy and Cooperative Discovery System.	Ning Zhong,Setsuo Ohsuga	1995	Toward a Multi-Strategy and Cooperative Discovery System.	KDD	datamining
3036	KDD	Resource and Knowledge Discovery in Global Information Systems: A Preliminary Design and Experiment.	Osmar R. Zaïane,Jiawei Han	1995	Resource and Knowledge Discovery in Global Information Systems: A Preliminary Design and Experiment.	KDD	datamining
3037	KDD	Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95), Montreal, Canada, August 20-21, 1995	Usama M. Fayyad,Ramasamy Uthurusamy	1995	Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD-95), Montreal, Canada, August 20-21, 1995	KDD	datamining
3038	ICDE	Semantic Query Optimization for Methods in Object-Oriented Database Systems.	Karl Aberer,Gisela Fischer	1995	Although the main difference between the relational and the object-oriented data model is the possibility to define object behavior, query optimization techniques in object-oriented database systems are mainly based on the structural part of objects. We claim that the optimization potential emerging from methods has been strongly underestimated so far. In this paper we concentrate on the question of how semantic knowledge about methods can be considered in query optimization. We rely on the algebraic and rule-based approach for query optimization and present a framework that allows to integrate schema-specific knowledge by tailoring the query optimizer according to the particular application's needs. We sketch an implementation of our concepts within the OODBMS VODAK using the Volcano optimizer generator.	ICDE	database
3039	ICDE	A Uniform Framework for Integrating Knowledge in Heterogeneous Knowledge Systems.	Sibel Adali,Ross Emery	1995	Integrating knowledge from multiple sources is an important aspect of automated reasoning systems. Wiederhold and his colleagues (1993) have proposed the concept of a mediator-a device that will express how such an integration is to be achieved. In (1994) Subrahmanian et al. presented a uniform declarative and operational framework for mediators for amalgamating multiple knowledge bases and data structures (e.g. relational, object-oriented, spatial, and temporal structures) when these knowledge bases (possibly) contain inconsistencies, uncertainties, and nonmonotonic modes of negation. We specify the programming environment for this framework and show that it can be used to extract and integrate information obtained from different sources of data and resolve conflicts. We also show that it can be extended easily to integrate new knowledge bases.	ICDE	database
3040	ICDE	Flexible Relation: An Approach for Integrating Data from Multiple, Possibly Inconsistent Databases.	Shailesh Agarwal,Arthur M. Keller,Gio Wiederhold,Krishna Saraswat	1995	In this work we address the problem of dealing with data inconsistencies while integrating data sets derived from multiple autonomous relational databases. The fundamental assumption in the classical relational model is that data is consistent and hence no support is provided for dealing with inconsistent data. Due to this limitation of the classical relational model, the semantics for detecting, representing, and manipulating inconsistent data have to be explicitly encoded in the applications by the application developer. In this paper, we propose the flexible relational model, which extends the classical relational model by providing support for inconsistent data. We present a flexible relation algebra, which provides semantics for database operations in the presence of potentially inconsistent data. Finally, we discuss issues raised for query optimization when the data may be inconsistent.	ICDE	database
3041	ICDE	An International Masters in Software Engineering: Experience and Prospects.	Alberto Apostolico,Gianfranco Bilardi,Franco Bombi,Richard A. DeMillo	1995	Describes our experience with a newly-established international partnership between the Software Engineering Research Center (SERC), a university-based National Science Foundation (NSF) sponsored industrial research organization in the United States and an Italian industry-university team based in Padua, Italy.	ICDE	database
3042	ICDE	Mining Sequential Patterns.	Rakesh Agrawal,Ramakrishnan Srikant	1995	We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction.	ICDE	database
3043	ICDE	Efficient Processing of Proximity Queries for Large Databases.	Walid G. Aref,Daniel Barbará,Stephen Johnson,Sharad Mehrotra	1995	Emerging multimedia applications require database systems to provide support for new types of objects and to process queries that may have no parallel in traditional database applications. One such important class of queries are the proximity queries that aims to retrieve objects in the database that are related by a distance metric in a way that is specified by the query. The importance of proximity queries has earlier been realized in developing constructs for visual languages. In this paper, we present algorithms for answering a class of proximity queries-fixed-radius nearest-neighbor queries over point object. Processing proximity queries using existing query processing techniques results in high CPU and I/O costs. We develop new algorithms to answer proximity queries over objects that lie in the one-dimensional space (e.g., words in a document). The algorithms exploit query semantics to reduce the CPU and I/O costs, and hence improve performance. We also show how our algorithms can be generalized to handle d-dimensional objects.	ICDE	database
3044	ICDE	Design, Implementation and Evaluation of SCORE (a System for COntent based REtrieval of Pictures).	Y. Alp Aslandogan,Chuck Thier,Clement T. Yu,Chengwen Liu,Krishnakumar R. Nair	1995	We make use of a refined E-R model to represent the contents of pictures. We propose remedies to handle mismatches which may arise due to differences in perception of picture contents. An iconic user interface for visual query construction is presented. A naive user can specify his/her intention without learning a query language. A function which computes the similarity between a picture and a user's description is provided. Pictures which are sufficiently close to the user description, as measured by the similarity function, are retrieved. We present the results of a user-friendliness experiment to evaluate the user interface as well as retrieval effectiveness. Encouraging retrieval results and valuable lessons are obtained.	ICDE	database
3045	ICDE	A High Performance Configurable Storage Manager.	Alexandros Biliris,Euthimios Panagos	1995	Presents the architecture of /spl Bscr/eSS (Bell Laboratories Storage System)-a high-performance configurable database storage manager providing key facilities for the fast development of object-oriented, relational or home-grown database management systems. /spl Bscr/eSS is based on a multi-client multi-server architecture offering distributed transaction management facilities and extensible support for persistence. We present some novel aspects of the /spl Bscr/eSS architecture, including a fast object reference technique that allows re-organization of databases without affecting existing references, and two operation modes that an application running on a client or server machine can use to interact with the storage system-(i) copy on access and (ii) shared memory. Subject Terms: storage management; client-server systems; transaction processing; object-oriented databases; distributed databases; relational databases; high-performance configurable database storage manager; BeSS; Bell Laboratories Storage System; object-oriented database management systems; relational database management systems; home-grown database management systems; multi-client multi-server architecture; distributed transaction management facilities; extensible support; persistence; fast object reference technique; database reorganization; operation modes; copy on access; shared memory	ICDE	database
3046	ICDE	Title, Table of Contents, General Chairs' Message, Program Chairs' Message, Reviewers, Committees, Author Index.		1995	Title, Table of Contents, General Chairs' Message, Program Chairs' Message, Reviewers, Committees, Author Index.	ICDE	database
3047	ICDE	Transactions in the Client-Server EOS Object Store.	Alexandros Biliris,Euthimios Panagos	1995	The paper describes the client-server software architecture of the EOS storage manager and the concurrency control and recovery mechanisms it employs. Unlike most client-server storage systems that use the standard two-phase locking protocol, EOS offers a semi-optimistic locking scheme based on a multigranularity two-version two-phase locking protocol. Under this scheme, many readers are allowed to access a data item while it is being updated by a single writer. For recovery, EOS maintains a write-ahead redo-only log because of the potential benefits it offers in a client-server environment. First, there are no undo records, as log records of aborted transactions are never inserted in the log; this minimizes the I/O and network transfer costs associated with logging during normal transaction execution. Secondly, it reduces the space required for the log. Thirdly, it facilitates fast recovery from system crashes because only one forward scan of the log is required for installing the updates performed by transactions that committed prior to the crash. Performance results of the EOS recovery subsystem are also presented.	ICDE	database
3048	ICDE	Building an Integrated Active OODBMS: Requirements, Architecture, and Design Decisions.	Alejandro P. Buchmann,Jürgen Zimmermann,José A. Blakeley,David L. Wells	1995	Active OODBMSs must provide efficient support for event detection, composition and rule execution. Previous experience of building active capabilities on top of existing closed OODBMSs has proven to be ineffective. We propose instead an active OODBMS architecture where event detection and rule support are tightly integrated with the rest of the core OODBMS functionality. After presenting an analysis of the requirements of active OODBMSs, we discuss the event set, rule execution modes and lifespan of the events supported in our architecture. We also discuss event composition coupling relative to transaction boundaries. Since building an active OODBMS ex nihilo is extremely expensive, we are building the REACH (REal-time ACtive Heterogeneous) OODBMS by extending Texas Instruments' Open OODB toolkit. Open OODB is particularly well-suited for our purposes because it is the first DBMS whose architecture closely resembles the active database paradigm. It provides low-level event detection and invokes appropriate DBMS functionality as actions. We describe the architecture of the event detection and composition mechanisms, and the rule-firing process of the REACH active OODBMS, and show how these mechanisms interplay with the Open OODB core mechanisms.	ICDE	database
3049	ICDE	Toward Scalability and Interoperability of Heterogeneous Information Sources.	Son Dao	1995	Future large and complex information systems create new challenges and opportunities for research and advanced development in data management. A brief description of Hughes research and prototype efforts to meet these challenges is summarized.	ICDE	database
3050	ICDE	Active Database Management of Global Data Integrity Constraints in Heterogeneous Database Environments.	Lyman Do,Pamela Drew	1995	Today, enterprises maintain many disparate information sources over which complex business applications are expected. The informal and ad hoc characteristics of these environments make the information very prone to inconsistency. Yet, the flexibility of application execution given to different parts of an organization is desirable. This paper introduces a new mechanism in which the execution of asynchronous, pre-existing, yet related, applications can be harnessed. A multidatabase framework that supports the concurrent execution of these heterogeneous, distributed applications is presented. Using this framework, we introduce an intuitive conceptual model and algorithm for the enforcement of interdatabase constraints based on active database technology.	ICDE	database
3051	ICDE	ECA Rule Integration into an OODBMS: Architecture and Implementation.	Sharma Chakravarthy,V. Krishnaprasad,Z. Tamizuddin,R. H. Badani	1995	Making a database system active entails not only the specification of expressive ECA (event-condition-action) rules, algorithms for the detection of composite events, and rule management, but also a viable architecture for rule execution that extends a passive DBMS, and its implementation. We propose an integrated active DBMS architecture for incorporating ECA rules using the Open OODB Toolkit (from Texas Instruments). We then describe the implementation of the composite event detector, and rule execution model for object-oriented active DBMS. Finally, the functionality supported by this architecture and its extensibility are analyzed along with the experiences gained.	ICDE	database
3052	ICDE	Modeling Scientific Experiments with an Object Data Model.	I-Min A. Chen,Victor M. Markowitz	1995	We examine the main requirements for modeling scientific experiments and propose constructs that fulfil these requirements. We show that existing object-oriented and semantic data models do not provide such constructs. Experiment (protocol) and object constructs can be combined in order to provide seamless object and experiment modeling. We present an example of combining protocol and object constructs into a unified framework, the Object-Protocol Model (OPM), and briefly describe the implementation of an OPM interface on top of commercial relational database management systems (DBMSs).	ICDE	database
3053	ICDE	Improving SQL with Generalized Quantifiers.	Ping-Yu Hsu,Douglas Stott Parker Jr.	1995	A generalized quantifier is a particular kind of operator on sets. Coming under increasing attention recently by linguists and logicians, they correspond to many useful natural language phrases, including phrases like: three, Chamberlin's three, more than three, fewer than three, at most three, all but three, no more than three, not more than half the, at least two and not more than three, no student's, most male and all female, etc. Reasoning about quantifiers is a source of recurring problems for most SQL users, and leads to both confusion and incorrect expression of queries. By adopting a more modern and natural model of quantification these problems can be alleviated. We show how generalized quantifiers can be used to improve the SQL interface.	ICDE	database
3054	ICDE	Optimizing Queries with Materialized Views.	Surajit Chaudhuri,Ravi Krishnamurthy,Spyros Potamianos,Kyuseok Shim	1995	While much work has addressed the problem of maintaining materialized views, the important question of optimizing queries in the presence of materialised views has not been resolved. In this paper, we analyze the optimization question and provide a comprehensive and efficient solution. Our solution has the desirable property that it is a simple generalization of the traditional query optimization algorithm.	ICDE	database
3055	ICDE	The Design and Implementation of a Full-Fledged Multiple DBMS.	Shu-Chin Su Chen,Chih-Shing Yu,Yen-Yao Yao,San-Yih Hwang,B. Paul Lin	1995	We have described our design of the multiple DBMS (MDBMS). This MDBMS enables users to access data controlled by different DBMSs as if data were managed by a single DBMS. It supports facilities for SQL queries and transactions, and considers security functions. In addition, an ODBC driver at the client site has been realized to ease the development of MDBMS applications. Several popular commercial DBMSs, including Oracle, Informix and Sybase, have been successfully integrated. The MDBMS is in operation now. However, we found the performance to be unsatisfactory. It took about several seconds to process an SQL query with single join on two relations of hundreds of tuples. We have identified the performance bottleneck to be on the retrieval of meta data. The current MDBMS Server employs a commercial DBMS to store meta data, which is necessary for processing a global query. The processing of a query is slow because it needs to retrieve the schema information via an external DBMS several times. We are currently designing a core storage manager and an access manager specifically for maintaining the meta data and the intermediate results of a global query. We expect this design to significantly improve the performance.	ICDE	database
3056	ICDE	Scalable Parallel Query Server for Decision Support Applications.	Jen-Yao Chung	1995	Decision-support applications require the ability to query against large amounts of detailed historical data. We are exploiting parallel technology to improve query response time through query decomposition, CPU and I/O parallelism, and client/server approach. IBM System/390 Parallel Query Server is built on advanced and low-cost CMOS microprocessors for decision-support applications. We discuss our design, implementation and performance of a scalable parallel query server.	ICDE	database
3057	ICDE	Praire: A Rule Specification Framework for Query Optimizers.	Dinesh Das,Don S. Batory	1995	From our experience, current rule-based query optimizers do not provide a very intuitive and well-defined framework to define rules and actions. To remedy this situation, we propose an extensible and structured algebraic framework called Prairie for specifying rules. Prairie facilitates rule-writing by enabling a user to write rules and actions more quickly, correctly and in an easy-to-understand and easy-to-debug manner. Query optimizers consist of three major parts: a search space, a cost model and a search strategy. The approach we take is only to develop the algebra which defines the search space and the cost model and use the Volcano optimizer-generator as our search engine. Using Prairie as a front-end we translate Prairie rules to Volcano to validate our claim that Prairie makes it easier to write rules. We describe our algebra and present experimental results which show that using a high-level framework like Prairie to design large-scale optimizers does not sacrifice efficiency.	ICDE	database
3058	ICDE	An Object-Oriented Conceptual Modeling of Video Data.	Young Francis Day,Serhan Dagtas,Mitsutoshi Iino,Ashfaq A. Khokhar,Arif Ghafoor	1995	We propose a graphical data model for specifying spatio-temporal semantics of video data. The proposed model segments a video clip into subsegments consisting of objects. Each object is detected and recognized, and the relevant information of each object is recorded. The motions of objects are modeled through their relative spatial relationships as time evolves. Based on the semantics provided by this model, a user can create his/her own, object-oriented view of the video database. Using the propositional logic, we describe a methodology for specifying conceptual queries involving spatio-temporal semantics and expressing views for retrieving various video clips. Alternatively, a user can sketch the query, by exemplifying the concept. The proposed methodology can be used to specify spatio-temporal concepts at various levels of information granularity.	ICDE	database
3059	ICDE	Locking in OODBMS Client Supported Nestd Transactions.	Laurent Daynès,Olivier Gruber,Patrick Valduriez	1995	Nested transactions facilitate the control of complex persistent applications by enabling both fine-tuning of the scope of rollback and safe intra-transaction parallelism. We are concerned with supporting concurrent nested transactions on client workstations of an OODBMS. Use of the traditional design and implementation of a lock manager results in a high CPU overhead: in-cache traversals of the 007 benchmark perform, at best, 4.5 times slower than the same traversal achieved in virtual memory by a nonpersistent programming language. We propose a new design and implementation of a lock manager which cuts that factor down to 1.8. This lock manager supports nested transactions with both sibling and parent/child parallelisms, and provides object locking at a cost comparable to page locking. Object locking is therefore a better alternative due to its higher functionality.	ICDE	database
3060	ICDE	Enterprise Workflow Architecture.	Weimin Du,Steve Peterson,Ming-Chien Shan	1995	Workflow builders are designed to facilitate development of automated processes and support flexible applications that can be updated, enhanced or completely revamped. The Hewlett-Packard WorkManager is an open product data management solution with workflow management capabilities. WorkManager supports the entire product lifecycle by providing a single, logical repository for all data, and it manages and tracks enterprise-wide processes. With a strong information management platform at its core, WorkManager provides central administration capabilities, including supervision and intervention, where necessary. Because enterprise data is usually fragmented and stored in a variety of legacy systems, and different organizations have different amount of control over their data, an enterprise workflow system needs to support processes accessing data from different sites and applications. This paper describes the architecture of distributed workflow, Hewlett-Packard's solution to the enterprise workflow problem. The architecture is an extension of the existing WorkManager architecture. Its development is based on user requirements and four high-level user models. The user models and the architecture are described.	ICDE	database
3061	ICDE	Practical Issues for RDBMS Application Development.	Kwo-Jean Farn,Shin-Ling Hu	1995	We discuss some functions of relational database management systems (RDBMS) that may help RDBMS users to increase their productivity. First, for a data dictionary, we can define each field attribute characteristic in the create table statement, such as signed, unsigned, negative, nonnegative, list or coded value, range value, default value; uppercase, lowercase or upperlow case; IDstamp value; datestamp value; or computation field. We also point out some inconvenient functions of RDBMS. A more intelligent query optimizer is also needed. For users in a Chinese environment, Chinese characteristics such as field name defining, sorting, and partial searching are required. In addition, for an area center using a horizontal fragmentation scheme, a tool which which can automatically parallel update the other site when the central site's kernel part changes is required.	ICDE	database
3062	ICDE	A Structure Based Schema Integration Methodology.	Manuel García-Solaco,Fèlix Saltor,Malú Castellanos	1995	The process of integrating the schemas of several databases into an integrated schema is not easy, due to semantic heterogeneities. We present a method/sup 1/ to detect class similarities by following a strategy and applying comparison criteria, that exploits the semantically rich structures of the schemas (previously enriched), along both the generalization/specialization and the aggregation dimensions. Relaxations may be applied to conform a pair of classes, resulting in penalizations in the computation of the degree of similarity. Our approach needs less comparisons than methods based on attribute comparison.	ICDE	database
3063	ICDE	Sampling-Based Selectivity Estimation for Joins Using Augmented Frequent Value Statistics.	Peter J. Haas,Arun N. Swami	1995	We compare empirically the cost of estimating the selectivity of a star join using the sampling-based t-cross procedure to the cost of computing the join and obtaining the exact answer. The relative cost of sampling can be excessive when a join attribute value exhibits heterogeneous skew. To alleviate this problem, we propose Algorithm TCM, a modified version of t-cross that incorporates augmented frequent value (AFV) statistics. We provide a sampling-based method for estimating AFV statistics that does not require indexes on attribute values, requires only one pass though each relation, and uses an amount of memory much smaller than the size of a relation. Our experiments show that the use of estimated AFV statistics can reduce the relative cost of sampling by orders of magnitude. We also show that use of estimated AFV statistics can reduce the relative error of the classical System R selectivity formula.	ICDE	database
3064	ICDE	Two-Level Caching of Composite Object Views of Relational Databases.	Catherine Hamon,Arthur M. Keller	1995	We describe a two-level client-side cache for composite objects mapped as views of a relational database. A semantic model, the Structural Model, is used to specify joins on the relational database that are useful for defining composite objects. The lower level of the cache contains the tuples from each relation that have already been loaded into memory. These tuples are linked together from relation to relation according to the joins of the structural model. This level of the cache is shared among all applications using the data on this client. The higher level of the cache contains composed objects of data extracted from the lower level cache. This level of the cache uses the object schema of a single application, and the data is copied from the lower level cache for convenient access by the application. This two-level cache is designed as part of the Penguin system, which supports multiple applications, each with its own object schema, to share data stored in a common relational database.	ICDE	database
3065	ICDE	An Industrial Perspective of Software Architecture.	Christine Hofmeister,Robert L. Nord,Dilip Soni	1995	The software architecture of a system describes how it is decomposed into components, how these components are interconnected, and how they communicate and interact with each other and with the environment. Software architecture represents critical, system-wide design decisions which affect quality, reconfigurability and reuse, and the cost for development and maintenance. In order to understand architecture as it is practised in the real world, we conducted a survey of a variety of industrial software systems. Our survey revealed the need for rigorous descriptions, systematic techniques, and well-defined processes to make architecture-level software development an engineering practice rather than an art.	ICDE	database
3066	ICDE	Set-Oriented Mining for Association Rules in Relational Databases.	Maurice A. W. Houtsma,Arun N. Swami	1995	Describe set-oriented algorithms for mining association rules. Such algorithms imply performing multiple joins and may appear to be inherently less efficient than special-purpose algorithms. We develop new algorithms that can be expressed as SQL queries, and discuss the optimization of these algorithms. After analytical evaluation, an algorithm named SETM emerges as the algorithm of choice. SETM uses only simple database primitives, viz. sorting and merge-scan join. SETM is simple, fast and stable over the range of parameter values. The major contribution of this paper is that it shows that at least some aspects of data mining can be carried out by using general query languages such as SQL, rather than by developing specialized black-box algorithms. The set-oriented nature of SETM facilitates the development of extensions.	ICDE	database
3067	ICDE	Navigation Server: A Highly Parallel DBMS on Open Systems.	Ron-Chung Hu,Rick Stellwagen	1995	Navigation Server was jointly developed to provide a highly scalable, high-performance parallel database server in the industry. By combining ATandT's experience in massively parallel systems, such as Teradata system, with Sybase's industry-leading open, client/server DBMS, Navigation Server was developed with some specific design objectives: Scalability. Minimizing interference by minimizing resource sharing among the concurrent processes, the shared-nothing architecture has, as of today, emerged as the architecture of choice for highly scalable parallel systems. Navigation Server adopts the shared-nothing parallel architecture to allow parallelized queries, updates, load, backup, and other utilities on a partitioned database. Portability Built on top of Sybase's open system products, Navigation Server is portable to Unix-based parallel machines. Further the shared-nothing software architecture demands minimal changes when porting Navigation Server to various parallel platforms ranging from symmetric multi-processing, clustered, to massively parallel processing systems. Availability. For a parallel system with many nodes, it may be often to see some hardware component failure. To achieve high availability, Navigation Server implements a hierarchical monitoring scheme to monitor all the running processes. With the monitoring frequency configurable by users, a process will be restarted automatically on an alternate node once a failure is detected. Usability. Navigation Server appears as a single Sybase SQL server to end users. Besides, it provides Sybase SQL Server two management tools: Configurator and Navigation Server Manager. The Configurator analyzes customers' workload, monitors system performance, and recommends configurations for optimal performance and resource utilization. The Navigation Server Manager provides graphical utilities to administer the system simply and efficiently.	ICDE	database
3068	ICDE	A Performance Evaluation of Load Balancing Techniques for Join Operations on Multicomputer Database Systems.	Kien A. Hua,Wallapak Tavanapong,Honesty C. Young	1995	There has been a wealth of research in the area of parallel join algorithms. Among them, hash-based algorithms are particularly suitable for shared-nothing database systems. The effectiveness of these techniques depends on the uniformity in the distribution of the join attribute values. When this condition is not met, a severe fluctuation may occur among the bucket sizes, causing uneven workload for the processing nodes. Many parallel join algorithms with load balancing capability have been proposed to address this problem. Among them, the sampling and incremental approaches have been shown to provide an improvement over the more conventional methods. The comparison between these two approaches, however, has not been investigated. In this paper, we improve these techniques and implement them on an nCUBE/2 parallel computer to compare their performance. Our study indicates that the sampling technique is the better approach.	ICDE	database
3069	ICDE	Record Subtyping in Flexible Relations by Means of Attribute Dependencies.	Christian Kalus,Peter Dadam	1995	The model of flexible relations supports heterogeneous sets of tuples in a strongly typed way. The elegance of the standard relational model is presented by using a single, generic scheme constructor. In each model supporting structural variants the shape of some part of a heterogeneous scheme may be determined by the contents of some other part of the scheme. We formalize this relationship by a certain kind of integrity constraint we have called attribute dependency (AD). We motivate how ADs can be used, besides their application in type and integrity checking, to incorporate record subtyping into our extended relational model. Moreover, we show that ADs yield a stronger assertion than the traditional record subtyping rub as they consider interdependencies among refinements. We discuss how ADs are related to query processing and how they may help to identify redundant operations.	ICDE	database
3070	ICDE	Bottom-Up Evaluation of Logic Programs Using Binary Decision Diagrams.	Mizuho Iwaihara,Yusaku Inoue	1995	Binary decision diagram (BDD) is a data structure to manipulate Boolean functions and recognized as a powerful tool in the VLSI CAD area. We consider that compactness and efficient operations of BDDs can be utilized for storing temporary relations in bottom-up evaluation of logic queries. We show two methods of encoding relations into BDDs, called logarithmic encoding and linear encoding, define relational operations on BDDs and discuss optimizations in ordering BDD variables to construct memory and time efficient BDDs. Our experiments show that our BDD-based bottom-up evaluator has remarkable performance against traditional hash table-based methods for transitive closure queries on dense graphs.	ICDE	database
3071	ICDE	A Version Numbering Scheme with a Useful Lexicographical Order.	Arthur M. Keller,Jeffrey D. Ullman	1995	We describe a numbering scheme for versions with alternatives that has a useful lexicographical ordering. The version hierarchy is a tree. By inspection of the version numbers, we can easily determine whether one version is an ancestor of another. If so, we can determine the version sequence between these two versions. If not, we can determine the most recent common ancestor to these two versions (i.e., the least upper bound, lub). Sorting the version numbers lexicographically results in a version being followed by all descendants and preceded by all its ancestors. We use a representation of nonnegative integers that is self delimiting and whose lexicographical ordering matches the ordering by value.	ICDE	database
3072	ICDE	Computing Temporal Aggregates.	Nick Kline,Richard T. Snodgrass	1995	Aggregate computation, such as selecting the minimum attribute value of a relation, is expensive, especially in a temporal database. We describe the basic techniques behind computing aggregates in conventional databases and show that these techniques are not efficient when applied to temporal databases. We examine the problem of computing constant intervals (intervals of time for which the aggregate value is constant) used for temporal grouping. We introduce two new algorithms for computing temporal aggregates: the aggregation tree and the k-ordered aggregation tree. An empirical comparison demonstrates that the choice of algorithm depends in part on the amount of memory available, the number of tuples in the underlying relation, and the degree to which the tuples are ordered. This study shows that the simplest strategy is to first sort the underlying relation, then apply the k-ordered aggregation tree algorithm with k=1.	ICDE	database
3073	ICDE	Infobusiness Issues in ROC.	Lung-Lung Liu	1995	The infobusiness operation has been popular for many years in the ROC. Management information systems in the government, military, and enterprise were the original applications, and then came the information service requirement from various kinds of users. Computer networks, database systems, and information providers together proposed the draft infobusiness environment. Closed systems are still the ones that major infobusiness operations provide to their customers. Issues in the infobusiness development include: (1) closed systems limited the infobusiness opportunity. (2) Chinese character handling and the inconvenient localized environment blocked the user and the vendor in information service applications. (3) Public computer networks are not popular, hence the add-on value of infobusiness is invisible. (4) Large database handling experience is not available. These issues concern techniques, standards, and even laws. For example, the open system concept is generally acceptable, but it is usually too vague for the public. Open databases still do not talk smoothly to one another, especially when different operating systems on networks are trying to exchange Chinese information. Another factor is that the total number of standard Chinese characters is still in negotiation internationally although applications have been practised for 20 years on computers. In order to unify the number of Chinese characters, there is discussion about whether laws are necessary to define a formal discipline for creating new Chinese characters.	ICDE	database
3074	ICDE	A Cost-effective Near-line Storage Server for Multimedia System.	Siu-Wah Lau,John C. S. Lui,P. C. Wong	1995	We consider a storage server architecture for multimedia information systems. While most other works on multimedia storage servers assume on-line disk storage, we consider a two-tier storage architecture with a robotic tape library as the vast near-line storage and on-line disks as the front-line storage. Magnetic tapes are cheaper, more robust, and have a larger capacity; hence they are more cost effective for large scale storage systems (e.g., video on demand (VOD) systems may store tens of thousands of videos). We study in detail the design issues of the tape subsystem and propose some novel tape scheduling algorithms which give faster response and require less disk buffering.	ICDE	database
3075	ICDE	Pushing Semantics Inside Recursion: A General Framework for Semantic Optimization of Recursive Queries.	Laks V. S. Lakshmanan,Rokia Missaoui	1995	We consider a class of linear query programs and integrity constraints and develop methods for (i) computing the residues and (ii) pushing them inside the recursive programs, minimizing redundant computation and run-time overhead. We also discuss applications of our strategy to intelligent query answering.	ICDE	database
3076	ICDE	RBE: Rendering By Example.	Ravi Krishnamurthy,Moshé M. Zloof	1995	Rendering is defined to be a customized presentation of data in such a way that allows users to subsequently interact with the presented data. Traditionally such a user interface would be a custom application written using conventional programming languages; in contrast we propose an application-independent, declarative (i.e., what-you-want) language that we call Rendering By Example, RBE, with the capability to specify a wide variety of renderings. RBE is a domain calculus language over user interface widgets. Most previous domain calculus database languages (e.g., QBE, LDL, Datalog) mainly addressed the data processing problem. The main contribution in developing RBE is to model semantics of user interactions in a declarative way. This declarative specification not only allows quick and ad-hoc specification of renderings (i.e., user interfaces) but also provides a framework to understand renderings as an abstract concept, independent of the application. Further, such a linguistic abstraction provides the basis for user-interface research. RBE is part of the ICBE language that is being prototyped in the Picture Programming project at HP Labs.	ICDE	database
3077	ICDE	An Evaluation of Sampling-Based Size Estimation Methods for Selections in Database Systems.	Yibei Ling,Wei Sun	1995	The results of a performance study of the representative sampling-based size estimation methods in database management systems are reported in this paper. Major performance measurement includes estimation accuracy, the amount of sample taken, and the coverage. The impact of skewed data on the performance is also discussed. These results allow a better understanding and assessment of sampling estimation methods and determine the suitability of different methods under different situations.	ICDE	database
3078	ICDE	A Similarity Graph-Based Approach to Declustering Problems and Its Application towards Paralleling Grid Files.	Duen-Ren Liu,Shashi Shekhar	1995	We propose a new similarity-based technique for declustering data. The proposed method can adapt to available information about query distributions, data distributions, data sizes and partition-size constraints. The method is based on max-cut partitioning of a similarity graph defined over the given set of data, under constraints on the partition sizes. It maximizes the chances that a pair of data-items that are to be accessed together by queries are allocated to distinct disks. We show that the proposed method can achieve optimal speed-up for a query-set, if there exists any other declustering method which will achieve the optimal speed-up. Experiments in parallelizing grid files show that the proposed method outperforms mapping-function-based methods for interesting query distributions as well for non-uniform data distributions.	ICDE	database
3079	ICDE	A Trace-Based Simulation of Pointer Swizzling Techniques.	Mark L. McAuliffe,Marvin H. Solomon	1995	Persistent object-oriented applications that traverse large object graphs can improve their performance by caching objects in main memory while they are being used. While caching offers large performance benefits, the techniques used to locate these cached objects in memory can still impede the application's performance. We present the results of a trace-based simulation study of pointer swizzling techniques (techniques for reducing the cost of access to cached objects). We used traces derived from actual persistent programs to find a class of swizzling techniques that performs well, yet permits changes to the contents of in-memory object caches over the lifetime of an application. Our study demonstrates the superiority of a class of techniques known as indirect swizzling for a variety of workloads and system configurations.	ICDE	database
3080	ICDE	The Design and Experimental Evaluation of an Information Discovery Mechanism for Networks of Autonomous Database Systems.	Dennis McLeod,Antonio Si	1995	An approach and mechanism to support the dynamic discovery of information units within a collection of autonomous and heterogeneous database systems is described. The mechanism is based upon a core set of database constructs that characterizes object database systems, along with a set of self-adaptive heuristics employing techniques from machine learning. The approach provides an uniform framework for organizing, indexing, searching, and browsing database information units within an environment of multiple, autonomous, interconnected databases. The feasibility of the approach and mechanism is illustrated using a protein/genetics application environment. Metrics for measuring the performance of the discovery system are presented and the effectiveness of the system is thereby evaluated. Performance tradeoffs are examined and analyzed by experiments performed, employing a simulation model.	ICDE	database
3081	ICDE	Disk Read-Write Optimizations and Data Integrity in Transaction Systems Using Write-Ahead Logging.	C. Mohan	1995	We discuss several disk read-write optimizations that are implemented in different transaction systems and disk hardware to improve performance. These include: (1) when multiple sectors are written to disk, the sectors may be written out of sequence (SCSI disk interfaces do this). (2) Avoiding initializing pages on disk when a file is extended. (3) Not accessing individual pages during a mass delete operation (e.g., dropping an index from a file which contains multiple indexes). (4) Permitting a previously deallocated page to be reallocated without the need to read the deallocated version of the page from disk during its reallocation. (5) Purging of file pages from the buffer pool during a file erase operation (e.g., a table drop). (6) Avoiding logging for bulk operations like index create. We consider a system which implements the above optimizations and in which a page consists of multiple disk sectors and recovery is based on write-ahead logging using a log sequence number on every page. For such a system, we present a simple method for guaranteeing the detection of the partial disk write of a page. Detecting partial writes is very important not only to ensure data integrity from the users' viewpoint but also to make the transaction system software work correctly. Once a partial write is detected, it is easy to recover such a page using media recovery techniques. Our method imposes minimal CPU and space overheads. It has been implemented in DB2/6000 and ADSM.	ICDE	database
3082	ICDE	A Transaction Transformation Approach to Active Rule Processing.	Danilo Montesi,Riccardo Torlone	1995	Describes operational aspects of a novel approach to active rule processing based on a transaction transformation technique. A user-defined transaction, which is viewed as a sequence of atomic database updates forming a semantic unit, is translated by means of active rules into a new transaction that explicitly includes the additional updates due to active rule processing. It follows that the execution of the new transaction in a passive environment corresponds to the execution of the original transaction within the active environment defined by the given rules. Both immediate and deferred execution models are considered. The approach presents two main features. First, it relies on a well known formal basis that allow us to derive solid results on equivalence, confluence and optimization issues. Second, it is easy to implement as it does not require any specific run-time support.	ICDE	database
3083	ICDE	OCAM: A Collaborative System for Multimedia Applications.	Hassan Mountassir,S. Serre	1995	Software engineering tasks as design and programming require the concurrent participation of multiple users, possibly geographically dispersed. But traditional software environments have not been designed to facilitate collaborative work. In this paper we present briefly a tool for communication among many persons in which users can elaborate documents with synchronous and asynchronous interaction modes.	ICDE	database
3084	ICDE	Relational Database Compression Using Augmented Vector Quantization.	Wee Keong Ng,Chinya V. Ravishankar	1995	Data compression is one way to alleviate the I/O bottleneck problem faced by I/O-intensive applications such as databases. However, this approach is not widely used because of the lack of suitable database compression techniques. In this paper, we design and implement a novel database compression technique based on vector quantization (VQ). VQ is a data compression technique with wide applicability in speech and image coding, but it is not directly suitable for databases because it is lossy. We show how one may use a lossless version of vector quantization to reduce database space storage requirements and improve disk I/O bandwidth.	ICDE	database
3085	ICDE	A Transparent Object-Oriented Schema Change Approach Using View Evolution.	Young-Gook Ra,Elke A. Rundensteiner	1995	When a database is shared by many users, updates to the database schema are almost always prohibited because there is a risk of making existing application programs obsolete when they run against the modified schema. This paper addresses the problem by integrating schema evolution with view facilities. When new requirements necessitate schema updates for a particular user, the user specifies schema changes to the personal view rather than to the shared base schema. Our view evolution approach then computes a new view schema that reflects the semantics of the desired schema change, and replaces the old view with the new one. We present algorithms that implement the set of schema evolution operations typically supported by OODB systems as view definitions. This approach provides the means for schema change without affecting other views (and thus without affecting existing application programs). The persistent data is shared by different views of the schema, i.e., both old as well as newly developed applications can continue to interoperate. In this paper, we present examples that demonstrate our approach.	ICDE	database
3086	ICDE	Design of Multimedia Storage Systems for On-Demand Playback.	Yen-Jen Oyang,Meng-Huang Lee,Chun-Hung Wen,Chih-Yuan Cheng	1995	This paper presents a comprehensive procedure to design multimedia storage systems for on-demand playback. The design stresses effective utilization of disk bandwidth with minimal data buffer to minimize overall system costs. The design procedure is most distinctive in the following two aspects: it bases on a tight upper bound of the lumped disk seek time for the Scan disk scheduling algorithm to achieve effective utilization of disk bandwidth; it starts with a general two-level hierarchical disk array structure to derive the optimal configuration for specific requirements.	ICDE	database
3087	ICDE	Object Exchange Across Heterogeneous Information Sources.	Yannis Papakonstantinou,Hector Garcia-Molina,Jennifer Widom	1995	We address the problem of providing integrated access to diverse and dynamic information sources. We explain how this problem differs from the traditional database integration problem and we focus on one aspect of the information integration problem, namely information exchange. We define an object-based information exchange model and a corresponding query language that we believe are well suited for integration of diverse information sources. We describe how, the model and language have been used to integrate heterogeneous bibliographic information sources. We also describe two general-purpose libraries we have implemented for object exchange between clients and servers.	ICDE	database
3088	ICDE	Deputy Mechanisms for Object-Oriented Databases.	Zhiyong Peng,Yahiko Kambayashi	1995	Concepts of deputy objects and deputy classes for object-oriented databases (OODBs) are introduced. They can be used for unified realization of object views, roles and migration. The previous researches on these concepts were carried out separately, although they are very closely related. Objects appearing in a view can be regarded as playing roles in that view. Object migration is caused by change of roles of an object. Deputy objects can be used for unified treatment of them and generalization of these concepts. The schemata of deputy objects are defined by deputy classes. A set of algebraic operations are developed for deputy class derivation. In addition, three procedures for update propagation between deputy objects and source objects have been designed, which can support dynamic classification. The unified realization of object views, roles and migration by deputy mechanisms can achieve the following advantages. (1) Treating view objects as roles of an object allows them to have additional attributes and methods so that the autonomous views suitable for OODBs can be realized. (2) Handling object roles in the same way as object views enables object migration to be easily realized by dynamic classification functions of object views. (3) Generalization of object views, roles and migration makes it possible that various semantic constraints on them can, be defined and enforced uniformly.	ICDE	database
3089	ICDE	Axiomatization of Dynamic Schema Evolution in Objectbases.	Randal J. Peters,M. Tamer Özsu	1995	Axiomatization of Dynamic Schema Evolution in Objectbases.	ICDE	database
3090	ICDE	Query Interoperation Among Object-Oriented and Relational Databases.	Xiaolei Qian,Louiqa Raschid	1995	We develop an efficient algorithm for the query interoperation among existing heterogeneous object-oriented and relational databases. Our algorithm utilizes a canonical deductive database as a uniform representation of object-oriented schema and data. High-order object queries are transformed to the canonical deductive database in which they are partially evaluated and optimized, before being translated to relational queries. Our algorithm can be incorporated into object-oriented interfaces to relational databases or object-oriented federated databases to support object queries to heterogeneous relational databases.	ICDE	database
3091	ICDE	Buffer Management for Video Database Systems.	Doron Rotem,J. Leon Zhao	1995	Future multimedia information systems are likely to manage thousands of videos with various lengths and display requirements. Mismatch of playback and delivery rates of compressed video data requires sophisticated buffer management algorithms to guarantee smooth playback of video data. In this paper, we address some of the many design and operational issues including buffer size requirements, refreshing policies, and support of multiple access points to the same video object. Three different buffer management strategies are proposed and analyzed to minimize the average waiting time while ensuring display without jerkiness. We also evaluate the effectiveness these buffer management strategies with a simulation study.	ICDE	database
3092	ICDE	SEQ: A Model for Sequence Databases.	Praveen Seshadri,Miron Livny,Raghu Ramakrishnan	1995	This paper presents the SEQ model which is the basis for a system to manage various kinds of sequence data. The model separates the data from the ordering information, and includes operators based on two distinct abstractions of a sequence. The main contributions of the SEQ model are: (a) it can deal with different types of sequence data, (b) it supports an expressive range of sequence queries, (c) it draws from many of the diverse existing approaches to modeling sequence data.	ICDE	database
3093	ICDE	Generalized Partial Indexes.	Praveen Seshadri,Arun N. Swami	1995	This paper demonstrates the use of generalized partial indexes for efficient query processing. We propose that partial indexes be built on those portions of the database that are statistically likely to be the most useful for query processing. We identify three classes of statistical information, and two levels at which it may be available. We describe indexing strategies that use this information to significantly improve average query performance. Results from simulation experiments demonstrate that the proposed generalized partial indexing strategies perform well compared to the traditional approach to indexing.	ICDE	database
3094	ICDE	CCAM: A Connectivity-Clustered Access Method for Aggregate Queries on Transportation Networks: A Summary of Results.	Shashi Shekhar,Duen-Ren Liu	1995	CCAM is an access method for general networks. It uses connectivity clustering. The nodes of the network are assigned to disk pages via the graph partitioning approach to maximize the CRR, i.e., the chances that a pair of connected nodes are allocated to a common page of the file. CCAM supports the operations of insert, delete, create, and find as well as the new operations, get-A-successor and get-successors, which retrieve one or all successors of a node to facilitate aggregate computations on networks. CCAM includes methods for static clustering, as well as dynamic incremental reclustering, to maintain, high CRR, in the face of updates without incurring high overheads. Experimental analysis indicates that CCAM can outperform many other access methods for network operations.	ICDE	database
3095	ICDE	Ternary Relationship Decomposition Strategies Based on Binary Imposition Rules.	Il-Yeol Song,Trevor H. Jones	1995	We review a set of rules identifying which combinations of ternary and binary relationships can be combined simultaneously in semantically related situations. We investigate the effect of these rules on decomposing ternary relationships to simpler, multiple binary relationships. We also discuss the relevance of these decomposition strategies to ER modeling. We show that if at least one 1:1 or 1:M binary constraint can be identified within the construct of the ternary itself, then any ternary relationship can be decomposed to a binary format. From this methodology we construct a heuristic-the Constrained Ternary Decomposition (CTD) rule.	ICDE	database
3096	ICDE	The AQUA Approach to Querying Lists and Trees in Object-Oriented Databases.	Bharathi Subramanian,Theodore W. Leung,Scott L. Vandenberg,Stanley B. Zdonik	1995	Relational database systems and most object-oriented database systems provide support for queries. Usually these queries represent retrievals over sets or multisets. Many new applications for databases, such as multimedia systems and digital libraries, need support for queries on complex bulk types such as lists and trees. In this paper we describe an object-oriented query algebra called AQUA (= A Query Algebra) for lists and trees. The operators in the algebra preserve the ordering between the elements of a list or tree, even when the result list or tree contains an arbitrary set of nodes from the original tree. We also present predicate languages for lists and trees which allow order-sensitive queries because they use pattern matching to examine groups of list or tree nodes rather than individual nodes. The ability to decompose predicate patterns enables optimizations that make use of indices.	ICDE	database
3097	ICDE	A New Recursive Subclass of Domain Independent Formulas Based on Subimplication.	Joonyeoub Sung,Lawrence J. Henschen	1995	We motivate and define subimplication completion of a relational calculus query and of a general deductive database. Subimplication completion not only avoids getting unexpected answers, but also makes some domain dependent queries and databases domain independent. We define a new recursive subclass of domain independent formulas, called weakly range-restricted formulas, which is strictly larger than the class of range-restricted formulas. We also define admissible and deductive databases and show that under the subimplication completion they are domain independent and safe.	ICDE	database
3098	ICDE	A Heuristic Information Retrieval Model on a Massively Parallel Processor.	Inien Syu,Sheau-Dong Lang,Kien A. Hua	1995	We adapt a competition-based connectionist model to information retrieval. This model, which has been proposed for diagnostic problem solving, treats documents as disorders and user information needs as manifestations, and it uses a competitive activation mechanism which converges to a set of disorders that best explain the given manifestations. Our experimental results using four standard document collections demonstrate the efficiency and the retrieval precision of this model, comparable to or better than that of various information retrieval models reported in the literature. We also propose a parallel implementation of the model on a SIMD machine, MasPar's MP-I. Our experimental results demonstrate the potential to achieve significant speedups.	ICDE	database
3099	ICDE	A Common Framework for Classifying and Specifying Deductive Database Updating Problems.	Ernest Teniente,Toni Urpí	1995	We propose two interpretations of the event rules which provide a common framework for classifying and specifying deductive database updating problems such as view updating, materialized view maintenance, integrity constraints checking, integrity constraints maintenance, repairing inconsistent databases, integrity constraints satisfiability or condition monitoring. Moreover, these interpretations allow us to identify and to specify some problems that have received little attention up to now like enforcing or preventing condition activation. By considering only a unique set of rules for specifying all these problems, we want to show that it is possible to provide general methods able to deal with all these problems as a whole	ICDE	database
3100	ICDE	The Impact of Data Placement on Memory Management for Multi-Server OODBMS.	Shivakumar Venkataraman,Miron Livny,Jeffrey F. Naughton	1995	We demonstrate the close relationship between data placement and memory management for symmetric multi-server OODBMS. We propose and investigate memory management algorithms for two data placement strategies, namely declustering and clustering. Through a detailed simulation, we show that by declustering the data most of the benefits of complex global memory management algorithms are realized by simple algorithms. In contrast we show that when data is clustered, the simple algorithms perform poorly.	ICDE	database
3101	ICDE	Translation of Object-Oriented Queries to Relational Queries.	Clement T. Yu,Yi Zhang,Weiyi Meng,Won Kim,Gaoming Wang,Tracy Pham,Son Dao	1995	Proposes a formal approach for translating OODB queries to equivalent relational queries. The translation is accomplished through the use of relational predicate graphs and OODB predicate graphs. One advantage of using such a graph-based approach is that we can achieve bidirectional translation between relational queries and OODB queries.	ICDE	database
3102	ICDE	Efficient Processing of Nested Fuzzy SQL Queries.	Qi Yang,Chengwen Liu,Jing Wu,Clement T. Yu,Son Dao,Hiroshi Nakajima	1995	Fuzzy databases have been introduced to deal with uncertain or incomplete information in many applications. The efficiency of processing fuzzy queries in fuzzy databases is a major concern. We provide techniques to unnest nested fuzzy queries of two blocks in fuzzy databases. We show both theoretically and experimentally that unnesting improves the performance of nested queries significantly. The results obtained in the paper form the basis for unnesting fuzzy queries of arbitrary blocks in fuzzy databases.	ICDE	database
3103	ICDE	Context-Dependent Interpretations of Linguistic Terms in Fuzzy Relational Databases.	Weining Zhang,Clement T. Yu,Bryan Reagan,Hiroshi Nakajima	1995	Approaches are proposed to allow fuzzy terms to be interpreted according to the context within which they are used. Such an interpretation is natural and useful. A query-dependent interpretation is proposed to allow a fuzzy term to be interpreted relative to a partial answer of a query. A scaling process is used to transform a pre-defined meaning of a fuzzy term into on appropriate meaning in the given context. Sufficient conditions are given for a nested fuzzy query with RELATIVE quantifiers to be unnested for an efficient evaluation. An attribute-dependent interpretation is proposed to model the applications in which the meaning of a fuzzy term in an attribute must be interpreted with respect to values in other related attributes. Two necessary and sufficient conditions for a tuple to have a unique attribute-dependent interpretation are provided. We describe an interpretation system that allows queries to be processed based on the attribute-dependent interpretation of the data. Two techniques, grouping and shifting, are proposed to improve the implementation.	ICDE	database
3104	ICDE	A Universal Relation Approach to Federated Database Management.	J. Leon Zhao,Arie Segev,Abhirup Chatterjee	1995	We describe a manufacturing environment where, driven by market forces, organizations cooperate as well as compete with one another. We argue that a federated database system (FDBS) is appropriate for such an environment. Contrary to conventional wisdom, complete transparency, assumed desirable and mandatory in distributed database systems, is neither desirable nor feasible in this environment. We propose a new approach that is based on schema coordination rather than integration under which each component database is free to change its data structure, attribute naming, and data semantics. A federated metadata model based on the notion of universal relation is introduced for the FDBS. We also develop the query processing paradigm, and present procedures for query transformation and heterogeneity resolution.	ICDE	database
3105	ICDE	Singapore NII : Building the Electronic Universe.	Michael Yap	1995	The National Information Infrastructure (NII) is an infrastructure consisting of efficient transport, information processing and service facilities that combine both computer and communication technologies. The needs of business and the public in general drive the definition of the infrastructure. Its goal is to increase the well-being of people as a whole. To deliver the promise of a more effective way to do business, the NII must strive to bring as many of these services or their equivalent to the end-users. Further, these services must be easily accessible and easy to use in addition to being affordable. The NII attempts to (re)engineer the real-world capabilities over the physical telecommunication network. In addition, the NII provides for a rich set of common computing services and supports the reuse of large components, over and above providing a physical telecommunication network.	ICDE	database
3106	SIGMOD Conference	The Handwritten Trie: Indexing Electronic Ink.	Walid G. Aref,Daniel Barbará,Padmavathi Vallabhaneni	1995	The emergence of the pen as the main interface device for personal digital assistants and pen-computers has made handwritten text, and more generally ink, a first-class object. As for any other type of data, the need of retrieval is a prevailing one. Retrieval of handwritten text is more difficult than that of conventional data since it is necessary to identify a handwritten word given slightly different variations in its shape. The current way of addressing this is by using handwriting recognition, which is prone to errors and limits the expressiveness of ink. Alternatively, one can retrieve from the database handwritten words that are similar to a query handwritten word using techniques borrowed from pattern and speech recognition. In particular, Hidden Markov Models (HMM) can be used as representatives of the handwritten words in the database. However, using HMM techniques to match the input against every item in the database (sequential searching) is unacceptably slow and does not scale up for large ink databases. In this paper, an indexing technique based on HMMs is proposed. The new index is a variation of the trie data structure that uses HMMs and a new search algorithm to provide approximate matching. Each node in the tree contains handwritten letters, where each letter is represented by an HMM. Branching in the trie is based on the ranking of matches given by the HMMs. The new search algorithm is parametrized so that it provides means for controlling the matching quality of the search process via a time-based budget. The index dramatically improves the search time in a database of handwritten words. Due to the variety of platforms for which this work is aimed, ranging from personal digital assistants to desktop computers, we implemented both main-memory and disk-based systems. The implementations are reported in this paper, along with performance results that show the practicality of the technique under a variety of conditions.	SIGMOD Conferen	database
3107	SIGMOD Conference	The Query By Image Content (QBIC) System.	Jonathan Ashley,Myron Flickner,James L. Hafner,Denis Lee,Wayne Niblack,Dragutin Petkovic	1995	The Query By Image Content (QBIC) System.	SIGMOD Conferen	database
3108	SIGMOD Conference	Use of a Component Architecture in Integrating Relational and Non-relational Storage Systems.	Robert G. Atkinson	1995	Use of a Component Architecture in Integrating Relational and Non-relational Storage Systems.	SIGMOD Conferen	database
3109	SIGMOD Conference	Applying Update Streams in a Soft Real-Time Database System.	Brad Adelberg,Hector Garcia-Molina,Ben Kao	1995	Many papers have examined how to efficiently export a materialized view but to our knowledge none have studied how to efficiently import one. To import a view, i.e., to install a stream of updates, a real-time database system must process new updates in a timely fashion to keep the database fresh, but at the same time must process transactions and ensure they meet their time constraints. In this paper, we discuss the various properties of updates and views (including staleness) that affect this tradeoff. We also examine, through simulation, four algorithms for scheduling transactions and installing updates in a soft real-time database.	SIGMOD Conferen	database
3110	SIGMOD Conference	A Database Interface for File Updates.	Serge Abiteboul,Sophie Cluet,Tova Milo	1995	Database systems are concerned with structured data. Unfortunately, data is still often available in an unstructured manner (e.g., in files) even when it does have a strong internal structure (e.g., electronic documents or programs). In a previous paper [2], we focussed on the use of high-level query languages to access such files and developed optimization techniques to do so. In this paper, we consider how structured data stored in files can be updated using database update languages. The interest of using database languages to manipulate files is twofold. First, it opens database systems to <i>external</i> data. This concerns data residing in files or data transiting on communication channels and possibly coming from other databases [2]. Secondly, it provides high level query/update facilities to systems that usually rely on very primitive linguistic support. (See [6] for recent works in this direction). Similar motivations appear in [4, 5, 7, 8, 11, 12, 13, 14, 15, 17, 19, 20, 21] In a previous paper, we introduced the notion of structuring schemas as a mean of providing a database view on structured data residing in a file. A structuring schema consists of a grammar together with semantic actions (in a database language). We also showed how queries <i>on files</i> expressed in a high-level query language (O<inf>2</inf>-SQL [3]) could be evaluated efficiently using variations of standard database optimization techniques. The problem of update was mentioned there but remained largely unexplored. This is the topic of the present paper. We argue that updates on files can be expressed conveniently using high-level database update languages that work on the database view of the file. The key problem is how to propagate an update specified on the database (here a view) to the file (here the physical storage). As a first step, we propose a <i>naive</i> way of update propagation: the database view of the file is materialized; the update is performed on the database; the database is unparsed to produce an updated file. For this, we develop an <i>unparsing</i> technique. The problems that we meet while developing this technique are related to the well-known view update problem. ( See, for instance [9, 10, 16, 23].) The technique relies on the existence of an inverse mapping from the database to the file. We show that the existence of such an inverse mapping results from the use of restricted structuring schemas. The <i>naive</i> technique presents two major drawbacks. It is inefficient: it entails intense data construction and unparsing, most of which dealing with data not involved in the update. It may result in information loss: information in the file, that is not recorded in the database, may be lost in the process. The major contribution of this paper is a combination of techniques that allows to minimize both the data construction and the unparsing work. First, we briefly show how optimization techniques from [2] can be used to focus on the relevant portion of the database and to avoid constructing the entire database. Then we show that for a class of structuring schemas satisfying a <i>locality</i> condition, it is possible to carefully circumscribe the unparsing. Some of the results in the paper are negative. They should not come as a surprise since we are dealing with complex theoretical foundations: language theory (for parsing and unparsing), and first-order logic (for database languages). However, we do present positive results for particular classes of structuring schemas. We believe that the restrictions imposed on these schemas are very acceptable in practice. (For instance, all real examples of structuring schemas that we examined are <i>local.</i>) The paper is organized as follows. In Section 2, we present the update problem and the structuring schemas; in Section 3, a naive technique for update propagation and the unparsing technique. Section 4 introduces a locality condition, and presents a more efficient technique for propagating updates in local structuring schemas. The last section is a conclusion.	SIGMOD Conferen	database
3111	SIGMOD Conference	Broadcast Disks: Data Management for Asymmetric Communications Environments.	Swarup Acharya,Rafael Alonso,Michael J. Franklin,Stanley B. Zdonik	1995	This paper proposes the use of repetitive broadcast as a way of augmenting the memory hierarchy of clients in an asymmetric communication environment. We describe a new technique called Broadcast Disks for structuring the broadcast in a way that provides improved performance for non-uniformly accessed data. The Broadcast Disk superimposes multiple disks spinning at different speeds on a single broadcast channel--in effect creating an arbitrarily fine-grained memory hierarchy. In addition to proposing and defining the mechanism, a main result of this work is that exploiting the potential of the broadcast structure requires a re-evaluation of basic cache management policies. We examine several pure cache management policies and develop and measure implementable approximations to these policies. These results and others are presented in a set of simulation studies that substantiates the basic idea and develops some of the intuitions required to design a particular broadcast program.	SIGMOD Conferen	database
3112	SIGMOD Conference	Efficient Optimistic Concurrency Control Using Loosely Synchronized Clocks.	Atul Adya,Robert Gruber,Barbara Liskov,Umesh Maheshwari	1995	This paper describes an efficient optimistic concurrency control scheme for use in distributed database systems in which objects are cached and manipulated at client machines while persistent storage and transactional support are provided by servers. The scheme provides both serializability and external consistency for committed transactions; it uses loosely synchronized clocks to achieve global serialization. It stores only a single version of each object, and avoids maintaining any concurrency control information on a per-object basis; instead, it tracks recent invalidations on a per-client basis, an approach that has low in-memory space overhead and no per-object disk overhead. In addition to its low space overheads, the scheme also performs well. The paper presents a simulation study that compares the scheme to adaptive callback locking, the best concurrency control scheme for client-server object-oriented database systems studied to date. The study shows that our scheme outperforms adaptive callback locking for low to moderate contention workloads, and scales better with the number of clients. For high contention workloads, optimism can result in a high abort rate; the scheme presented here is a first step toward a hybrid scheme that we expect to perform well across the full range of workloads.	SIGMOD Conferen	database
3113	SIGMOD Conference	A Critique of ANSI SQL Isolation Levels.	Hal Berenson,Philip A. Bernstein,Jim Gray,Jim Melton,Elizabeth J. O'Neil,Patrick E. O'Neil	1995	ANSI SQL-92 [MS, ANSI] defines Isolation Levels in terms of phenomena: Dirty Reads, Non-Repeatable Reads, and Phantoms. This paper shows that these phenomena and the ANSI SQL definitions fail to properly characterize several popular isolation levels, including the standard locking implementations of the levels covered. Ambiguity in the statement of the phenomena is investigated and a more formal statement is arrived at; in addition new phenomena that better characterize isolation types are introduced. Finally, an important multiversion isolation type, called Snapshot Isolation, is defined.	SIGMOD Conferen	database
3114	SIGMOD Conference	Semint: A System Prototype for Semantic Integration in Heterogeneous Databases.	Wen-Syan Li,Chris Clifton	1995	Semint: A System Prototype for Semantic Integration in Heterogeneous Databases.	SIGMOD Conferen	database
3115	SIGMOD Conference	Fault Tolerant Design of Multimedia Servers.	Steven Berson,Leana Golubchik,Richard R. Muntz	1995	Recent technological advances have made multimedia on-demand servers feasible. Two challenging tasks in such systems are: a) satisfying the real-time requirement for continuous delivery of objects at specified bandwidths and b) efficiently servicing multiple clients simultaneously. To accomplish these tasks and realize economies of scale associated with servicing a large user population, the multimedia server can require a large disk subsystem. Although a single disk is fairly reliable, a large disk farm can have an unacceptably high probability of disk failure. Further, due to the real-time constraint, the reliability and availability requirements of multimedia systems are very stringent. In this paper we investigate techniques for providing a high degree of reliability and availability, at low disk storage, bandwidth, and memory costs for on-demand multimedia servers.	SIGMOD Conferen	database
3116	SIGMOD Conference	Semantic Assumptions and Query Evaluation in Temporal Databases.	Claudio Bettini,Xiaoyang Sean Wang,Elisa Bertino,Sushil Jajodia	1995	When querying a temporal database, a user often makes certain semantic assumptions on stored temporal data. This paper formalizes and studies two types of semantic assumptions: point-based and interval-based. The point-based assumptions include those assumptions that use interpolation methods, while the interval-based assumptions include those that involve different temporal types (time granularities). Each assumption is viewed as a way to derive certain implicit data from the explicit data stored in the database. The database system must use all explicit as well as (possibly infinite) implicit data to answer user queries. This paper introduces a new method to facilitate such query evaluations. A user query is translated into a system query such that the answer of this system query over the explicit data is the same as that of the user query over the explicit and the implicit data. The paper gives such a translation procedure and studies the properties (safety in particular) of user queries and system queries.	SIGMOD Conferen	database
3117	SIGMOD Conference	Real World Requirements for Decision Support - Implications for RDBMS.	Sanju K. Bansal	1995	Real World Requirements for Decision Support - Implications for RDBMS.	SIGMOD Conferen	database
3118	SIGMOD Conference	Hypergraph Based Reorderings of Outer Join Queries with Complex Predicates.	Gautam Bhargava,Piyush Goel,Balakrishna R. Iyer	1995	Complex queries containing outer joins are, for the most part, executed by commercial DBMS products in an as written manner. Only a very few reorderings of the operations are considered and the benefits of considering comprehensive reordering schemes are not exploited. This is largely due to the fact there are no readily usable results for reordering such operations for relations with duplicates and/or outer join predicates that are other than simple. Most previous approaches have ignored duplicates and complex predicates; the very few that have considered these aspects have suggested approaches that lead to a possibly exponential number of, and redundant intermediate joins. Since traditional query graph models are inadequate for modeling outer join queries with complex predicates, we present the needed hypergraph abstraction and algorithms for reordering such queries with joins and outer joins. As a result, the query optimizer can explore a significantly larger space of execution plans, and choose one with a low cost. Further, these algorithms are easily incorporated into well known and widely used enumeration methods such as dynamic programming.	SIGMOD Conferen	database
3119	SIGMOD Conference	An Overview of DB2 Parallel Edition.	Chaitanya K. Baru,Gilles Fecteau,Ambuj Goyal,Hui-I Hsiao,Anant Jhingran,Sriram Padmanabhan,Walter G. Wilson	1995	An Overview of DB2 Parallel Edition.	SIGMOD Conferen	database
3120	SIGMOD Conference	Copy Detection Mechanisms for Digital Documents.	Sergey Brin,James Davis,Hector Garcia-Molina	1995	In a digital library system, documents are available in digital form and therefore are more easily copied and their copyrights are more easily violated. This is a very serious problem, as it discourages owners of valuable information from sharing it with authorized users. There are two main philosophies for addressing this problem: prevention and detection. The former actually makes unauthorized use of documents difficult or impossible while the latter makes it easier to discover such activity.In this paper we propose a system for registering documents and then detecting copies, either complete copies or partial copies. We describe algorithms for such detection, and metrics required for evaluating detection mechanisms (covering accuracy, efficiency, and security). We also describe a working prototype, called COPS, describe implementation issues, and present experimental results that suggest the proper settings for copy detection parameters.	SIGMOD Conferen	database
3121	SIGMOD Conference	The LyriC Language: Querying Constraint Objects.	Alexander Brodsky,Yoram Kornatzky	1995	We propose a novel data model and its language for querying object-oriented databases where objects may hold spatial, temporal or constraint data, conceptually represented by linear equality and inequality constraints. The proposed LyriC language is designed to provide a uniform and flexible framework for diverse application realms such as (1) constraint-based design in two-, three-, or higher-dimensional space, (2) large-scale optimization and analysis, based mostly on linear programming techniques, and (3) spatial and geographic databases. LyriC extends flat constraint query languages, especially those for linear constraint databases, to structurally complex objects. The extension is based on the object-oriented paradigm, where constraints are treated as first-class objects that are organized in classes. The query language is an extension of the language XSQL, and is built around the idea of extended path expressions. Path expressions in a query traverse nested structures in one sweep. Constraints are used in a query to filter stored constraints and to create new constraint objects.	SIGMOD Conferen	database
3122	SIGMOD Conference	The REACH Active OODBMS.	Alejandro P. Buchmann,Alin Deutsch,Jürgen Zimmermann,M. Higa	1995	The REACH Active OODBMS.	SIGMOD Conferen	database
3123	SIGMOD Conference	The Data That You Won't Find in Databases: Tutorial panel on data exchange formats.	Peter Buneman,David Maier	1995	The Data That You Won't Find in Databases: Tutorial panel on data exchange formats.	SIGMOD Conferen	database
3124	SIGMOD Conference	The Algres Testbed of CHIMERA: An Active Object-Oriented Database System.	Stefano Ceri,Piero Fraternali,Stefano Paraboschi,Giuseppe Psaila	1995	The Algres Testbed of CHIMERA: An Active Object-Oriented Database System.	SIGMOD Conferen	database
3125	SIGMOD Conference	Join Queries with External Text Sources: Execution and Optimization Techniques.	Surajit Chaudhuri,Umeshwar Dayal,Tak W. Yan	1995	Text is a pervasive information type, and many applications require querying over text sources in addition to structured data. This paper studies the problem of query processing in a system that loosely integrates an extensible database system and a text retrieval system. We focus on a class of conjunctive queries that include joins between text and structured data, in addition to selections over these two types of data. We adapt techniques from distributed query processing and introduce a novel class of join methods based on probing that is especially useful for joins with text systems, and we present a cost model for the various alternative query processing methods. Experimental results confirm the utility of these methods. The space of query plans is extended due to the additional techniques, and we describe an optimization algorithm for searching this extended space. The techniques we describe in this paper are applicable to other types of external data managers loosely integrated with a database system.	SIGMOD Conferen	database
3126	SIGMOD Conference	The NAOS System.	Christine Collet,Thierry Coupaye	1995	The NAOS System.	SIGMOD Conferen	database
3127	SIGMOD Conference	An Online Video Placement Policy based on Bandwith to Space Ratio (BSR).	Asit Dan,Dinkar Sitaram	1995	In a video-on-demand server, resource reservation is required to guarantee continuous delivery. Hence any given storage device (or a striping group treated as a single logical device) can serve only up to a fixed number of client access streams. Each storage device is also limited by the number of video files it can store. For the reasons of availability, incremental growth, and heterogeneity, there may be multiple storage devices in a video server environment. Hence, one or more copies of a particular video may be placed on different storage devices. Since the access rates to different videos are not uniform, there may be load imbalance among the devices. In this paper, we propose a dynamic placement policy (called the Bandwidth to Space Ratio (BSR) Policy) that creates and/or deletes replica of a video, and mixes hot and cold videos so as to make the best use of bandwidth and space of a storage device. The proposed policy is evaluated using a simulation study.	SIGMOD Conferen	database
3128	SIGMOD Conference	Dynamic Resource Brokering for Multi-User Query Execution.	Diane L. Davison,Goetz Graefe	1995	We propose a new framework for resource allocation based on concepts from microeconomics. Specifically, we address the difficult problem of managing resources in a multiple-query environment composed of queries with widely varying resource requirements. The central element of the framework is a resource broker that realizes a profit by selling resources to competing operators using a performance-based currency. The guiding principle for brokering resources is profit maximization. In other words, since the currency is derived from the performance objective, the broker can achieve the best performance by making the scheduling and resource allocation decisions that maximize profit. Moreover, the broker employs dynamic techniques and adapts by changing previous allocation decisions while queries are executing. In a first validation study of the framework, we developed a prototype broker that manages memory and disk bandwidth for a multi-user query workload. The performance objective for the prototype broker is to minimize slowdown with the constraint of fairness. Slowdown measures how much higher the response time is in a multi-user environment than a single-user environment, and fairness measures how even is the degradation in response time among all queries as the system load increases, Our simulation results show the viability of the broker framework and the effectiveness of our query admission and resource allocation policies for multi-user workloads.	SIGMOD Conferen	database
3129	SIGMOD Conference	Objects and SQL: Strange Relations? Panel.	Donald R. Deutsch	1995	Objects and SQL: Strange Relations? Panel.	SIGMOD Conferen	database
3130	SIGMOD Conference	Using the CALANDA Time Series Management System.	Werner Dreyer,Angelika Kotz Dittrich,Duri Schmidt	1995	Using the CALANDA Time Series Management System.	SIGMOD Conferen	database
3131	SIGMOD Conference	Reducing Multidatabase Query Response Time by Tree Balancing.	Weimin Du,Ming-Chien Shan,Umeshwar Dayal	1995	Execution of multidatabase queries differs from that of traditional queries in that sort merge and hash joins are more often favored, as nested loop join requires repeated accesses to external data sources. As a consequence, left deep join trees obtained by traditional (e.g., System-R style) optimizers for multidatabase queries are often suboptimal, with respect to response time, due to the long delay for a sort merge (or hash) join node to produce its last result after the subordinate join node did. In this paper, we present an optimization strategy that first produces an optimal left deep join tree and then reduces the response time using simple tree transformations. This strategy has the advantages of guaranteed minimum total resource usage, improved response time, and low optimization overhead. We describe a class of basic transformations that is the cornerstone of our approach. Then we present algorithms that effectively apply basic transformations to balance a left deep join tree, and discuss how the technique can be incorporated into existing query optimizers.	SIGMOD Conferen	database
3132	SIGMOD Conference	Research and Products: Are They Relevant To Each Other? (Panel).	Herb Edelstein	1995	Research and Products: Are They Relevant To Each Other? (Panel).	SIGMOD Conferen	database
3133	SIGMOD Conference	Keynote Address.	Larry Ellison	1995	Keynote Address.	SIGMOD Conferen	database
3134	SIGMOD Conference	Keynote Address.	Robert S. Epstein	1995	Keynote Address.	SIGMOD Conferen	database
3135	SIGMOD Conference	Indexing Multimedia Databases (Tutorial).	Christos Faloutsos	1995	Indexing Multimedia Databases (Tutorial).	SIGMOD Conferen	database
3136	SIGMOD Conference	FastMap: A Fast Algorithm for Indexing, Data-Mining and Visualization of Traditional and Multimedia Datasets.	Christos Faloutsos,King-Ip Lin	1995	A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the 'Query By Example' type (which translates to a range query); the 'all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc.However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points.This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for.We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N), while it manages to preserve distances and the overall structure of the data-set.	SIGMOD Conferen	database
3137	SIGMOD Conference	The SPIFFI Scalable Video-on-Demand System.	Craig S. Freedman,David J. DeWitt	1995	This paper presents a simulation study of a video-on-demand system. We present video server algorithms for real-time disk scheduling, prefetching, and buffer pool management. The performance of these algorithms is compared against the performance of simpler algorithms such as elevator and round-robin disk scheduling and global LRU buffer pool management. Finally, we show that the SPIFFI video-on-demand system scales nearly linearly as the number of disks, videos, and terminals is increased.	SIGMOD Conferen	database
3138	SIGMOD Conference	Towards an Effective Calculus for Object Query Languages.	Leonidas Fegaras,David Maier	1995	We define a standard of effectiveness for a database calculus relative to a query language. Effectiveness judges suitability to serve as a processing framework for the query language, and comprises aspects of coverage, manipulability and efficient evaluation. We present the monoid calculus, and argue its effectiveness for object-oriented query languages, exemplified by OQL of ODMG-93. The monoid calculus readily captures such features as multiple collection types, aggregations, arbitrary composition of type constructors and nested query expressions. We also show how to extend the monoid calculus to deal with vectors and arrays in more expressive ways than current query languages do, and illustrate how it can handle identity and updates.	SIGMOD Conferen	database
3139	SIGMOD Conference	A General Solution of the n-dimensional B-tree Problem.	Michael Freeston	1995	We present a generic solution to a problem which lies at the heart of the unpredictable worst-case performance characteristics of a wide class of multi-dimensional index designs: those which employ a recursive partitioning of the data space. We then show how this solution can produce modified designs with fully predictable and controllable worst-case characteristics. In particular, we show how the recursive partitioning of an n-dimensional dataspace can be represented in such a way that the characteristics of the one-dimensional B-tree are preserved in n dimensions, as far as is topologically possible i.e. a representation guaranteeing logarithmic access and update time, while also guaranteeing a one-third minimum occupancy of both data and index nodes.	SIGMOD Conferen	database
3140	SIGMOD Conference	``One Size Fits All'' Database Architectures Do Not Work for DDS.	Clark D. French	1995	``One Size Fits All'' Database Architectures Do Not Work for DDS.	SIGMOD Conferen	database
3141	SIGMOD Conference	OFL: A Functional Execution Model for Object Query Languages.	Georges Gardarin,Fernando Machuca,Philippe Pucheral	1995	We present a functional paradigm for querying efficiently abstract collections of complex objects. Abstract collections are used to model class extents, multivalued attributes as well as indexes or hashing tables. Our paradigm includes a functional language called OFL (Object Functional Language) and a supporting execution model based on graph traversals. OFL is able to support any complex object algebra with recursion as macros. It is an appropriate target language for OQL-like query compilers. The execution model provides various strategies including set-oriented and pipelined traversals. OFL has been implemented on top of an object manager. Measures of a typical query extracted from a geographical benchmark show the value of hybrid strategies integrating pipelined and set-oriented evaluations. They also show the potential of function result memorization, a typical optimization approach known as Memoization 2 in functional languages.	SIGMOD Conferen	database
3142	SIGMOD Conference	Parallel Database Systems 101.	Jim Gray	1995	Parallel Database Systems 101.	SIGMOD Conferen	database
3143	SIGMOD Conference	The SAMOS Active DBMS Prototype.	Stella Gatziu,Andreas Geppert,Klaus R. Dittrich	1995	The SAMOS Active DBMS Prototype.	SIGMOD Conferen	database
3144	SIGMOD Conference	Incremental Maintenance of Views with Duplicates.	Timothy Griffin,Leonid Libkin	1995	We study the problem of efficient maintenance of materialized views that may contain duplicates. This problem is particularly important when queries against such views involve aggregate functions, which need duplicates to produce correct results. Unlike most work on the view maintenance problem that is based on an algorithmic approach, our approach is algebraic and based on equational reasoning. This approach has a number of advantages: it is robust and easily extendible to new language constructs, it produces output that can be used by query optimizers, and it simplifies correctness proofs.We use a natural extension of the relational algebra operations to bags (multisets) as our basic language. We present an algorithm that propagates changes from base relations to materialized views. This algorithm is based on reasoning about equivalence of bag-valued expressions. We prove that it is correct and preserves a certain notion of minimality that ensures that no unnecessary tuples are computed. Although it is generally only a heuristic that computing changes to the view rather than recomputing the view from scratch is more efficient, we prove results saying that under normal circumstances one should expect, the change propagation algorithm to be significantly faster and more space efficient than complete recomputing of the view. We also show that our approach interacts nicely with aggregate functions, allowing their correct evaluation on views that change.	SIGMOD Conferen	database
3145	SIGMOD Conference	PTool: A Light Weight Persistent Object Manager.	Robert L. Grossman,David Hanley,Xiao Qin	1995	PTool: A Light Weight Persistent Object Manager.	SIGMOD Conferen	database
3146	SIGMOD Conference	Informix Online XPS.	Robert H. Gerber	1995	Informix Online XPS.	SIGMOD Conferen	database
3147	SIGMOD Conference	DIRECTV and Oracle Rdb: The Challenges of VLDB Transaction Processing.	William L. Gettys	1995	DIRECTV and Oracle Rdb: The Challenges of VLDB Transaction Processing.	SIGMOD Conferen	database
3148	SIGMOD Conference	Storage Technology: RAID and Beyond.	Garth A. Gibson	1995	Storage Technology: RAID and Beyond.	SIGMOD Conferen	database
3149	SIGMOD Conference	Adapting Materialized Views after Redefinitions.	Ashish Gupta,Inderpal Singh Mumick,Kenneth A. Ross	1995	We consider a variant of the view maintenance problem: How does one keep a materialized view up-to-date when the view definition itself changes? Can one do better than recomputing the view from the base relations? Traditional view maintenance tries to maintain the materialized view in response to modifications to the base relations; we try to adapt the view in response to changes in the view definition.Such techniques are needed for applications where the user can change queries dynamically and see the changes in the results fast. Data archaeology, data visualization, and dynamic queries are examples of such applications.We consider all possible redefinitions of SQL SELECT-FROM-WHERE-GROUPBY, UNION, and EXCEPT views, and show how these views can be adapted using the old materialization for the cases where it is possible to do so. We identify extra information that can be kept with a materialization to facilitate redefinition. Multiple simultaneous changes to a view can be handled without necessarily materializing intermediate results. We identify guidelines for users and database administrators that can be used to facilitate efficient view adaptation.	SIGMOD Conferen	database
3150	SIGMOD Conference	Things Every Update Replication Customer Should Know.	Rob Golding	1995	Things Every Update Replication Customer Should Know.	SIGMOD Conferen	database
3151	SIGMOD Conference	Information Translation, Mediation, and Mosaic-Based Browsing in the TSIMMIS System.	Joachim Hammer,Hector Garcia-Molina,Kelly Ireland,Yannis Papakonstantinou,Jeffrey D. Ullman,Jennifer Widom	1995	Information Translation, Mediation, and Mosaic-Based Browsing in the TSIMMIS System.	SIGMOD Conferen	database
3152	SIGMOD Conference	The Merge/Purge Problem for Large Databases.	Mauricio A. Hernández,Salvatore J. Stolfo	1995	Many commercial organizations routinely gather large numbers of databases for various marketing and business analysis functions. The task is to correlate information from different databases by identifying distinct individuals that appear in a number of different databases typically in an inconsistent and often incorrect fashion. The problem we study here is the task of merging data from multiple sources in as efficient manner as possible, while maximizing the accuracy of the result. We call this the merge/purge problem. In this paper we detail the sorted neighborhood method that is used by some to solve merge/purge and present experimental results that demonstrates this approach may work well in practice but at great expense. An alternative method based upon clustering is also presented with a comparative evaluation to the sorted neighborhood method. We show a means of improving the accuracy of the results based upon a multi-pass approach that succeeds by computing the Transitive Closure over the results of independent runs considering alternative primary key attributes in each pass.	SIGMOD Conferen	database
3153	SIGMOD Conference	Enterprise Transaction Processing on Windows NT.	Greg Hope	1995	Enterprise Transaction Processing on Windows NT.	SIGMOD Conferen	database
3154	SIGMOD Conference	Enhancing Database Correctness: a Statistical Approach.	Wen-Chi Hou,Zhongyang Zhang	1995	In this paper, we introduce a new type of integrity constraint, which we call a statistical constraint, and discuss its applicability to enhancing database correctness. Statistical constraints manifest embedded relationships among current attribute values in the database and are characterized by their probabilistic nature. They can be used to detect potential errors not easily detected by the conventional constraints. Methods for extracting statistical constraints from a relation and enforcement of such constraints are described. Preliminary performance evaluation of enforcing statistical constraints on a real life database is also presented.	SIGMOD Conferen	database
3155	SIGMOD Conference	DataMine - Interactive Rule Discovery System.	Tomasz Imielinski,Aashu Virmani	1995	DataMine - Interactive Rule Discovery System.	SIGMOD Conferen	database
3156	SIGMOD Conference	Balancing Histogram Optimality and Practicality for Query Result Size Estimation.	Yannis E. Ioannidis,Viswanath Poosala	1995	Many current database systems use histograms to approximate the frequency distribution of values in the attributes of relations and based on them estimate query result sizes and access plan costs. In choosing among the various histograms, one has to balance between two conflicting goals: optimality, so that generated estimates have the least error, and practicality, so that histograms can be constructed and maintained efficiently. In this paper, we present both theoretical and experimental results on several issues related to this trade-off. Our overall conclusion is that the most effective approach is to focus on the class of histograms that accurately maintain the frequencies of a few attribute values and assume the uniform distribution for the rest, and choose for each relation the histogram in that class that is optimal for a self-join query.	SIGMOD Conferen	database
3157	SIGMOD Conference	High Availability of Commercial Applications.	Kestutis Ivinskis	1995	The increased performance capabilities of UNIX server systems have led to their acceptance as the server of choice for medium-sized and large organizations. But performance is just one facet. Another facet is the end user perception of the availability of an information system.Traditional mainframe based IS shops have a long experience in supplying computing services to their commercial end users. The ultimate goal of the end user is to have no downtimes for his work at his PC or workstation terminal. Key issues related to system availability in client/server based information systems remain the same as in the mainframe based world, e.g. system responsiveness, maximum downtime per year and maximum number of system outages per year. But there are also new aspects, which have been introduced into the discussion.In a multi-tiered client/server based information system the OLTP workload is distributed on different servers. Hence one can ask: Why should a failure of one server automatically imply downtime for the whole system ? Can't most of the system continue to operate ? Redistribution of the workload on the remaining active servers can be used to attack this problem. Workload balancing can be applied for replicated system services. Other techniques have to be applied for non-replicated system services.This paper considers client/server based applications running in a local or wide area network of computers in a distributed system.	SIGMOD Conferen	database
3158	SIGMOD Conference	The ECRC Multi Database System.	Willem Jonker,Heribert Schütz	1995	The ECRC Multi Database System.	SIGMOD Conferen	database
3159	SIGMOD Conference	VisDB: A System for Visualizing Large Databases.	Daniel A. Keim,Hans-Peter Kriegel	1995	The VisDB system developed at the University of Munich is a sophisticated tool for visualizing and analyzing large databases. The key idea of the VisDB system is to support the exploration of large databases by using the phenomenal abilities of the human vision system which is able to analyze visualizations of mid-size to large amounts of data very efficiently. The goal of the VisDB system is to provide visualizations of large portions of the database, allowing properties of the data and structure in the data to become perceptually apparent.	SIGMOD Conferen	database
3160	SIGMOD Conference	Enterprise Objects Framework, A Second Generation Object-Relational Enabler.	Charly Kleissner	1995	Today's information system executives desperately need to improve programmer productivity and reduce software maintenance costs. They are demanding flexibility in frameworks and architectures in order to meet unforeseen changes (see [Yankee 94]). Adaptability is a major requirement of most company's information systems efforts. Management of change is one of the key computing concepts of the 1990s.Object-oriented tools and development frameworks are starting to deliver the benefits of increased productivity and flexibility. These next-generation products now need to be combined with relational databases to leverage investments and facilitate access to business data. Object-Relational Enablers automate the process of storing complex objects in a relational database management system (see [Aberdeen 94]).The Enterprise Objects Framework product is a second generation product bringing the benefits of object-oriented programming to relational database application development. Enterprise Objects Framework enables developers to construct reusable business objects that combine business logic with persistent storage in industry-standard relational databases. Enterprise objects are first class citizens in the NEXTSTEP and OpenStep developer and user environments. They can be geographically distributed throughout heterogeneous servers within an enterprise using the Portable Distributed Objects product (see [NeXT-DO 94]).In this extended abstract we first describe the enterprise object distribution model and then give a brief synopsis of how relational data is mapped into objects. We then present an outline of the system architecture, explain how objects are mapped to multiple tables, and summarize the transaction semantics as well as the application development life-cycle. We conclude with an outlook on future development.	SIGMOD Conferen	database
3161	SIGMOD Conference	Order-of-Magnitude Advantage of TPC-C Though Massive Parallelism.	Charles Levine	1995	TPC Benchmark&trade; C (TPC-C) is the modern standard for measuring OLTP performance. Running TPC-C, Tandem demonstrated a massively parallel configuration of 112 CPUs which achieved ten times higher performance than any other system previously measured (and today is still better by a factor of five). This result qualifies as the largest industry-standard benchmark ever run.This paper briefly describes how the benchmark was configured and the results which were obtained.	SIGMOD Conferen	database
3162	SIGMOD Conference	Efficient Maintenance of Materialized Mediated Views.	James J. Lu,Guido Moerkotte,Joachim Schü,V. S. Subrahmanian	1995	Integrating data and knowledge from multiple heterogeneous sources -- like databases, knowledge bases or specific software packages -- is often required for answering certain queries. Recently, a powerful framework for defining mediated views spanning multiple knowledge bases by a set of constrained rules was proposed [24, 4, 16]. We investigate the materialization of these views by unfolding the view definition and the efficient maintenance of the resulting materialized mediated view in case of updates. Thereby, we consider two kinds of updates: updates to the view and updates to the underlying sources. For each of these two cases several efficient algorithms maintaining materialized mediated views are given. We improve on previous algorithms like the DRed algorithm [12] and introduce a new fixpoint operator WP which -- opposed to the standard fixpoint operator TP [9] -- allows us to correctly capture the update's semantics without any recomputation of the materialized view.	SIGMOD Conferen	database
3163	SIGMOD Conference	QBI: Query By Icons.	Antonio Massari,Stefano Pavani,Lorenzo Saladini,Panos K. Chrysanthis	1995	QBI is an icon-based query processing and exploration facility for large distributed databases [3]. As opposed to other interactive query interfaces, it combines (1) a pure iconic specification, i.e., no diagrams of any form, only icon manipulation, with (2) intensional browsing or metaquery tools that assist in the formulation of complete queries without involving path specification or access to the actual data in the database.Path expressions are automatically generated by QBI and irrespective of their length, represented by a single icon, allowing for better use of the screen. It requires no special knowledge of the content of the underlying database nor understanding of the details of the database schema. Hence, QBI is domain independent and equally useful to both unsophisticated and expert users.	SIGMOD Conferen	database
3164	SIGMOD Conference	An Overview of the Emerging Third-Generation SQL Standard (Tutorial).	Nelson Mendonça Mattos,Jim Melton	1995	An Overview of the Emerging Third-Generation SQL Standard (Tutorial).	SIGMOD Conferen	database
3165	SIGMOD Conference	Recovery Protocols for Shared Memory Database Systems.	Lory D. Molesky,Krithi Ramamritham	1995	Significant performance advantages can be gained by implementing a database system on a cache-coherent shared memory multiprocessor. However, problems arise when failures occur. A single node (where a node refers to a processor/memory pair) crash may require a reboot of the entire shared memory system. Fortunately, shared memory multiprocessors that isolate individual node failures are currently being developed. Even with these, because of the side effects of the cache coherency protocol, a transaction executing strictly on a single node may become dependent on the validity of the memory of many nodes thereby inducing unnecessary transaction aborts. This happens when database objects, such as records, and database support structures, such as index structures and shared lock tables, are stored in shared memory.In this paper, we propose crash recovery protocols for shared memory database systems which avoid the unnecessary transaction aborts induced by the effects of using shared physical memory. Our recovery protocols guarantee that if one or more nodes crash, all the effects of active transactions running on the crashed nodes will be undone, and no effects of transactions running on nodes which did not crash will be undone. In order to show the practicality of our protocols, we discuss how existing features of cache-coherent multiprocessors can be utilized to implement these recovery protocols. Specifically, we demonstrate that (1) for many types of database objects and support structures, volatile (in-memory) logging is sufficient to avoid unnecessary transaction aborts, and (2) a very low overhead implementation of this strategy can be achieved with existing multiprocessor features.	SIGMOD Conferen	database
3166	SIGMOD Conference	The Lotus Notes Storage System.	Kenneth Moore	1995	Lotus Notes is a commercial product that empowers individuals and organizations to collaborate and share information [1].Notes enables the easy development of applications such as messaging, document management, workflow, and asynchronous conferencing. Notes applications can be deployed globally, across independent organizations, among a heterogeneous network of loosely coupled computers that range in size from small notebooks to large multi-processor systems.The third major release of Lotus Notes occurred in May 1993. Notes is a client-server product, with clients available on Windows, OS/2, Macintosh, SCO UNIX, HP-UX, AIX, and Solaris. The server is available on Windows, OS/2, Windows NT (for Intel processors), NetWare, SCO UNIX, HP-UX, AIX, and Solaris.	SIGMOD Conferen	database
3167	SIGMOD Conference	Integration Approaches for CIM.	Moira C. Norrie	1995	In response to pressures to reduce product lead times, manufacturing companies are increasingly aware of the need for some form of integration along the whole product chain. Engineering tasks must be coordinated and data exchanged between the various specialised tools. An enterprise has two main tracks of information flow, namely technical and managerial, and product data management spans both tracks. On the technical track, applications are highly specialised supporting tasks such as product design (CAD) and the programming of numerically controlled machines (CAM). Generally, the various application systems on the technical track are referred to as CAx systems. CAx systems may not only differ in terms of functionality but also in terms of the amount and type of data managed, the run-time environment and performance characteristics. For complete support of Computer Integrated Manufacturing (CIM), we must be able to integrate existing technical and administrative component application systems. These component systems vary in their data management support and many CAx systems store their data directly in files rather than in a database system. The issues are how to describe the dependencies between these component systems and ensure system-wide data consistency. A particularly difficult problem is that of how to interface existing application systems in such a way that their operation can be monitored and controlled and a global transaction scheme provided. Integration must be achieved in a way that supports system evolution in terms of the introduction and replacement of application systems. This is particularly important given the trend towards the notions of the extended enterprise and virtual factories in which a particular product chain may span several enterprises. Further, emerging legal statutes (especially in relation to environmental factors) are resulting in changes to the requirements for product data management. Enterprise integration must be both flexible and dynamic. The best way of achieving this is to integrate component systems by mans of a control layer which coordinates tasks based on explicit inter-system dependencies amenable to both direct view and update. Product Data Management systems (also known as Engineering Databases) have been developed for the integration of CAx systems by managing product data centrally. One problem with a centralised system controlling access to data is that its availability is critical to the operation of all component systems. In an effort to overcome this, systems are being developed which replicate the metadata and data required for coordination. Alternatively, coordination approaches have been proposed which aim to maximise component subsystem autonomy and increase CIM system flexibility. These systems place less emphasis on data sharing and more emphasis on task coordination. The integration effort is minimised and only that information strictly essential to coordination is managed centrally.	SIGMOD Conferen	database
3168	SIGMOD Conference	Cover Your Assets.	Michael A. Olson	1995	Cover Your Assets.	SIGMOD Conferen	database
3169	SIGMOD Conference	Topological Relations in the World of Minimum Bounding Rectangles: A Study with R-trees.	Dimitris Papadias,Yannis Theodoridis,Timos K. Sellis,Max J. Egenhofer	1995	Topological Relations in the World of Minimum Bounding Rectangles: A Study with R-trees.	SIGMOD Conferen	database
3170	SIGMOD Conference	An Effective Hash Based Algorithm for Mining Association Rules.	Jong Soo Park,Ming-Syan Chen,Philip S. Yu	1995	In this paper, we examine the issue of mining association rules among items in a large database of sales transactions. The mining of association rules can be mapped into the problem of discovering large itemsets where a large itemset is a group of items which appear in a sufficient number of transactions. The problem of discovering large itemsets can be solved by constructing a candidate set of itemsets first and then, identifying, within this candidate set, those itemsets that meet the large itemset requirement. Generally this is done iteratively for each large k-itemset in increasing order of k where a large k-itemset is a large itemset with k items. To determine large itemsets from a huge number of candidate large itemsets in early iterations is usually the dominating factor for the overall data mining performance. To address this issue, we propose an effective hash-based algorithm for the candidate set generation. Explicitly, the number of candidate 2-itemsets generated by the proposed algorithm is, in orders of magnitude, smaller than that by previous methods, thus resolving the performance bottleneck. Note that the generation of smaller candidate sets enables us to effectively trim the transaction database size at a much earlier stage of the iterations, thereby reducing the computational cost for later iterations significantly. Extensive simulation study is conducted to evaluate performance of the proposed algorithm.	SIGMOD Conferen	database
3171	SIGMOD Conference	Efendi: Federated Database System of Cadlab.	Elke Radeke,Ralf Böttger,Bernd Burkert,Yaron Engel,Gerd Kachel,Silvia Kolmschlag,Dietmar Nolte	1995	Efendi: Federated Database System of Cadlab.	SIGMOD Conferen	database
3172	SIGMOD Conference	Leveraging The Information Asset.	Janet Perna	1995	Data is a corporate asset, and being able to derive more information from data can provide database users with a competitive advantage. For example, catching on to trends quickly can reduce unwanted store inventory and lower capital outlay for the same profit. If you have store sales data by product analyzed on a daily basis, that can make a 2-3% difference in margin -- and in a business where margins might be 4%, this is a significant competitive edge. This paper will cover what technology is needed by customers to leverage their information assets. Real-time access to production point of sale information, database mining for analysis to detect trends immediately, high performance, and multi-vendor database connectivity, cooperation among heterogeneous clients and servers are among the customer needs we are seeing in the marketplace.	SIGMOD Conferen	database
3173	SIGMOD Conference	OODB Indexing by Class-Division.	Sridhar Ramaswamy,Paris C. Kanellakis	1995	Indexing a class hierarchy, in order to efficiently search or update the objects of a class according to a (range of) value(s) of an attribute, impacts OODB performance heavily. For this indexing problem, most systems use the class hierarchy index (CH) technique of [15] implemented using B+-trees. Other techniques, such as those of [14, 18,31], can lead to improved average-case performance but involve the implementation of new data-structures. As a special form of external dynamic two-dimensional range searching, this OODB indexing problem is solvable within reasonable worst-case bounds [12]. Based on this insight, we have developed a technique, called indexing by class-division (CD), which we believe can be used as a practical alternative to CH. We present an optimized implementation and experimental validation of CD's average-case performance. The main advantages of the CD technique are: (1) CD is an extension of CH that provides a significant speed-up over CH for a wide spectrum of range queries--this speed-up is at least linear in the number of classes queried for uniform data and larger otherwise; and (2) CD queries, updates and concurrent use are implementable using existing B+-tree technology. The basic idea of class-division involves a time-space tradeoff and CD requires some space and update overhead in comparison to CH. In practice, this overhead is a small factor (2 to 3) and, in worst-case, is bounded by the depth of the hierarchy and the logarithm of its size.	SIGMOD Conferen	database
3174	SIGMOD Conference	Nearest Neighbor Queries.	Nick Roussopoulos,Stephen Kelley,Frédéic Vincent	1995	A frequently encountered type of query in Geographic Information Systems is to find the k nearest neighbor objects to a given point in space. Processing such queries requires substantially different search algorithms than those for location or range queries. In this paper we present an efficient branch-and-bound R-tree traversal algorithm to find the nearest neighbor object to a point, and then generalize it to finding the k nearest neighbors. We also discuss metrics for an optimistic and a pessimistic search ordering strategy as well as for pruning. Finally, we present the results of several experiments obtained using the implementation of our algorithm and examine the behavior of the metrics and the scalability of the algorithm.	SIGMOD Conferen	database
3175	SIGMOD Conference	Adaptive Parallel Aggregation Algorithms.	Ambuj Shatdal,Jeffrey F. Naughton	1995	Aggregation and duplicate removal are common in SQL queries. However, in the parallel query processing literature, aggregate processing has received surprisingly little attention; furthermore, for each of the traditional parallel aggregation algorithms, there is a range of grouping selectivities where the algorithm performs poorly. In this work, we propose new algorithms that dynamically adapt, at query evaluation time, in response to observed grouping selectivities. Performance analysis via analytical modeling and an implementation on a workstation-cluster shows that the proposed algorithms are able to perform well for all grouping selectivities. Finally, we study the effect of data skew and show that for certain data sets the proposed algorithms can even outperform the best of traditional approaches.	SIGMOD Conferen	database
3176	SIGMOD Conference	Workflow Automation: Applications, Technology, and Research (Tutorial).	Amit P. Sheth	1995	Workflow Automation: Applications, Technology, and Research (Tutorial).	SIGMOD Conferen	database
3177	SIGMOD Conference	InfoHarness: A System for Search and Retrieval of Heterogeneous Information.	Leon A. Shklar,Amit P. Sheth,Vipul Kashyap,Satish Thatte	1995	Enormous amounts of heterogeneous information have been accumulated within corporations, government organizations and universities. It is becoming increasingly easier to create new information, but the knowledge about the existence, location, and means of retrieval of information, have become so confusing as to give rise to the phenomenon of write-only databases.	SIGMOD Conferen	database
3178	SIGMOD Conference	VERSANT Replication: Supporting Fault-Tolerant Object Databases.	Yuh-Ming Shyy,H. Stephen Au-Yeung,C. P. Chou	1995	VERSANT Replication: Supporting Fault-Tolerant Object Databases.	SIGMOD Conferen	database
3179	SIGMOD Conference	Temporal Conditions and Integrity Constraints in Active Database Systems.	A. Prasad Sistla,Ouri Wolfson	1995	In this paper, we present a unified formalism, based on Past Temporal Logic, for specifying conditions and events in the rules for active database system. This language permits specification of many time varying properties of database systems. It also permits specification of temporal aggregates. We present an efficient incremental algorithm for detecting conditions specified in this language. The given algorithm, for a subclass of the logic, was implemented on top of Sybase.	SIGMOD Conferen	database
3180	SIGMOD Conference	Object-Oriented, Rapid Application Development in a PC Database Environment.	Fox Development Team	1995	Object-Oriented, Rapid Application Development in a PC Database Environment.	SIGMOD Conferen	database
3181	SIGMOD Conference	Data Extraction and Transformation for the Data Warehouse.	Cass Squire	1995	Data Extraction and Transformation for the Data Warehouse.	SIGMOD Conferen	database
3182	SIGMOD Conference	Paradise: A Database System for GIS Applications.	Paradise Team	1995	Paradise: A Database System for GIS Applications.	SIGMOD Conferen	database
3183	SIGMOD Conference	SHORE: Combining the Best Features of OODBMS and File Systems.	Shore Team	1995	SHORE: Combining the Best Features of OODBMS and File Systems.	SIGMOD Conferen	database
3184	SIGMOD Conference	Upsizing from File Server to Clent Server Architectures.	The Access Team	1995	Upsizing from File Server to Clent Server Architectures.	SIGMOD Conferen	database
3185	SIGMOD Conference	Design and Implementation of Advanced Knowledge Processing in the KDMS KRISYS (Demonstration Description).	Joachim Thomas,Stefan Deßloch,Nelson Mendonça Mattos	1995	Design and Implementation of Advanced Knowledge Processing in the KDMS KRISYS (Demonstration Description).	SIGMOD Conferen	database
3186	SIGMOD Conference	Pattern Matching and Pattern Discovery in Scientific, Program, and Document Databases.	Jason Tsong-Li Wang,Kaizhong Zhang,Dennis Shasha	1995	Over the past several years we have created or borrowed algorithms for combinatorial pattern matching and pattern discovery on sequences [2] and trees.In matching problems, given a pattern, a set of data objects and a distance metric, we find the distance between the pattern and one or more data objects. In discovery problems by contrast, given a set of objects, a metric, and a distance, we seek a pattern that matches many of those objects within the given distance. (So, discovery is a lot like data mining.) Our toolkit performs both matching and discovery with current targeted applications in molecular biology and document comparison.	SIGMOD Conferen	database
3187	SIGMOD Conference	Implementing Crash Recovery in QuickStore: A Performance Study.	Seth J. White,David J. DeWitt	1995	Implementing crash recovery in an Object-Oriented Database System (OODBMS) raises several challenging issues for performance that are not present in traditional DBMSs. These performance concerns result both from significant architectural differences between OODBMSs and traditional database systems and differences in OODBMS's target applications. This paper compares the performance of several alternative approaches to implementing crash recovery in an OODBMS based on a client-server architecture. The four basic recovery techniques examined in the paper are termed page differencing, sub-page differencing, whole-page logging, and redo-at-server. All of the recovery techniques were implemented in the context of QuickStore, a memory-mapped store built using the EXODUS Storage Manager, and their performance is compared using the OO7 database benchmark. The results of the performance study show that the techniques based on differencing generally provide superior performance to whole-page logging.	SIGMOD Conferen	database
3188	SIGMOD Conference	Parallel Evaluation of Multi-Join Queries.	Annita N. Wilschut,Jan Flokstra,Peter M. G. Apers	1995	A number of execution strategies for parallel evaluation of multi-join queries have been proposed in the literature; their performance was evaluated by simulation. In this paper we give a comparative performance evaluation of four execution strategies by implementing all of them on the same parallel database system, PRISMA/DB. Experiments have been done up to 80 processors. The basic strategy is to first determine an execution schedule with minimum total cost and then parallelize this schedule with one of the four execution strategies. These strategies, coming from the literature, are named: Sequential Parallel, Synchronous Execution, Segmented Right-Deep, and Full Parallel. Based on the experiments clear guidelines are given when to use which strategy.	SIGMOD Conferen	database
3189	SIGMOD Conference	Carnot and InfoSleuth: Database Technology and the World Wide Web.	Darrell Woelk,William Bohrer,Nigel Jacobs,KayLiang Ong,Christine Tomlinson,C. Unnikrishnan	1995	Carnot and InfoSleuth: Database Technology and the World Wide Web.	SIGMOD Conferen	database
3190	SIGMOD Conference	View Maintenance in a Warehousing Environment.	Yue Zhuge,Hector Garcia-Molina,Joachim Hammer,Jennifer Widom	1995	A warehouse is a repository of integrated information drawn from remote data sources. Since a warehouse effectively implements materialized views, we must maintain the views as the data sources are updated. This view maintenance problem differs from the traditional one in that the view definition and the base data are now decoupled. We show that this decoupling can result in anomalies if traditional algorithms are applied. We introduce a new algorithm, ECA (for Eager Compensating Algorithm), that eliminates the anomalies. ECA is based on previous incremental view maintenance algorithms, but extra compensating queries are used to eliminate anomalies. We also introduce two streamlined versions of ECA for special cases of views and updates, and we present an initial performance study that compares ECA to a view recomputation algorithm in terms of messages transmitted, data transferred, and I/O costs.	SIGMOD Conferen	database
3191	VLDB	Using Formal Methods to Reason about Semantics-Based Decompositions of Transactions.	Paul Ammann,Sushil Jajodia,Indrakshi Ray	1995	Using Formal Methods to Reason about Semantics-Based Decompositions of Transactions.	VLDB	database
3192	VLDB	Efficient Incremental Garbage Collection for Client-Server Object Database Systems.	Laurent Amsaleg,Michael J. Franklin,Olivier Gruber	1995	Efficient Incremental Garbage Collection for Client-Server Object Database Systems.	VLDB	database
3193	VLDB	Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases.	Rakesh Agrawal,King-Ip Lin,Harpreet S. Sawhney,Kyuseok Shim	1995	Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases.	VLDB	database
3194	VLDB	Querying Shapes of Histories.	Rakesh Agrawal,Giuseppe Psaila,Edward L. Wimmers,Mohamed Zaït	1995	Querying Shapes of Histories.	VLDB	database
3195	VLDB	A Practical and Modular Implementation of Extended Transaction Models.	Roger S. Barga,Calton Pu	1995	A Practical and Modular Implementation of Extended Transaction Models.	VLDB	database
3196	VLDB	A Non-Uniform Data Fragmentation Strategy for Parallel Main-Menory Database Systems.	Nick Bassiliades,Ioannis P. Vlahavas	1995	A Non-Uniform Data Fragmentation Strategy for Parallel Main-Menory Database Systems.	VLDB	database
3197	VLDB	Document Management as a Database Problem.	Rudolf Bayer	1995	Document Management as a Database Problem.	VLDB	database
3198	VLDB	Value-cognizant Speculative Concurrency Control.	Azer Bestavros,Spyridon Braoudakis	1995	Value-cognizant Speculative Concurrency Control.	VLDB	database
3199	VLDB	Estimating the Selectivity of Spatial Queries Using the `Correlation' Fractal Dimension.	Alberto Belussi,Christos Faloutsos	1995	Estimating the Selectivity of Spatial Queries Using the `Correlation' Fractal Dimension.	VLDB	database
3200	VLDB	Applying Database Technology in the ADSM Mass Storage System.	Luis-Felipe Cabrera,Robert M. Rees,Wayne Hineman	1995	Applying Database Technology in the ADSM Mass Storage System.	VLDB	database
3201	VLDB	A Data Transformation System for Biological Data Sources.	Peter Buneman,Susan B. Davidson,Kyle Hart,G. Christian Overton,Limsoon Wong	1995	A Data Transformation System for Biological Data Sources.	VLDB	database
3202	VLDB	Near Neighbor Search in Large Metric Spaces.	Sergey Brin	1995	Near Neighbor Search in Large Metric Spaces.	VLDB	database
3203	VLDB	OS Support for VLDBs: Unix Enhancements for the Teradata Data Base.	John Catozzi,Sorana Rabinovici	1995	OS Support for VLDBs: Unix Enhancements for the Teradata Data Base.	VLDB	database
3204	VLDB	BigSur: A System For the Management of Earth Science Data.	Paul Brown,Michael Stonebraker	1995	BigSur: A System For the Management of Earth Science Data.	VLDB	database
3205	VLDB	Declustering Databases on Heterogeneous Disk Systems.	Ling Tony Chen,Doron Rotem,Sridhar Seshadri	1995	Declustering Databases on Heterogeneous Disk Systems.	VLDB	database
3206	VLDB	Retrieval of Composite Multimedia Objects.	Surajit Chaudhuri,Shahram Ghandeharizadeh,Cyrus Shahabi	1995	Retrieval of Composite Multimedia Objects.	VLDB	database
3207	VLDB	Database De-Centralization - A Practical Approach.	Tor Didriksen,César A. Galindo-Legaria,Eirik Dahle	1995	Database De-Centralization - A Practical Approach.	VLDB	database
3208	VLDB	A Performance Evaluation of OID Mapping Techniques.	André Eickler,Carsten Andreas Gerlhof,Donald Kossmann	1995	A Performance Evaluation of OID Mapping Techniques.	VLDB	database
3209	VLDB	The hBP-tree: A Modified hB-tree Supporting Concurrency, Recovery and Node Consolidation.	Georgios Evangelidis,David B. Lomet,Betty Salzberg	1995	The hBP-tree: A Modified hB-tree Supporting Concurrency, Recovery and Node Consolidation.	VLDB	database
3210	VLDB	Managing a DB2 Parallel Edition Database.	Gilles Fecteau	1995	Managing a DB2 Parallel Edition Database.	VLDB	database
3211	VLDB	Schema and Database Evolution in the O2 Object Database System.	Fabrizio Ferrandina,Thorsten Meyer,Roberto Zicari,Guy Ferran,Joëlle Madec	1995	Schema and Database Evolution in the O2 Object Database System.	VLDB	database
3212	VLDB	Processing Object-Oriented Queries with Invertible Late Bound Functions.	Staffan Flodin,Tore Risch	1995	Processing Object-Oriented Queries with Invertible Late Bound Functions.	VLDB	database
3213	VLDB	A Cost Model for Clustered Object-Oriented Databases.	Georges Gardarin,Jean-Robert Gruser,Zhao-Hui Tang	1995	A Cost Model for Clustered Object-Oriented Databases.	VLDB	database
3214	VLDB	Improving Performance in Replicated Databases through Relaxed Coherency.	Rainer Gallersdörfer,Matthias Nicola	1995	Improving Performance in Replicated Databases through Relaxed Coherency.	VLDB	database
3215	VLDB	Index Concurrency Control in Firm Real-Time Database Systems.	Brajesh Goyal,Jayant R. Haritsa,S. Seshadri,V. Srinivasan	1995	Index Concurrency Control in Firm Real-Time Database Systems.	VLDB	database
3216	VLDB	Generalizing GlOSS to Vector-Space Databases and Broker Hierarchies.	Luis Gravano,Hector Garcia-Molina	1995	As large numbers of text databases have become available on the Internet, it is getting harder to locate the right sources for given queries. In this paper we present gGlOSS, a generalized Glossary-Of-Servers Server, that keeps statistics on the available databases to estimate which databases are the potentially most useful for a given query. gGlOSS extends our previous work, which focused on databases using the boolean model of document retrieval, to cover databases using the more sophisticated vector-space retrieval model. We evaluate our new techniques using real-user queries and 53 databases. Finally, we further generalize our approach by showing how to build a hierarchy of gGlOSS brokers. The top level of the hierarchy is so small it could be widely replicated, even at end-user workstations.	VLDB	database
3217	VLDB	Aggregate-Query Processing in Data Warehousing Environments.	Ashish Gupta,Venky Harinarayan,Dallan Quass	1995	Aggregate-Query Processing in Data Warehousing Environments.	VLDB	database
3218	VLDB	Sampling-Based Estimation of the Number of Distinct Values of an Attribute.	Peter J. Haas,Jeffrey F. Naughton,S. Seshadri,Lynne Stokes	1995	Sampling-Based Estimation of the Number of Distinct Values of an Attribute.	VLDB	database
3219	VLDB	OPOSSUM: Desk-Top Schema Management through Customizable Visualization.	Eben M. Haber,Yannis E. Ioannidis,Miron Livny	1995	OPOSSUM: Desk-Top Schema Management through Customizable Visualization.	VLDB	database
3220	VLDB	The Oracle Warehouse.	Gary Hallmark	1995	The Oracle Warehouse.	VLDB	database
3221	VLDB	Discovery of Multiple-Level Association Rules from Large Databases.	Jiawei Han,Yongjian Fu	1995	Discovery of Multiple-Level Association Rules from Large Databases.	VLDB	database
3222	VLDB	Coloring Away Communication in Parallel Query Optimization.	Waqar Hasan,Rajeev Motwani	1995	Coloring Away Communication in Parallel Query Optimization.	VLDB	database
3223	VLDB	Generalized Search Trees for Database Systems.	Joseph M. Hellerstein,Jeffrey F. Naughton,Avi Pfeffer	1995	Generalized Search Trees for Database Systems.	VLDB	database
3224	VLDB	Benchmarking Spatial Join Operations with Spatial Output.	Erik G. Hoel,Hanan Samet	1995	Benchmarking Spatial Join Operations with Spatial Output.	VLDB	database
3225	VLDB	The ClustRa Telecom Database: High Availability, High Throughput, and Real-Time Response.	Svein-Olaf Hvasshovd,Øystein Torbjørnsen,Svein Erik Bratsberg,Per Holager	1995	The ClustRa Telecom Database: High Availability, High Throughput, and Real-Time Response.	VLDB	database
3226	VLDB	Flexible Relations - Operational Support of Variant Relational Structures.	Christian Kalus,Peter Dadam	1995	Flexible Relations - Operational Support of Variant Relational Structures.	VLDB	database
3227	VLDB	W3QS: A Query System for the World-Wide Web.	David Konopnicki,Oded Shmueli	1995	W3QS: A Query System for the World-Wide Web.	VLDB	database
3228	VLDB	High-Concurrency Locking in R-Trees.	Marcel Kornacker,Douglas Banks	1995	High-Concurrency Locking in R-Trees.	VLDB	database
3229	VLDB	The Double Life of the Transaction Abstraction: Fundamental Principle and Evolving System Concept.	Henry F. Korth	1995	The Double Life of the Transaction Abstraction: Fundamental Principle and Evolving System Concept.	VLDB	database
3230	VLDB	Efficient Search of Multi-Dimensional B-Trees.	Harry Leslie,Rohit Jain,Dave Birdsall,Hedieh Yaghmai	1995	Efficient Search of Multi-Dimensional B-Trees.	VLDB	database
3231	VLDB	DB2 Common Server: Technology, Progress, & Directions.	Bruce G. Lindsay	1995	DB2 Common Server: Technology, Progress, & Directions.	VLDB	database
3232	VLDB	Redo Recovery after System Crashes.	David B. Lomet,Mark R. Tuttle	1995	Redo Recovery after System Crashes.	VLDB	database
3233	VLDB	NeuroRule: A Connectionist Approach to Data Mining.	Hongjun Lu,Rudy Setiono,Huan Liu	1995	NeuroRule: A Connectionist Approach to Data Mining.	VLDB	database
3234	VLDB	The Fittest Survives: An Adaptive Approach to Query Optimization.	Hongjun Lu,Kian-Lee Tan,Son Dao	1995	The Fittest Survives: An Adaptive Approach to Query Optimization.	VLDB	database
3235	VLDB	From VLDB to VMLDB (Very MANY Large Data Bases): Dealing with Large-Scale Semantic Heterogenity.	Stuart E. Madnick	1995	From VLDB to VMLDB (Very MANY Large Data Bases): Dealing with Large-Scale Semantic Heterogenity.	VLDB	database
3236	VLDB	Managing Intra-operator Parallelism in Parallel Database Systems.	Manish Mehta,David J. DeWitt	1995	Managing Intra-operator Parallelism in Parallel Database Systems.	VLDB	database
3237	VLDB	Providing Database Migration Tools - A Practicioner's Approach.	Andreas Meier	1995	Providing Database Migration Tools - A Practicioner's Approach.	VLDB	database
3238	VLDB	A Scalable Architecture for Autonomous Heterogeneous Database Interactions.	Steven Milliner,Athman Bouguettaya,Mike P. Papazoglou	1995	A Scalable Architecture for Autonomous Heterogeneous Database Interactions.	VLDB	database
3239	VLDB	Hot Block Clustering for Disk Arrays with Dynamic Striping.	Kazuhiko Mogi,Masaru Kitsuregawa	1995	Hot Block Clustering for Disk Arrays with Dynamic Striping.	VLDB	database
3240	VLDB	L/MRP: A Buffer Management Strategy for Interactive Continuous Data Flows in a Multimedia DBMS.	Frank Moser,Achim Kraiss,Wolfgang Klas	1995	L/MRP: A Buffer Management Strategy for Interactive Continuous Data Flows in a Multimedia DBMS.	VLDB	database
3241	VLDB	Accessing a Relational Database through an Object-Oriented Database Interface.	Jack A. Orenstein,D. N. Kamber	1995	Accessing a Relational Database through an Object-Oriented Database Interface.	VLDB	database
3242	VLDB	Dynamic Multi-Resource Load Balancing in Parallel Database Systems.	Erhard Rahm,Robert Marek	1995	Dynamic Multi-Resource Load Balancing in Parallel Database Systems.	VLDB	database
3243	VLDB	Scientific Journals: Extinction or Explosion? (Panel).	Raghu Ramakrishnan,Hector Garcia-Molina,Gerhard Rossbach,Abraham Silberschatz,Gio Wiederhold,Jaco Zijlstra	1995	Scientific Journals: Extinction or Explosion? (Panel).	VLDB	database
3244	VLDB	Databases and Workflow Management: What is it All About? (Panel).	Andreas Reuter,Stefano Ceri,Jim Gray,Betty Salzberg,Gerhard Weikum	1995	Databases and Workflow Management: What is it All About? (Panel).	VLDB	database
3245	VLDB	Towards a Cooperative Transaction Model - The Cooperative Activity Model.	Marek Rusinkiewicz,Wolfgang Klas,Thomas Tesch,Jürgen Wäsch,Peter Muth	1995	Towards a Cooperative Transaction Model - The Cooperative Activity Model.	VLDB	database
3246	VLDB	Query Processing in Tertiary Memory Databases.	Sunita Sarawagi	1995	Query Processing in Tertiary Memory Databases.	VLDB	database
3247	VLDB	An Efficient Algorithm for Mining Association Rules in Large Databases.	Ashok Savasere,Edward Omiecinski,Shamkant B. Navathe	1995	An Efficient Algorithm for Mining Association Rules in Large Databases.	VLDB	database
3248	VLDB	Metrics for Accessing Heterogeneous Data: Is There Any Hope? (Panel).	Leonard J. Seligman,Nicholas J. Belkin,Erich J. Neuhold,Michael Stonebraker,Gio Wiederhold	1995	Metrics for Accessing Heterogeneous Data: Is There Any Hope? (Panel).	VLDB	database
3249	VLDB	Promises and Realities of Active Database Systems.	Eric Simon,Angelika Kotz Dittrich	1995	Promises and Realities of Active Database Systems.	VLDB	database
3250	VLDB	Similarity based Retrieval of Pictures Using Indices on Spatial Relationships.	A. Prasad Sistla,Clement T. Yu,Chengwen Liu,King-Lup Liu	1995	Similarity based Retrieval of Pictures Using Indices on Spatial Relationships.	VLDB	database
3251	VLDB	Informix-Online XPS: A Dynamically Scalable RDBMS for Open Parallel Platforms.	Hannes Spintzik	1995	Informix-Online XPS: A Dynamically Scalable RDBMS for Open Parallel Platforms.	VLDB	database
3252	VLDB	Mining Generalized Association Rules.	Ramakrishnan Srikant,Rakesh Agrawal	1995	Mining Generalized Association Rules.	VLDB	database
3253	VLDB	Bypassing Joins in Disjunctive Queries.	Michael Steinbrunn,Klaus Peithner,Guido Moerkotte,Alfons Kemper	1995	Bypassing Joins in Disjunctive Queries.	VLDB	database
3254	VLDB	Procedures in Object-Oriented Query Languages.	Kazimierz Subieta,Yahiko Kambayashi,Jacek Leszczylowski	1995	Procedures in Object-Oriented Query Languages.	VLDB	database
3255	VLDB	A Product Specification Database for Visual Prototyping.	Kazutoshi Sumiya,Kouichi Yasutake,Hirohiko Tanaka,Norio Sanada,Yoshihiko Imai	1995	A Product Specification Database for Visual Prototyping.	VLDB	database
3256	VLDB	Type Classification of Semi-Structured Documents.	Markus Tresch,Neal Palmer,Allen Luniewski	1995	Type Classification of Semi-Structured Documents.	VLDB	database
3257	VLDB	Very Large Databases: How Large, How Different?	David Vaskevitch	1995	Very Large Databases: How Large, How Different?	VLDB	database
3258	VLDB	DB2 Query Parallelism: Staging and Implementation.	Yun Wang	1995	DB2 Query Parallelism: Staging and Implementation.	VLDB	database
3259	VLDB	OODB Bulk Loading Revisited: The Partitioned-List Approach.	Janet L. Wiener,Jeffrey F. Naughton	1995	OODB Bulk Loading Revisited: The Partitioned-List Approach.	VLDB	database
3260	VLDB	A Performance Study of Workfile Disk Management for Concurrent Mergesorts in a Multiprocessor Database System.	Kun-Lung Wu,Philip S. Yu,Jen-Yao Chung,James Z. Teng	1995	A Performance Study of Workfile Disk Management for Concurrent Mergesorts in a Multiprocessor Database System.	VLDB	database
3261	VLDB	Duplicate Removal in Information System Dissemination.	Tak W. Yan,Hector Garcia-Molina	1995	Duplicate Removal in Information System Dissemination.	VLDB	database
3262	VLDB	Eager Aggregation and Lazy Aggregation.	Weipeng P. Yan,Per-Åke Larson	1995	Eager Aggregation and Lazy Aggregation.	VLDB	database
3263	SIGMOD Record	Response to A Close Look at the IFO Data Model.	Serge Abiteboul,Richard Hull	1995	Response to A Close Look at the IFO Data Model.	SIGMOD Record	database
3264	SIGMOD Record	ACM Multimedia '94 Conference Workshop on Multimedia Database Management Systems.	P. Bruce Berra,Kingsley C. Nwosu,Bhavani M. Thuraisingham	1995	This paper describes the ACM Multimedia '94 Conference Workshop on Multimedia Database Management Systems held on 21 October 1994 in San Francisco, California. The workshop consisted of four sessions: designing multimedia database management systems, video and continuous media service, multimedia storage and retrieval management, and miscellaneous topics in multimedia data management. The workshop concluded with a discussion session on directions for multimedia database management. Twenty-eight participants from U.S.A., U.K., Germany, Norway, and Egypt attended the workshop.	SIGMOD Record	database
3265	SIGMOD Record	Digital Library Services in Mobile Computing.	Bharat K. Bhargava,Melliyal Annamalai,Evaggelia Pitoura	1995	Digital libraries bring about the integration, management, and communication of gigabytes of multimedia data in a distributed environment. Digital library systems currently envision users as being static when they access information. But it is expected in the near future that tens of millions of users will have access to a digital library through wireless access. Providing digital library services to users whose location is constantly changing, whose network connections are through a wireless medium, and whose computing power is low necessitates modifications to existing digital library systems. In this paper, we identify the issues that arise when users are mobile, classify queries that are specific to mobile users and introduce an architecture that supports flexible and transparent access to digital libraries for mobile users. The main features of the architecture include a layered data representation, support of adaptability, dual broadcast and on demand querying, caching, and mobile-specific user interfaces.	SIGMOD Record	database
3266	SIGMOD Record	Trade Press News.	Rafael Alonso	1995	Trade Press News.	SIGMOD Record	database
3267	SIGMOD Record	Trade Press News.	Rafael Alonso	1995	Trade Press News.	SIGMOD Record	database
3268	SIGMOD Record	Managing Video Data in a Mobile Environment.	Rafael Alonso,Yuh-Lin Chang,Liviu Iftode,V. S. Mani	1995	Two key technological trends of the last few years have been the emergence of handheld computational elements and the implementation of practical wireless communication networks. These two changes have made mobile computer systems feasible. While there has been much research interest devoted to mobile computer issues, such systems have not yet been commercially successful. This has been ascribed to the lack of a killer mobile app. We believe that the support of video on mobile systems will indeed make possible many new interesting applications. However, providing mobile video is a non-trivial task, and much work needs to be done before practical systems are widely available. In this short note we address the issue of mobile multimedia from a practitioner's perspective. We note what software and hardware are currently available in the market in support of mobile multimedia, and point out some of their deficiencies. We also discuss some of the communication and data management research issues that need to be tackled in order to address said deficiencies. Exploring these research issues is the focus of our project.	SIGMOD Record	database
3269	SIGMOD Record	Temporal Database System Implementations.	Michael H. Böhlen	1995	Although research on temporal database systems has been active for about 20 years, implementations have not appeared until recently. This is one reason why current commercial database systems provide only limited temporal functionality. This paper summarizes extant state of the art of temporal database implementations. Rather than being very specific about each system we have attempted to provide an indication of the functionality together with pointers to additional information. It is hoped that this leads to more efforts pushing the implementation of temporal database systems in the near future.	SIGMOD Record	database
3270	SIGMOD Record	An Annotated Bibliography of Benchmarks for Object Databases.	Akmal B. Chaudhri	1995	This annotated bibliography presents a collection of published papers, technical reports, Master's and PhD Theses that have investigated various aspects of object database performance.	SIGMOD Record	database
3271	SIGMOD Record	The Third Manifesto.	Hugh Darwen,C. J. Date	1995	We present a manifesto for the future direction of data and database management systems. The manifesto consists of a series of prescriptions, proscriptions, and very strong suggestions.	SIGMOD Record	database
3272	SIGMOD Record	Design and User Testing of a Multi-Paradigm Query Interface to an Object-Oriented Database.	Dac Khoa Doan,Norman W. Paton,Alistair C. Kilgour	1995	This paper reports on experience obtained during the design, implementation and use of a multi-paradigm query interface to an object-oriented database. The specific system which has been developed allows equivalent data retrieval tasks to be expressed using textual, form-based and graph-based notations, and supports automatic translation of queries between these three paradigms. The motivation behind the development of such an interface is presented, as is the software architecture which supports the multi-paradigm functionality. Feedback from initial user trials with a dual-paradigm version of the system indicates that users can use it to perform complex query tasks without difficulty, that given the choice users overwhelmingly prefer the graph- based to the text-based interaction style, and that graphical visualisation of textual queries appears to aid users in query construction.	SIGMOD Record	database
3273	SIGMOD Record	Implementation Aspects of an Object-Oriented DBMS.	Asuman Dogac,Mehmet Altinel,Cetin Ozkan,Ilker Durusoy	1995	This paper describes the design and implementation of an OODBMS, namely the METU Object-Oriented DBMS (MOOD). MOOD [Dog 94b] is developed on the Exodus Storage Manager (ESM) [ESM 92] and therefore some of the kernel functions like storage management, concurrency control, backup and recovery of data were readily available through ESM. In addition ESM has a client-server architecture and each MOOD process is a client application in ESM. The kernel functions provided by MOOD are the optimization and interpretation of SQL statements, dynamic linking of functions, and catalog management. SQL statements are interpreted whereas functions (which have been previously compiled with C++) within SQL statements are dynamically linked and executed. A query optimizer is implemented by using the Volcano Query Optimizer Generator. A graphical user interface, namely Mood-View [Arp 93a, Arp 93b], is developed using Motif. MoodView displays both the schema information and the query results graphically. Additionally it is possible to update the database schema and to traverse the references in query results graphically.The system is coded in GNU C++ on Sun Sparc 2 workstations. MOOD has a SQL-like object-oriented query language, namely MOODSQL [Ozk 93b, Dog 94c]. MOOD type system is derived from C++, thus eliminating the impedance mismatch between MOOD and C++. The users can also access the MOOD Kernel from their application programs written in C++. For this purpose MOOD Kernel defines a class named UserRequest that contains a method for the execution of MOODSQL statements. The MOOD source code is available both for anonymous ftp users from ftp.cs.wisc.edu and for the WWW users from the site http://www.srdc.metu.edu.tr along with its related documents.In MOOD, each object is given a unique Object Identifier (OID) at object creation time by the ESM which is the disk start address of the object returned by the ESM. Object encapsulation is considered in two parts, method encapsulation and attribute encapsulation. These encapsulation properties are similar to the public and private declarations of C++.Methods can be defined in C++ by users to manipulate user defined classes and after compilation, they are dynamically linked and executed during the interpretation of SQL statements. This late binding facility is essential since database environments enforce run-time modification of schema and objects. With our approach, the interpretation of functions are avoided thus increasing the efficiency of the system. Dynamic linking primitives are implemented by the use of the shared object facility of SunOS [Sun 90]. Overloading is realized by making use of the signature concept of C++.	SIGMOD Record	database
3274	SIGMOD Record	METU Interoperable Database System.	Asuman Dogac,Cevdet Dengi,Ebru Kilic,Gökhan Özhan,Fatma Ozcan,Sena Nural,Cem Evrendilek,Ugur Halici,Ismailcem Budak Arpinar,Pinar Koksal,N. Kesim,Sema Mancuhan	1995	METU INteroperable Database System (MIND) is a multidatabase system that aims at achieving interoperability among heterogeneous, federated DBMSs. MIND architecture if based on OMG distributed object management model. It is implemented on top of a CORBA compliant ORB, namely, ObjectBroker. MIND provides users a single ODMG-93 compliant common data model, and a single global query language based on SQL. This makes it possible to incorporate both relational and object oriented databases into the system. Currently Oracle 7, Sybase and METU OODBMS (MOOD) have been incorporated into MIND. The main components of MIND are a global query processor, a global transaction manager, a schema integrator, interfaces to supported database systems and a user graphical interface.In MIND all local databases are encapsulated in a generic database object with a well defined single interface. This approach hides the differences between local databases from the rest of the system. The integration of export schemas is currently performed manually by using an object definition language (ODL) which is based on OMG's interface definition language. The DBA builds the integrated schema as a view over export schemas. the functionalities of ODL allow selection and restructuring of schema elements from existing local schemas.MIND global query optimizer aims at maximizing the parallel execution of the intersite joins of the global subqueries. Through MIND global transaction manager, the serializable execution of the global transactions are provided.	SIGMOD Record	database
3275	SIGMOD Record	Data and Knowledge Base Research at Hong Kong University of Science and Technology.	Pamela Drew,Babak Hamidzadeh,Kamalakar Karlapalem,Alex Chia-Yee Kean,Dik Lun Lee,Qing Li,Frederick H. Lochovsky,Chung-Dak Shum,Beat Wüthrich	1995	The National Technical University of Athens (NTUA) is the leading Technical University in Greece. The Computer Science Division of the Electrical and Computer Engineering Department covers several fields of practical, theoretical and technical computer science and is involved in several research projects supported by the EEC, the government and industrial companies. The Knowledge and Data Base Systems (KDBS) Laboratory was established in 1992 at the National Technical University of Athens. It is recognised internationally, evidenced by its participation as a central node in the Esprit Network of Excellence IDOMENEUS. The Information and Data on Open MEdia for NEtworks of USers, project aims to coordinate and improve European efforts in the development of next-generation information environments which will be capable of maintaining and communicating a largely extended class of information in an open set of media. The KDBS Laboratory employs one full-time research engineer and several graduate students. Its infrastructure includes a LAN with several DECstation 5000/200 and 5000/240 workstations, an HP Multimedia Workstation, several PCs and software for database and multimedia applications. The basic research interests of our Laboratory include: Spatial Database Systems, Multimedia Database Systems and Active Database Systems. Apart from the above database areas, interests of the KDBS Laboratory span several areas of Information Systems, such as Software Engineering Databases, Transactional Systems, Image Databases, Conceptual Modeling, Information System Development, Temporal Databases, Advanced Query Processing and Optimization Techniques. The group's efforts on Spatial Database Systems, include the study of new data structures, storage techniques, retrieval mechanisms and user interfaces for large geographic data bases. In particular, we look at specialized, spatial data structures (R-Trees and their variations) which allow for the direct access of the data based on their spatial properties, and not some sort of encoded representation of the objects' coordinates. We study implementation and optimization techniques of spatial data structures and develop models that make performance estimation. Finally, we are investigating techniques for the efficient representation of relationships and reasoning in space. The activities on Multimedia Database Systems, include the study of advanced data models, storage techniques, retrieval mechanisms and user interfaces for large multimedia data bases. The data models under study include the object-oriented model and the relational model with appropriate extensions to support multimedia data. We are also investigating content-based search techniques for image data bases. In a different direction, we are studying issues involved in the development of multimedia front-ends for conventional, relational data base systems. In the area of Active Database Systems, we are developing new mechanisms for implementing triggers in relational databases. Among the issues involved, we address the problem of efficiently finding qualifying rules against updates in large sets of triggers. This problem is especially critical in database system implementations of triggers, where large amounts of data may have to be searched in order to find out if a particular trigger may qualify to run or not. Continuing work that started at the Foundation for Research and Technology (FORTH), Institute of Computer Science, the group is investigating reuse-oriented approaches to information systems application development. The approaches are based on a repository that has been implemented at FORTH as a special purpose object store, with emphasis on multimodal and fast retrieval. Issues of relating and describing software artifacts (designs, code, etc.) are among the topics under investigation. A new important research direction of the group is on Data Warehouses, which are seen as collections of materialized views captured over a period of time from a heterogeneous distributed information system. Issues such as consistent updates, data warehouse evolution, view reconciliation and data quality are being investigated. Research in Image Databases deals with the retrieval by image content, that uses techniques from the area of Image Processing. We are currently at early stage in this direction, having collected many segmentation and edge detection algorithms, which will be used and evaluated in images of various contents. Our work on Advanced Query Processing and Optimization Techniques includes dynamic or parametric query optimization techniques. In most database systems, the values of many important runtime parameters of the system, the data, or the query are unknown at query optimization time. Dynamic, or parametric, query optimization attempts to identify several execution plans, each one of which is optimal for a subset of all possible values of the run time parameters. In the next sections we present in detail our research efforts on the three main research areas of the KDBS Laboratory: Spatial, Multimedia and Active Databases.	SIGMOD Record	database
3276	SIGMOD Record	From the Guest Editors - Special Section on Data Management Issues in Mobile Computing.	Margaret H. Dunham,Abdelsalam Helal	1995	From the Guest Editors - Special Section on Data Management Issues in Mobile Computing.	SIGMOD Record	database
3277	SIGMOD Record	Mobile Computing and Databases: Anything New?	Margaret H. Dunham,Abdelsalam Helal	1995	Mobile Computing and Databases: Anything New?	SIGMOD Record	database
3278	SIGMOD Record	The New Middleware.	Rich Finkelstein	1995	USING MIDDLEWARE, CUSTOMERS CAN DEPLOY COST-EFFECTIVE AND HIGHLY FUNCTIONAL CLIENT/SERVER APPLICATIONS &mdash; ONCE THEY WORK OUT THE KINKS.	SIGMOD Record	database
3279	SIGMOD Record	Mapping Extended Entity Relationship Model to Object Modeling Technique.	Joseph Fong	1995	A methodology of reengineering existing extended Entity-Relationship(EER) model to Object Modeling Technique(OMT) model is described. A set of translation rules from EER model to a generic Object-Oriented(OO) model of OMT methodology is devised. Such reengineering practices not only can provide us with significant insight to the interoperability between the OO and the traditional semantic modelling techniques, but also can lead us to the development of a practical design methodology for object-oriented databases(OODB).	SIGMOD Record	database
3280	SIGMOD Record	Wireless Client/Server Computing for Personal Information Services and Applications.	Ahmed K. Elmagarmid,Jin Jing,Tetsuya Furukawa	1995	We are witnessing a profound change in the global information infrastructure that has the potential to fundamentally impact many facets of our life. An important aspect of the evolving infrastructure is the seamless, ubiquitous wireless connectivity which engenders continuous interactions between people and interconnected computers. A challenging area of future ubiquitous wireless computing is the area of providing mobile users with integrated Personal Information Services and Applications (PISA). In this paper, a wireless client/server computing architecture will be discussed for the delivery of PISA. Data management issues such as transactional services and cache consistency will be examined under this architecture.	SIGMOD Record	database
3281	SIGMOD Record	Parallelism and its Price: A Case Study of NonStop SQL/MP.	Susanne Englert,Ray Glasstone,Waqar Hasan	1995	We describe the use of parallel execution techniques and measure the price of parallel execution in NonStop SQL/MP, a commercial parallel database system from Tandem Computers. Non-Stop SQL uses intra-operator parallelism to parallelize joins, groupings and scans. Parallel execution consists of starting up several processes and communicating data between them. Our measurements show (a) Startup costs are negligible when processes are reused rather than created afresh (b) Communication costs are significant &mdash; they may exceed the costs of operators such as scan, grouping or join. We also show two counter-examples to the common intuition that parallel execution reduces response time at the expense of increased work &mdash; parallel execution may reduce work or may increase response time depending on communication costs.	SIGMOD Record	database
3282	SIGMOD Record	Addressing Techniques Used in Database Object Managers O2 and Orion.	André Gamache,Nadjiba Sahraoui	1995	Addressing mechanisms used by the new generation of Data Base Management Systems (DBMS) differ significantly from traditional ones. Such changes are the direct result of new applications requirements such as office information systems (OIS) and computer aided design (CAD). In this context, object format requires different representations on disk and in main memory, and this is often valid for interobject references. It is evident that these mechanisms are closely linked to the mode of object-identity implementation, as well as clustering strategies. All of these functions are controlled by the object manager.This article describes these mechanisms through the implementation of two object managers for object-oriented DBMS: O2 and ORION. We show how the performance of these systems depends on their memory management and addressing scheme. The two managers to be discussed merges techniques proposed by both data base field and object-oriented programming field. Their own mechanism differs, according to the way it handles distribution. ORION-1SX and O2 have a Client/Server architecture, but each one uses a different approach for distributing of functionalities. ORION-1SX implements an object-server, whereas O2 uses a page-server approach. An analysis of the two systems shows that they both use a two-level addressing mechanism. buffer management for objects in memory is diffent and more complex in ORION. On the other hand, the clustering strategies in O2 have the advantage of being more dynamic and can be specified outside the schema.	SIGMOD Record	database
3283	SIGMOD Record	An Annotated Bibliography on Active Databases.	Ulrike Jaeger,Johann Christoph Freytag	1995	An Annotated Bibliography on Active Databases.	SIGMOD Record	database
3284	SIGMOD Record	Implementing Deletion in B+-Trees.	Jan Jannink	1995	This paper describes algorithms for key deletion in B+-trees. There are published algorithms and pseudocode for searching and inserting keys, but deletion, due to its greater complexity and perceived lesser importance, is glossed over completely or left as an exercise to the reader. To remedy this situation, we provide a well documented flowchart, algorithm, and pseudo-code for deletion, their relation to search and insertion algorithms, and a reference to a freely available, complete B+-tree library written in the C programming language.	SIGMOD Record	database
3285	SIGMOD Record	Information Systems Research at RWTH Aachen.	Matthias Jarke	1995	With about 8.000 researchers and 40.000 students, RWTH Aachen is the largest technical university in Europe. The science and engineering departments and their industrial collaborators offer a lot of challenges for database research.The chair Informatik V (Information Systems) focuses on the theoretical analysis, prototypical development, and practical evaluation of meta information systems. Meta information systems, also called repositories, document and coordinate the distributed processes of producing, integrating, operating, and evolving database-intensive applications.Our research approaches these problems from a technological and from an application perspective.On the one hand, we pursue theory and system aspects of the integration of deductive and object-oriented technologies. One outcome of this work is a deductive object manager called ConceptBase which has been developed over the past eight years and is currently used by many research groups and industrial teams throughout the world.On the other hand, a wide range of application-driven projects aims at building a sound basis of empirical knowledge about the demands on meta information systems, and about the quality of proposed solutions. They address application domains as diverse as requirements engineering, telecommunications, cooperative engineering, organization-wide quality management, evolution of chemical production processes, and medical knowledge management. They share the vision of supporting wide-area distributed cooperation not just by low-level interoperation technology but by exploiting conceptual product and process modeling.Under the direction of M. Jarke, Informatik V comprises three research groups with a total of twenty senior researchers and doctoral students: distributed information systems (leader: Dr. Manfred Jeusfeld), process information systems (Dr. Klaus Pohl), and knowledge-based systems (Prof. Wolfgang Nejdl). Database-related activities also exist in the Software Engineering and Applied Mathematics groups.	SIGMOD Record	database
3286	SIGMOD Record	A Close Look at the IFO Data Model.	Magdy S. Hanna	1995	The IFO data model was proposed by Abiteboul and Hull [Abiteboul 87] as a formalized semantic database model. It has been claimed by the authors that the model subsumes the Relational model [Codd 70], the Entity-Relationship model [Chen 76], the Functional Data Model [Kerschberg 76] and virtually all of the structured aspects of the Semantic Data Model [Hammer 81], the INSYDE Model [King 85], and the Extended Semantic Hierarchy Model [Brodie 84].This paper examines the IFO data model as presented in [Abiteboul 87], compares it to other models, and thus concludes that the IFO data model is actually a subset of the Semantic Data Model proposed by Hammer in [Hammer 81]. The paper also shows that the IFO data model has failed to support concepts that are essential to both the E-R model and the Semantic Data Model which are claimed to be subsumed by the IFO model.Section 2 discusses the three IFO constructs, objects, fragments, and relationships. The mapping of these constructs to constructs in the Semantic Data Model is established as an informal proof of the result that the IFO model is subsumed by the SDM.Section 3 lists constructs supported by the Entity-Relationship model [Chen 76, Teorey 86] as will as constructs supported by SDM [Hammer 81]that the IFO data model fails to support.	SIGMOD Record	database
3287	SIGMOD Record	HODFA: An Architectural Framework for Homogenizing Heterogeneous Legacy Database.	Kamalakar Karlapalem,Qing Li,Chung-Dak Shum	1995	One of the main difficulties in supporting global applications over a number of localized databases and migrating legacy information systems to modern computing environment is to cope with the heterogeneities of these systems. In this paper, we present a novel flexible architecture (called HODFA) to dynamically connect such localized heterogeneous databases in forming a homogenized federated database system and to support the process of transforming a collection of heterogeneous information systems onto a homogeneous environment. We further develop an incremental methodology of homogenization in the context of our HODFA framework, which can facilitate different degrees of homogenization in a stepwise manner, so that existing applications will not be affected during the process of homogenization.	SIGMOD Record	database
3288	SIGMOD Record	Multigranularity Locking in Multiple Job Classes Transaction Processing System.	Shan-hoi Ng,Sheung-lun Hung	1995	The conditions of when to apply fine and coarse granularity to different kinds of transaction are well understood. However, it is not very clear how multiple job classes using different lock granularities affect each other. This study aims at exploring the impact of multigranularity locking on the performance of multiple job classes transaction processing system which is common in multiuser database system. There are two key findings in the study. Firstly, lock granularity adopted by identical job classes should not differ from each other by a factor of more than 20; otherwise, serious data contention may result. Secondly, short job class transactions are generally benefited when its level of granularity is similar to that of the long job class since this will reduce the additional lock overhead and data contention which are induced by multigranularity locking.	SIGMOD Record	database
3289	SIGMOD Record	Why Decision Support Fails and How To Fix It.	Ralph Kimball,Kevin Strehlo	1995	Why Decision Support Fails and How To Fix It.	SIGMOD Record	database
3290	SIGMOD Record	On the Issue of Valid Time(s) in Temporal Databases.	Stavros Kokkotos,Efstathios V. Ioannidis,Themis Panayiotopoulos,Constantine D. Spyropoulos	1995	Recent research activities in the area of Temporal Databases have revealed some problems related to the definition of time. In this paper we discuss the problem arising from the definition of valid time and the assumptions about valid time, which exist in current Temporal Database approaches. For this problem we propose a solution, while we identify some consistency problems that may appear in Temporal Databases, and which require further investigation.	SIGMOD Record	database
3291	SIGMOD Record	Normalization in OODB Design.	Byung Suk Lee	1995	When we design an object-oriented database schema, we need to normalize object classes as we do for relations when designing a relational database schema. However, the normalization process for an object class cannot be the same as that of a relation, because of the distinct characteristics of an object-oriented data model such as complex attributes, collection data types, and the usage of object identifiers in place of relational key attributes. We need only one kind of dependency proposed here -- the object functional dependency -- which specifies the dependency of object attributes with respect to the object identifier. We also propose the object normal form of an object class, for which all determinants of object functional dependencies are object identifiers. There is no risk of update anomalies as long as all object classes are in the object normal form.	SIGMOD Record	database
3292	SIGMOD Record	An Aspect of Query Optimization in Multidatabase Systems (Extended Abstract).	Chiang Lee,Chia-Jung Chen,Hongjun Lu	1995	An Aspect of Query Optimization in Multidatabase Systems (Extended Abstract).	SIGMOD Record	database
3293	SIGMOD Record	Optimizing Jan Jannink's Implementation of B+-tree Deletion	R. Maelbrancke,H. Olivie	1995	In this note we propose optimization strategies for the B+-tree deletion algorithm. The optimizations are focused on even order B+-trees and on the reduction of the number of block accesses.	SIGMOD Record	database
3294	SIGMOD Record	A Comparison of Three User Interfaces to Relational Microcomputer Data Bases.	Carl Medsker,Margaret Christensen,Il-Yeol Song	1995	PAYOFF IDEA. Different styles of user interfaces can dramatically affect data base capabilities. In an environment comprising many different data bases, the goal is to select one data base management system (DBMS) that provides the best selection of design tools, minimizes development times, and enforces relational rules. This article presents a case study performed at the Hospital of the University of Pennsylvania, in which a test data base was developed for implementation with three DBMSs, each with a distinctly different user and programmer interface.	SIGMOD Record	database
3295	SIGMOD Record	A Research Status Report on Adaptation for Mobile Data Access.	Brian Noble,Mahadev Satyanarayanan	1995	Mobility demands the systems be adaptive. One approach is to make adaptation transparent to applications, allowing them to remain unchanged. An alternative approach views adaptation as a collaborative partnership between applications and the system. This paper is a status report on our research on both fronts. We report on our considerable experience with application-transparent adaptation in the Coda File System. We also describe our ongoing work on application-aware adaptation in Odyssey.2e	SIGMOD Record	database
3296	SIGMOD Record	Multi-Table Joins Through Bitmapped Join Indices.	Patrick E. O'Neil,Goetz Graefe	1995	This technical note shows how to combine some well-known techniques to create a method that will efficiently execute common multi-table joins. We concentrate on a commonly occurring type of join known as a star-join, although the method presented will generalize to any type of multi-table join. A star-join consists of a central detail table with large cardinality, such as an orders table (where an order row contains a single purchase) with foreign keys that join to descriptive tables, such as customers, products, and (sales) agents. The method presented in this note uses join indices with compressed bitmap representations, which allow predicates restricting columns of descriptive tables to determine an answer set (or foundset) in the central detail table; the method uses different predicates on different descriptive tables in combination to restrict the detail table through compressed bitmap representations of join indices, and easily completes the join of the fully restricted detail table rows back to the descriptive tables. We outline realistic examples where the combination of these techniques yields substantial performance improvements over alternative, more traditional query evaluation plans.	SIGMOD Record	database
3297	SIGMOD Record	A Framework for Providing Consistent and Recoverable Agent-Based Access to Heterogeneous in Mobile Databases.	Evaggelia Pitoura,Bharat K. Bhargava	1995	A Framework for Providing Consistent and Recoverable Agent-Based Access to Heterogeneous in Mobile Databases.	SIGMOD Record	database
3298	SIGMOD Record	Political Winds Change Direction Again.	Xiaolei Qian	1995	Political Winds Change Direction Again.	SIGMOD Record	database
3299	SIGMOD Record	Turmoil at NASA, and Numerous Funding Announcements.	Xiaolei Qian	1995	Since the last issue of this column six months ago, there have been many interesting program announcements, some of which have already passed deadline. We'll go over these announcements anyway, with the hope that they can get the readers better prepared for future funding opportunities. But first, we'll talk about the continuing budget battle at Congress, and the recent turmoil at NASA.	SIGMOD Record	database
3300	SIGMOD Record	Opportunities at ARPA, NSF, and Elsewhere	Xiaolei Qian	1995	We first report the relatively minor development on the federal budget. We then touch upon announcements from ARPA, NSF, Defense Nuclear Agency, Rome Laboratory, US Special Operations Command, and Office of National Drug Control Policy. We also report a recent ARPA reorganization.	SIGMOD Record	database
3301	SIGMOD Record	Condition Handling in SQL Persistent Stored Modules.	Jeff Richey	1995	The national and international standards committees responsible for Database Language SQL have proposed a candidate extension for SQL Persistent Stored Modules (SQL/PSM). The purpose of this extension is to provide a computationally complete language for the declaration and invocation of SQL stored modules and routines. Typically, such routines are stored in a database Server and executed from an application Client in a Client/Server environment.The proposed SQL/PSM consists of syntax and semantics for variable and cursor declarations, function and procedure (routines) invocations, condition handling, and control statements for looping and branching. An SQL routine is block structured, with each block consisting of local variable and condition handler declarations, a list of SQL statements, and local condition handler execution.Condition handling is a major new feature of SQL/PSM (henceforth referred to as PSM), although the style and comprehensiveness of the specification is still an issue in further progression of the standard. The specification currently under ballot includes conditions for exceptions, warnings, and other completions such as success of no data, and handlers for Continue, Exit, Redo, and Undo.Condition handling allows the user to separate condition handling code from the main flow of a routine, thereby eliminating the need to write numerous short and redundant code fragments to handle each unique condition. In some database products, one cannot even resolve the condition in the Server and must instead resort to the Client application program for resolution. Such approaches are often tedious, error-prone, and inflexible. Condition handling in the SQL module avoids these expensive alternatives, instead allowing the procedure to resolve its own conditions and then resume processing.Condition handling allows one to centralize the handling of conditions and gives users control over two major areas: run-time recovery from failures, and effects of conditions on transactions.Run-time recovery from failures has the following characteristics:&bull; allows a user to handle any run-time condition, either by exiting gracefully or by attempting recovery&bull; provides a recovery mechanism that includes the ability to resolve a condition and then resume action at the statement that caused the condition to be raised (if it was resolved)&bull; provides the ability to define what code will handle each conditionAfter a condition has been resolved, what is the state of the transaction? Condition handling must ensure that the SQL-data, schemas, and SQL-variables are all maintained in an appropriate stable state and can be committed or rolled back. Additionally, the transaction must comply with the ACID test rules.Thus, the benefits of condition handling include:&bull; allows reduction of error recovery code&bull; creates a model for trapping and resolving conditions&bull; provides the ability to resolve the condition and if possible to continue on&bull; avoids the cost of requiring the SQL-client to resolve the condition&bull; provides for greater data and path consistency in handling conditions&bull; separates one condition from another	SIGMOD Record	database
3302	SIGMOD Record	Florida International University High Performance Database Research Center.	Naphtali Rishe,Wei Sun,David Barton,Yi Deng,Cyril U. Orji,Michael Alexopoulos,Leonard Loureiro,Carlos Ordonez,Mario Sanchez,Artyom Shaposhnikov	1995	Florida International University High Performance Database Research Center.	SIGMOD Record	database
3303	SIGMOD Record	Data Management Research at The MITRE Corporation.	Arnon Rosenthal,Leonard J. Seligman,Catherine D. McCollum,Barbara T. Blaustein,Bhavani M. Thuraisingham,Edward Lafferty	1995	The MITRE Corporation provides technical assistance, system engineering, and acquisition support to large organizations, especially U.S. Government agencies. We help our customers to plan complex systems based on emerging technologies, and to implement systems based on commercial-off-the-shelf products. In MITRE's research program, instead of emphasizing concerns of DBMS or CASE vendors, our research emphasizes the issues of organizations who need to use such products. For example, we favor areas where we can build over commercial products, rather than changing their internals.Data management at MITRE goes beyond research, to include technology transition, system engineering, product evaluation, prototypes, tutorials, advice on customers' strategic directions, and participation in standards efforts. We use prototyping to illustrate potential improvements in customer systems, to understand vendors' capabilities, or both. There are close connections with efforts in object management, real-time systems, reengineering, artificial intelligence, and security.This paper emphasizes the research efforts, grouped into five major themes: information integration, security and privacy, active and responsive systems, metrics, and digital libraries. For each theme, we list the major questions being explored, and identify projects and contacts for further information.	SIGMOD Record	database
3304	SIGMOD Record	The Database Group at University of Hagen (FernUniversitaet).	Gunter Schlageter,Thomas Berkel,Eberhard Heuel,Silke Mittrach,Andreas Scherer,Wolfgang Wilkes	1995	The Database Group at University of Hagen (FernUniversitaet).	SIGMOD Record	database
3305	SIGMOD Record	Editor's (Farewell) Notes.	Arie Segev	1995	Editor's (Farewell) Notes.	SIGMOD Record	database
3306	SIGMOD Record	Report on The 1995 International Workshop on Temporal Databases.	Arie Segev,Christian S. Jensen,Richard T. Snodgrass	1995	This paper provides an overview of the 1995 International Workshop on Temporal Databases. It summarizes the technical papers and related discussions, and three panels: &ldquo;Wither TSQL3?&rdquo;, &ldquo;Temporal Data Management in Financial Applications,&rdquo; and &ldquo;Temporal Data Management Infrastructure & Beyond.&rdquo;	SIGMOD Record	database
3307	SIGMOD Record	The Database Group at National Technical University of Athens (NTUA).	Timos K. Sellis,Yannis Vassiliou	1995	The Database Group at National Technical University of Athens (NTUA).	SIGMOD Record	database
3308	SIGMOD Record	Replication: DB2, Oracle, or Sybase?	Doug Stacey	1995	Is replication salvation or the devil in disguise? Here's what three implementations tell us	SIGMOD Record	database
3309	SIGMOD Record	An Annotated Bibliography on Real-Time Database Systems.	Özgür Ulusoy	1995	An Annotated Bibliography on Real-Time Database Systems.	SIGMOD Record	database
3310	SIGMOD Record	SQL/CLI - A New Binding Style for SQL.	Murali Venkatrao,Michael Pizzo	1995	SQL/CLI - A New Binding Style for SQL.	SIGMOD Record	database
3311	SIGMOD Record	Editor's Notes.	Jennifer Widom	1995	Editor's Notes.	SIGMOD Record	database
3312	SIGMOD Record	Editor's Notes.	Jennifer Widom	1995	Editor's Notes.	SIGMOD Record	database
3313	SIGMOD Record	View Maintenance in Mobile Computing.	Ouri Wolfson,A. Prasad Sistla,Son Dao,Kailash Narayanan,Ramya Raj	1995	View Maintenance in Mobile Computing.	SIGMOD Record	database
3314	SIGMOD Record	An Introduction to Remy's Fast Polymorphic Record Projection.	Limsoon Wong	1995	Traditionally, a record projection is compiled when all fields of the record are known in advance. The need to know all fields in advance leads to very clumsy programs, especially for querying external data sources. In a paper that had not been widely circulated in the database community, Remy presented in programming language context a constant-time implementation of the record projection operation that does not have such a requirement. This paper introduces his technique and suggests an improvement to his technique in the context of database queries.	SIGMOD Record	database
3315	SIGMOD Record	Calls for Papers and Announcements.		1995	Calls for Papers and Announcements.	SIGMOD Record	database
3316	SIGMOD Record	Calls for Papers and Announcements.		1995	Calls for Papers and Announcements.	SIGMOD Record	database
3317	SIGMOD Record	Information Finding in a Digital Library: The Stanford Perspective.	Tak W. Yan,Hector Garcia-Molina	1995	In a digital library one of the most challenging problems is finding relevant information. Information finding is the research focus of the Stanford component of the ARPA-sponsored CS-TR Project, and the work has continued as one of the main thrusts in the Stanford Integrated Digital Library project [14]. In this paper we discuss some of the emerging issues in information finding, such as text-database discovery, efficient information dissemination, and copy detection and removal. We also outline our approaches to these issues.	SIGMOD Record	database
3318	SIGMOD Record	Application of OODB and SGML Techniques in Text Database: An Electronic Dictionary System.	Jian Zhang	1995	An electronic dictionary system (EDS) is developed with object-oriented database techniques based on ObjectStore. The EDS is composed of two parts: the Database Building Program (DBP), and the Database Querying Program (DQP). DBP reads in a dictionary encoded in SGML tags, and builds a database composed of a collection of trees which holds dictionary entries, and several lists which contain items of various lexical categories. With text exchangeability introduced by the SGML, DBP is able to accommodate dictionaries of different languages with different structures, after easy modification of a configuration file. The tree model, the Category Lists, and an optimization procedure enables DQP to quickly accomplish complicated queries, including context requirements, via simple SQL-like syntax and straightforward search methods. Results show that compared with relational database, DQP enjoys much higher speed and flexibility. With EDS this paper demonstrates how to apply OODBMS's to systems that handle text information with strong yet varied intrinsic hierarchies.	SIGMOD Record	database
3319	Artificial Intelligence in Medicine	Neural network assisted cardiac auscultation.	I. Cathers	1995	Neural network assisted cardiac auscultation.	Artificial Inte	medical
3320	Artificial Intelligence in Medicine	Development and retrospective evaluation of Hepaxpert-I: a routinely-used expert system for interpretive analysis of hepatitis A and B serologic findings.	Klaus-Peter Adlassnig,Wolfgang Horak	1995	Development and retrospective evaluation of Hepaxpert-I: a routinely-used expert system for interpretive analysis of hepatitis A and B serologic findings.	Artificial Inte	medical
3321	Artificial Intelligence in Medicine	The NST-EXPERT project: the need to evolve.	Amparo Alonso-Betanzos,Bertha Guijarro-Berdiñas,Vicente Moret-Bonillo,S. Lopez-Gonzalez	1995	The NST-EXPERT project: the need to evolve.	Artificial Inte	medical
3322	Artificial Intelligence in Medicine	Adaptive controllers for intelligent monitoring.	Riccardo Bellazzi,C. Siviero,Mario Stefanelli,Giuseppe De Nicolao	1995	Adaptive controllers for intelligent monitoring.	Artificial Inte	medical
3323	Artificial Intelligence in Medicine	An intelligent interactive system for delivering individualized information to patients.	Bruce G. Buchanan,Johanna D. Moore,D. E. Forsythe,Giuseppe Carenini,S. Ohlsson,Gordon Banks	1995	An intelligent interactive system for delivering individualized information to patients.	Artificial Inte	medical
3324	Artificial Intelligence in Medicine	Objects, contradictions and collaboration in medical cognition: an activity-theoretical perspective.	Yrjö Engeström	1995	Objects, contradictions and collaboration in medical cognition: an activity-theoretical perspective.	Artificial Inte	medical
3325	Artificial Intelligence in Medicine	Clinical monitoring using regression-based trend templates.	Ira J. Haimowitz,P. P. Le,Isaac S. Kohane	1995	Clinical monitoring using regression-based trend templates.	Artificial Inte	medical
3326	Artificial Intelligence in Medicine	Objectification and negotiation in interpreting clinical images: implications for computer-based patient records.	B. Kaplan	1995	Objectification and negotiation in interpreting clinical images: implications for computer-based patient records.	Artificial Inte	medical
3327	Artificial Intelligence in Medicine	Editorial.	Isaac S. Kohane	1995	Editorial.	Artificial Inte	medical
3328	Artificial Intelligence in Medicine	A case study in ontology library construction.	Gertjan van Heijst,Sabina Falasconi,Ameen Abu-Hanna,Guus Schreiber,Mario Stefanelli	1995	A case study in ontology library construction.	Artificial Inte	medical
3329	Artificial Intelligence in Medicine	Architectures for intelligent systems based on reusable components.	Mark A. Musen,Guus Schreiber	1995	Architectures for intelligent systems based on reusable components.	Artificial Inte	medical
3330	Artificial Intelligence in Medicine	Steering through the murky waters of a scientific conflict: situated and symbolic models of clinical cognition.	Vimla L. Patel,David R. Kaufman,José F. Arocha	1995	Steering through the murky waters of a scientific conflict: situated and symbolic models of clinical cognition.	Artificial Inte	medical
3331	Artificial Intelligence in Medicine	Causal inference from indirect experiments.	Judea Pearl	1995	Causal inference from indirect experiments.	Artificial Inte	medical
3332	Artificial Intelligence in Medicine	Neural network classification of infrared spectra of control and Alzheimer's diseased tissue.	Nicolino J. Pizzi,L. P. Choo,James R. Mansfield,Michael Jackson,W. C. Halliday,Henry H. Mantsch,Ray L. Somorjai	1995	Neural network classification of infrared spectra of control and Alzheimer's diseased tissue.	Artificial Inte	medical
3333	Artificial Intelligence in Medicine	An ignorant belief network to forecast glucose concentration from clinical databases.	Marco Ramoni,Alberto Riva,Mario Stefanelli,Vimla L. Patel	1995	An ignorant belief network to forecast glucose concentration from clinical databases.	Artificial Inte	medical
3334	Artificial Intelligence in Medicine	VIA-RAD: a blackboard-based system for diagnostic radiology. Visual Interaction Assistant for Radiology.	E. Rogers	1995	VIA-RAD: a blackboard-based system for diagnostic radiology. Visual Interaction Assistant for Radiology.	Artificial Inte	medical
3335	Artificial Intelligence in Medicine	Use of data abstraction methods to simplify monitoring.	Thomas A. Russ	1995	Use of data abstraction methods to simplify monitoring.	Artificial Inte	medical
3336	Artificial Intelligence in Medicine	Control theory as a conceptual framework for intensive care monitoring.	Brigitte Séroussi,V. Morice,F. Dreyfus,Jean-François Boisvieux	1995	Control theory as a conceptual framework for intensive care monitoring.	Artificial Inte	medical
3337	Artificial Intelligence in Medicine	Evaluation of a knowledge-based decision-support system for ventilator therapy management.	Nosrat Shahsavar,U. Ludwigs,H. Blomqvist,Hans Gill,O. Wigertz,G. Matell	1995	Evaluation of a knowledge-based decision-support system for ventilator therapy management.	Artificial Inte	medical
3338	Artificial Intelligence in Medicine	Model-based diagnosis of brain disorders: a prototype framework.	Pridi Siregar,P. Toulouse	1995	Model-based diagnosis of brain disorders: a prototype framework.	Artificial Inte	medical
3339	Artificial Intelligence in Medicine	One framework, two systems: flexible abductive methods in the problem-space paradigm applied to antibody identification and biopsy interpretation.	Jack W. Smith,A. Bayazitoglu,Todd R. Johnson,Kathy A. Johnson,N. K. Amra	1995	One framework, two systems: flexible abductive methods in the problem-space paradigm applied to antibody identification and biopsy interpretation.	Artificial Inte	medical
3340	Artificial Intelligence in Medicine	A theoretical approach to artificial intelligence systems in medicine.	B. Spyropoulos,G. Papagounos	1995	A theoretical approach to artificial intelligence systems in medicine.	Artificial Inte	medical
3341	Artificial Intelligence in Medicine	NEUREX: a tutorial expert system for the diagnosis of neurogenic diseases of the lower limbs.	Antonina Starita,Darya Majidi,A. Giordano,M. Battaglia,R. Cioni	1995	NEUREX: a tutorial expert system for the diagnosis of neurogenic diseases of the lower limbs.	Artificial Inte	medical
3342	Artificial Intelligence in Medicine	Situated clinical cognition.	Toomas Timpka	1995	Situated clinical cognition.	Artificial Inte	medical
3343	Artificial Intelligence in Medicine	Ontology-based configuration of problem-solving methods and generation of knowledge-acquisition tools: application of PROTEGE-II to protocol-based decision support.	Samson W. Tu,Henrik Eriksson,John H. Gennari,Yuval Shahar,Mark A. Musen	1995	Ontology-based configuration of problem-solving methods and generation of knowledge-acquisition tools: application of PROTEGE-II to protocol-based decision support.	Artificial Inte	medical
3344	Artificial Intelligence in Medicine	An algorithm for complete enumeration of the mechanisms of supraventricular tachycardias that use multiple atrioventricular, AV nodal, and/or Mahaim pathways.	Lawrence E. Widman,D. A. Tong	1995	An algorithm for complete enumeration of the mechanisms of supraventricular tachycardias that use multiple atrioventricular, AV nodal, and/or Mahaim pathways.	Artificial Inte	medical
3345	Artificial Intelligence in Medicine	An appraisal of INTERNIST-I.	David A. Wolfram	1995	An appraisal of INTERNIST-I.	Artificial Inte	medical
3346	FOCS	Improved Algorithms and Analysis for Secretary Problems and Generalizations.	Miklós Ajtai,Nimrod Megiddo,Orli Waarts	1995	In the classical secretary problem, n objects from an ordered set arrive in random order, and one has to accept k of them so that the final decision about each object is made only on the basis of its rank relative to the ones already seen. Variants of the problem depend on the goal: either maximize the probability of accepting the best k objects, or minimize the expectation of the sum of the ranks (or powers of ranks) of the accepted objects. The problem and its generalizations are at the core of tasks with a large data set, in which it may be impractical to backtrack and select previous choices.Optimal algorithms for the special case of k = 1 are well known. Partial solutions for the first variant with general k are also known. In contrast, an explicit solution for the second variant with general k has not been known. It seems that the fact that the expected sum of powers of the ranks of selected items is bounded as n tends to infinity has been known to follow from standard results. We derive our results by obtaining explicit algorithms. For each $z \geq 1$, the resulting expected sum of the zth powers of the ranks of the selected objects is at most $k^{z + 1}/(z + 1) + C(z) \cdot k^{z + 0.5}\log k$, where log k \equiv \max\{1, \log_2 k\}$, whereas the best possible value at all is kz + 1/(z + 1) + O(kz). Our methods are very intuitive and apply to some generalizations. We also derive a lower bound on the trade-off between the probability of selecting the best object and the expected rank of the selected object.	FOCS	theory
3347	FOCS	Linear Time Erasure Codes with Nearly Optimal Recovery (Extended Abstract).	Noga Alon,Jeff Edmonds,Michael Luby	1995	Linear Time Erasure Codes with Nearly Optimal Recovery (Extended Abstract).	FOCS	theory
3348	FOCS	Sublogarithmic Searching without Multiplications.	Arne Andersson	1995	We show that a unit-cost RAM with word length w can maintain an ordered set of w-bit integers (or binary strings) under the operations search, insert, delete, nearest neighbour in O(/spl radic/(logn)) worst-case time and range queries in O(/spl radic/(logn)+size of output) worst-case time. The operations rely on AC/sup 0/ instructions only, thereby solving an open problem posed by Fredman and Willard. The data structure is simple. We also present a static data structure that can process a set of /spl Theta/O(logn) searches in O(lognloglogn) time.	FOCS	theory
3349	FOCS	Reductions, Codes, PCPs, and Inapproximability.	Sanjeev Arora	1995	Many recent results show the hardness of approximating NP-hard functions. We formalize, in a very simple way, what these results involve: a code-like Levin reduction. Assuming a well-known complexity assumption, we show that such reductions cannot prove the NP-hardness of the following problems, where /spl epsiv/ is any positive fraction: (i) achieving an approximation ratio n/sup 1/2+/spl epsiv// for Clique, (ii) achieving an approximation ratio 1.5+/spl epsiv/ for Vertex Cover, and (iii) coloring a 3-colorable graph with O(logn) colors. In fact, we explain why current reductions cannot prove the NP-hardness of coloring 3-colorable graphs with 9 colors. Our formalization of a code-like reduction, together with our justification of why such reductions are natural, also clarifies why current proofs of inapproximability results use error-correcting codes.	FOCS	theory
3350	FOCS	Gambling in a Rigged Casino: The Adversarial Multi-Arm Bandit Problem.	Peter Auer,Nicolò Cesa-Bianchi,Yoav Freund,Robert E. Schapire	1995	In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the expected per-round payoff of our algorithm approaches that of the best arm at the rate O(T/sup -1/3/), and we give an improved rate of convergence when the best arm has fairly low payoff. We also consider a setting in which the player has a team of experts advising him on which arm to play; here, we give a strategy that will guarantee expected payoff close to that of the best expert. Finally, we apply our result to the problem of learning to play an unknown repeated matrix game against an all-powerful adversary.	FOCS	theory
3351	FOCS	Tracking the Best Disjunction.	Peter Auer,Manfred K. Warmuth	1995	Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions. This algorithm (called {\sc Winnow}) keeps one weight for each of then variables and does multiplicative updates to its weights. We develop a randomized version of {\sc Winnow} and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time. In this case a possible target {\it disjunction schedule} &Tgr; is a sequence of disjunctions (one per trial) and the {\it shift size} is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence.We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples. This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version. However, the amortized analysis needed for obtaining worst-case mistake bounds requires new techniques. In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term. Computer experiments support our theoretical findings.	FOCS	theory
3352	FOCS	Load Balancing in the L Norm.	Baruch Awerbuch,Yossi Azar,Edward F. Grove,Ming-Yang Kao,P. Krishnan,Jeffrey Scott Vitter	1995	Load Balancing in the L Norm.	FOCS	theory
3353	FOCS	Application-Controlled Paging for a Shared Cache (Extended Abstract).	Rakesh D. Barve,Edward F. Grove,Jeffrey Scott Vitter	1995	Application-Controlled Paging for a Shared Cache (Extended Abstract).	FOCS	theory
3354	FOCS	Integral Geometry of Higher-Dimensional Polytopes and the Average Case in Combinatorial Optimization.	Alexander I. Barvinok	1995	We consider the average case behavior of a linear optimization problem on various series of combinatorially interesting polytopes. From general results of integral geometry it follows that for all but an asymptotically negligible fraction of linear functions a polytope can be replaced by a pair of concentric balls with asymptotically equal radii so that the optimal value of the linear function on the polytope is in the interval between the optimal values of the linear function on these balls. In particular, we show that the average case behavior of the assignment problem, traveling salesman problem, and, generally speaking, of any optimization problem on a polynomial fraction of all permutations is the same.	FOCS	theory
3355	FOCS	Algorithms for Matrix Groups and the Tits Alternative.	Robert Beals	1995	Tits has shown that a finitely generated linear group either contains a nonabelian free group or has a solvable subgroup of finite index. We give a polynomial time algorithm for deciding which of these two conditions holds for a given finitely generated matrix group over an algebraic number field. Noting that many computational problems are undecidable for groups with nonabelian free subgroups, we investigate the complexity of problems relating to linear groups with solvable subgroups of finite index. For such a group G, we are able in polynomial time to compute a homomorphism phi such that phi(G) is a finite matrix group and the kernel of phi is solvable. If in addition G has a nilpotent subgroup of finite index, we obtain much stronger results. These include an effective encoding of elements of G such that the encoding length of an element obtained as a product of length L over the generators is 0(log L) times a polynomial in the input length. This result is the best possible; it has been shown by Tits and Wolf that if a finitely generated matrix group does not have a nilpotent subgroup of finite index, then the number of group elements expressible as words of length L over the generators grows as c^L for some constant c<1 depending on G. For groups with abelian subgroups of finite index, we obtain a Las Vegas algorithm for several basic computational tasks including membership testing and computing a presentation. This generalizes recent work of Beals and Babai, who give a Las Vegas algorithm for the case of finite groups, as well as recent work of Babai, Beals, Cai, Ivanyos, and Luks, who give a deterministic algorithm for the case of abelian groups.	FOCS	theory
3356	FOCS	Improved Depth Lower Vounds for Small Distance Connectivity.	Paul Beame,Russell Impagliazzo,Toniann Pitassi	1995	Improved Depth Lower Vounds for Small Distance Connectivity.	FOCS	theory
3357	FOCS	3-Coloring in Time O(1.3446): A No-MIS Algorithm.	Richard Beigel,David Eppstein	1995	3-Coloring in Time O(1.3446): A No-MIS Algorithm.	FOCS	theory
3358	FOCS	Fault Diagnosis in a Flash.	Richard Beigel,William Hurwood,Nabil Kahale	1995	Consider a set of n processors that can communicate with each other. Assume that each processor can be either good or faulty. Also assume that the processors can test each other. We consider how to use parallel testing rounds to identify the faulty processors, given an upper bound t on their number. We prove that 4 rounds are necessary and sufficient when 2/spl radic/(2n)/spl les/0.03n (for n sufficiently large). Furthermore, at least 5 rounds are necessary when t/spl ges/0.49n (for n sufficiently large), and 10 rounds are sufficient when t>0.5n (for all n). (It is well known that no general solution is possible when t/spl ges/0.5n).	FOCS	theory
3359	FOCS	Lower Bounds for Monotone Span Programs.	Amos Beimel,Anna Gál,Mike Paterson	1995	Span programs provide a linear algebraic model of computation. Lower Bounds for span programs imply lower bounds for formula size, symmetric branching programs and for contact schemes. Monotone span programs correspond also to linear secret-sharing schemes. We present a new technique for proving lower bounds for monotone span programs, and prove a lower bound of /spl Omega/(m/sup 2.5/) for the 6-clique function. Our results improve on the previously known bounds for explicit functions.	FOCS	theory
3360	FOCS	Linearity Testing in Characteristic Two.	Mihir Bellare,Don Coppersmith,Johan Håstad,Marcos A. Kiwi,Madhu Sudan	1995	Let Dist(f,g)=Pr/sub u/ [f(u)/spl ne/g(u)] denote the relative distance between functions f,g mapping from a group G to a group H, and let Dist(f) denote the minimum, over all linear functions (homomorphisms) g, of Dist(f,g). Given a function f:G/spl rarr/H we let Err(f)=Pr/sub u/,v[f(u)+f(v)/spl ne/f(u+v)] denote the rejection probability of the BLR (Blum-Luby-Rubinfeld) linearity test. Linearity testing is the study of the relationship between Err(f) and Dist(f), and in particular the study of lower bounds on Err(f) in terms of Dist(f). The case we are interested in is when the underlying groups are G=GF(2)/sup n/ and H=GF(2). The corresponding test is used in the construction of efficient PCPs and thence in the derivation of hardness of approximation results, and, in this context, improved analyses translate into better non-approximability results. However, while several analyses of the relation of Err(f) to Dist(f) are known, none is tight. We present a description of the relationship between Err(f) and Dist(f) which is nearly complete in all its aspects, and entirely complete (i.e. tight) in some. In particular we present functions L,U:[0,1]/spl rarr/[0,1] such that for all x/spl isin/[0,1] we have L(x)>Err(f)/spl les/U(x) whenever Dist(f)=x, with the upper bound being tight on the whole range, and the lower bound tight on a large part of the range and close on the rest. Part of our strengthening is obtained by showing a new connection between the linearity testing problem and Fourier analysis, a connection which may be of independent interest. Our results are used by M. Bellare et al. (1995) to present the best known hardness results for Max3SAT and other MaxSNP problems.	FOCS	theory
3361	FOCS	Free Bits, PCPs and Non-Approximability - Towards Tight Results.	Mihir Bellare,Oded Goldreich,Madhu Sudan	1995	The first part of this paper presents new proof systems and improved non-approximability results. In particular we present a proof system for NP using logarithmic randomness and two amortized free bits, so that Max clique is hard within N/sup 1/3/ and chromatic number within N/sup 1/5/. We also show hardness of 38/37 for Max-3-SAT, 27/26 for vertex cover, 82/81 for Max-cut, and 94/93 for Max-2-SAT. The second part of this paper presents a reverse of the FGLSS connection by showing that an NP-hardness result for the approximation of Max clique to within a factor of N/sup 1/(g+1/) would imply a probabilistic verifier for NP with logarithmic randomness and amortized free-bit complexity g. We also show that existing techniques won't yield proof systems of less than two bits in amortized free bit complexity. Finally, we initiate a comprehensive study of PCP and FPCP parameters, proving several triviality results and providing several useful transformations.	FOCS	theory
3362	FOCS	A Representation of Cuts within 6/5 Times the Edge Connectivity with Applications.	András A. Benczúr	1995	Let G be an undirected c-edge connected graph. In this paper we give an O(n/sup 2/)-sized planar geometric representation for all edge cuts with capacity less than 6/5c. The representation can be very efficiently built, by using a single run of the Karger-Stein algorithm for finding near-mincuts. We demonstrate that the representation provides an efficient query structure for near-mincuts, as well as a new proof technique through geometric arguments. We show that in algorithms based on edge splitting, computing our representation O(log n) times substitute for one, or sometimes even /spl Omega/(n), u-/spl nu/ mincut computations; this can lead to significant savings, since our representation can be computed /spl theta//spl tilde/(m/n) times faster than the currently best known u-/spl nu/ mincut algorithm. We also improve the running time of the edge augmentation problem, provided the initial edge weights are polynomially bounded.	FOCS	theory
3363	FOCS	The Loading Time Scheduling Problem (Extended Abstract).	Randeep Bhatia,Samir Khuller,Joseph Naor	1995	The Loading Time Scheduling Problem (Extended Abstract).	FOCS	theory
3364	FOCS	Simple Learning Algorithms for Decision Trees and Multivariate Polynomials.	Nader H. Bshouty,Yishay Mansour	1995	In this paper we develop a new approach for learning decision trees and multivariate polynomials via interpolation of multivariate polynomials. This new approach yields simple learning algorithms for multivariate polynomials and decision trees over finite fields under any constant bounded product distribution. The output hypothesis is a (single) multivariate polynomial that is an $\epsilon$-approximation of the target under any constant bounded product distribution.The new approach demonstrates the learnability of many classes under any constant bounded product distribution and using membership queries, such as j-disjoint disjunctive normal forms (DNFs) and multivariate polynomials with bounded degree over any field.The technique shows how to interpolate multivariate polynomials with bounded term size from membership queries only. This, in particular, gives a learning algorithm for an O(log n)-depth decision tree from membership queries only and a new learning algorithm of any multivariate polynomial over sufficiently large fields from membership queries only. We show that our results for learning from membership queries only are the best possible.	FOCS	theory
3365	FOCS	Using Autoreducibility to Separate Complexity Classes.	Harry Buhrman,Lance Fortnow,Leen Torenvliet	1995	A language is autoreducible if it can be reduced to itself by a Turing machine that does not ask its own input to the oracle. We use autoreducibility to separate exponential space from doubly exponential space by showing that all Turing complete sets for exponential space are autoreducible but there exists some Turing complete set for doubly exponential space that is not. We immediately also get a separation of logarithmic space from polynomial space. Although we already know how to separate these classes using diagonalization, our proofs separate classes solely by showing they have different structural properties, thus applying Post's Program (E. Pos, 1944) to complexity theory. We feel such techniques may prove unknown separations in the future. In particular if we could settle the question as to whether all complete sets for doubly exponential time were autoreducible we would separate polynomial time from either logarithmic space or polynomial space. We also show several other theorems about autoreducibility.	FOCS	theory
3366	FOCS	The Resolution of a Hartmanis Conjecture.	Jin-yi Cai,D. Sivakumar	1995	Building on the recent breakthrough by M. Ogihara (1995), we resolve a conjecture made by J. Hartmanis (1978) regarding the (non) existence of sparse sets complete for P under logspace many-one reductions. We show that if there exists a sparse hard set for P under logspace many-one reductions, then P=LOGSPACE. We further prove that if P has a sparse hard set under many-one reductions computable in NC/sup 1/, then P collapses to NC/sup 1/.	FOCS	theory
3367	FOCS	Private Information Retrieval.	Benny Chor,Oded Goldreich,Eyal Kushilevitz,Madhu Sudan	1995	We describe schemes that enable a user to access k replicated copies of a database (k/spl ges/2) and privately retrieve information stored in the database. This means that each individual database gets no information on the identity of the item retrieved by the user. For a single database, achieving this type of privacy requires communicating the whole database, or n bits (where n is the number of bits in the database). Our schemes use the replication to gain substantial saving. In particular, we have: A two database scheme with communication complexity of O(n/sup 1/3/). A scheme for a constant number, k, of databases with communication complexity O(n/sup 1/k/). A scheme for 1/3 log/sub 2/ n databases with polylogarithmic (in n) communication complexity.	FOCS	theory
3368	FOCS	Routing on Butterfly Networks with Random Faults.	Richard Cole,Bruce M. Maggs,Ramesh K. Sitaraman	1995	We show that even if every node or edge in an N-node butterfly network fails independently with some constant probability, p, it is still possible to identify a set of /spl Theta/(N) nodes between which packets can be routed in any permutation in O(logN) steps, with high probability. Although the analysis as complicated, the routing algorithm itself is relatively simple.	FOCS	theory
3369	FOCS	An Optimal Algorithm for Monte Carlo Estimation (Extended Abstract).	Paul Dagum,Richard M. Karp,Michael Luby,Sheldon M. Ross	1995	An Optimal Algorithm for Monte Carlo Estimation (Extended Abstract).	FOCS	theory
3370	FOCS	Optimal Algorithms for Curves on Surfaces.	Tamal K. Dey,Sumanta Guha	1995	We describe an optimal algorithm to decide if one closed curve on a triangulated 2-manifold can be continuously transformed to another, i.e., if they are homotopic. Our algorithm runs in O(n+k/sub 1/+k/sub 2/) time and space, where closed curves C/sub 1/ and C/sub 2/ of lengths k/sub 1/ and k/sub 2/, resp., on a genus g surface M (g/spl ne/2 if M orientable, and g/spl ne/3,4 if M is non-orientable) are presented as edge-vertex sequences in a triangulation T of size n of M. This also implies an optimal algorithm to decide if a closed curve on a surface can be continuously contracted to a point. Except for three low genus cases, our algorithm completes an investigation into the computational complexity of the two classical problems for surfaces posed by the mathematician Max Dehn at the beginning of this century. However, we make novel applications of methods from modern combinatorial group theory for an approach entirely different from previous ones, and much simpler to implement.	FOCS	theory
3371	FOCS	Algebraic Decompositions of Non-Convex Polyhedra.	Herbert Edelsbrunner	1995	Any arbitrary polyhedron $P \subseteq R^d$ can be written as algebraic sum of simple terms, each an integer multiple of the intersection of $d$ or fewer half-spaces defined by facets of $P$. $P$ can be non-convex and can have holes of any kind. Among the consequences of this result are a short boolean formula for $P$, a fast parallel algorithm for point classification, and a new proof of the Gram-Sommerville angle relation.	FOCS	theory
3372	FOCS	Divide-and-Conquer Approximation Algorithms via Spreading Metrics (Extended Abstract).	Guy Even,Joseph Naor,Satish Rao,Baruch Schieber	1995	Divide-and-Conquer Approximation Algorithms via Spreading Metrics (Extended Abstract).	FOCS	theory
3373	FOCS	Optimal On-Line Search and Sublinear Time Update in String Matching.	Paolo Ferragina,Roberto Grossi	1995	This paper investigates the problem of searching on-line for the occurrences (occ) of an arbitrary pattern of length p in a text of length n subjected to some updates after its preprocessing. Each text update consists of inserting or deleting an arbitrary string of length y. We present the first dynamic algorithm that achieves optimal query time, i.e., $\Theta(p+occ)$, sublinear time per update, i.e., $O(\sqrt{n} + y)$, and optimal space, i.e., $\Theta(n)$, in the worst case. As a result, our algorithm obtains the same query time and space usage of suffix trees [McCreight, J. Assoc. Comput. Mach., 23 (1976), pp. 262--272] while improving their O(n + y) update performance.	FOCS	theory
3374	FOCS	Competitive Access Time via Dynamic Storage Rearrangement (Preliminary Version).	Amos Fiat,Yishay Mansour,Adi Rosén,Orli Waarts	1995	Competitive Access Time via Dynamic Storage Rearrangement (Preliminary Version).	FOCS	theory
3375	FOCS	Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries.	Yoav Freund,Michael J. Kearns,Yishay Mansour,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire	1995	We examine the problem of learning to play various games optimally against resource-bounded adversaries, with an explicit emphasis on the computational efficiency of the learning algorithm. We are especially interested in providing efficient algorithms for games other than penny-matching (in which payoff is received for matching the adversary's action in the current round), and for adversaries other than the classically studied finite automata. In particular, we examine games and adversaries for which the learning algorithm's past actions may strongly affect the adversary's future willingness to cooperate (that is, permit high payoff), and therefore require carefully planned actions on the part of the learning algorithm. For example, in the game we call contract, both sides play O or 1 on each round, but our side receives payoff only if we play 1 in synchrony with the adversary; unlike penny-matching, playing O in synchrony with the adversary pays nothing. The name of the game is derived from the example of signing a contract, which becomes valid only if both parties sign (play 1).	FOCS	theory
3376	FOCS	Improved Hardness Results for Approximating the Chromatic Number.	Martin Fürer	1995	First, a simplified geometric proof is presented for the result of C. Lund and M. Yannakakis (1994) saying that for some /spl epsiv/	FOCS	theory
3377	FOCS	Resolving Message Complexity of Byzantine Agreement and beyond.	Zvi Galil,Alain J. Mayer,Moti Yung	1995	Byzantine Agreement among processors is a basic primitive in distributed computing. It comes in a number of basic fault models: Crash, Omission and Malicious adversarial behaviors. The message complexity of the primitive has been known for the strong failure models of Malicious and Omission adversary since the early 80's, while the question for the more benign Crash failure model has been open. We show how to solve agreement in the presence of crash failures using O(n) messages which is optimal, thus settling a thirteen year old open problem. Our solution has almost linear time and our new algorithmic techniques have further implications: a family of early stopping agreement protocols with improved message-complexity; and a new solution to Checkpoint yielding a substantial improvement of the protocol for distributed work performance under adaptive parallelism in a network of workstations.	FOCS	theory
3378	FOCS	Finding Points on Curves over Finite Fields (Extended Abstract).	Joachim von zur Gathen,Igor Shparlinski	1995	Finding Points on Curves over Finite Fields (Extended Abstract).	FOCS	theory
3379	FOCS	Learning Polynomials with Queries: The Highly Noisy Case.	Oded Goldreich,Ronitt Rubinfeld,Madhu Sudan	1995	Given a function f mapping n-variate inputs from a finite field F into F, we consider the task of reconstructing a list of all n-variate degree d polynomials that agree with f on a tiny but nonnegligible fraction, $\delta$, of the input space. We give a randomized algorithm for solving this task. The algorithm accesses f as a black box and runs in time polynomial in ${\frac{n}\d}$ and exponential in d, provided $\delta$ is $\Omega(\sqrt{d/|F|})$. For the special case when d = 1, we solve this problem for all $\epsilon\eqdef\delta - \frac1{|F|} >0$. In this case the running time of our algorithm is bounded by a polynomial in $\frac1\e$ and $n$. Our algorithm generalizes a previously known algorithm, due to Goldreich and Levin [in Proceedings of the 21st Annual ACM Symposium on Theory of Computing, Seattle, WA, ACM Press, New York, 1989, pp. 25--32.], that solves this task for the case when F = GF(2) (and d = 1).In the process we provide new bounds on the number of degree $d$ polynomials that may agree with any given function on $\d \geq \sqrt{d/|F|}$ fraction of the inputs. This result is derived by generalizing a well-known bound from coding theory on the number of codewords from an error-correcting code that can be close to an arbitrary word; our generalization works for codes over arbitrary alphabets, while the previous result held only for binary alphabets.	FOCS	theory
3380	FOCS	An Approximation Scheme for Planar Graph TSP.	Michelangelo Grigni,Elias Koutsoupias,Christos H. Papadimitriou	1995	We consider the special case of the traveling salesman problem (TSP) in which the distance metric is the shortest-path metric of a planar unweighted graph. We present a polynomial-time approximation scheme (PTAS) for this problem.	FOCS	theory
3381	FOCS	Improved Lower Bound on Testing Membership to a Polyhedron by Algebraic Decision Trees.	Dima Grigoriev,Marek Karpinski,Nicolai Vorobjov	1995	We introduce a new method of proving lower bounds on the depth of algebraic $d$-degree decision trees and apply it to prove a lower bound $\Omega (\log N)$ for testing membership to an $n$-dimensional convex polyhedron having $N$ faces of all dimensions, provided that $N< (nd)^{\Omega (n)}$. This bound apparently does not follow from the methods developed by M.\ Ben-Or, A.\ Bj\ orner, L.\ Lovasz, and A.\ Yao [B.\ 83], [BLY\ 93], [Y\ 94] because topological invariants used in these methods become trivial for convex polyhedra.	FOCS	theory
3382	FOCS	Counting Bottlenecks to Show Monotone P <=> NP.	Armin Haken	1995	The method of proving lower bounds by bottleneck counting is illustrated for monotone Boolean circuits. This paper gives another proof of the result of Razborov (1985) and Andreev (1985), that monotone Boolean circuits must have exponential size when solving a problem in NP. More specifically, the paper defines a graph recognition problem called BMS. Any monotone circuit that solves BMS, must contain a quantity of gates that is exponential in the eighth root of the input size. The actual instances of the BMS problem used to prove the lower bound are easy to separate for non-monotone circuits. The proof is self-contained and uses only elementary combinatorics.	FOCS	theory
3383	FOCS	Approximability of Flow Shop Scheduling.	Leslie A. Hall	1995	Shop scheduling problems are notorious for their intractability, both in theory and practice. In this paper, we demonstrate the existence of a polynomial approximation scheme for the flow shop scheduling problem with an arbitrary fixed number of machines. For the three common shop models (open, flow, and job), this result is the only known approximation scheme. Since none of the three models can be approximated arbitrarily closely in the general case (unless P=NP), the result demonstrates the approximability gap between the models in which the number of machines is fixed, and those in which it is part of the input of the instance. The result can be extended to flow shops with job release dates and delivery times and to flow shops with a fixed number stages, where the number of machines at any stage is fixed. We also describe a related polynomial approximation scheme for the problem of scheduling an open shop with a single bottleneck machine and an arbitrary number of non-bottleneck machines.	FOCS	theory
3384	FOCS	Transforming Men into Mice (Polynomial Algorithm for Genomic Distance Problem).	Sridhar Hannenhalli,Pavel A. Pevzner	1995	Many people believe that transformations of humans into mice happen only in fairy tales. However, despite some differences in appearance and habits, men and mice are genetically very similar. In the pioneering paper, J.H. Nadeau and B.A. Taylor (1984) estimated that surprisingly few genomic rearrangements (178/spl plusmn/39) happened since the divergence of human and mouse 80 million years ago. However, their analysis is nonconstructive and no rearrangement scenario for human-mouse evolution has been suggested yet. The problem is complicated by the fact that rearrangements in multi chromosomal genomes include inversions, translocations, fusions and fissions of chromosomes, a rather complex set of operations. As a result, at first glance, a polynomial algorithm for the genomic distance problem with all these operations looks almost as improbable as the transformation of a (real) man into a (real) mouse. We prove a duality theorem which expresses the genomic distance in terms of easily computable parameters reflecting different combinatorial properties of sets of strings. This theorem leads to a polynomial time algorithm for computing most parsimonious rearrangement scenarios. Based on this result and the latest comparative physical mapping data we have constructed a scenario of human-mouse evolution with 131 reversals/translocaitons/fusions/fissions. A combination of the genome rearrangement algorithm with the recently proposed experimental technique called ZOO FISH suggests a new constructive approach to the 100 year old problem of reconstructing mammalian evolution.	FOCS	theory
3385	FOCS	Computing Simulations on Finite and Infinite Graphs.	Monika Rauch Henzinger,Thomas A. Henzinger,Peter W. Kopke	1995	We present algorithms for computing similarity relations of labeled graphs. Similarity relations have applications for the refinement and verification of reactive systems. For finite graphs, we present an O(mn) algorithm for computing the similarity relation of a graph with n vertices and m edges (assuming m/spl ges/n). For effectively presented infinite graphs, we present a symbolic similarity-checking procedure that terminates if a finite similarity relation exists. We show that 2D rectangular automata, which model discrete reactive systems with continuous environments, define effectively presented infinite graphs with finite similarity relations. It follows that the refinement problem and the /spl forall/CTL* model-checking problem are decidable for 2D rectangular automata.	FOCS	theory
3386	FOCS	Fully Dynamic Biconnectivity and Transitive Closure.	Monika Rauch Henzinger,Valerie King	1995	This paper presents an algorithm for the fully dynamic biconnectivity problem whose running time is exponentially faster than all previously known solutions. It is the first dynamic algorithm that answers biconnectivity queries in time O(log/sup 2/n) in a n-node graph and can be updated after an edge insertion or deletion in polylogarithmic time. Our algorithm is a Las-Vegas style randomized algorithm with the update time amortized update time O(log/sup 4/n). Only recently the best deterministic result for this problem was improved to O(/spl radic/nlog/sup 2/n). We also give the first fully dynamic and a novel deletions-only transitive closure (i.e. directed connectivity) algorithms. These are randomized Monte Carlo algorithms. Let n be the number of nodes in the graph and let m/spl circ/ be the average number of edges in the graph during the whole update sequence: The fully dynamic algorithms achieve (1) query time O(n/logn) and update time O(m/spl circ//spl radic/nlog/sup 2/n+n); or (2) query time O(n/logn) and update time O(nm/spl circ//sup /spl mu/-1/)log/sup 2/n=O(nm/spl circ//sup 0.58/log/sup 2/n), where /spl mu/ is the exponent for boolean matrix multiplication (currently /spl mu/=2.38). The deletions-only algorithm answers queries in time O(n/logn). Its amortized update time is O(nlog/sup 2/n).	FOCS	theory
3387	FOCS	Hard-Core Distributions for Somewhat Hard Problems.	Russell Impagliazzo	1995	Consider a decision problem that cannot be 1-/spl delta/ approximated by circuits of a given size in the sense that any such circuit fails to give the correct answer on at least a /spl delta/ fraction of instances. We show that for any such problem there is a specific hard core set of inputs which is at least a /spl delta/ fraction of all inputs and on which no circuit of a slightly smaller size can get even a small advantage over a random guess. More generally, our argument holds for any non uniform model of computation closed under majorities. We apply this result to get a new proof of the Yao XOR lemma (A.C. Yao, 1982), and to get a related XOR lemma for inputs that are only k wise independent.	FOCS	theory
3388	FOCS	Speed is as Powerful as Clairvoyance.	Bala Kalyanasundaram,Kirk Pruhs	1995	We introduce resource augmentation as a method for analyzing online scheduling problems. In resource augmentation analysis the on-line scheduler is given more resources, say faster processors or more processors, than the adversary. We apply this analysis to two well-known on-line scheduling problems, the classic uniprocessor CPU scheduling problem 1 |ri, pmtn|&Sgr; Fi, and the best-effort firm real-time scheduling problem 1|ri, pmtn| &Sgr; wi( 1- Ui). It is known that there are no constant competitive nonclairvoyant on-line algorithms for these problems. We show that there are simple on-line scheduling algorithms for these problems that are constant competitive if the online scheduler is equipped with a slightly faster processor than the adversary. Thus, a moderate increase in processor speed effectively gives the on-line scheduler the power of clairvoyance. Furthermore, the on-line scheduler can be constant competitive on all inputs that are not closely correlated with processor speed. We also show that the performance of an on-line scheduler is best-effort real time scheduling can be significantly improved if the system is designed in such a way that the laxity of every job is proportional to its length.	FOCS	theory
3389	FOCS	The Bit Vector Intersection Problem (Preliminary Version).	Richard M. Karp,Orli Waarts,Geoffrey Zweig	1995	The Bit Vector Intersection Problem (Preliminary Version).	FOCS	theory
3390	FOCS	Disjoint Paths in Densely Embedded Graphs.	Jon M. Kleinberg,Éva Tardos	1995	We consider the following maximum disjoint paths problem (MDPP). We are given a large network, and pairs of nodes that wish to communicate over paths through the network-the goal is to simultaneously connect as many of these pairs as possible in such a way that no two communication paths share an edge in the network. This classical problem has been brought into focus recently in papers discussing applications to routing in high-speed networks, where the current lack of understanding of the MDPP is an obstacle to the design of practical heuristics. We consider the class of densely embedded, nearly-Eulerian graphs, which includes the two-dimensional mesh and other planar and locally planar interconnection networks. We obtain a constant-factor approximation algorithm for the maximum disjoint paths problem for this class of graphs; this improves on an O(log n)-approximation for the special case of the two-dimensional mesh due to Aumann-Rabani and the authors. For networks that are not explicitly required to be high-capacity, this is the first constant-factor approximation for the MDPP in any class of graphs other than trees. We also consider the MDPP in the on-line setting, relevant to applications in which connection requests arrive over time and must be processed immediately. Here we obtain an asymptptically optimal O(log n)competitive on-line algorithm for the same class of graphs; this improves on an O(log n log log n) competitive algorithm for the special case of the mesh due to B. Awerbuch et al (1994).	FOCS	theory
3391	FOCS	Approximating the Volume of Definable Sets.	Pascal Koiran	1995	The first part of this paper deals with finite-precision arithmetic. We give an upper bound on the precision that should be used in a Monte-Carlo integration method. Such bounds have been known only for convex sets; our bound applies to almost any reasonable set. In the second part of the paper, we show how to construct in polynomial time first-order formulas that approximately define the volume of definable sets. This result is based on a VC dimension hypothesis, and is inspired from the well-known complexity-theoretic result BPP/spl sube//sub 2/. Finally, we show how these results can be applied to sets defined by systems of inequalities involving polynomial or exponential functions. In particular, we describe an application to a problem of structural complexity in the Blum-Shub-Smale model of computation over the reals.	FOCS	theory
3392	FOCS	Tight Fault Locality (Extended Abstract).	Shay Kutten,David Peleg	1995	Tight Fault Locality (Extended Abstract).	FOCS	theory
3393	FOCS	Faster Algorithms for the Construction of Parameterized Suffix Trees (Preliminary Version).	S. Rao Kosaraju	1995	Faster Algorithms for the Construction of Parameterized Suffix Trees (Preliminary Version).	FOCS	theory
3394	FOCS	Controllability, Recognizability, and Complexity Issues in Robot Motion Planning.	Jean-Claude Latombe	1995	Path planning has been widely studied by computer scientists. However, it is a very simplified version of the motion planning problems occurring in robotics. This paper examines extensions yielding two important issues: controllability and recognizability. The controllability issue arises when the number of controls is smaller than the number of independent parameters defining the robot's configuration: Can the motions span the configuration space? The recognizability issue occurs when there are errors in control and sensing: Can the robot recognize goal achievement? Both issues have interesting impact on the computational complexity of motion planning. This paper will also discuss a new path planning scheme based on random sampling of configuration space, to deal with many-degree-of-freedom robots. The blend of controllability, recognizability, and complexity issues discussed in this paper is unique to robotics and its study is key to the development of autonomous robots.	FOCS	theory
3395	FOCS	On Computing Boolean Functions by Sparse Real Polynomials.	Matthias Krause,Pavel Pudlák	1995	We investigate the complexity of Boolean functions f with respect to realizations by real polynomials p (voting polynomials) in the sense that the sign of p(x) determines the value f(x). Considerable research has been done on determining the minimal degree needed for realizing or approximating particular functions. In this paper we focus our interest on estimating the minimal number of monomials, i.e. the length of realizing polynomials. Our main observation is that, in contrast to the degree, the minimal length essentially depends on whether we realize f over the domain.	FOCS	theory
3396	FOCS	Derandomizing Semidefinite Programming Based Approximation Algorithms.	Sanjeev Mahajan,Ramesh Hariharan	1995	Derandomizing Semidefinite Programming Based Approximation Algorithms.	FOCS	theory
3397	FOCS	Reconstructing Strings from Substrings in Rounds.	Dimitris Margaritis,Steven Skiena	1995	We establish a variety of combinatorial bounds on the tradeoffs inherent in reconstructing strings using few rounds of a given number of substring queries per round. These results lead us to propose a new approach to sequencing by hybridization (SBH), which uses interaction to dramatically reduce the number of oligonucleotides used for de novo sequencing of large DNA fragments, while preserving the parallelism which is the primary advantage of SBH.	FOCS	theory
3398	FOCS	Spectral Methods for Matrix Rigidity with Applications to Size-Depth Tradeoffs and Communication Complexity.	Satyanarayana V. Lokam	1995	The rigidity of a matrix measures the number of entries that must be changed in order to reduce its rank below a certain value. The known lower bounds on the rigidity of explicit matrices are very weak. It is known that stronger lower bounds would have implications to complexity theory. We consider weaker forms of the rigidity problem over the complex numbers. Using spectral methods, we derive lower bounds on these variants. We then give two applications of such weaker forms. First, we show that our lower bound on a variant of rigidity implies lower bounds on size-depth tradeoffs for arithmetic circuits with bounded coefficients computing linear transformations. These bounds generalize a recent result of Nisan and Wigderson. The second application is conditional; we show that it would suffice to prove lower bounds on certain weaker forms of rigidity to conclude several separation results in communication complexity theory. Our results complement and strengthen a result of Razborov.	FOCS	theory
3399	FOCS	Markov Chain Algorithms for Planar Lattice Structures (Extended Abstract).	Michael Luby,Dana Randall,Alistair Sinclair	1995	Markov Chain Algorithms for Planar Lattice Structures (Extended Abstract).	FOCS	theory
3400	FOCS	Efficient Access to Optical Bandwidth - Wavelength Routing on Directed Fiber Trees, Rings, and Trees of Rings.	Milena Mihail,Christos Kaklamanis,Satish Rao	1995	Efficient Access to Optical Bandwidth - Wavelength Routing on Directed Fiber Trees, Rings, and Trees of Rings.	FOCS	theory
3401	FOCS	Lower Bounds for Arithmetic Circuits via Partial Serivatives (Preliminary Version).	Noam Nisan,Avi Wigderson	1995	Lower Bounds for Arithmetic Circuits via Partial Serivatives (Preliminary Version).	FOCS	theory
3402	FOCS	Sparse P-Hard Sets Yield Space-Efficient Algorithms.	Mitsunori Ogihara	1995	J. Hartmanis (1978) conjectured that there exist no sparse complete sets for P under logspace many-one reductions. In this paper, in support of the conjecture, it is shown that if P has sparse hard sets under logspace many-one reductions, then P/spl sube/DSPACE[log/sup 2/n]. The result follows from a more general statement: if P has 2/sup polylog/ sparse hard sets under poly-logarithmic space-computable many-one reductions, then P/spl sube/DSPACE[polylog].	FOCS	theory
3403	FOCS	Amortization, Lazy Evaluation, and Persistence: Lists with Catenation via Lazy Linking.	Chris Okasaki	1995	Amortization has been underutilized in the design of persistent data structures, largely because traditional accounting schemes break down in a persistent setting. Such schemes depend on saving credits for future use, but a persistent data structure may have multiple futures, each competing for the same credits. We describe how lazy evaluation can often remedy this problem, yielding persistent data structures with good amortized efficiency. In fact, such data structures can be implemented purely functionally in any functional language supporting lazy evaluation. As can example of this technique, we present a purely functional (and therefore persistent) implementation of lists that simultaneously support catenation and all other usual list primitives in constant amortized time. This data structure is much simpler than the only existing data structure with comparable bounds, the recently discovered catenable lists of Kaplan and Tarjan, which support all operations in constant worst-case time.	FOCS	theory
3404	FOCS	Coding for Computing.	Alon Orlitsky,James R. Roche	1995	A sender communicates with a receiver who wishes to reliably evaluate a function of their combined data. We show that if only the sender can transmit, the number of bits required is a conditional entropy of a naturally defined graph. We also determine the number of bits needed when the communicators exchange two messages.	FOCS	theory
3405	FOCS	Synthesizers and Their Application to the Parallel Construction of Psuedo-Random Functions.	Moni Naor,Omer Reingold	1995	We present a new cryptographic primitive called pseudo-random synthesizer and show how to use it in order to get a parallel construction of a pseudo-random function. We show an NC/sup 1/ implementation of pseudo-random synthesizers based on the RSA or the Diffie-Hellman assumptions. This yields the first parallel (NC/sup 2/) pseudo-random function and the only alternative to the original construction of Goldreich, Gold-wasser and Micali (GGM). The security of our constructions is similar to the security of the underling assumptions. We discuss the connection with problems in computational learning theory.	FOCS	theory
3406	FOCS	Splitters and Near-Optimal Derandomization.	Moni Naor,Leonard J. Schulman,Aravind Srinivasan	1995	We present a fairly general method for finding deterministic constructions obeying what we call k-restrictions; this yields structures of size not much larger than the probabilistic bound. The structures constructed by our method include (n,k)-universal sets (a collection of binary vectors of length n such that for any subset of size k of the indices, all 2/sup k/ configurations appear) and families of perfect hash functions. The near-optimal constructions of these objects imply the very efficient derandomization of algorithms in learning, of fixed-subgraph finding algorithms, and of near optimal /spl Sigma/II/spl Sigma/ threshold formulae. In addition, they derandomize the reduction showing the hardness of approximation of set cover. They also yield deterministic constructions for a local-coloring protocol, and for exhaustive testing of circuits.	FOCS	theory
3407	FOCS	Contention Resolution with Bounded Delay.	Mike Paterson,Aravind Srinivasan	1995	When distributed processes contend for a shared resource, we need a good distributed contention resolution protocol, e.g., for multiple-access channels (ALOHA, Ethernet), PRAM emulation, and optical routing. Under a stochastic model of request generation from n synchronous processes, Raghavan & Upfal (1995) have shown a protocol which is stable for a positive request rate; their main result is that for every resource request, its expected delay (time to get serviced) is O(log n). Assuming that the initial clock times of the processes are within a known bound of each other, we present a stable protocol, wherein the expected delay for each request is O(1). We derive this by showing an analogous result for can infinite number of processes, assuming that all processes agree on the time.	FOCS	theory
3408	FOCS	Tight Bounds for a Distributed Selection Game with Applications to Fixed-Connection Machines.	C. Greg Plaxton	1995	We define a distributed selection game that generalizes a selection problem considered by S.R. Kosaraju (1989). We offer a tight analysis of our distributed selection game, and show that the lower bound for this abstract communication game directly implies near-tight lower bounds for certain selection problems on fixed-connection machines. For example, we prove that any deterministic comparison-based selection algorithm on an (n/log n)-processor bounded-degree hypercubic machine requires /spl Omega/(log/sup 3/2/n) steps in the worst case. This lower bound implies a non-trivial separation between the power of bounded-degree hypercubic and expander-based machines. Furthermore, we show that the algorithm underlying our tight upper bound for the distributed selection game can be adapted to run in O((log/sup 3/2/n) (log log n)/sup 2/) steps on any (n/log n)-processor hypercubic machine.	FOCS	theory
3409	FOCS	Pseudorandom Generators, Measure Theory, and Natural Proofs.	Kenneth W. Regan,D. Sivakumar,Jin-yi Cai	1995	We prove that if strong pseudorandom number generators exist, then the class of languages that have polynomial-sized circuits (P/poly) is not measurable within exponential time, in terms of the resource-bounded measure theory of Lutz. We prove our result by showing that if P/poly has measure zero in exponential time, then there is a natural proof against P/poly, in the terminology of Razborov and Rudich (1994). We also provide a partial converse of this result.	FOCS	theory
3410	FOCS	RSPACE(S) \subseteq DSPACE(S).	Michael E. Saks,Shiyu Zhou	1995	RSPACE(S) \subseteq DSPACE(S).	FOCS	theory
3411	FOCS	Efficient Parallel Solution of Sparse Eigenvalue and Eigenvector Problems.	John H. Reif	1995	This paper gives a new algorithm for computing the characteristic polynomial of a symmetric sparse matrix. We derive an interesting algebraic version of nested dissection, which constructs a sparse factorization the matrix A-/spl lambda/ where A is the input matrix. While nested dissection is commonly used to minimize the fill-in in the solution of sparse linear systems, our innovation is to use the separator structure to bound also the work for manipulation of rational polynomials in the recursively factored matrices. We compute the characteristic polynomial sparse symmetric matrix in polylog time using O(n(n+P(s(n))))/spl les/O(n(n+s(n)/sup 2.376/)) processors, where the sparsity graph of the matrix has separator size s(n). Our method requires only that the matrix be symmetric and nonsingular (it need not be positive definite as usual for nested dissection techniques); we use perturbation methods to avoid singularities. For the frequently occurring case where the matrix has small separator size our polylog parallel algorithm requires work bounds competitive with the best known sequential algorithms (i.e. sparse Lanczos methods), for example: (1) when the sparsity graph is a planar graph, s(n)/spl les//spl radic/n, and we require only n/sup 2.188/ processors, and (2) in the case where the input matrix is b-banded, we require only O(nP(b))=O(n) processors, for constant b.	FOCS	theory
3412	FOCS	Faster Approximate Agreement with Multi-Writer Registers.	Eric Schenk	1995	We consider the complexity of the wait-free approximate agreement problem in an asynchronous shared memory comprised of only single-bit multi-writer multi-reader registers. For real-valued inputs x/sub 1/,...,x/sub n/ and /spl epsiv/ we show matching upper and lower bounds of /spl Theta/(log(ma.	FOCS	theory
3413	FOCS	Minimum Coloring Random and Semi-Random Graphs in Polynomial Expected Time.	C. R. Subramanian	1995	We present new algorithms for k-coloring and minimum (/spl chi/(G)-) coloring random and semi-random k-colorable graphs in polynomial expected time. The random graphs are drawn from the G(n,p,k) model and the semi-random graphs are drawn from the G/sub SB/(n,p,k) model. In both models, an adversary initially splits the n vertices into k color classes, each of size /spl Theta/(n). Then the edges between vertices in different color classes are chosen one by one, according to some probability distribution. The model G/sub SB/(n,p,k) was introduced by A. Blum (1991) and with respect to randomness, it lies between the random model G(n,p,k) where all edges are chosen with equal probability and the worst-case model.	FOCS	theory
3414	FOCS	A Unified Analysis of Paging and Caching.	Eric Torng	1995	Paging (caching) is the problem of managing a two-level memory hierarchy in order to minimise the time required to process a sequence of memory accesses. In order to measure this quantity, we define the system parameter miss penalty to represent the extra time required to access slow memory. In the context of paging, miss penalty is large, so most previous studies of on-line paging have implicitly set miss penalty=/spl infin/ in order to simplify the model. We show that this seemingly insignificant simplification substantially alters the precision of derived results. Consequently, we reintroduce miss penalty to the paging problem and present a more accurate analysis of on-line paging (and caching). We validate using this more accurate model by deriving intuitively appealing results for the paging problem which cannot be derived using the simplified model.	FOCS	theory
3415	FOCS	Cognitive Computation (Extended Abstract).	Leslie G. Valiant	1995	Cognitive Computation (Extended Abstract).	FOCS	theory
3416	FOCS	On One-Dimensional Quantum Cellular Automata.	John Watrous	1995	Since Richard Feynman introduced the notion of quantum computation in 1982, various models of quantum computers have been proposed (R. Feynman, 1992). These models include quantum Turing machines and quantum circuits. We define another quantum computational model, one dimensional quantum cellular automata, and demonstrate that any quantum Turing machine can be efficiently simulated by a one dimensional quantum cellular automaton with constant slowdown. This can be accomplished by consideration of a restricted class of one dimensional quantum cellular automata called one dimensional partitioned quantum cellular automata. We also show that any one dimensional partitioned quantum cellular automaton can be simulated by a quantum Turing machine with linear slowdown, but the problem of efficiently simulating an arbitrary one dimensional quantum cellular automaton with a quantum Turing machine is left open. From this discussion, some interesting facts concerning these models are easily deduced.	FOCS	theory
3417	FOCS	Perspectives on Database Theory.	Mihalis Yannakakis	1995	Database management systems address the need to store, retrieve, and manipulate large amounts of data in an organized fashion. The database held has grown tremendously in the last 25 years. It is reported that the database industry generated $7 billion in revenue in 1994 and is growing at a rate of 35% per year. Industrial and academic research have been instrumental to this growth. Theory has played an important role in defining the right abstractions and concepts, and providing a firm foundation for the field. In order to access effectively a large volume of data, one needs an abstract logical view of the data, which must be separate from the physical storage of data. The important first component of a database is therefore an abstract view of data (called the data model) and the accompanying specialized high-level language that is used to access the data. The second important component is the data structures that are used to store the data along with the algorithms to support the efficient translation from the logical to the physical world. The third important component is the mechanisms that allow the database to be accessed concurrently by many users, without violating its integrity. Theory has contributed to all three fronts, starting with what is undoubtedly the cornerstone of the area, the introduction and formal definition of the relational model by F.P. Codd (1970). It is a highly unusual compliment for theory when the major commercial products in the field have at their core a mathematically rigorous, formal model. Our primary aims in this paper will be to give a flavor of the types of problems that database theory addresses, and to review how research in the area has evolved over the years. At the end we will try to point to some topics that may be of interest to people in the FOCS community tempted to work in database theory.	FOCS	theory
3418	FOCS	A Scheduling Model for Reduced CPU Energy.	F. Frances Yao,Alan J. Demers,Scott Shenker	1995	The energy usage of computer systems is becoming an important consideration, especially for battery-operated systems. Various methods for reducing energy consumption have been investigated, both at the circuit level and at the operating systems level. In this paper, we propose a simple model of job scheduling aimed at capturing some key aspects of energy minimization. In this model, each job is to be executed between its arrival time and deadline by a single processor with variable speed, under the assumption that energy usage per unit time, P, is a convex function, of the processor speed s. We give an off-line algorithm that computes, for any set of jobs, a minimum-energy schedule. We then consider some on-line algorithms and their competitive performance for the power function P(s)=s/sup p/ where p/spl ges/2. It is shown that one natural heuristic, called the Average Rate heuristic, uses at most a constant times the minimum energy required. The analysis involves bounding the largest eigenvalue in matrices of a special type.	FOCS	theory
3419	FOCS	36th Annual Symposium on Foundations of Computer Science, Milwaukee, Wisconsin, 23-25 October 1995		1995	36th Annual Symposium on Foundations of Computer Science, Milwaukee, Wisconsin, 23-25 October 1995	FOCS	theory
3420	SODA	Design of Practical and Provably Good Random Number Generators (Extended Abstract).	William Aiello,Sivaramakrishnan Rajagopalan,Ramarathnam Venkatesan	1995	Design of Practical and Provably Good Random Number Generators (Extended Abstract).	SODA	theory
3421	SODA	Fairness in Scheduling.	Miklós Ajtai,James Aspnes,Moni Naor,Yuval Rabani,Leonard J. Schulman,Orli Waarts	1995	Fairness in Scheduling.	SODA	theory
3422	SODA	Improved Randomized On-Line Algorithms for the List Update Problem.	Susanne Albers	1995	The best randomized on-line algorithms known so far for the list update problem achieve a competitiveness of $\sqrt{3} \approx 1.73$. In this paper we present a new family of randomized on-line algorithms that beat this competitive ratio. Our improved algorithms are called TIMESTAMP algorithms and achieve a competitiveness of $\max\{2-p, 1+p(2-p)\}$, for any real number $p\in[0,1]$. Setting $p = (3-\sqrt{5})/2$, we obtain a $\phi$-competitive algorithm, where $\phi = (1+\sqrt{5})/2\approx 1.62$ is the golden ratio. TIMESTAMP algorithms coordinate the movements of items using some information on past requests. We can reduce the required information at the expense of increasing the competitive ratio. We present a very simple version of the TIMESTAMP algorithms that is \mbox{$1.68$-competitive}. The family of TIME\-STAMP algorithms also includes a new deterministic 2-competitive on-line algorithm that is different from the MOVE-TO-FRONT rule.	SODA	theory
3423	SODA	On-line Approximate List Indexing with Applications.	Arne Andersson,Ola Petersson	1995	On-line Approximate List Indexing with Applications.	SODA	theory
3424	SODA	Average Case Analysis of Dynamic Graph Algorithms.	David Alberts,Monika Rauch Henzinger	1995	Average Case Analysis of Dynamic Graph Algorithms.	SODA	theory
3425	SODA	Improved Bounds for All Optical Routing.	Yonatan Aumann,Yuval Rabani	1995	Improved Bounds for All Optical Routing.	SODA	theory
3426	SODA	Sorting Permutations by Transpositions.	Vineet Bafna,Pavel A. Pevzner	1995	Sorting Permutations by Transpositions.	SODA	theory
3427	SODA	Parameterized Pattern Matching by Boyer-Moore-Type Algorithms.	Brenda S. Baker	1995	Parameterized Pattern Matching by Boyer-Moore-Type Algorithms.	SODA	theory
3428	SODA	Guaranteeing Fair Service to Persistent Dependent Tasks.	Amotz Bar-Noy,Alain J. Mayer,Baruch Schieber,Madhu Sudan	1995	We introduce a new scheduling problem that is motivated by applications in the area of access and flow control in high-speed and wireless networks. An instance of the problem consists of a set of persistent tasks that have to be scheduled repeatedly. Each task has a demand to be scheduled as often as possible. There is no explicit limit on the number of tasks that can be scheduled concurrently. However, such limits are imposed implicitly because some tasks may be in conflict and cannot be scheduled simultaneously. These conflicts are presented in the form of a conflict graph. We define parameters which quantify the fairness and regularity of a given schedule. We then proceed to show lower bounds on these parameters and present fair and efficient scheduling algorithms for the case where the conflict graph is an interval graph. Some of the results presented here extend to the case of perfect graphs and circular-arc graphs as well.	SODA	theory
3429	SODA	Improved Algorithms for Protein Motif Recognition.	Bonnie Berger,David Bruce Wilson	1995	Improved Algorithms for Protein Motif Recognition.	SODA	theory
3430	SODA	Dihedral Bounds for Mesh Generation in High Dimensions.	Marshall W. Bern,L. Paul Chew,David Eppstein,Jim Ruppert	1995	Dihedral Bounds for Mesh Generation in High Dimensions.	SODA	theory
3431	SODA	Path Optimization and Near-Greedy Analysis for Graph Partitioning: An Empirical Study.	Jonathan W. Berry,Mark K. Goldberg	1995	Path Optimization and Near-Greedy Analysis for Graph Partitioning: An Empirical Study.	SODA	theory
3432	SODA	From Valid Inequalities to Heuristics: A Unified View of Primal-Dual Approximation Algorithms in Covering Problems.	Dimitris Bertsimas,Chung-Piaw Teo	1995	In recent years approximation algorithms based on primal-dual methods have been successfully applied to a broad class of discrete optimization problems. In this paper, we propose a generic primal-dual framework to design and analyze approximation algorithms for integer programming problems of the covering type that uses valid inequalities in its design. The worst-case bound of the proposed algorithm is related to a fundamental relationship (called strength) between the set of valid inequalities and the set of minimal solutions to the covering problems. In this way, we can construct an approximation algorithm simply by constructing the required valid inequalities. We apply the proposed algorithm to several problems, such as covering problems related to totally balanced matrices, cyclic scheduling, vertex cover, general set covering, intersections of polymatroids, and several network design problems attaining (in most cases) the best worst-case bound known in the literature.	SODA	theory
3433	SODA	Circular Separability of Polygon.	Jean-Daniel Boissonnat,Jurek Czyzowicz,Olivier Devillers,Mariette Yvinec	1995	Circular Separability of Polygon.	SODA	theory
3434	SODA	Trustee-based Tracing Extensions to Anonymous Cash and the Making of Anonymous Change.	Ernest F. Brickell,Peter Gemmell,David W. Kravitz	1995	Trustee-based Tracing Extensions to Anonymous Cash and the Making of Anonymous Change.	SODA	theory
3435	SODA	On Algorithm Design for Metrical Task Systems.	William R. Burley,Sandy Irani	1995	On Algorithm Design for Metrical Task Systems.	SODA	theory
3436	SODA	Algorithms for Dynamic Closest Pair and n-Body Potential Fields.	Paul B. Callahan,S. Rao Kosaraju	1995	Algorithms for Dynamic Closest Pair and n-Body Potential Fields.	SODA	theory
3437	SODA	Output-Sensitive Construction of Polytopes in Four Dimensions and Clipped Voronoi Diagrams in Three.	Timothy M. Chan,Jack Snoeyink,Chee-Keng Yap	1995	Output-Sensitive Construction of Polytopes in Four Dimensions and Clipped Voronoi Diagrams in Three.	SODA	theory
3438	SODA	Algorithms for the Optimal Loading of Recursive Neural Nets.	Vijay Chandru,Abhi Dattasharma,S. Sathiya Keerthi,N. K. Sancheti,V. Vinay	1995	Algorithms for the Optimal Loading of Recursive Neural Nets.	SODA	theory
3439	SODA	On the All-Pairs Euclidean Short Path Problem.	Danny Z. Chen	1995	On the All-Pairs Euclidean Short Path Problem.	SODA	theory
3440	SODA	Voronoi Diagrams of Lines in 3-Space Under Polyhedral Convex Distance Functions.	L. Paul Chew,Klara Kedem,Micha Sharir,Boaz Tagansky,Emo Welzl	1995	Voronoi Diagrams of Lines in 3-Space Under Polyhedral Convex Distance Functions.	SODA	theory
3441	SODA	External-Memory Graph Algorithms.	Yi-Jen Chiang,Michael T. Goodrich,Edward F. Grove,Roberto Tamassia,Darren Erik Vengroff,Jeffrey Scott Vitter	1995	External-Memory Graph Algorithms.	SODA	theory
3442	SODA	The Statistical Adversary Allows Optimal Money-Making Trading Strategies.	Andrew Chou,Jeremy R. Cooperstock,Ran El-Yaniv,Michael Klugerman,Frank Thomson Leighton	1995	The Statistical Adversary Allows Optimal Money-Making Trading Strategies.	SODA	theory
3443	SODA	An Analysis of Some Heuristics for the Maximum Planar Subgraph Problem.	Robert J. Cimikowski	1995	An Analysis of Some Heuristics for the Maximum Planar Subgraph Problem.	SODA	theory
3444	SODA	Doing Two-Level Logic Minimization 100 Times Faster.	Olivier Coudert	1995	Doing Two-Level Logic Minimization 100 Times Faster.	SODA	theory
3445	SODA	Multiple Translational Containment: Approximate and Exact Algorithms.	Karen L. Daniels,Victor Milenkovic	1995	Multiple Translational Containment: Approximate and Exact Algorithms.	SODA	theory
3446	SODA	A New Way to Weigh Malnourished Euclidean Graphs.	Gautam Das,Giri Narasimhan,Jeffrey S. Salowe	1995	A New Way to Weigh Malnourished Euclidean Graphs.	SODA	theory
3447	SODA	Locally Orientable Graphs, Cell Structures, and a New Algorithm for the Incremental Maintenance of Connectivity Carcasses.	Yefim Dinitz,Alek Vainshtein	1995	Locally Orientable Graphs, Cell Structures, and a New Algorithm for the Incremental Maintenance of Connectivity Carcasses.	SODA	theory
3448	SODA	Selecting the Median.	Dorit Dor,Uri Zwick	1995	Improving a long-standing result of Schönhage, Paterson, and Pippenger [ J. Comput. System Sci., 13 (1976), pp. 184--199] we show that the median of a set containing $n$ elements can always be found using at most $c \cdot n$ comparisons, where c<2.95.	SODA	theory
3449	SODA	Localizing a Robot with Minimum Travel.	Gregory Dudek,Kathleen Romanik,Sue Whitesides	1995	We consider the problem of localizing a robot in a known environment modeled by a simple polygon P. We assume that the robot has a map of P but is placed at an unknown location inside P. From its initial location, the robot sees a set of points called the visibility polygon V of its location. In general, sensing at a single point will not suffice to uniquely localize the robot, since the set H of points in P with visibility polygon V may have more than one element. Hence, the robot must move around and use range sensing and a compass to determine its position (i.e., localize itself). We seek a strategy that minimizes the distance the robot travels to determine its exact location.We show that the problem of localizing a robot with minimum travel is NP-hard. We then give a polynomial time approximation scheme that causes the robot to travel a distance of at most (k - 1)d, where k = |H|, which is no greater than the number of reflex vertices of P, and d is the length of a minimum length tour that would allow the robot to verify its true initial location by sensing. We also show that this bound is the best possible.	SODA	theory
3450	SODA	Efficient Parallel Computations for Singular Band Matrices.	Wayne Eberly	1995	Efficient Parallel Computations for Singular Band Matrices.	SODA	theory
3451	SODA	Subgraph Isomorphism in Planar Graphs and Related Problems.	David Eppstein	1995	Subgraph Isomorphism in Planar Graphs and Related Problems.	SODA	theory
3452	SODA	Lower Bounds for Linear Satisfiability Problems.	Jeff Erickson	1995	Lower Bounds for Linear Satisfiability Problems.	SODA	theory
3453	SODA	On the Entropy of DNA: Algorithms and Measurements Based on Memory and Rapid Convergence.	Martin Farach,Michiel O. Noordewier,Serap A. Savari,Larry A. Shepp,Aaron D. Wyner,Jacob Ziv	1995	On the Entropy of DNA: Algorithms and Measurements Based on Memory and Rapid Convergence.	SODA	theory
3454	SODA	Fast Incremental Text Editing.	Paolo Ferragina,Roberto Grossi	1995	Fast Incremental Text Editing.	SODA	theory
3455	SODA	Optimal One-Way Sorting on a One-Dimensional Sub-Bus Array.	James D. Fix,Richard E. Ladner	1995	Optimal One-Way Sorting on a One-Dimensional Sub-Bus Array.	SODA	theory
3456	SODA	Graph Isomorphism Testing without Numberics for Graphs of Bounded Eigenvalue Multiplicity.	Martin Fürer	1995	Graph Isomorphism Testing without Numberics for Graphs of Bounded Eigenvalue Multiplicity.	SODA	theory
3457	SODA	Broadcast in Radio Networks.	Iris Gaber,Yishay Mansour	1995	Broadcast in Radio Networks.	SODA	theory
3458	SODA	Algorithms for Graphic Polymatroids and Parametric s-Sets.	Harold N. Gabow	1995	Algorithms for Graphic Polymatroids and Parametric s-Sets.	SODA	theory
3459	SODA	Splay Trees for Data Compression.	Dennis Grinberg,Sivaramakrishnan Rajagopalan,Ramarathnam Venkatesan,Victor K. Wei	1995	Splay Trees for Data Compression.	SODA	theory
3460	SODA	Online Bin Packing with Lookahead.	Edward F. Grove	1995	Online Bin Packing with Lookahead.	SODA	theory
3461	SODA	On the Performance of Spectral Graph Partitioning Methods.	Stephen Guattery,Gary L. Miller	1995	On the Performance of Spectral Graph Partitioning Methods.	SODA	theory
3462	SODA	Characterizations of k-Terminal Flow Networks and Computing Network Flows in Partial k-Trees.	Torben Hagerup,Jyrki Katajainen,Naomi Nishimura,Prabhakar Ragde	1995	Characterizations of k-Terminal Flow Networks and Computing Network Flows in Partial k-Trees.	SODA	theory
3463	SODA	Approximating Discrete Collections via Local Improvements.	Magnús M. Halldórsson	1995	Approximating Discrete Collections via Local Improvements.	SODA	theory
3464	SODA	Finding Subsets Maximizing Minimum Structures.	Magnús M. Halldórsson,Kazuo Iwano,Naoki Katoh,Takeshi Tokuyama	1995	We consider the problem of finding a set of k vertices in a graph that are in some sense remote. Stated more formally, given a graph G and an integer k, find a set P of k vertices for which the total weight of a minimum structure on P is maximized. In particular, we are interested in three problems of this type, where the structure to be minimized is a spanning tree ({\sc Remote-MST}), Steiner tree, or traveling salesperson tour.We study a natural greedy algorithm that simultaneously approximates all three problems on metric graphs. For instance, its performance ratio for {\sc Remote-MST} is exactly 4, while this problem is NP-hard to approximate within a factor of less than 2. We also give a better approximation for graphs induced by Euclidean points in the plane, present an exact algorithm for graphs whose distances correspond to shortest-path distances in a tree, and prove hardness and approximability results for general graphs.	SODA	theory
3465	SODA	Morphing Binary Trees.	John Hershberger,Subhash Suri	1995	Morphing Binary Trees.	SODA	theory
3466	SODA	Practical Methods for Approximating Shortest Paths on a Convex Polytope in R.	John Hershberger,Subhash Suri	1995	Practical Methods for Approximating Shortest Paths on a Convex Polytope in R.	SODA	theory
3467	SODA	The Quickest Transshipment Problem.	Bruce Hoppe,Éva Tardos	1995	The Quickest Transshipment Problem.	SODA	theory
3468	SODA	Greedy Dynamic Routing on Arrays.	Nabil Kahale,Frank Thomson Leighton	1995	Greedy Dynamic Routing on Arrays.	SODA	theory
3469	SODA	Improved Interior Point Algorithms for Exact and Approximate Solution of Multicommodity Flow Problems.	Anil Kamath,Omri Palmon	1995	Improved Interior Point Algorithms for Exact and Approximate Solution of Multicommodity Flow Problems.	SODA	theory
3470	SODA	Fast Approximation Algorithm for Minimum Cost Multicommodity Flow.	Anil Kamath,Omri Palmon,Serge A. Plotkin	1995	Minimum-cost multicommodity flow problem is one of the classical optimization problems that arises in a variety of contexts. Applications range from finding optimal ways to route information through communication networks to VLSI layout. In this paper, we describe an efficient deterministic approximation algorithm, which given that there exists a multicommodity flow of cost $B$ that satisfies all the demands, produces a flow of cost at most $(1+\delta)B$ that satisfies $(1-\epsilon)$-fraction of each demand. For constant $\delta$ and $\epsilon$, our algorithm runs in $O^*(kmn^2)$ time, which is an improvement over the previously fastest (deterministic) approximation algorithm for this problem due to Plotkin, Shmoys, and Tardos, that runs in $O^*(k^2m^2)$ time.	SODA	theory
3471	SODA	Register Allocation in Structured Programs.	Sampath Kannan,Todd A. Proebsting	1995	Register Allocation in Structured Programs.	SODA	theory
3472	SODA	Counting and Random Generation of Strings in Regular Languages.	Sampath Kannan,Z. Sweedyk,Stephen R. Mahaney	1995	Counting and Random Generation of Strings in Regular Languages.	SODA	theory
3473	SODA	A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies when the Number of Character States is Fixed.	Sampath Kannan,Tandy Warnow	1995	A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies when the Number of Character States is Fixed.	SODA	theory
3474	SODA	Computing the Local Consensus of Trees.	Sampath Kannan,Tandy Warnow,Shibu Yooseph	1995	The inference of consensus from a set of evolutionary trees is a fundamental problem in a number of fields such as biology and historical linguistics, and many models for inferring this consensus have been proposed. In this paper we present a model for deriving what we call a local consensus tree T from a set of trees ${\cal T}$. The model we propose presumes a function f, called a total local consensus function, which determines for every triple A of species, the form that the local consensus tree should take on A. We show that all local consensus trees, when they exist, can be constructed in polynomial time and that many fundamental problems can be solved in linear time. We also consider partial local consensus functions and study optimization problems under this model. We present linear time algorithms for several variations. Finally we point out that the local consensus approach ties together many previous approaches to constructing consensus trees.	SODA	theory
3475	SODA	Polynomial Methods for Separable Convex Optimization in Unimodular Spaces.	Alexander V. Karzanov,S. Thomas McCormick	1995	Polynomial Methods for Separable Convex Optimization in Unimodular Spaces.	SODA	theory
3476	SODA	Of Mice and Men: Algorithms for Evolutionary Distances Between Genomes with Translocation.	John D. Kececioglu,R. Ravi	1995	Of Mice and Men: Algorithms for Evolutionary Distances Between Genomes with Translocation.	SODA	theory
3477	SODA	Lower Bounds for Identifying Subset Members with Subset Queries.	Emanuel Knill	1995	Lower Bounds for Identifying Subset Members with Subset Queries.	SODA	theory
3478	SODA	Using Network Flows for Surface Modeling.	Rolf H. Möhring,Matthias Müller-Hannemann,Karsten Weihe	1995	Using Network Flows for Surface Modeling.	SODA	theory
3479	SODA	Average-Case Analysis of Off-Line and On-Line Knapsack Problems.	George S. Lueker	1995	Average-Case Analysis of Off-Line and On-Line Knapsack Problems.	SODA	theory
3480	SODA	Adapted Diameters and the Efficient Computation of Fourier Transforms on Finite Groups.	David Keith Maslen,Daniel N. Rockmore	1995	Adapted Diameters and the Efficient Computation of Fourier Transforms on Finite Groups.	SODA	theory
3481	SODA	Chaining Multiple-Alignment Fragments in Sub-Quadratic Time.	Gene Myers,Webb Miller	1995	Chaining Multiple-Alignment Fragments in Sub-Quadratic Time.	SODA	theory
3482	SODA	Computing a Minimum-Weight k-Link Path in Graphs with the Concave Monge Property.	Baruch Schieber	1995	Computing a Minimum-Weight k-Link Path in Graphs with the Concave Monge Property.	SODA	theory
3483	SODA	A Combinatorial Algorithm for Minimizing Symmetric Submodular Functions.	Maurice Queyranne	1995	A Combinatorial Algorithm for Minimizing Symmetric Submodular Functions.	SODA	theory
3484	SODA	Fast Deterministic Approximation for the Multicommodity Flow Problem.	Tomasz Radzik	1995	Fast Deterministic Approximation for the Multicommodity Flow Problem.	SODA	theory
3485	SODA	On the Statistical Dependencies of Coalesced Hashing and Their Implications for Both Full and Limited Independence.	Alan Siegel	1995	On the Statistical Dependencies of Coalesced Hashing and Their Implications for Both Full and Limited Independence.	SODA	theory
3486	SODA	David P. Williamson: An Approximation Algorithm for Minimum-Cost Vertex-Connectivity Problems.	R. Ravi	1995	David P. Williamson: An Approximation Algorithm for Minimum-Cost Vertex-Connectivity Problems.	SODA	theory
3487	SODA	The P-range Tree: A New Data Structure for Range Searching in Secondary Memory.	Sairam Subramanian,Sridhar Ramaswamy	1995	The P-range Tree: A New Data Structure for Range Searching in Secondary Memory.	SODA	theory
3488	SODA	Randomized Rounding Without Solving the Linear Program.	Neal E. Young	1995	Randomized Rounding Without Solving the Linear Program.	SODA	theory
3489	SODA	Finding Optimal Edge-Rankings of Trees.	Xiao Zhou,Takao Nishizeki	1995	Finding Optimal Edge-Rankings of Trees.	SODA	theory
3490	SODA	Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1995. San Francisco, California.	Kenneth L. Clarkson	1995	Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1995. San Francisco, California.	SODA	theory
3491	STOC	Parallel randomized load balancing (Preliminary Version).	Micah Adler,Soumen Chakrabarti,Michael Mitzenmacher,Lars Eilstrup Rasmussen	1995	Parallel randomized load balancing (Preliminary Version).	STOC	theory
3492	STOC	Wait-free made fast (Extended Abstract).	Yehuda Afek,Dalia Dauber,Dan Touitou	1995	Wait-free made fast (Extended Abstract).	STOC	theory
3493	STOC	Motion planning for a steering-constrained robot through moderate obstacles.	Pankaj K. Agarwal,Prabhakar Raghavan,Hisao Tamaki	1995	Motion planning for a steering-constrained robot through moderate obstacles.	STOC	theory
3494	STOC	Distinguishing tests for nondeterministic and probabilistic machines.	Rajeev Alur,Costas Courcoubetis,Mihalis Yannakakis	1995	Distinguishing tests for nondeterministic and probabilistic machines.	STOC	theory
3495	STOC	Computing faces in segment and simplex arrangements (Preliminary Version).	Nancy M. Amato,Michael T. Goodrich,Edgar A. Ramos	1995	Computing faces in segment and simplex arrangements (Preliminary Version).	STOC	theory
3496	STOC	Knowledge on the average-perfect, statistical and logarithmic.	William Aiello,Mihir Bellare,Ramarathnam Venkatesan	1995	Knowledge on the average-perfect, statistical and logarithmic.	STOC	theory
3497	STOC	Sorting in linear time?	Arne Andersson,Torben Hagerup,Stefan Nilsson,Rajeev Raman	1995	Sorting in linear time?	STOC	theory
3498	STOC	A tight lower bound for searching a sorted array.	Arne Andersson,Johan Håstad,Ola Petersson	1995	A tight lower bound for searching a sorted array.	STOC	theory
3499	STOC	Polynomial time approximation schemes for dense instances of -hard problems.	Sanjeev Arora,David R. Karger,Marek Karpinski	1995	Polynomial time approximation schemes for dense instances of -hard problems.	STOC	theory
3500	STOC	Euclidean spanners: short, thin, and lanky.	Sunil Arya,Gautam Das,David M. Mount,Jeffrey S. Salowe,Michiel H. M. Smid	1995	Euclidean spanners: short, thin, and lanky.	STOC	theory
3501	STOC	Improved approximation guarantees for minimum-weight -trees and prize-collecting salesmen.	Baruch Awerbuch,Yossi Azar,Avrim Blum,Santosh Vempala	1995	Consider a salesperson that must sell some quota of brushes in order to win a trip to Hawaii. This salesperson has a map (a weighted graph) in which each city has an attached demand specifying the number of brushes that can be sold in that city. What is the best route to take to sell the quota while traveling the least distance possible? Notice that unlike the standard traveling salesman problem, not only do we need to figure out the order in which to visit the cities, but we must decide the more fundamental question: which cities do we want to visit? In this paper we give the first approximation algorithms with poly-logarithmic performance guarantees for this problem, as well as for the slightly more general PCTSP problem of Balas, and a variation we call the bank-robber problem (also called the orienteering problem by Golden, Levi, and Vohra). We do this by providing an O(log^2 k) approximation to the k-MST problem which is defined as follows. Given an undirected graph on n nodes with non-negative edge weights and an integer k > n, find the tree of least weight that spans k vertices. (If desired, one may specify in the problem a root vertex that must be in the tree as well.) Our result improves on the previous best bound of O(k^0.5) of Ravi et al. and comes quite close to the bound of O(log k) of Garg and Hochbaum for the special case of points in 2-dimensional Euclidean space.	STOC	theory
3502	STOC	Bandwidth allocation with preemption.	Amotz Bar-Noy,Ran Canetti,Shay Kutten,Yishay Mansour,Baruch Schieber	1995	Bandwidth allocation is a fundamental problem in the design of networks where bandwidth has to be reserved for connections in advance. The problem is intensified when the requested bandwidth exceeds the capacity and not all requests can be served. Furthermore, acceptance/rejection decisions regarding connections have to be made on-line, without knowledge of future requests. We show that the ability to preempt (i.e., abort) connections while in service in order to be able to schedule ``more valuable'''' connections substantially improves the overall throughput of some networks. We present bandwidth allocation strategies that use preemption and show that they achieve constant competiveness with respect to the throughput, given that any single call occupies only a constant fraction of the bandwidth. Our results should be contrasted with recent works showing that nonpreemptive strategies have at most logarithmic competitiveness.	STOC	theory
3503	STOC	More on the complexity of negation-limited circuits.	Robert Beals,Tetsuro Nishino,Keisuke Tanaka	1995	More on the complexity of negation-limited circuits.	STOC	theory
3504	STOC	The relative complexity of NP search problems.	Paul Beame,Stephen A. Cook,Jeff Edmonds,Russell Impagliazzo,Toniann Pitassi	1995	The relative complexity of NP search problems.	STOC	theory
3505	STOC	Incremental cryptography and application to virus protection.	Mihir Bellare,Oded Goldreich,Shafi Goldwasser	1995	Incremental cryptography and application to virus protection.	STOC	theory
3506	STOC	Provably secure session key distribution: the three party case.	Mihir Bellare,Phillip Rogaway	1995	Provably secure session key distribution: the three party case.	STOC	theory
3507	STOC	A constant-factor approximation for the -MST problem in the plane.	Avrim Blum,Prasad Chalasani,Santosh Vempala	1995	A constant-factor approximation for the -MST problem in the plane.	STOC	theory
3508	STOC	Lower bounds for cutting planes proofs with small coefficients.	Maria Luisa Bonet,Toniann Pitassi,Ran Raz	1995	Lower bounds for cutting planes proofs with small coefficients.	STOC	theory
3509	STOC	The k-Steiner ratio in graphs.	Al Borchers,Ding-Zhu Du	1995	A Steiner minimum tree (SMT) is the shortest-length tree in a metric space interconnecting a set of points, called the regular points, possibly using additional vertices. A k-size Steiner minimum tree (kSMT) is one that can be split into components where all regular points are leaves and all components have at most k leaves. The k-Steiner ratio, $\rho_{k}$, is the infimum of the ratios SMT/kSMT over all finite sets of regular points in all possible metric spaces, where the distances are given by a complete graph. Previously, only $\rho_{2}$ and $\rho_{3}$ were known exactly in graphs, and some bounds were known for other values of k. In this paper, we determine $\rho_{k}$ exactly for all k. From this we prove a better approximation ratio for the Steiner tree problem in graphs.	STOC	theory
3510	STOC	On the Fourier spectrum of monotone functions (Extended Abstract).	Nader H. Bshouty,Christino Tamon	1995	On the Fourier spectrum of monotone functions (Extended Abstract).	STOC	theory
3511	STOC	Bounding the power of preemption in randomized scheduling.	Ran Canetti,Sandy Irani	1995	We study on-line scheduling in overloaded systems. Requests for jobs arrive one by one as time proceeds; the serving agents have limited capacity and not all requests can be served. Still, we want to serve the best set of requests according to some criterion. In this situation, the ability to preempt (i.e., abort) jobs in service in order to make room for better jobs that would otherwise be rejected has proven to be of great help in some scenarios. We show that, surprisingly, in many other scenarios this is not the case. In a simple, generic model, we prove a polylogarithmic lower bound on the competitiveness of randomized and preemptive on-line scheduling algorithms. Our bound applies to several recently studied problems. In fact, in certain scenarios our bound is quite close to the competitiveness achieved by known deterministic, nonpreemptive algorithms.	STOC	theory
3512	STOC	Lower bounds for off-line range searching.	Bernard Chazelle	1995	Lower bounds for off-line range searching.	STOC	theory
3513	STOC	On real Turing machines that toss coins.	Felipe Cucker,Marek Karpinski,Pascal Koiran,Thomas Lickteig,Kai Werther	1995	On real Turing machines that toss coins.	STOC	theory
3514	STOC	Work-time-optimal parallel algorithms for string problems.	Artur Czumaj,Zvi Galil,Leszek Gasieniec,Kunsoo Park,Wojciech Plandowski	1995	Work-time-optimal parallel algorithms for string problems.	STOC	theory
3515	STOC	What do we know about the Metropolis algorithm?	Persi Diaconis,Laurent Saloff-Coste	1995	What do we know about the Metropolis algorithm?	STOC	theory
3516	STOC	A 2-level cactus model for the system of minimum and minimum+1 edge-cuts in a graph and its incremental maintenance.	Yefim Dinitz,Zeev Nutov	1995	A 2-level cactus model for the system of minimum and minimum+1 edge-cuts in a graph and its incremental maintenance.	STOC	theory
3517	STOC	Bubbles: adaptive routing scheme for high-speed dynamic networks (Extended Abstract).	Shlomi Dolev,Evangelos Kranakis,Danny Krizanc,David Peleg	1995	Bubbles: adaptive routing scheme for high-speed dynamic networks (Extended Abstract).	STOC	theory
3518	STOC	A nearly optimal time-space lower bound for directed -connectivity on the NNJAG model.	Jeff Edmonds,Chung Keung Poon	1995	A nearly optimal time-space lower bound for directed -connectivity on the NNJAG model.	STOC	theory
3519	STOC	Geometric lower bounds for parametric matroid optimization.	David Eppstein	1995	Geometric lower bounds for parametric matroid optimization.	STOC	theory
3520	STOC	Testing multivariate linear functions: overcoming the generator bottleneck.	Funda Ergün	1995	The problem of testing program correctness has received considerable attention in computer science. One approach to this problem is the notion of self-testing programs \cite{BlumLubyRubinfeld}. Self-testing usually becomes more costly in the case of testing multivariate functions. In this paper we present efficient methods for self-testing multivariate linear functions. We then apply these methods to several multivariate linear problems to construct efficient self-testers.	STOC	theory
3521	STOC	String matching in Lempel-Ziv compressed strings.	Martin Farach,Mikkel Thorup	1995	String matching in Lempel-Ziv compressed strings.	STOC	theory
3522	STOC	Randomized graph products, chromatic numbers, and Lovasz theta-function.	Uriel Feige	1995	Randomized graph products, chromatic numbers, and Lovasz theta-function.	STOC	theory
3523	STOC	Impossibility results for recycling random bits in two-prover proof systems.	Uriel Feige,Joe Kilian	1995	Impossibility results for recycling random bits in two-prover proof systems.	STOC	theory
3524	STOC	A fully-dynamic data structure for external substring search (Extended Abstract).	Paolo Ferragina,Roberto Grossi	1995	A fully-dynamic data structure for external substring search (Extended Abstract).	STOC	theory
3525	STOC	Randomized and multipointer paging with locality of reference.	Amos Fiat,Anna R. Karlin	1995	Randomized and multipointer paging with locality of reference.	STOC	theory
3526	STOC	Secure hypergraphs: privacy from partial broadcast (Extended Abstract).	Matthew K. Franklin,Moti Yung	1995	Secure hypergraphs: privacy from partial broadcast (Extended Abstract).	STOC	theory
3527	STOC	Short length versions of Menger's theorem (Extended Abstract).	Zvi Galil,Xiangdong Yu	1995	Short length versions of Menger's theorem (Extended Abstract).	STOC	theory
3528	STOC	Tight analyses of two local load balancing algorithms.	Bhaskar Ghosh,Frank Thomson Leighton,Bruce M. Maggs,S. Muthukrishnan,C. Greg Plaxton,Rajmohan Rajaraman,Andréa W. Richa,Robert Endre Tarjan,David Zuckerman	1995	This paper presents an analysis of the following load balancing algorithm. At each step, each node in a network examines the number of tokens at each of its neighbors and sends a token to each neighbor with at least 2d+1 fewer tokens, where d is the maximum degree of any node in the network. We show that within $O(\Delta / \alpha)$ steps, the algorithm reduces the maximum difference in tokens between any two nodes to at most $O((d^2 \log n)/\alpha)$, where $\Delta$ is the global imbalance in tokens (i.e., the maximum difference between the number of tokens at any node initially and the average number of tokens), n is the number of nodes in the network, and $\alpha$ is the edge expansion of the network. The time bound is tight in the sense that for any graph with edge expansion $\alpha$, and for any value $\Delta$, there exists an initial distribution of tokens with imbalance $\Delta$ for which the time to reduce the imbalance to even $\Delta/2$ is at least $\Omega(\Delta/\alpha)$. The bound on the final imbalance is tight in the sense that there exists a class of networks that can be locally balanced everywhere (i.e., the maximum difference in tokens between any two neighbors is at most 2d), while the global imbalance remains $\Omega((d^2 \log n) / \alpha)$. Furthermore, we show that upon reaching a state with a global imbalance of $O((d^2 \log n)/\alpha)$, the time for this algorithm to locally balance the network can be as large as $\Omega(n^{1/2})$. We extend our analysis to a variant of this algorithm for dynamic and asynchronous networks. We also present tight bounds for a randomized algorithm in which each node sends at most one token in each step.	STOC	theory
3529	STOC	Monotone circuits for connectivity have depth (log n) (Extended Abstract).	Mikael Goldmann,Johan Håstad	1995	Monotone circuits for connectivity have depth (log n) (Extended Abstract).	STOC	theory
3530	STOC	Descriptive complexity theory over the real numbers.	Erich Grädel,Klaus Meer	1995	Descriptive complexity theory over the real numbers.	STOC	theory
3531	STOC	Transforming cabbage into turnip: polynomial algorithm for sorting signed permutations by reversals.	Sridhar Hannenhalli,Pavel A. Pevzner	1995	Genomes frequently evolve by reversals &rgr;(i,j) that transform a gene order &pgr;1 &hellip; &pgr;i&pgr;i+1 &hellip; &pgr;j-1&pgr;j &hellip; &pgr;n into &pgr;1 &hellip; &pgr;i&pgr;j-1 &hellip; &pgr;i+1&pgr;j &hellip; &pgr;n. Reversal distance between permutations &pgr; and &sgr;is the minimum number of reversals to transform &pgr; into &Agr;. Analysis of genome rearrangements in molecular biology started in the late 1930's, when Dobzhansky and Sturtevant published a milestone paper presenting a rearrangement scenario with 17 inversions between the species of Drosophilia. Analysis of genomes evolving by inversions leads to a combinatorial problem of sorting by reversals studied in detail recently. We study sorting of signed permutations by reversals, a problem that adequately models rearrangements in a small genomes like chloroplast or mitochondrial DNA. The previously suggested approximation algorithms for sorting signed permutations by reversals compute the reversal distance between permutations with an astonishing accuracy for both simulated and biological data. We prove a duality theorem explaining this intriguing performance and show that there exists a &ldquo;hidden&rdquo; parameter that allows one to compute the reversal distance between signed permutations in polynomial time.	STOC	theory
3532	STOC	Bounding delays in packet-routing networks.	Mor Harchol-Balter,David Wolfe	1995	Bounding delays in packet-routing networks.	STOC	theory
3533	STOC	Fast protein folding in the hydrophobic-hydrophilic model within three-eights of optimal (Extended Abstract).	William E. Hart,Sorin Istrail	1995	Fast protein folding in the hydrophobic-hydrophilic model within three-eights of optimal (Extended Abstract).	STOC	theory
3534	STOC	How many queries are needed to learn?	Lisa Hellerstein,Krishnan Pillaipakkamnatt,Vijay V. Raghavan,Dawn Wilkins	1995	We investigate the query complexity of exact learning in the membership and (proper) equivalence query model. We give a complete characterization of concept classes that are learnable with a polynomial number of polynomial sized queries in this model. We give applications of this characterization, including results on learning a natural subclass of DNF formulas, and on learning with membership queries alone. Query complexity has previously been used to prove lower bounds on the time complexity of exact learning. We show a new relationship between query complexity and time complexity in exact learning: If any &ldquo;honest&rdquo; class is exactly and properly learnable with polynomial query complexity, but not learnable in polynomial time, then P = NP. In particular, we show that an honest class is exactly polynomial-query learnable if and only if it is learnable using an oracle for &Ggr;p4.	STOC	theory
3535	STOC	Randomized dynamic graph algorithms with polylogarithmic time per operation.	Monika Rauch Henzinger,Valerie King	1995	Randomized dynamic graph algorithms with polylogarithmic time per operation.	STOC	theory
3536	STOC	What's decidable about hybrid automata?	Thomas A. Henzinger,Peter W. Kopke,Anuj Puri,Pravin Varaiya	1995	Hybrid automata model systems with both digital and analog components, such as embedded control programs. Many verification tasks for such programs can be expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachability problem for hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes. Our algorithm is based on the construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton. The translation has practical significance for verification, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular automata. The translation also preserves the $\omega$-languages of initialized rectangular automata with bounded nondeterminism. On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an undecidable reachability problem. In particular, we prove that the reachability problem is undecidable for timed automata augmented with a single stopwatch.	STOC	theory
3537	STOC	Lower bounds for sorting networks.	Nabil Kahale,Frank Thomson Leighton,Yuan Ma,C. Greg Plaxton,Torsten Suel,Endre Szemerédi	1995	Lower bounds for sorting networks.	STOC	theory
3538	STOC	Subquadratic-time factoring of polynomials over finite fields.	Erich Kaltofen,Victor Shoup	1995	Subquadratic-time factoring of polynomials over finite fields.	STOC	theory
3539	STOC	Persistent lists with catenation via recursive slow-down.	Haim Kaplan,Robert Endre Tarjan	1995	Persistent lists with catenation via recursive slow-down.	STOC	theory
3540	STOC	A randomized fully polynomial time approximation scheme for the all terminal network reliability problem.	David R. Karger	1995	The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures. This problem has obvious applications in the design of communication networks. Since the problem is ${\sharp {\cal P}}$-complete and thus believed hard to solve exactly, a great deal of research has been devoted to estimating the failure probability. In this paper, we give a fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and $1/\epsilon$ an estimate for the failure probability that is accurate to within a relative error of $1\pm\epsilon$ with high probability. We also give a deterministic polynomial approximation scheme for the case of small failure probabilities. Some extensions to evaluating probabilities of $k$-connectivity, strong connectivity in directed Eulerian graphs and $r$-way disconnection, and to evaluating the Tutte polynomial are also described. This version of the paper corrects several errata that appeared in the previous journal publication [D. R. Karger, SIAM J. Comput., 29 (1999), pp. 492--514].	STOC	theory
3541	STOC	Adding multiple cost constraints to combinatorial optimization problems, with applications to multicommodity flows.	David R. Karger,Serge A. Plotkin	1995	Adding multiple cost constraints to combinatorial optimization problems, with applications to multicommodity flows.	STOC	theory
3542	STOC	Polynomial bounds for VC dimension of sigmoidal neural networks.	Marek Karpinski,Angus Macintyre	1995	We introduce a new method for proving explicit upper bounds on the VC Dimension of general functional basis networks, and prove as an application, for the first time, the VC Dimension of analog neural networks with the sigmoid activation function $\sigma(y)=1/1+e^{-y}$ to be bounded by a quadratic polynomial in the number of programmable parameters.	STOC	theory
3543	STOC	Randomized query processing in robot path planning (Extended Abstract).	Lydia E. Kavraki,Jean-Claude Latombe,Rajeev Motwani,Prabhakar Raghavan	1995	Randomized query processing in robot path planning (Extended Abstract).	STOC	theory
3544	STOC	Improved approximation algorithms for uniform connectivity problems.	Samir Khuller,Balaji Raghavachari	1995	Improved approximation algorithms for uniform connectivity problems.	STOC	theory
3545	STOC	Additive versus exponentiated gradient updates for linear prediction.	Jyrki Kivinen,Manfred K. Warmuth	1995	Additive versus exponentiated gradient updates for linear prediction.	STOC	theory
3546	STOC	Approximations for the disjoint paths problem in high-diameter planar networks.	Jon M. Kleinberg,Éva Tardos	1995	Approximations for the disjoint paths problem in high-diameter planar networks.	STOC	theory
3547	STOC	Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros.	Victor Y. Pan	1995	Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros.	STOC	theory
3548	STOC	Large-scale assembly of DNA strings and space-efficient construction of suffix trees.	S. Rao Kosaraju,Arthur L. Delcher	1995	Large-scale assembly of DNA strings and space-efficient construction of suffix trees.	STOC	theory
3549	STOC	On randomized one-round communication complexity.	Ilan Kremer,Noam Nisan,Dana Ron	1995	On randomized one-round communication complexity.	STOC	theory
3550	STOC	Log-space polynomial end-to-end communication.	Eyal Kushilevitz,Rafail Ostrovsky,Adi Rosén	1995	Communication between processors is the essence of distributed computing: clearly, without communication, distributed computation is impossible. However, as networks become larger and larger, the frequency of link failures increases. The end-to-end communication problem asks how to efficiently carry out fault-free communication between two processors over a network, in spite of such frequent link failures. The sole minimum assumption is that the two processors that are trying to communicate are not permanently disconnected (i.e., the communication should proceed even when there does not (ever) simultaneously exist an operational path between the two processors that are trying to communicate).We present a protocol to solve the end-to-end problem with logarithmic-space and polynomial communication at the same time. This is an exponential memory improvement to all previous polynomial communication solutions. That is, all previous polynomial communication solutions needed at least linear (in n, the size of the network) amount of memory per link.Our protocol transfers packets over the network, maintains a simple-to-compute O(log n)-bits potential function at each link in order to perform routing, and uses a novel technique of packet canceling which allows us to keep only one packet per link. The computations of both our potential function and our packet-canceling policy are totally local in nature.	STOC	theory
3551	STOC	Efficient stopping rules for Markov chains.	László Lovász,Peter Winkler	1995	Efficient stopping rules for Markov chains.	STOC	theory
3552	STOC	Many-to-one packet routing on grids (Extended Abstract).	Yishay Mansour,Boaz Patt-Shamir	1995	Many-to-one packet routing on grids (Extended Abstract).	STOC	theory
3553	STOC	A Delaunay based numerical method for three dimensions: generation, formulation, and partition.	Gary L. Miller,Dafna Talmor,Shang-Hua Teng,Noel Walkington	1995	A Delaunay based numerical method for three dimensions: generation, formulation, and partition.	STOC	theory
3554	STOC	On data structures and asymmetric communication complexity.	Peter Bro Miltersen,Noam Nisan,Shmuel Safra,Avi Wigderson	1995	On data structures and asymmetric communication complexity.	STOC	theory
3555	STOC	Symmetric logspace is closed under complement.	Noam Nisan,Amnon Ta-Shma	1995	We present a Logspace, many-one reduction from the undirected s-t connectivity problem to its complement. This shows that SL=coSL.	STOC	theory
3556	STOC	On the complexity of bilinear forms: dedicated to the memory of Jacques Morgenstern.	Noam Nisan,Avi Wigderson	1995	On the complexity of bilinear forms: dedicated to the memory of Jacques Morgenstern.	STOC	theory
3557	STOC	A lower bound for integer multiplication with read-once branching programs.	Stephen Ponzio	1995	We prove that read-once branching programs computing integer multiplication require size $2^{\Omega(\sqrt{n})}$. This is the first nontrivial lower bound for multiplication on branching programs that are not oblivious. By the appropriate problem reductions, we obtain the same lower bound for other arithmetic functions.	STOC	theory
3558	STOC	Two Steiner tree packing problems (Extended Abstract).	William R. Pulleyblank	1995	Two Steiner tree packing problems (Extended Abstract).	STOC	theory
3559	STOC	A computational view of population genetics.	Yuval Rabani,Yuri Rabinovich,Alistair Sinclair	1995	A computational view of population genetics.	STOC	theory
3560	STOC	Stochastic contention resolution with short delays.	Prabhakar Raghavan,Eli Upfal	1995	We study contention resolution protocols under a stochastic model of continuous request generation from a set of contenders. The performance of such a protocol is characterized by two parameters: the maximum arrival rate for which the protocol is stable and the expected delay of a request from arrival to service. Known solutions are either unstable for any constant injection rate, or have polynomial (in the number of contenders) expected delay. Our main contribution is a protocol that is stable for a constant injection rate, while achieving logarithmic expected delay. We extend our results to the case of multiple servers, with each request being targeted for a specific server. This is related to the optically connected parallel computer (or OCPC ) model. Finally, we prove a lower bound showing that long delays are inevitable in a class of protocols including backoff-style protocols, if the arrival rate is large enough (but still smaller than 1).	STOC	theory
3561	STOC	Recognition of graphs with threshold dimension two.	Thomas Raschle,Klaus Simon	1995	Recognition of graphs with threshold dimension two.	STOC	theory
3562	STOC	A parallel repetition theorem.	Ran Raz	1995	We show that a parallel repetition of any two-prover one-round proof system (MIP(2,1)) decreases the probability of error at an exponential rate. No constructive bound was previously known. The constant in the exponent (in our analysis) depends only on the original probability of error and on the total number of possible answers of the two provers. The dependency on the total number of possible answers is logarithmic, which was recently proved to be almost the best possible [U. Feige and O. Verbitsky, Proc.11th Annual IEEE Conference on Computational Complexity, IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 70--76].	STOC	theory
3563	STOC	Work efficient parallel solution of Toeplitz systems and polynomial GCD.	John H. Reif	1995	Work efficient parallel solution of Toeplitz systems and polynomial GCD.	STOC	theory
3564	STOC	Explicit dispersers with polylog degree.	Michael E. Saks,Aravind Srinivasan,Shiyu Zhou	1995	Explicit dispersers with polylog degree.	STOC	theory
3565	STOC	Linear-time encodable and decodable error-correcting codes.	Daniel A. Spielman	1995	Linear-time encodable and decodable error-correcting codes.	STOC	theory
3566	STOC	Improved approximations of packing and covering problems.	Aravind Srinivasan	1995	Improved approximations of packing and covering problems.	STOC	theory
3567	STOC	Average-case completeness of a word problem for groups.	Jie Wang	1995	Average-case completeness of a word problem for groups.	STOC	theory
3568	STOC	Security of quantum protocols against coherent measurements.	Andrew Chi-Chih Yao	1995	Security of quantum protocols against coherent measurements.	STOC	theory
3569	STOC	Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, 29 May-1 June 1995, Las Vegas, Nevada, USA		1995	Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, 29 May-1 June 1995, Las Vegas, Nevada, USA	STOC	theory
3570	ICCV	Active Fixation Using Attentional Shifts, Affine Resampling, and Multiresolution Search.	A. Lynn Abbott,Bibo Zheng	1995	Presents a new approach for fixing two cameras at a single location in a 3D scene. Fixation requires the detection of binocular disparity for a single point of interest in the scene so that vergence control can reduce that disparity to zero. Most existing systems use area-based matching, since feature-based matching is computationally prohibitive. Unfortunately, the area-based approach does not perform well when confronted with steeply inclined surfaces, occlusions, repeating patterns or featureless image regions. The method presented in this paper utilizes attentional shifts and affine resampling to combat these problems. These are integrated with adaptive window-size control and coarse-to-fine correlation-based searching. The effectiveness of the approach for complex scenes is demonstrated with several stereo image pairs.	ICCV	visu
3571	ICCV	Tracking and Recognizing Rigid and Non-Rigid Facial Motions Using Local Parametric Models of Image Motion.	Michael J. Black,Yaser Yacoob	1995	This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences.	ICCV	visu
3572	ICCV	Reconstructing Complex Surfaces from Multiple Stereo Views.	Pascal Fua	1995	We present a framework for 3D surface reconstruction that can be used to model fully 3 dimensional scenes from an arbitrary number of stereo views. Taken from vastly different viewpoints. This is a key step toward producing 3D world descriptions of complex scenes using stereo and is a very challenging problem: real world scenes tend to contain many 3D objects, they do not usually conform to the 2-1/2D assumption made by traditional algorithms, and one cannot take it for granted that the computed 3D points can easily be clustered into separate groups. By combining a particle based representation, robust fitting, and optimization of an image based objective function, we have been able to reconstruct surfaces without any a priori knowledge of their topology and in spite of the noisiness of the stereo data. Our current implementation goes through three steps-initializing a set of particles from the input 3D data, optimizing their location, and finally grouping them into global surfaces. Using several complex scenes containing multiple objects, we demonstrate its competence and ability to merge information and thus to go beyond what can be done with conventional stereo alone.	ICCV	visu
3573	ICCV	Epipole and Fundamental Matrix Estimation Using Virtual Parallax.	Boubakeur Boufama-Seddik,Roger Mohr	1995	The paper addresses the problem of computing the fundamental matrix which describes a geometric relationship between a pair of stereo images: the epipolar geometry. We propose a novel method based on virtual parallax. Instead of computing directly the 3/spl times/3 fundamental matrix, we compute a homography with one epipole position, and show that this is equivalent to computing the fundamental matrix. Simple equations are derived by reducing the number of parameters to estimate. As a consequence, we obtain an accurate fundamental matrix of rank two with a stable linear computation. Experiments with simulated and real images validate our method and clearly show the improvement over existing methods.	ICCV	visu
3574	ICCV	Seeing Behind the Scene: Analysis of Photometric Properties of Occluding Edges by the Reversed Projection Blurring Model.	Naoki Asada,Hisanaga Fujiwara,Takashi Matsuyama	1995	This paper analyzes photometric properties of occluding edges and proves that (1) we can observe surface edges on the farther object located close to the occluding edge even if they are occluded by the nearer object, (2) the image of an occluding edge coincides with that of a surface edge on the nearer object if the brightness of the farther object is uniform around the occluding edge. First, we propose a blurring model named the reversed projection blurring model to analyze photometric properties of blurring phenomena of an occluding edge. Using this model, the theoretical proof of the two properties mentioned above is given. Finally, experimental results in real world environments demonstrate the validity of our blurring model as well as the observability of the photometric properties of occluding edges.	ICCV	visu
3575	ICCV	Visual Navigation Using a Single Camera.	Jean-Yves Bouguet,Pietro Perona	1995	We assess the usefulness of monocular recursive motion estimation techniques for vehicle navigation in the absence of a model for the environment. For this purpose we extend a recently proposed recursive motion estimator, the Essential filter, to handle scale estimation. We examine experimentally the accuracy with which the motion and position of the vehicle may be computed on an 8000 frame indoors sequence. The issues of sampling time frequency and number of necessary features in the environment are addressed systematically.	ICCV	visu
3576	ICCV	Layered Representation of Motion Video Using Robust Maximum-Likelihood Estimation of Mixture Models and MDL Encoding.	Serge Ayer,Harpreet S. Sawhney	1995	Representing and modeling the motion and spatial support of multiple objects and surfaces from motion video sequences is an important intermediate step towards dynamic image understanding. One such representation, called layered representation, has recently been proposed. Although a number of algorithms have been developed for computing these representations, there has not been a consolidated effort into developing a precise mathematical formulation of the problem. This paper presents one such formulation based on maximum likelihood estimation (MLE) of mixture models and the minimum description length (MDL) encoding principle. The three major issues in layered motion representation are: (i) how many motion models adequately describe image motion, (ii) what are the motion model parameters, and (iii) what is the spatial support layer for each motion model.	ICCV	visu
3577	ICCV	Scale-Space from Nonlinear Filters.	J. Andrew Bangham,Paul D. Ling,Richard Harvey	1995	Decomposition by extrema is put into the context of linear vision systems and scale-space. One dimensional discrete M- and N-sieves neither introduce new edges as the scale increases nor create new extrema. They share this property with diffusion based filters. Furthermore M- and N-sieve algorithms are extremely fast with order complexity n. Used to decompose an image, the resulting granularity is appropriate for pattern recognition.	ICCV	visu
3578	ICCV	Nonlinear Manifold Learning for Visual Speech Recognition.	Christoph Bregler,Stephen M. Omohundro	1995	A technique for representing and learning smooth nonlinear manifolds is presented and applied to several lip reading tasks. Given a set of points drawn from a smooth manifold in an abstract feature space, the technique is capable of determining the structure of the surface and of finding the closest manifold point to a given query point. We use this technique to learn the space of lips in a visual speech recognition task. The learned manifold is used for tracking and extracting the lips, for interpolating between frames in an image sequence and for providing features for recognition. We describe a system based on hidden Markov models and this learned lip manifold that significantly improves the performance of acoustic speech recognizers in degraded environments. We also present preliminary results on a purely visual lip reader.	ICCV	visu
3579	ICCV	Region Tracking through Image Sequences.	Benedicte Bascle,Rachid Deriche	1995	The paper describes an approach to the tracking of complex shapes through image sequences, that combines deformable region models and deformable contours. A deformable region model is presented: its optimisation is based on texture correlation and is constrained by the use of a motion model, such as rigid, affine or homographic. The use of texture information (versus edge information) noticeably improves the tracking performances of deformable models in the presence of texture. Then the region contour is refined using an edge based deformable model in order to better deal with specularities, non planar objects and occlusions. The method is illustrated and validated by experimental results on real images.	ICCV	visu
3580	ICCV	Electronically Directed Focal Stereo.	Peter J. Burt,Lambert E. Wixson,Garbis Salgian	1995	A key to developing computationally efficient stereo vision is the incorporation of intelligent control. Stereo is most effective when it is able to focus its analysis on regions and details of a scene that are important to the task at hand, while avoiding less important regions and unnecessary detail. The paper describes two methods for electronically focusing stereo measurement through simple image pre-processing. The first allows measurement sensitivity to be adjusted. The second allows the shape of the 3D region in which measurements are gathered to be matched to the shape of surfaces in the scene.	ICCV	visu
3581	ICCV	Recognition Using Region Correspondences.	Ronen Basri,David W. Jacobs	1995	Recognition systems attempt to recover information about the identity of the observed objects and their location in the environment. A fundamental problem in recognition is the following. Given a correspondence between some portions of an object model and some portions of an image, determine whether the image contains an instance of the object, and, in case it does, determine the transformation that relates the model to the image. The current approaches to this problem are divided into methods that use ``global'''' properties of the object (e.g., centroid and moments of inertia) and methods that use ``local'''' properties of the object (e.g., corners and line segments). Global properties are sensitive to occlusion and, specifically, to self occlusion. Local properties are difficult to locate reliably, and their matching involves intensive computation. A novel method for recognition that uses region information is presented. In our approach the model is divided into volumes, and the image is divided into regions. Given a match between subsets of volumes and regions (without any explicit correspondence between different pieces of the regions) the alignment transformation is computed. The method applies to planar objects under similarity, affine, and projective transformations and to projections of 3-D objects undergoing affine and projective transformations. The new approach combines many of the advantages of the previous two approaches, while avoiding some of their pitfalls. Like the global methods, our approach makes use of region information that reflects the true shape of the object. But like local methods, our approach can handle occlusion.	ICCV	visu
3582	ICCV	Recognition of Human Body Motion Using Phase Space Constraints.	Lee W. Campbell,Aaron F. Bobick	1995	A new method for representing and recognizing human body movements is presented. The basic idea is to identify sets of constraints that are diagnostic of a movement: expressed using body-centered coordinates such as joint angles and in force only during a particular movement. Assuming the availability of Cartesian tracking data, we develop techniques for a representation of movements defined by space curves in subspaces of a phase space. The phase space has axes of joint angles and torso location and attitude, and the axes of the subspaces are subsets of the axes of the phase space. Using this representation we develop a system for learning new movements from ground truth data by searching for constraints. We then use the learned representation for recognizing movements in unsegmented data. We train and test the system on nine fundamental steps from classical ballet performed by two dancers; the system accurately recognizes the movements in the unsegmented stream of motion.	ICCV	visu
3583	ICCV	Head-Eye Calibration.	Mengxiang Li,Demetrios Betsis	1995	We deal with the calibration problem of an active head-eye system, which consists of a pair of cameras mounted on a head with 13 degrees of freedom. The aim of the calibration is to establish relative positions of different 3D systems: between camera and neck, eye and neck, etc., so that we can keep track of the camera position in a fixed (calibration) reference system as a function of the visual parameters of the head-eye system. We formulate the problem and propose both closed-form and nonlinear optimization approaches to solve it. Experiments were carried out and comparison of results with other algorithms were made on both simulated and real data.	ICCV	visu
3584	ICCV	Active Visual Navigation Using Non-Metric Structure.	Paul A. Beardsley,Ian D. Reid,Andrew Zisserman,David W. Murray	1995	Demonstrates a method of using nonmetric visual information derived from an uncalibrated active vision system to navigate an autonomous vehicle through free-space regions detected in a cluttered environment. The structure of 3-space is recovered modulo an affine transformation using an uncalibrated active stereo head carried by the vehicle. The plane at infinity, necessary for recovering affine structure from projective structure, is found in a novel manner by making controlled rotations of the head. The structure is composed of 3D points obtained by detecting and matching image corners through the stereo image sequence. Considerable care has been taken to ensure that the processing is reliable, robust and automatic. Driveable regions are determined from the projection of the affine structure onto a plane parallel to the ground determined using projective constructs. Two methods of negotiating the regions are explored. The first introduces metric information to allow control of a Euclidean vehicle. The second uses visual servoing of the active head to navigate in the affinely described free-space regions.	ICCV	visu
3585	ICCV	Learning Geometric Hashing Functions for Model-Based Object Recognition.	George Bebis,Michael Georgiopoulos,Niels da Vitoria Lobo	1995	A major problem associated with geometric hashing and methods which have emerged from it is the non-uniform distribution of invariants over the hash space. This problem can affect the performance of the method significantly. Finding a good geometric hash function which redistributes the invariants uniformly over the hash space is not easy. In this paper, a new approach is proposed for alleviating the above problem. It is based on the use of an elastic hash table which is implemented as a self-organizing feature map neural network (SOFM-NN). In contrast to existing approaches which try to redistribute the invariants over the hash bins, we proceed oppositely, spreading the hash bins over the invariants. During training, the SOFM-NN resembles an elastic net which deforms over the hash space. The objective of the deformation process is to spread more hash bins in hash space areas which are heavily occupied and less hash bins in lower density areas. The advantage of the proposed approach is that it is a process that adapts to the invariants through learning. Hence, it makes absolutely no assumptions about the statistical characteristics of the invariants and the geometric hash function is actually computed through learning. Furthermore, the well known topology preserving property of the SOFM-NN guarantees that the computed geometric hash function should be well behaved. Finally, the proposed approach is inherently parallelizable.	ICCV	visu
3586	ICCV	Recovering Object Surfaces from Viewed Changes in Surface Texture Patterns.	Peter N. Belhumeur,Alan L. Yuille	1995	Explores the reconstruction of object surfaces from viewed changes in surface texture patterns. Our approach differs from those in the past in that instead of simply producing local estimates of the surface orientation, our algorithm recovers complete surfaces. Past approaches only found the surface orientation locally and, therefore, did not take advantage of the surface integrability constraint. Our algorithm does not assume that the surface texture pattern is isotropic, and it does not assume that the viewed surface is at some point fronto-parallel. Furthermore, our algorithm has mechanisms for handling texture boundaries and, consequently, does not produce erratic results in the regions abutting these boundaries. Results on real images are presented demonstrating the potential of our approach.	ICCV	visu
3587	ICCV	Monocular Tracking of the Human Arm in 3D.	Enrico Di Bernardo,Luis Goncalves,Enrico Ursella,Pietro Perona	1995	Monocular Tracking of the Human Arm in 3D.	ICCV	visu
3588	ICCV	Stereo in the Presence of Specular Reflection.	Dinkar N. Bhat,Shree K. Nayar	1995	The problem of accurate depth estimation using stereo in the presence of specular reflection is addressed. Specular reflection, a fundamental and ubiquitous reflection mechanism, is viewpoint dependent and can cause large intensity differences at corresponding points, resulting in significant depth errors. We analyze the physics of specular reflection and the geometry of stereopsis which led us to a relationship between stereo vergence, surface roughness, and the likelihood of a correct match. Given a lower bound on surface roughness, an optimal binocular stereo configuration can be determined which maximizes precision in depth estimation despite specular reflection. However, surface roughness is difficult to estimate in unstructured environments. Therefore, trinocular configurations, independent of surface roughness, are determined such that at each scene point visible to all sensors, at least one stereo pair can compute produce depth. We have developed a simple algorithm to reconstruct depth from the multiple stereo pairs.	ICCV	visu
3589	ICCV	Geodesic Active Contours.	Vicent Caselles,Ron Kimmel,Guillermo Sapiro	1995	A novel scheme for the detection of object boundaries is presented. The technique is based on active contours deforming according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric as defined by the image content. This geodesic approach for object segmentation allows to connect classical snakes based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved as showed by a number of examples. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well.	ICCV	visu
3590	ICCV	Fast Object Recognition in Noisy Images Using Simulated Annealing.	Margrit Betke,Nicholas C. Makris	1995	A fast simulated annealing algorithm is developed for automatic object recognition. The object recognition problem is addressed as the problem of best describing a match between a hypothesized object and an image. The normalized correlation coefficient is used as a measure of the match. Templates are generated on-line during the search by transforming model images. Simulated annealing reduces the search time by orders of magnitude with respect to an exhaustive search. The algorithm is applied to the problem of how landmarks, e.g., traffic signs, can be recognized by a navigating robot. We illustrate the performance of our algorithm with real-world images of complicated scenes with traffic signs. False positive matches occur only for templates with very small information content. To avoid false positive matches, we propose a method to select model images for robust object recognition by measuring the information content of the model images. The algorithm works well in noisy images for model images with high information content.	ICCV	visu
3591	ICCV	Face Recognition from One Example View.	David Beymer,Tomaso Poggio	1995	To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially rotate the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.	ICCV	visu
3592	ICCV	On Multi-Feature Integration for Deformable Boundary Finding.	Amit Chakraborty,Marcel Worring,James S. Duncan	1995	Precise segmentation of underlying objects in an image is very important especially for biomedical image analysis. We present an integrated approach for boundary finding using region and curvature information along with the gradient. Unlike the previous methods, where smoothing is enforced by penalizing curvature, here the grey level curvature is used as an extra source of information. However, information fusion may not be useful unless used properly. To address that, we present results that highlight the pros and cons of using the various sources of information and indicate when one should get precedence over the others.	ICCV	visu
3593	ICCV	Face Detection by Fuzzy Pattern Matching.	Qian Chen,Haiyuan Wu,Masahiko Yachida	1995	The paper describes an approach to detect faces whose size and position are unknown in an image with a complex background. The candidates of faces are detected by finding out face like regions in the input image using the fuzzy pattern matching method. The perceptually uniform color space is used in our research in order to obtain reliable results. The skin color that is used to detect face like regions, is represented by a model developed by us called skin color distribution function. The skin color regions are then extracted by estimating a measure that describes how well the color of a pixel looks like the skin color for each pixel in the input image. The faces which appear in images are modeled as several 2 dimensional patterns. The face like regions are extracted by a fuzzy pattern matching approach using these face models. The face candidates are then verified by estimating how well the extracted facial features fit a face model which describes the geometrical relations among facial features.	ICCV	visu
3594	ICCV	A Model of Figure-Ground Segregation from Kinetic Occlusion.	George T. Chou	1995	The paper presents a model of image segmentation that can distinguish foreground from background purely on the basis of motion information. The main processing steps involved are: detection of motion boundaries, and analysis of figure ground relationship. The proposed model utilizes the observation that in kinetic occlusion, motion boundaries typically display mixture motion information, and foreground surfaces tend to move with motion boundaries. Through distributed probabilistic modeling, these constraints can be embedded into computations with efficient network representations. The resulting networks use spatiotemporal Gabor filters as front ends, and are suitable for parallel distributed processing. We demonstrate the application of the model in the decomposition of moving images into surfaces according to depth.	ICCV	visu
3595	ICCV	Motion from the Frontier of Curved Surfaces.	Roberto Cipolla,Kalle Åström,Peter J. Giblin	1995	The frontier of a curved surface is the envelope of contour generators showing the boundary, at least locally, of the visible region swept out under viewer motion. In general, the outlines of curved surfaces (apparent contours) from different viewpoints are generated by different contour generators on the surface and hence do not provide a constraint on viewer motion. We show that frontier points, however, have projections which correspond to a real point on the surface and can be used to constrain viewer motion by the epipolar constraint. We show how to recover viewer motion from frontier points for both continuous and discrete motion, calibrated and uncalibrated cameras. We present preliminary results of an iterative scheme to recover the epipolar line structure from real image sequences using only the outlines of curved surfaces. A statistical evaluation as also performed to estimate the stability of the solution.	ICCV	visu
3596	ICCV	Surface Geometry from Cusps of Apparent Contours.	Roberto Cipolla,Gordon J. Fletcher,Peter J. Giblin	1995	It is known that the deformations of the apparent contours of a surface under perspective projection and viewer motion enable the recovery of the geometry of the surface, for example by utilising the epipolar parametrization. These methods break down with apparent contours that are singular i.e. with cusps. In this paper, we study this situation in detail and show how, nevertheless, the surface geometry (including the Gauss curvature and mean curvature of the surface) can be recovered by following the cusps. Indeed the formulae are much simpler in this case, and require lower spatio-temporal derivatives than in the general case of nonsingular apparent contours. We give a simulated example, and also show that following cusps does not by itself provide us with information on ego-motion.	ICCV	visu
3597	ICCV	Improving Laser Triangulation Sensors Using Polarization.	James Clark,Emanuele Trucco,H.-F. Cheung	1995	We report a novel application of polarization based vision addressing the robustness of laser triangulation range sensors. Such sensors are based on the accurate detection of a pattern of laser light projected onto a scene, usually a point or line. Typical problems arise with highly specularly reflective surfaces, which can generate visible reflections of the light in various parts of the image. This can confuse the detection algorithms and lead to wrong range measurements. This paper demonstrates experimentally the feasibility of polarization based vision for disambiguating multiple specular inter reflections of the laser light. We concentrate on metal components as they have high interest for inspection in manufacturing, and show positive results with situations of various complexities.	ICCV	visu
3598	ICCV	Auxiliary Variables for Deformable Models.	Laurent D. Cohen	1995	We present a mathematical formulation for curve and surface reconstruction algorithms by introduction of auxiliary variables. For deformable models and templates, two step iterative algorithms have been often used where, at each iteration, the model is first locally deformed according to the potential data attraction and then globally smoothed. We show how these approaches can be interpreted as the introduction of auxiliary variables and the minimization of a two variables energy. This permits us to transform an implicit data constraint defined by a non convex potential into an explicit convex reconstruction problem. We show some mathematical properties and results on this new auxiliary problem, in particular when the potential is a function of the distance to the closest feature point. We then illustrate our approach for some deformable models and templates and image restoration.	ICCV	visu
3599	ICCV	Site Model Acquisition and Extension from Aerial Images.	Robert T. Collins,Yong-Qing Cheng,Christopher O. Jaynes,Frank Stolle,Xiaoguang Wang,Allen R. Hanson,Edward M. Riseman	1995	A system has been developed to acquire, extend and refine 3D geometric site models from aerial imagery. This system hypothesizes potential building roofs in an image, automatically locates supporting geometric evidence in other images, and determines the precise shape and position of the new buildings via multiimage triangulation. Model-to-image registration techniques are applied to align new, incoming images against the site model. Model extension and refinement procedures are then performed to add previously unseen buildings and to improve the geometric accuracy of the existing 3D building models.	ICCV	visu
3600	ICCV	Real-Time Obstacle Avoidance Using Central Flow Divergence and Peripheral Flow.	David Coombs,Martin Herman,Tsai-Hong Hong,Marilyn Nashman	1995	The lure of using motion vision as a fundamental element in the perception of space drives this effort to use flow features as the sole cues for robot mobility. Real-time estimates of image flow and flow divergence provide the robot's sense of space. The robot steers down a conceptual corridor comparing left and right peripheral flows. Large central flow divergence warns the robot of impending collisions at dead ends. When this occurs, the robot turns around and resumes wandering. Behavior is generated by directly using flow-based information in the 2D image sequence; no 3D reconstruction is attempted. Active mechanical gate stabilization simplifies the visual interpretation problems by reducing camera rotation. By combining corridor following and dead-end deflection, the robot has wandered around the lab at 30 cm/s for as long as 20 minutes without collision. The ability to support this behavior in real-time with current equipment promises expanded capabilities as computational power increases in the future.	ICCV	visu
3601	ICCV	A Multi-Body Factorization Method for Motion Analysis.	João Paulo Costeira,Takeo Kanade	1995	The structure from motion problem has been extensively studied in the field of computer vision. Yet, the bulk of the existing work assumes that the scene contains only a single moving object. The more realistic case where an unknown number of objects move in the scene has received little attention, especially for its theoretical treatment. We present a new method for separating and recovering the motion and shape of multiple independently moving objects in a sequence of images. The method does not require prior knowledge of the number of objects, nor is dependent on any grouping of features into an object at the image level. For this purpose, we introduce a mathematical construct of object shapes, called the shape interaction matrix, which is invariant to both the object motions and the selection of coordinate systems. This invariant structure is computable solely from the observed trajectories of image features without grouping them into individual objects. Once the structure is computed, it allows for segmenting features into objects by the process of transforming it into a canonical form, as well as recovering the shape and motion of each object.	ICCV	visu
3602	ICCV	Learning-Based Hand Sign Recognition Using SHOSLIF-M.	Yuntao Cui,Daniel L. Swets,Juyang Weng	1995	We present a self-organizing framework called the SHOSLIF-M for learning and recognizing spatiotemporal events (or patterns) from intensity image sequences. The proposed framework consists of a multiclass, multivariate discriminant analysis to automatically select the most discriminating features (MDF), a space partition tree to achieve a logarithmic retrieval time complexity for a database of n items, and a general interpolation scheme to do view inference and generalization in the MDF space based on a small number of training samples. The system is tested to recognize 28 different hand signs. The experimental results show that the learned system can achieve a 96% recognition rate for test sequences that have not been used in the training phase.	ICCV	visu
3603	ICCV	Better Optical Triangulation Through Spacetime Analysis.	Brian Curless,Marc Levoy	1995	The standard methods for extracting range data from optical triangulation scanners are accurate only for planar objects of uniform reflectance illuminated by an incoherent source. Using these methods, curved surfaces, discontinuous surfaces, and surfaces of varying reflectance cause systematic distortions of the range data. Coherent light sources such as lasers introduce speckle artifacts that further degrade the data. We present a new ranging method based on analyzing the time evolution of the structured light reflections. Using our spacetime analysis, we can correct for each of these artifacts, thereby attaining significantly higher accuracy using existing technology. We present results that demonstrate the validity of our method using a commercial laser stripe triangulation scanner.	ICCV	visu
3604	ICCV	Adaptive Shape Evolution Using Blending.	Douglas DeCarlo,Dimitris N. Metaxas	1995	We propose a shape representation scheme which allows two shapes to be combined into a single model. The desired regions of the two shapes are selected, and then merged together forming a blended shape. For reconstruction, blending is incorporated into a deformable model framework. The model automatically adapts to the data, blending when necessary. Hierarchical blending allows multiple blends of a shape to occur forming an evolution from the initial shape of a sphere to the final shape. Blending also allows the insertion of a hole between arbitrary locations. The models used are globally defined, making the recovered shape a natural symbolic description. We present reconstruction experiments involving shapes of various topologies.	ICCV	visu
3605	ICCV	Real-Time X-Ray Inspection of 3D Defects in Circuit Board Patterns.	Hideaki Doi,Yoko Suzuki,Yasuhiko Hara,Tadashi Iida,Yasuhiro Fujishita,Koichi Karasaki	1995	Real-Time X-Ray Inspection of 3D Defects in Circuit Board Patterns.	ICCV	visu
3606	ICCV	COSMOS-A Representation Scheme for Free-Form Surfaces.	Chitra Dorai,Anil K. Jain	1995	We address the problem of representing and recognizing arbitrarily curved 3D rigid objects when: the objects may vary in shape and complexity, and no restrictive assumptions are made about the types of surfaces on the object. We propose a new and general surface representation scheme for recognizing objects with free form (sculpted) surfaces from range data. In this scheme, an object is described concisely in terms of maximal surface patches of constant shape index. These maximal patches are mapped onto the unit sphere via their orientations, and aggregated via shape spectral functions. Properties such as surface area, curvedness and connectivity that capture local and global information are also built into the representation. The scheme yields not only a meaningful and rich surface description useful for the recoverability of the object, but also a set of powerful indexing primitives for object matching. We demonstrate the generality and the effectiveness of our scheme using real range images of complex objects. We also present results on the categorization of object views based on a novel shape spectral matching technique.	ICCV	visu
3607	ICCV	Indexing Visual Representations through the Complexity Map.	Benoit Dubuc,Steven W. Zucker	1995	In differential geometry curves are characterized as mappings from an interval to the plane. In topology curves are characterized as a Hausdorff space with certain countability properties. Neither of these definitions captures the role that curves play in vision, however, in which curves can denote simple objects (such as a straight line), or complicated objects (such as a jumble of string). The difference between these situations is in part a measure of their complexity, and in part a measure of their dimensionality. Note that the map defining such curves is unknown, as is the proper way to represent them. We propose a formal complexity theory of curves appropriate for computational vision in general, and for problems like separating straight lines from jumbles in particular. The theory is applied to the problem of perceptual grouping.	ICCV	visu
3608	ICCV	Facial Expression Recognition Using a Dynamic Model and Motion Energy.	Irfan A. Essa,Alex Pentland	1995	Previous efforts at facial expression recognition have been based on the Facial Action Coding System (FACS), a representation developed in order to allow human psychologists to code expression from static facial mugshots. We develop new more accurate representations for facial expression by building a video database of facial expressions and then probabilistically characterizing the facial muscle activation associated with each expression using a detailed physical model of the skin and muscles. This produces a muscle based representation of facial motion, which is then used to recognize facial expressions in two different ways. The first method uses the physics based model directly, by recognizing expressions through comparison of estimated muscle activations. The second method uses the physics based model to generate spatio temporal motion energy templates of the whole face for each different expression. These simple, biologically plausible motion energy templates are then used for recognition. Both methods show substantially greater accuracy at expression recognition than has been previously achieved.	ICCV	visu
3609	ICCV	Transfer of Fixation for an Active Stereo Platform via Affine Structure Recovery.	Stuart M. Fairley,Ian D. Reid,David W. Murray	1995	This paper describes an algorithm for stereo tracking using 3D affine transfer of a body-centred fixation point. Transfer is based on corners detected in the image and matched over time and in stereo. The paper presents a method of basing the transfer on all the available data, providing immunity to noise and poor conditioning. The paper also shows an implementation at video rates on a four axis active camera platform. Graceful degradation in the presence of insufficient data and fixed latency tracking in parallel with the structure calculation provide robust performance. Recovered trajectories are shown in an approximately Euclidean frame while structure transfer is demonstrated by the evolution of the target's convex hull.	ICCV	visu
3610	ICCV	On the Geometry and Algebra of the Point and Line Correspondences Between N Images.	Olivier D. Faugeras,Bernard Mourrain	1995	We explore the geometric and algebraic relations that exist between correspondences of points and lines in an arbitrary number of images. We propose to use the formalism of the Grassmann-Cayley algebra as the simplest way to make both geometric and algebraic statements in a very synthetic and effective way (i.e. allowing actual computation if needed). We have a fairly complete picture of the situation in the case of points; there are only three types of algebraic relations which are satisfied by the coordinates of the images of a 3-D point: bilinear relations arising when we consider pairs of images among the N and which are the well-known epipolar constraints, trilinear relations arising when we consider triples of images among the N, and quadrilinear relations arising when we consider four-tuples of images among the N. In the case of lines, we show how the traditional perspective projection equation can be suitably generalized and that in the case of three images there exist two independent trilinear relations between the coordinates of the images of a 3-D line.	ICCV	visu
3611	ICCV	3D-2D Projective Registration of Free-Form Curves and Surfaces.	Jacques Feldmar,Nicholas Ayache,Fabienne Betting	1995	Some medical interventions require knowing the correspondence between an MRI/CT pre-operative image and the actual position of the patient. Examples occur in neurosurgery, radiotherapy, interventional radiology, but also in video surgery (laparoscopy). We present in this article three new techniques for performing this task without artificial markers. We find the 3D-2D projective transformation (composition of a rigid displacement and a perspective projection) which maps a 3D object onto a 2D image of this object. Depending on the object model (curve or surface), and on the 2D image acquisition system (X-Ray, video), the techniques are different but the framework is common. It does not depend on the initial relative positions of the objects and deals with the occlusions and the outliers. Results are presented on real medical data to demonstrate the validity of our approach.	ICCV	visu
3612	ICCV	Global Rigidity Constraints in Image Displacement Fields.	Cornelia Fermüller,Yiannis Aloimonos	1995	Image displacement fields-optical flow fields, stereo disparity fields, normal flow fields-due to rigid motion possess a global geometric structure which is independent of the scene in view. Motion vectors of certain lengths and directions are constrained to lie on the imaging surface at particular loci whose location and form depends solely on the 3D motion parameters. If optical flow fields or stereo disparity fields are considered, then equal vectors are shown to lie on conic sections. Similarly, for normal motion fields, equal vectors lie within regions whose boundaries also constitute conics. By studying various properties of these curves and regions and their relationships, a characterization of the structure of rigid motion fields is given. The goal of this paper is to introduce a concept underlying the global structure of image displacement fields. This concept gives rise to various constraints that could form the basis of algorithms for the recovery of visual information from multiple views.	ICCV	visu
3613	ICCV	Color Constancy in Diagonal Chromaticity Space.	Graham D. Finlayson	1995	Simple constraints on the sets of possible surface reflectances and illuminants are exploited in a new color constancy algorithm that builds upon Forsyth's (1990) theory of color constancy. The goal defined for a color constancy algorithm is to discount variations in the color and intensity of the incident illumination and thereby extract illumination-independent descriptors of surface colors from images. Forsyth's method is based on two constraints: first, the surface colors under a canonical illuminant all fall within an established maximal convex gamut of possible colors and second that a diagonal matrix accurately maps colors between illuminants. These constraints taken together turn out to be very effective in solving for color constancy; however, other strong assumptions about the scenes are required for the method to work-the illumination must be uniform, the surfaces must be planar, and there can be no specularities. We show that these restrictions are necessary only because Forsyth sets out to recover the intensity of descriptors. At the outset we abandon 3-dimensional descriptor recovery in favor of recovering only orientation (i.e. 2 dimensions). Intensity information is factored out of the problem by mapping 3-dimensional (r, g, b) camera responses onto 2-dimensional chromaticities; specifically (r/b, g/b). We show that this diagonal chromaticity space has two important properties: first, gamut convexity is preserved and second illumination change is still described by a diagonal matrix. It follows that Forsyth's algorithm can be directly applied to the recover chromaticity descriptors and from these the 3D descriptor orientations can be derived. The basic algorithm is then extended to include a maximal gamut constraint on the set of illuminants that is analogous to the gamut constraint on surface colors. The diagonal chromaticity space facilitates the expression of the illumination constraint in the algorithm. Tests on real images show that the algorithm provides good color constancy.	ICCV	visu
3614	ICCV	Color Constancy under Varying Illumination.	Graham D. Finlayson,Brian V. Funt,Kobus Barnard	1995	Illumination is rarely constant in intensity or color throughout a scene. Multiple light sources with different spectra-sun and sky, direct and interreflected light-are the norm. Nonetheless, almost all color constancy algorithms assume that the spectrum of the incident illumination remains constant across the scene. We assume the converse, that illumination does vary, in developing a new algorithm for color constancy. Rather than creating difficulties, varying illumination is in fact a very powerful constraint. Indeed tests of our algorithm using real images of an office scene show excellent results.	ICCV	visu
3615	ICCV	Bayesian Decision Theory, the Maximum Local Mass Estimate, and Color Constancy.	William T. Freeman,David H. Brainard	1995	Vision algorithms are often developed in a Bayesian framework. Two estimators are commonly used: maximum a posteriori (MAP), and minimum mean squared error (MMSE). We argue that neither is appropriate for perception problems. The MAP estimator makes insufficient use of structure in the posterior probability. The squared error penalty of the MMSE estimator does not reflect typical penalties. We describe a new estimator, which we call maximum local mass (MLM) [10, 26, 65], which integrates the local probability density. The MLM method is sensitive to local structure of the posterior probability, which MAP is not. The new method uses an optimality criterion that is appropriate for perception tasks: it finds the most probable approximately correct answer. For the case of low observation noise, we provide an efficient approximation. We apply this new estimator to color constancy. An unknown illuminant falls on surfaces of unknown colors. We seek to estimate both the illuminant spectrum and the surface spectra from photosensor responses which depend on the product of the unknown spectra. In simulations, we show that the MLM method performs better than the MAP estimator, and better than two standard color constancy algorithms. The MLM method may prove useful in other vision problems as well.	ICCV	visu
3616	ICCV	Polymorphic Grouping for Image Segmentation.	Claudia Fuchs,Wolfgang Förstner	1995	The paper describes a new approach to image segmentation. It accepts the inherent deficiencies occuring when extracting low-level features and when dealing with the complexity of real scenes. Image segmentation therefore is understood as deriving a rich symbolic description useful for tasks such as stereo or object recognition in outdoor scenes. The approach is based on a polymorphic scheme for simultaneously extracting points, lines and segments in a topologically consistent manner, together with their mutual relations derived from the feature adjacency graph (FAG) thereby performing several grouping steps which gradually use more and more specific domain knowledge to achieve an optimal image description. The heart of the approach is (1) a detailed analysis of the FAG and (2) a robust estimation for validating the found geometric hypotheses. The analysis of the FAG, derived from the exoskeleton of the features, allows to detect inconsistencies of the extracted features with the ideal image model, a cell-complex. The FAG is used for finding hypotheses about incidence relations and geometric hypotheses, such as collinearity or parallelity, also between non-neighbored points and lines. The M-type robust estimation is used for simultaneously eliminating wrong hypotheses on geometric relationships. It uses a new argument for the weighting function.	ICCV	visu
3617	ICCV	Combining Color and Geometry for the Active, Visual Recognition of Shadows.	Gareth Funka-Lea,Ruzena Bajcsy	1995	Shadows are a frequent occurrence, but they cannot be infallibly recognized until a scene's geometry and lighting are known. We present a number of cues which together strongly suggest the identification of a shadow and which can be examined with low cost. The techniques are: a color image segmentation method that recovers single material surfaces as single image regions irregardless of the surface partially in shadow, a method to recover the penumbra and umbra of shadow; a method for determining whether some object could be obstructing a light source. The last cue requires the examination of well understood shadows in the scene. Our observer is equipped with an extendable probe for casting its own shadows. Actively obtained shadows allow the observer to experimentally determine the location of the light sources in the scene. The system has been tested both indoors and out.	ICCV	visu
3618	ICCV	Surface Orientation and Curvature from Differential Texture Distortion.	Jonas Gårding	1995	A unified differential geometric framework for estimation of local surface shape and orientation from projective texture distortion is proposed, based on a differential version of the texture stationarity assumption introduced by Malik and Rosenholtz. This framework allows the information content of the gradient of any texture descriptor defined in a local coordinate frame to be characterized in a very compact form. The analysis encompasses both full affine texture descriptors and the classical texture gradients. For estimation of local surface orientation and curvature from uncertain observations of affine texture distortion, the proposed framework allows the dimensionality of the search space to be reduced from five to one.	ICCV	visu
3619	ICCV	Optical Flow and Deformable Objects.	Andrea Giachetti,Vincent Torre	1995	When a plane undergoes a deformation that can be represented by a planar linear vector field, the projected vector field on the image plane of an optical device is at most quadratic. This 2D motion field has one singular point, with eigenvalues identical to those of the singular point describing the deformation. As a consequence, the nature of the singular point of the deformation is a projective invariant. When the plane moves and experiences a linear deformation at the same time, the associated 2D motion field is still quadratic with at most 3 singular points. In the case of a normal rototranslation, i.e. when the angular velocity is normal to the plane, and of a linear deformation, the 2D motion field has at most one singular point and substantial information on the rigid motion and on the deformation can be recovered from it. Experiments with simulated deformations and real deformable objects show that the proposed analysis can provide accurate results and information on more general 3D deformations.	ICCV	visu
3620	ICCV	Calibration-Free Visual Control Using Projective Invariance.	Gregory D. Hager	1995	Much of the previous work on hand-eye coordination has emphasized the reconstructive aspects of vision. Recently, techniques that avoid explicit reconstruction by placing visual feedback into a control loop have been developed. When properly defined, these methods lead to calibration insensitive hand-eye coordination. Recent work on projective geometry as applied to vision is used to extend this paradigm in two ways. First, it is shown how results from projective geometry can be used to perform online calibration. Second, results on projective invariance are used to define setpoints for visual control that are independent of viewing location. These ideas are illustrated through a number of examples and have been tested on an implemented system.	ICCV	visu
3621	ICCV	A Linear Method for Reconstruction from Lines and Points.	Richard I. Hartley	1995	Discusses the basic role of the trifocal tensor in scene reconstruction. This 3/spl times/3/spl times/3 tensor plays a role in the analysis of scenes from three views analogous to the role played by the fundamental matrix in the two-view case. In particular, the trifocal tensor maybe computed by a linear algorithm from a set of 13 line correspondences in three views. It is further shown in this paper to be essentially identical to a set of coefficients introduced by Shashua (1994) to effect point transfer in the three-view case. This observation means that the 13-line algorithm may be extended to allow for the computation of the trifocal tensor given any mixture of sufficiently many line and point correspondences. From the trifocal tensor, the camera image matrices may be computed, and the scene may be reconstructed. For unrelated uncalibrated cameras, this reconstruction is unique up to projectivity. Thus, projective reconstruction of a set of lines and points may be reconstructed linearly from three views.	ICCV	visu
3622	ICCV	In Defence of the 8-Point Algorithm.	Richard I. Hartley	1995	The fundamental matrix is a basic tool in the analysis of scenes taken with two uncalibrated cameras, and the 8 point algorithm is a frequently cited method for computing the fundamental matrix from a set of 8 or more point matches. It has the advantage of simplicity of implementation. The prevailing view is, however, that it is extremely susceptible to noise and hence virtually useless for most purposes. The paper challenges that view, by showing that by preceding the algorithm with a very simple normalization (translation and scaling) of the coordinates of the matched points, results are obtained comparable with the best iterative algorithms. This improved performance is justified by theory and verified by extensive experiments on real images.	ICCV	visu
3623	ICCV	Segmented Shape Descriptions from 3-View Stereo.	Parag Havaldar,Gérard G. Medioni	1995	We address the recovery of segmented, 3-D descriptions of an object from intensity images. We use three views of an object from slightly different viewpoints as our input. For each image we extract a hierarchy of groups based on proximity, parallelism and symmetry in a robust manner. The groups in the three images are matched by computing the epipolar geometry. For each set of matched groups from the three images, we then label the contours of the groups as true or limb edges. Using the information about groups, the label associated with their contours and projective properties of subclasses of Generalized Cylinders, we infer the 3-D structure of these groups. The proposed method not only allows robust shape recovery but also produces segmented parts. Our approach can also deal with groups generated as a result of texture or shadows on the object. We present results on real images of moderately complex objects.	ICCV	visu
3624	ICCV	The Illumination-Invariant Recognition of Texture in Color Texture.	Glenn Healey,Lizhi Wang	1995	The Illumination-Invariant Recognition of Texture in Color Texture.	ICCV	visu
3625	ICCV	Reconstruction from Image Sequences by Means of Relative Depths.	Anders Heyden	1995	The paper deals with the problem of reconstructing the locations of n points in space from m different images without camera calibration. It shows how these problems can be put into a similar theoretical framework. A new concept, the reduced fundamental matrix, is introduced. It contains just 4 parameters and can be used to predict locations of points in the images and to make reconstruction. We also introduce the concept of reduced fundamental tensor which describes the relations between points in 3 images. It has 15 components and depends on 9 parameters. Necessary and sufficient conditions for a tensor to be a reduced fundamental tensor are derived. This framework can be generalised to a sequence of images. The dependencies between the different representations are investigated. Furthermore a canonical form of the camera matrices in a sequence are presented.	ICCV	visu
3626	ICCV	Object Pose: Links Between Paraperspective and Perspective.	Radu Horaud,Stéphane Christy,Fadi Dornaika,Bart Lamiroy	1995	D.F. Dementhon and L.S. Davis (1995) proposed a method for determining the pose of a 3D object with respect to a camera from 3D to 2D point correspondences. The method consists of iteratively improving the pose computed with a weak perspective camera model to converge at the limit, to a pose estimation computed with a perspective camera model. We show that the method of Dementhon and Davis can be extended to paraperspective. The iterative paraperspective pose algorithm that we describe in detail has interesting properties both in terms of speed and rate of convergence. Moreover, we introduce a simple way of taking into account the orthogonality constraint associated with the rotation matrix and we define the optimal experimental setup to be used in the presence of camera calibration errors.	ICCV	visu
3627	ICCV	Statistical Learning, Localization, and Identification of Objects.	Joachim Hornegger,Heinrich Niemann	1995	This work describes a statistical approach to deal with learning and recognition problems in the field of computer vision. An abstract theoretical framework is provided, which is suitable for automatic model generation from examples, identification, and localization of objects. Both, the learning and localization stage are formalized as parameter estimation tasks. The statistical learning phase is unsupervised with respect to the matching of model and scene features. The general mathematical description yields algorithms which can even treat parameter estimation problems from projected data. The experiments show that this probabilistic approach is suitable for solving 2D and 3D object recognition problems using grey-level images. The method can also be applied to 3D image processing issues using range images, i.e. 3D input data.	ICCV	visu
3628	ICCV	Computing Visual Correspondence: Incorporating the Probability of a False Match.	Daniel P. Huttenlocher,Eric W. Jaquith	1995	We describe a method for computing visual correspondence which employs a formal model of the probability of a false match. This model estimates the chance that the best match for each point could have occurred at random. The model is effective at identifying points in one image for which there is no corresponding point in the other image, as occurs at depth boundaries in stereo and at motion boundaries in optical flow. More generally, the model can be used to identify points where the best match is of poor quality, as occurs in regions of uniform texture. We describe the similarity measure used in the method and present the formal model of a false match. We also show examples of using the method to compute stereo disparity.	ICCV	visu
3629	ICCV	Closed-World Tracking.	Stephen S. Intille,Aaron F. Bobick	1995	A new approach to tracking weakly modeled objects in a semantically rich domain is presented. We define a closed-world as a space-time region of an image sequence in which the complete taxonomy of objects is known, and in which each pixel should be explained as belonging to one of those objects. Given contextual object information, context-specific features can be dynamically selected as the basis for tracking. A context-specific feature is one that has been chosen based upon the context to maximize the chance of successful tracking between frames. Our work is motivated by the goal of video annotation-the semi-automatic generation of symbolic descriptions of action taking place in a contextually-rich dynamic scene. We describe how contextual knowledge in the football domain can be applied to closed-world football player tracking and present the details of our implementation. We include tracking results based on hundreds of images that demonstrate the wide range of tracking situations the algorithm successfully handles as well as a few examples of where the algorithm fails.	ICCV	visu
3630	ICCV	Mosaic Based Representations of Video Sequences and Their Applications.	Michal Irani,P. Anandan,Steven C. Hsu	1995	Recently, there has been a growing interest in the use of mosaic images to represent the information contained in video sequences. The paper systematically investigates how to go beyond thinking of the mosaic simply as a visualization device, but rather as a basis for efficient representation of video sequences. We describe two different types of mosaics called the static and the dynamic mosaic that are suitable for different needs and scenarios. We discuss a series of extensions to these basic mosaics to provide representations at multiple spatial and temporal resolutions and to handle 3D scene information. We describe techniques for the basic elements of the mosaic construction process, namely alignment, integration, and residual analysis. We describe several applications of mosaic representations including video compression, enhancement, enhanced visualization, and other applications in video indexing, search, and manipulation.	ICCV	visu
3631	ICCV	Saliency Maps and Attention Selection in Scale and Spatial Coordinates: An Information Theoretic Approach.	Martin Jägersand	1995	Information measures with respect to spatial locations and scales of objects in an image are important to image processing and interpretation. It allows us to focus attention on relevant data, saving effort and reducing false positives. In particular, the information content of a man-made scene is typically confined to a small set of scales. We devise a scale space based measure of image information. Kullback contrasts between successive resolution lengths gives the differential information gain. Experiments show that this measure gives a clear indication of characteristic lengths in a variety of real world images and is superior to power spectrum based measurements. Decomposing the expected information gain into spatial coordinates gives us a saliency map for use by an attention selector. We combine the scale and spatial decompositions into a single information measure, giving both the spatial extent and scale range of interest. The information measure has an efficient implementation, and thus can be used routinely in early vision processing.	ICCV	visu
3632	ICCV	Model-Based Matching of Line Drawings by Linear Combinations of Prototypes.	Michael J. Jones,Tomaso Poggio	1995	We describe a technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search. The object models are learned from example images (also called prototypes) of an object class. The models consist of a linear combination of prototypes. The flow fields giving pixelwise correspondences between a base prototype and each of the other prototypes must be given. A novel image of an object of the same class is matched to a model by minimizing an error between the novel image and the current guess for the closest model image. Currently, the algorithm applies to line drawings of objects. An extension to real grey level images is discussed.	ICCV	visu
3633	ICCV	Structure and Motion Estimation from Dynamic Silhouettes under Perspective Projection.	Tanuja Joshi,Narendra Ahuja,Jean Ponce	1995	Addresses the problem of estimating the structure and motion of a smooth curved object from its silhouettes observed over time by a trinocular stereo rig under perspective projection. We first construct a model for the local structure along the silhouette for each frame in the temporal sequence. Successive local models are then integrated into a global surface description by estimating the motion between successive time instants. The algorithm tracks certain surface features (parabolic points) and image features (silhouette inflections and frontier points) which are used to bootstrap the motion estimation process. The entire silhouette along with the reconstructed local structure are then used to refine the initial motion estimate. We have implemented the proposed approach and report results on real images.	ICCV	visu
3634	ICCV	3D Human Body Model Acquisition from Multiple Views.	Ioannis A. Kakadiaris,Dimitris N. Metaxas	1995	We present a novel motion-based approach for the part determination and shape estimation of a human's body parts. The novelty of the technique is that neither a prior model of the human body is employed nor prior body part segmentation is assumed. We present a human body part identification strategy (HBPIS) that recovers all the body parts of a moving human based on the spatiotemporal analysis of its deforming silhouette. We formalize the process of simultaneous part determination and 2D shape estimation by employing the supervisory control theory of discrete event systems. In addition, in order to acquire the 3D shape of the body parts, we present a new algorithm which selectively integrates the (segmented by the HBPIS) apparent contours, from three mutually orthogonal views. The effectiveness of the approach is demonstrated through a series of experiments, where a subject performs a set of movements according to a protocol that reveals the structure of the human body.	ICCV	visu
3635	ICCV	A Robot System that Observes and Replicates Grasping Tasks.	Sing Bang Kang,Katsushi Ikeuchi	1995	To alleviate the problem of overwhelming complexity in grasp synthesis and path planning associated with robot task planning, we adopt the approach of teaching the robot by demonstrating in front of it. The system has four components: the observation system, the grasping task recognition module, the task translator and the robot system. The observation system comprises an active multibaseline stereo system and a dataglove. The data stream recorded is then used to track object motion; this paper illustrates how complimentary sensory data can be used for this purpose. The data stream is also interpreted by the grasping task recognition module, which produces higher levels of abstraction to describe both the motion and actions taken in the task. The resulting information are provided to the task translator which creates commands for the robot system to replicate the observed task. In this paper we describe how these components work with special emphasis on the observation system. The robot system that we use to perform the grasping tasks comprises the PUMA 560 arm and the Utah/MIT hand.	ICCV	visu
3636	ICCV	A Multibaseline Stereo System with Active Illumination and Real-Time Image Acquisition.	Sing Bing Kang,Jon A. Webb,C. Lawrence Zitnick,Takeo Kanade	1995	We describe our implementation of a parallel depth recovery scheme for a four-camera multibaseline stereo in a convergent configuration. Our system is capable of image capture at video rate. This is critical in applications that require three-dimensional tracking. We obtain dense stereo depth data by projecting a light pattern of frequency modulated sinusoidally varying intensity onto the scene, thus increasing the local discriminability at each pixel and facilitating matches. In addition, we make most of the camera view areas by converging them at a volume of interest. Results show that we are able to extract stereo depth data that are, on the average, less than 1 mm in error at distances between 1.5 to 3.5 m away from the cameras.	ICCV	visu
3637	ICCV	Unsupervised Parallel Image Classificiation Using a Hierarchical Markovian Model.	Zoltan Kato,Josiane Zerubia,Marc Berthod	1995	The paper deals with the problem of unsupervised classification of images modeled by Markov random fields (MRF). If the model parameters are known then we have various methods to solve the segmentation problem (simulated annealing, ICM, etc...). However, when they are not known, the problem becomes more difficult. One has to estimate the hidden label field parameters from the only observable image. Our approach consists of extending a recent iterative method of estimation, called iterative conditional estimation (ICE) to a hierarchical Markovian model. The idea resembles the estimation-maximization (EM) algorithm as we recursively look at the maximum a posteriori (MAP) estimate of the label field given the estimated parameters then we look at the maximum likelihood (ML) estimate of the parameters given a tentative labeling obtained at the previous step. We propose unsupervised image classification algorithms using a hierarchical model. The only parameter supposed to be known is the number of regions, all the other parameters are estimated. The presented algorithms have been implemented on a Connection Machine CM200. Comparative tests have been done on noisy synthetic and real images (remote sensing).	ICCV	visu
3638	ICCV	Annular Symmetry Operators: A Method for Locating and Describing Objects.	Michael F. Kelly,Martin D. Levine	1995	We present a machine vision system in which segmentation is computed in conjunction with a structural description of objects in the scene. It is assumed that contrast edges capture all relevant object information. The principles which dictate how edge features are grouped to infer objects are based upon detecting SYMMETRICAL ENCLOSING edge configurations. These are detected using ANNULAR OPERATORS applied at multiple scales to edge data which have been extracted at multiple scales from a gray level image. The subsequent grouping of symmetry points results in a set of PARTS which make it possible to identify the LOCATION of objects within an image. These parts are used as a basis for constructing coarse graph-based DESCRIPTORS for the PERCEPTUALLY SIGNIFICANT objects found in the scene. Results are presented to illustrate the method's performance on several images.	ICCV	visu
3639	ICCV	Gradient Flows and Geometric Active Contour Models.	Satyanad Kichenassamy,Arun Kumar,Peter J. Olver,Allen Tannenbaum,Anthony J. Yezzi	1995	In this paper, we analyze the geometric active contour models discussed previously from a curve evolution point of view and propose some modifications based on gradient flows relative to certain new feature-based Riemannian metrics. This leads to a novel snake paradigm in which the feature of interest may be considered to lie at the bottom of a potential well. Thus the snake is attracted very naturally and efficiently to the desired feature. Moreover, we consider some 3-D active surface models based on these ideas.	ICCV	visu
3640	ICCV	Direct Estimation of Affine Image Deformations Using Visual Front-End Operations with Automatic Scale Selection.	Tony Lindeberg	1995	This article deals with the problem of estimating deformations of brightness patterns using visual front-end operations. Estimating such deformations constitutes an important subtask in several computer vision problems relating to image correspondence and shape estimation. The following subjects are treated: The problem of decomposing affine flow fields into simpler components is analysed in detail. A canonical parametrization is presented based on singular value decomposition, which naturally separates the rotationally invariant components of the flow field from the rotationally variant ones. A novel mechanism is presented for automatic selection of scale levels when estimating local affine deformations. This mechanism is expressed within a multiscale framework where disparity estimates are computed in a hierarchical coarse-to-fine manner and corrected using iterative techniques. Then, deformation estimates are selected from the scales that minimize a certain normalized residual over scales. Finally, the descriptors so obtained serve as initial data for computing refined estimates of the local deformations.	ICCV	visu
3641	ICCV	3D Surface Reconstruction from Stereoscopic Image Sequences.	Reinhard Koch	1995	3D Surface Reconstruction from Stereoscopic Image Sequences.	ICCV	visu
3642	ICCV	Towards a Unified IU Environment: Coordination of Existing IU Tools with the IUE.	Charles A. Kohl,Jeffrey J. Hunter,Cynthia L. Loiselle	1995	Progress in the field of computer vision/image understanding (IU) has long been hampered by the lack of standard software environments for research and application development. The Image Understanding Environment (IUE) is being implemented to provide a freely-distributed standard software environment that is appropriate for a wide range of research and development activities. Nevertheless, we recognize that the IUE will not serve everyone's individual needs and that conversion to the IUE could be an expensive process for many sites. Therefore, we are investing significant effort to make the IUE an open environment that can work in coordination with existing IU systems and tools. This paper introduces the work being performed at Amerinex AI to address the processing and data representation factors involved in this coordination.	ICCV	visu
3643	ICCV	Multiscale Detection of Curvilinear Structures in 2D and 3D Image Data.	Thomas Koller,Guido Gerig,Gábor Székely,Daniel Dettwiler	1995	Multiscale Detection of Curvilinear Structures in 2D and 3D Image Data.	ICCV	visu
3644	ICCV	3D Pose Estimation by Fitting Image Gradients Directly to Polyhedral Models.	Henner Kollnig,Hans-Hellmut Nagel	1995	Addresses the problem of pose estimation and tracking of vehicles in image sequences from traffic scenes recorded by a stationary camera. In a new algorithm, the vehicle pose is estimated by directly fitting image gradients to polyhedral vehicle models without an edge segment extraction process. The new approach is significantly more robust than approaches that rely on feature extraction because the new approach exploits more information from the image data. We can track vehicles that are partially occluded by textured objects, e.g. foliage, where classical approaches based on edge segment extraction fail. Results from various experiments with real-world traffic scenes are presented.	ICCV	visu
3645	ICCV	Gabor Wavelets for 3-D Object Recognition.	Xing Wu,Bir Bhanu	1995	This paper presents a model-based object recognition approach that uses a hierarchical Gabor wavelet representation. The key idea is to use magnitude, phase and frequency measures of Gabor wavelet representation in an innovative flexible matching approach that can provide robust recognition. A Gabor grid a topology-preserving map, efficiently encodes both signal energy and structural information of an object in a sparse multi-resolution representation. The Gabor grid subsamples the Gabor wavelet decomposition of an object model and is deformed to allow the indexed object model match with the image data. Flexible matching between the model and the image minimizes a cost function based on local similarity and geometric distortion of the Gabor grid. Grid erosion and repairing is performed whenever a collapsed grid, due to object occlusion, is detected. The results on infrared imagery are presented. Where objects undergo rotation, translation, scale, occlusion and aspect variations under changing environmental conditions.	ICCV	visu
3646	ICCV	Texture Segmentation and Shape in the Same Image.	John Krumm,Steven A. Shafer	1995	Uniformly textured surfaces in 3D scenes provide important cues for image understanding. Texture can be used for both segmentation and for 3D shape inference. Unfortunately, virtually all current algorithms are based on assumptions that make it impossible to do texture segmentation and shape-from-texture in the same image. Texture segmentation algorithms rely on an absence of 3D effects that tend to distort the texture. Shape-from-texture algorithms depend on these effects, relying instead on the texture being already segmented. To really understand texture in images, texture segmentation and shape-from-texture must be viewed as a combined problem to be solved simultaneously. We present a solution to this problem with a region-growing algorithm that explicitly accounts for perspective distortions of otherwise uniform texture. We use the image spectrogram to compute local surface normals, which are in turn used to frontalize the texture. These frontalized texture patches are then subjected to a region-growing algorithm based on similarity in the local frequency domain and a minimum description length criteria. We show results of our algorithm on real texture images taken in the lab and outdoors.	ICCV	visu
3647	ICCV	Vision Based Hand Modeling and Tracking for Virtual Teleconferencing and Telecollaboration.	James J. Kuch,Thomas S. Huang	1995	The authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression. The model can be fitted to any person's hand and can be done using a single camera. Once the model is fitted to a real human hand, it is then used in several tracking scenarios in order to verify its effectiveness. With successful tracking achieved, the model is ready to be incorporated into a virtual environment or model based compression scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks at very low bit rates and at very high image quality.	ICCV	visu
3648	ICCV	Reflectance Function Estimation and Shape Recovery from Image Sequence of a Rotating Object.	Jiping Lu,James J. Little	1995	We describe a technique for surface recovery of a rotating object illuminated under a collinear light source (where the light source lies on or near the optical axis). We show that the surface reflectance function can be directly estimated from the image sequence without any assumption on the reflectance property of the object surface. From the image sequence, the 3D locations of some singular surface points are calculated and their brightness values are extracted for the estimation of the reflectance function. We also show that the surface can be recovered by using shading information in two images of the rotating object. Iteratively using the first-order Taylor series approximation and the estimated reflectance function, the depth and orientation of the surface can be recovered simultaneously. The experimental results on real image sequences of both matte and specular surfaces demonstrate that the technique is feasible and robust.	ICCV	visu
3649	ICCV	An Integrated Stereo-Based Approach to Automatic Vehicle Guidance.	Quang-Tuan Luong,Joseph Weber,Daphne Koller,Jitendra Malik	1995	Proposes a new approach for vision-based longitudinal and lateral vehicle control. The novel feature of this approach is the use of binocular vision. We integrate two modules consisting of a new, domain-specific, efficient binocular stereo algorithm, and a lane marker detection algorithm, and show that the integration results in a improved performance for each of the modules. Longitudinal control is supported by detecting and measuring the distances to leading vehicles using binocular stereo. The knowledge of the camera geometry with respect to the locally planar road is used to map the images of the road plane in the two camera views into alignment. This allows us to separate image features into those lying in the road plane, e.g. lane markers, and those due to other objects which are dynamically integrated into an obstacle map. Therefore, in contrast with the previous work, we can cope with the difficulties arising from occlusion of lane markers by other vehicles. The detection and measurement of the lane markers provides us with the positional parameters and the road curvature which are needed for lateral vehicle control. Moreover, this information is also used to update the camera geometry with respect to the road, therefore allowing us to cope with the problem of vibrations and road inclination to obtain consistent results from binocular stereo.	ICCV	visu
3650	ICCV	Affine Surface Reconstruction by Purposive Viewpoint Control.	Kiriakos N. Kutulakos	1995	We present an approach for building an affine representation of an unknown curved object viewed under orthographic projection from images of its occluding contour. It is based on the observation that the projection of a point on a curved, featureless surface can be computed along a special viewing direction that does not belong to the point's tangent plane. We show that by circumnavigating the object on the tangent plane of selected surface points, we can (1) compute two orthogonal projections of every point projecting to the occluding contour during this motion, and (2) compute the affine coordinates of these points. Our approach demonstrates that affine shape of curved objects can be computed directly, i.e., without Euclidean calibration or image velocity and acceleration measurements.	ICCV	visu
3651	ICCV	Hierarchical Statistical Models for the Fusion of Multiresolution Image Data.	Jean-Marc Laferté,Fabrice Heitz,Patrick Pérez,Eric Fabre	1995	This paper presents a class of nonlinear hierarchical algorithms for the fusion of multiresolution image data in low-level vision. The approach combines nonlinear causal Markov models defined on hierarchical graph structures, with standard bayesian estimation theory. Two random processes defined on simple hierarchical graphs (quadtrees or ternary graphs) are introduced to represent the multiresolution observations at hand and the hidden labels to be estimated. An optimal algorithm (inspired from the Viterbi algorithm) is developed to compute the bayesian estimates on the hierarchical graph structures. Estimates are obtained within two passes on the graph structure. This algorithm is non-iterative and yields a per pixel computational complexity which is independent of image size. This approach is compared to the multiscale algorithm proposed by (Bouman et al., 1994) for single-resolution image segmentation (that we have extended for multiresolution data fusion).	ICCV	visu
3652	ICCV	A Unified Approach to Coding and Interpreting Face Images.	Andreas Lanitis,Christopher J. Taylor,Timothy F. Cootes	1995	Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression and lighting. We describe a compact parametrised model of facial appearance which takes into account all these sources of variability. The model represents both shape and grey-level appearance and is created by performing a statistical analysis over a training set of face images. A robust multi-resolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located and a set of shape and grey-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, pose recovery, gender recognition and expression recognition. The system performs well on all the tasks listed above.	ICCV	visu
3653	ICCV	Determining Wet Surfaces from Dry.	Howard B. Mall Jr.,Niels da Vitoria Lobo	1995	Wet surfaces are ubiquitous in our visual experience. Autonomous machines with vision systems will need to identify wet surfaces from dry. Wet surfaces (especially rough, absorbent ones) appear darker when wet. This paper presents the Lekner and Dorf (1988) model for describing the darkening caused by wetting. We explain how to use this optics model to transform intensity values of a region of an image to make that region appear wet. We also show how the model can be reversed in order to make a wet part of an image appear dry. It is also shown that this technique can be used to identify wet regions. This identification is contrasted with darkening caused by shadows. Comparisons of the gray-level histograms of these real images show the validity of this approach for distinguishing wet surfaces from dry.	ICCV	visu
3654	ICCV	Finding Faces in Cluttered Scenes Using Labeled Random Graph Matching.	Thomas K. Leung,Michael C. Burl,Pietro Perona	1995	Finding Faces in Cluttered Scenes Using Labeled Random Graph Matching.	ICCV	visu
3655	ICCV	On Representation and Matching of Multi-Coloured Objects.	Jiri Matas,R. Marik,Josef Kittler	1995	A new representation for objects with multiple colours-the colour adjacency graph (CAG)-is proposed. Each node of the CAG represents a single chromatic component of the image defined as a set of pixels forming a unimodal cluster in the chromatic scattergram. Edges encode information about adjacency of colour components and their reflectance ratio. The CAG is related to both the histogram and region adjacency graph representations. It is shown to be preserving and combining the best features of these two approaches while avoiding their drawbacks. The proposed approach is tested on a range of difficult object recognition and localisation problems involving complex imagery of non-rigid 3D objects under varied viewing conditions with excellent results.	ICCV	visu
3656	ICCV	Automatic Recognition of Human Facial Expressions.	Katsuhiro Matsuno,Chil-Woo Lee,Satoshi Kimura,Saburo Tsuji	1995	The paper presents a new idea for detecting an unknown human face in input imagery and recognizing his/her facial expression represented in the deformation of the two dimensional net, called potential net. The method deals with the facial information, faceness and expressions, as an overall pattern of the net activated by edges in a single input image of face, rather than from changes in the shape of the facial organs or their geometrical relationships. We build models of facial expressions from the deformation patterns in the potential net for face images in the training set of different expressions and then project them into emotion space. Expression of an unknown subject can be recognized from the projection of the net for the image into the emotion space. The potential net is further used to model the common human face. The mosaic method representing energy in the net is used as a template for finding candidates for the face area and the candidates are verified their faceness by projecting them into emotion space in order to select the finalist. Precise location of the face is determined by the histogram analysis of vertical and horizontal projections of edges.	ICCV	visu
3657	ICCV	A Recursive Filter for Phase Velocity Assisted Shape-Based Tracking of Cardiac Non-Rigid Motion.	John C. McEachen II,François G. Meyer,R. Todd Constable,Arye Nehorai,James S. Duncan	1995	A framework for tracking pointwise periodic non-rigid motion of the heart's left ventricular (LV) wall is presented which incorporates information from two different magnetic resonance imaging (MRI) techniques. New developments in phase-contrast cine MR imaging have produced spatial maps of instantaneous velocity that heave proven accuracy within the myocardium, or wall, of the heart. This information is combined with shape-based matching techniques to provide improved estimates of trajectories, especially in regions where shape information is limited. These raw trajectories act as input to a recursive least squares (RLS) filter which applies the constraints of temporal periodicity and spatial smoothness for the final estimate. The results of the RLS filter are compared with the motion of actual implanted markers. Comparisons are also made between exclusively shape-based filtered and phase-contrast enhanced trajectory estimates using both phantom and actual canine heart MR images.	ICCV	visu
3658	ICCV	Topologically Adaptable Snakes.	Tim McInerney,Demetri Terzopoulos	1995	The paper presents a typologically adaptable snakes model for image segmentation and object representation. The model is embedded in the framework of domain subdivision using simplicial decomposition. This framework extends the geometric and topological adaptability of snakes while retaining all of the features of traditional snakes, such as user interaction, and overcoming many of the limitations of traditional snakes. By superposing a simplicial grid over the image domain and using this grid to iteratively reparameterize the deforming snakes model, the model is able to flow into complex shapes, even shapes with significant protrusions or branches, and to dynamically change topology as necessitated by the data. Snakes can be created and can split into multiple parts or seamlessly merge into other snakes. The model can also be easily converted to and from the traditional parametric snakes model representation. We apply a 2D model to various synthetic and real images in order to segment objects with complicated shapes and topologies.	ICCV	visu
3659	ICCV	A Unifying Framework for Structure and Motion Recovery from Image Sequences.	Philip F. McLauchlan,David W. Murray	1995	The paper proposes a statistical framework that enables 3D structure and motion to be computed optimally from an image sequence, on the assumption that feature measurement errors are independent and Gaussian distributed. The analysis and results demonstrate that computing both camera/scene motion and 3D structure is essential to computing either with any accuracy. Having computed optimal estimates of structure and motion over a small number of initial images, a recursive version of the algorithm (previously reported) recomputes sub optimal estimates given new image data. The algorithm is designed explicitly for real time implementation, and the complexity is proportional to the number of tracked features. 3D projective, affine and Euclidean models of structure and motion recovery have been implemented, incorporating both point and line features into the computation. The framework can handle any feature type and camera model that may be encapsulated as a projection equation from scene to image.	ICCV	visu
3660	ICCV	Rigidity Checking of 3D Point Correspondences under Perspective Projection.	Daniel P. McReynolds,David G. Lowe	1995	An algorithm is described which rapidly verifies the potential rigidity of three dimensional point correspondences from a pair of two dimensional views under perspective projection. The output of the algorithm is a simple yes or no answer to the question ``Could these corresponding points from two views be the projection of a rigid configuration?'''' Potential applications include 3D object recognition from a single previous view and correspondence matching for stereo or motion over widely separated views. Our analysis begins with the observation that it is often the case that two views cannot provide an accurate structure-from-motion estimate because of ambiguity and ill- conditioning. However, it is argued that an accurate yes/no answer to the rigidity question is possible and experimental results support this assertion with as few as six pairs of corresponding points over a wide range of scene structures and viewing geometries. Rigidity checking verifies point correspondences by using 3D recovery equations as a matching condition. The proposed algorithm improves upon other methods that fall under this approach because it works with as few as six corresponding points under full perspective projection, handles correspondences from widely separated views, makes full use of the disparity of the correspondences, and is integrated with a linear algorithm for 3D recovery due to Kontsevich. The rigidity decision is based on the residual error of an integrated pair of linear and nonlinear structure-from-motion estimators. Results are given for experiments with synthetic and real image data. A complete implementation of this algorithm is being made publicly available.	ICCV	visu
3661	ICCV	Task-Oriented Generation of Visual Sensing Strategies.	Jun Miura,Katsushi Ikeuchi	1995	In vision-guided robotic operations, vision is used for extracting necessary information for achieving the task. Since visual sensing is usually performed with limited resources, visual sensing strategies should be planned so that only necessary information is obtained efficiently. This paper describes a method of systematically generating visual sensing strategies based on knowledge of the task to be performed. The generation of the appropriate visual sensing strategy entails knowing what information to extract, where to get it, and how to get it. This is facilitated by the knowledge of the task, which describes what objects are involved in the operation, and how they are assembled. Our method has been implemented using a laser range finder as the sensor. Experimental results show the feasibility of the method, and point out the importance of task-oriented evaluation of visual sensing strategies.	ICCV	visu
3662	ICCV	Probabilistic Visual Learning for Object Detection.	Baback Moghaddam,Alex Pentland	1995	We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.	ICCV	visu
3663	ICCV	Volumetric Deformable Models with Parameter Functions: A New Approach to the 3D Motion Analysis of the LV from MRI-SPAMM.	Jinah Park,Dimitris N. Metaxas,Leon Axel	1995	We present a new method for analyzing the 3D motion of the heart's left ventricle (LV) from tagged magnetic resonance imaging (MRI) data. Our technique is based on the development of a new class of volumetric physics-based deformable models whose parameters are functions and can capture the local shape variation of an object. These parameters require no complex post-processing in order to be used by a physician. These volumetric models allow the accurate estimation of the shape and motion of the inner and outer walls of the LV as well as within the walls. We also present a new technique for calculating forces exerted by tagged MRI data to material points of the deformable model. Furthermore, by plotting the variations over time of the extracted LV model parameters from normal heart data we are able to quantitatively analyze and compare the epicardial and endocardial motion.	ICCV	visu
3664	ICCV	Shape Extraction for Curves Using Geometry-Driven Diffusion and Functional Optimization.	Eric J. Pauwels,Peter Fiddelaers,Luc J. Van Gool	1995	In this paper we show how both geometry-driven diffusion and optimization of the Mumford-Shah functional can be used to develop a type of curve-evolution that is able to preserve salient features of closed curves (such as corners and straight line segments), while simultaneously suppressing noise and irrelevant details. The idea is to characterize the curve by means of its angle-function (i.e. the angle between the tangent and a fixed axis) and to apply the appropriate dynamics to this one-dimensional representation. We show how constrained evolution equations can be used to keep the corresponding curve closed at all times.	ICCV	visu
3665	ICCV	Validation of 3D Registration Methods Based on Points and Frames.	Xavier Pennec,Jean-Philippe Thirion	1995	Validation of 3D Registration Methods Based on Points and Frames.	ICCV	visu
3666	ICCV	Determining Facial Expressions in Real-Time.	Yael Moses,David Reynard,Andrew Blake	1995	We suggest an approach to describing and tracking the deformation of facial features. We concentrate on the mouth since its shape is important in detecting emotion. However, we believe that our system could be extended to deal with other facial features. In our system, the mouth is described by a valley contour which is based between the lips. This contour is shown to exist independently of illumination, viewpoint, identity, and expression. We present a real time mouth tracking system that follows this valley. It is shown to be robust to changes in identity, illumination and viewpoint. A simple classification algorithm was found to be sufficient to discriminate between 5 different mouth shapes, with a 100% recognition rate.	ICCV	visu
3667	ICCV	Matching of 3D Curves Using Semi-Differential Invariants.	Tomás Pajdla,Luc J. Van Gool	1995	Matching of 3D Curves Using Semi-Differential Invariants.	ICCV	visu
3668	ICCV	Automatic Generation of GRBF Networks for Visual Learning.	Shayan Mukherjee,Shree K. Nayar	1995	Learning can often be viewed as the problem of mapping from an input space to an output space. Examples of these mappings are used to construct a continuous function that approximates given data and generalizes for intermediate instances. Generalized Radial Basis Function (GRBF) networks are used to formulate this approximating function. A novel method is introduced to construct an optimal GRBF network for a given mapping and error bound using the integral wavelet transform. Simple one-dimensional examples are used to demonstrate how the optimal network is superior to one constructed using standard ad hoc optimization techniques. The paper concludes with an application of optimal GRBF networks to object recognition and pose estimation. The results of this application are favorable.	ICCV	visu
3669	ICCV	Recognizing 3D Objects Using Photometric Invariant.	Kenji Nagao	1995	We describe an efficient algorithm for recognizing 3D objects by combining photometric, and geometric invariants. A photometric property is derived, that is invariant to the changes of illumination and to relative object motion with respect to the camera and/or the lighting source in 3D space. We argue that conventional color constancy algorithms can not be used in the recognition of 3D objects. Further we show recognition does not require a full constancy of colors, rather, it only needs something that remains unchanged under the varying light conditions and poses of the objects. Combining the derived color invariant and the spatial constraints on the object surfaces, we identify corresponding positions in the model and the data space coordinates, using centroid invariance of corresponding groups of feature positions. Tests are given to show the stability and efficiency of our approach to 3D object recognition.	ICCV	visu
3670	ICCV	Structure and Semi-Fluid Motion Analysis of Stereoscopic Satellite Images for Cloud Tracking.	Kannappan Palaniappan,Chandra Kambhamettu,Frederick Hasler,Dmitry B. Goldgof	1995	Time-varying multispectral observations of clouds from meteorological satellites are used to estimate cloud-top heights (structure) and cloud winds (semi-fluid motion). Stereo image pairs over several time steps were acquired by two geostationary satellites with synchronized scanning instruments. Cloud-top height estimation from these image pairs is performed using an improved automatic stereo analysis algorithm on a massively parallel Maspar computer with 16 K processors. A new category of motion behavior known as semi-fluid motion is described for modeling cloud motions and an automatic algorithm for extracting semi-fluid motion is developed to track cloud winds. The time sequential dense estimates of cloud-top height depth maps in conjunction with intensity data are used to estimate local semi-fluid motion parameters for cloud tracking. Both stereo disparities and motion correspondences are estimated to sub-pixel accuracy. The Interactive Image SpreadSheet (IISS) is a new versatile visualization tool that was enhanced to analyze and visualize the results of the stereo analysis and semi-fluid motion estimation algorithms. Experimental results using time-varying data of the visible channel from two satellites in geosynchronous orbit is presented for the Hurricane Frederic.	ICCV	visu
3671	ICCV	Results Using Random Field Models for the Segmentation of Color Images of Natural Scenes.	Dileep Kumar Panjwani,Glenn Healey	1995	We present results using a Markov random field color texture model for the unsupervised segmentation of images of outdoor scenes. The color random field model describes textured regions in terms of spatial interaction within color bands and between different color bands. The model is used by a segmentation algorithm based on agglomerative hierarchical clustering. At the heart of the clustering is a step wise optimal merging process that at each iteration maximizes a global performance functional. The test for stopping the clustering is based on changes in the likelihood of the image. We provide experimental results that demonstrate the performance of the segmentation algorithm on color images of natural scenes. Most of the processing during segmentation is local making the algorithm amenable to high performance parallel implementation.	ICCV	visu
3672	ICCV	Real-Time Focus Range Sensor.	Shree K. Nayar,Masahiro Watanabe,Minori Noguchi	1995	Structures of dynamic scenes can only be recovered using a real-time range sensor. Depth-from-defocus offers a direct solution to fast and dense range estimation. It is computationally efficient as it circumvents the correspondence problem faced by stereo and feature tracking in structure-from-motion. However, accurate depth estimation requires theoretical and practical solutions to a variety of problems including the recovery of textureless surfaces, precise blur estimation, and magnification variations caused by defocusing. Both textured and textureless surfaces are recovered using an illumination pattern that is projected via the same optical path used to acquire images. The illumination pattern is optimized to ensure maximum accuracy and spatial resolution in the computed depth. The relative blurring in two images is computed using a narrow-band linear operator that is designed by considering all the optical, sensing and computational elements of the depth-from-defocus system. Defocus-invariant magnification is achieved by the use of an additional aperture in the imaging optics. A prototype focus range sensor has been developed that produces up to 512/spl times/480 depth estimates at 30 Hz with an accuracy better than 0.3%. Several experimental results are included to demonstrate the performance of the sensor.	ICCV	visu
3673	ICCV	Deformable Velcro(tm) Surfaces.	Walter M. Neuenschwander,Pascal Fua,Gábor Székely,Olaf Kübler	1995	Deformable Velcro(tm) Surfaces.	ICCV	visu
3674	ICCV	Surface Reconstruction: GNCs and MFA.	Mads Nielsen	1995	The reconstruction of noise corrupted surfaces can be inferred by methodologies such as Bayesian estimation and minimum description length. Both of these imply a formulation where the reconstruction minimizes a functional. Often this functional is non convex and the minimum cannot be found by simple gradient methods. The paper concerns functionals with quadratic data term, criteria for such functionals to be convex, and the variational approach of minimizing non convex functionals. Initial convexity of the approximating functional is considered to be a critical point. Two fully automatic methods of generating convex functionals are presented. They are based on Gaussian convolution and are compared to the Blake-Zisserman graduated non convexity (GNC) (A. Blake, A. Zisserman, 1987) and G.L. Bilbro et al. (1992) and D. Geiger and F. Girosi's (1991) mean field annealing (MFA) of the weak membrane.	ICCV	visu
3675	ICCV	The Nonparametric Approach for Camera Calibration.	MaoLin Qiu,Song De Ma	1995	The Nonparametric Approach for Camera Calibration.	ICCV	visu
3676	ICCV	Invariant of a Pair of Non-Coplanar Conies in Space: Definition, Geometric Interpretation and Computation.	Long Quan	1995	The joint invariants of a pair of coplanar conics has been widely used in recent vision literature. In this paper, the algebraic invariant of a pair of non-coplanar conics in space is concerned. The algebraic invariant of a pair of non-coplanar conics is first derived from the invariant algebra of a pair of quaternary quadratic forms by using the dual representation of space conics. Then, this algebraic invariant is geometrically interpreted in terms of cross-ratios. Finally, an analytical procedure for projective reconstruction of a space conic from two uncalibrated images is developed and the correspondence conditions of the conics between two views are also explicited.	ICCV	visu
3677	ICCV	Detecting Kinetic Occlusion.	Sourabh A. Niyogi	1995	Visual motion boundaries provide a powerful cue for the perceptual organization of scenes. Motion boundaries are present when surfaces in motion occlude one another. Conventional approaches to motion analysis have relied on assumptions of data conservation and smoothness, which has made analysis of motion boundaries difficult. We show that a common source of motion boundary, kinetic occlusion, can be detected using spatiotemporal junction analysis. Junction analysis is accomplished by utilizing distributed representations of motion used in models of human visual motion sensing. By detecting changes in the direction of motion in these representations, spatiotemporal junctions are detected in a manner which differentiates accretion from deletion. We demonstrate successful occlusion detection on spatiotemporal imagery containing occluding surfaces in motion.	ICCV	visu
3678	ICCV	A Snake for Model-Based Segmentation.	Petia Radeva,Joan Serrat,Enric Martí	1995	Despite the promising results of numerous applications, the hitherto proposed snake techniques share some common problems: snake attraction by spurious edge points, snake degeneration (shrinking and flattening), convergence and stability of the deformation process, snake initialization and local determination of the parameters of elasticity. We argue here that these problems can be solved only when all the snake aspects are considered. The snakes proposed here implement a new potential field and external force in order to provide a deformation convergence, attraction by both near and far edges as well as snake behaviour selective according to the edge orientation. Furthermore, we conclude that in the case of model-based segmentation, the internal force should include structural information about the expected snake shape. Experiments using this kind of snakes for segmenting bones in complex hand radiographs show a significant improvement.	ICCV	visu
3679	ICCV	A Theory of Specular Surface Geometry.	Michael Oren,Shree K. Nayar	1995	A theoretical framework is introduced for the perception of specular surface geometry. When an observer moves in three-dimensional space, real scene features, such as surface markings, remain stationary with respect to the surfaces they belong to. In contrast, a virtual feature, which is the specular reflection of a real feature, travels on the surface. Based on the notion of caustics, a novel feature classification algorithm is developed that distinguishes real and virtual features from their image trajectories that result from observer motion. Next, using support functions of curves, a closed-form relation is derived between the image trajectory of a virtual feature and the geometry of the specular surface it travels on. It is shown that in the 2D case where camera motion and the surface profile are coplanar, the profile is uniquely recovered by tracking just two unknown virtual features. Finally, these results are generalized to the case of arbitrary 3D surface profiles that are travelled by virtual features when camera motion is not confined to a plane. An algorithm is developed that uniquely recovers 3D surface profiles using a single virtual feature tracked from the occluding boundary of the object. All theoretical derivations and proposed algorithms are substantiated by experiments.	ICCV	visu
3680	ICCV	Object Indexing Using an Iconic Sparse Distributed Memory.	Rajesh P. N. Rao,Dana H. Ballard	1995	A general-purpose object indexing technique is described that combines the virtues of principal component analysis with the favorable matching properties of high-dimensional spaces to achieve high-precision recognition. An object is represented by a set of high-dimensional iconic feature vectors comprised of the responses of derivatives of Gaussian filters at a range of orientations and scales. Since these filters can be shown to form the eigenvectors of arbitrary images containing both natural and man-made structures, they are well-suited for indexing in disparate domains. The indexing algorithm uses an active vision system in conjunction with a modified form of Kanerva's (1988, 1993) sparse distributed memory which facilitates interpolation between views and provides a convenient platform for learning the association between an object's appearance and its identity. The robustness of the indexing method was experimentally confirmed by subjecting the method to a range of viewing conditions and the accuracy was verified using a well-known model database containing a number of complex 3D objects under varying pose.	ICCV	visu
3681	ICCV	Model-Based Tracking of Self-Occluding Articulated Objects.	James M. Rehg,Takeo Kanade	1995	Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.	ICCV	visu
3682	ICCV	Weakly-Calibrated Stereo Perception for Rover Navigation.	Luc Robert,Michel Buffa,Martial Hebert	1995	Presents a vision system for autonomous navigation based on stereo perception without 3D reconstruction. This approach uses weakly calibrated stereo images, i.e. images for which only the epipolar geometry is known. The vision system first rectifies the images, matches selected points between the two images, and then computes the relative elevation of the points relative to a reference plane as well as the images of their projections on this plane. We have integrated this vision module into a complete navigation system. In this system, the relative elevation is used as a shape indicator in order to compute appropriate steering directions everytime a new stereo pair is processed. We have conducted initial experiments in unstructured, outdoor environments with an wheeled rover.	ICCV	visu
3683	ICCV	Trilinearity of Three Perspective Views and its Associated Tensor.	Amnon Shashua,Michael Werman	1995	It has been established that certain trilinear forms of three perspective views give rise to a tensor of 27 intrinsic coefficients. We show in this paper that a permutation of the the trilinear coefficients produces three homography matrices (projective transformations of planes) of three distinct intrinsic planes, respectively. This, in turn, yields the result that 3D invariants are recovered directly-simply by appropriate arrangement of the tensor's coefficients. On a secondary level, we show new relations between fundamental matrix, epipoles, Euclidean structure and the trilinear tensor. On the practical side, the new results extend the existing envelope of methods of 3D recovery from 2D views-for example, new linear methods that cut through the epipolar geometry, and new methods for computing epipolar geometry using redundancy available across many views.	ICCV	visu
3684	ICCV	A Model-Based Integrated Approach to Track Myocardial Deformation Using Displacement and Velocity Constraints.	Pengcheng Shi,Glynn P. Robinson,R. Todd Constable,Albert J. Sinusas,James S. Duncan	1995	Accurate estimation of heart wall dense field motion and deformation could help to better understand the physiological processes associated with ischemic heart diseases, and to provide significant improvement in patient treatment. We present a new method of estimating left ventricular deformation which integrates instantaneous velocity information obtained within the mid-wall region with shape information found on the boundaries of the left ventricle. Velocity information is obtained from phase contrast magnetic resonance images, and boundary information is obtained from shape-based motion tracking of the endo- and cardial boundaries. The integration takes place within a continuum biomechanical heart model which is embedded in a finite element framework. We also employ a feedback mechanism to improve tracking accuracy. The integration of the two disparate but complementary sources overcomes some of the limitations of previous work in the field which concentrates on motion estimation from a single image-derived source.	ICCV	visu
3685	ICCV	Probabilistic 3D Object Recognition.	Ilan Shimshoni,Jean Ponce	1995	A probabilistic 3D object recognition algorithm is presented. In order to guide the recognition process the probability that match hypotheses between image features and model features are correct is computed. A model is developed which uses the probabilistic peaking effect of measured angles and ratios of lengths by tracing iso angle and iso ratio curves on the viewing sphere. The model also accounts for various types of uncertainty in the input such as incomplete and inexact edge detection. For each match hypothesis the pose of the object and the pose uncertainty which is due to the uncertainty in vertex position are recovered. This is used to find sets of hypotheses which reinforce each other by matching features of the same object with compatible uncertainty subsets. A probabalistic expression is used to rank these hypothesis sets. The hypothesis sets with the highest rank are output. The algorithm has been fully implemented, and tested on real images.	ICCV	visu
3686	ICCV	A Comparison of Projective Reconstruction Methods for Pairs of Views.	Charlie Rothwell,Gabriela Csurka,Olivier D. Faugeras	1995	Recently, different approaches for uncalibrated stereo have been suggested which permit projective reconstruction from multiple views. These use weak calibration which is represented by the epipolar geometry, and so no knowledge of the intrinsic or extrinsic camera parameters is required. We consider projective reconstructions from pairs of views, and compare a number of the available methods. Consequently we conclude which methods are most likely to be of use in applications that are dependent on 3D uncalibrated reconstructions.	ICCV	visu
3687	ICCV	An Integral Approach to Free-Formed Object Modeling.	Heung-Yeung Shum,Martial Hebert,Katsushi Ikeuchi,Raj Reddy	1995	Presents a new approach to free-formed object modeling from multiple range images. In most conventional approaches, successive views are registered sequentially. In contrast to the sequential approaches, we propose an integral approach which reconstructs statistically optimal object models by simultaneously aggregating all data from multiple views into a weighted least-squares (WLS) formulation. The integral approach has two components. First, a global resampling algorithm constructs partial representations of the object from individual views so that correspondences can be established among different views. The global resampling algorithm is based on the spherical attribute image (SAI) previously introduced in the context of object representation and recognition. Second, a weighted least-squares algorithm integrates resampled partial representations of multiple views, using the technique of principal component analysis with missing data (PCAMD). Experiments using real range images show that our approach is robust against noise and mismatches, and generates accurate object models.	ICCV	visu
3688	ICCV	Locating Objects Using the Hausdorff Distance.	William Rucklidge	1995	The Hausdorff distance is a measure defined between two point sets representing a model and an image. In the past, it has been used to search images for instances of a model that has been translated or translated and scaled by finding transformations that bring a large number of model features close to image features, and vice versa. The Hausdorff distance is reliable even when the image contains multiple objects, noise, spurious features, and occlusions. We apply it to the task of locating an affine transformation of a model in an image; this corresponds to determining the pose of a planar object that has undergone weak perspective projection. We develop a rasterised approach to the search and a number of techniques that allow us to quickly locate all transformations of the model that satisfy two quality criteria; we can also quickly locate only the best transformation. We discuss an implementation of this approach, and present some examples of its use.	ICCV	visu
3689	ICCV	Steerable Wedge Filters.	Eero P. Simoncelli,Hany Farid	1995	Steerable filters, as developed by Freeman and Adelson (1991), are a class of rotation-invariant linear operators that may be used to analyze local orientation patterns in imagery. The most common examples of such operators are directional derivatives of Gaussians and their 2D Hilbert transforms. The inherent symmetry of these filters produces an orientation response that is periodic with period /spl pi/, even when the underlying image structure does not have such symmetry. This problem may be alleviated by reconsidering the full class of steerable filters. We develop a family of even- and odd-symmetric steerable filters that have a spatially asymmetric wedge-like shape and are optimally localized in their orientation response. Unlike the original steerable filters, these filters are not based on directional derivatives and the Hilbert transform relationship is imposed on their angular components. We demonstrate the ability of these filters to properly represent oriented structures.	ICCV	visu
3690	ICCV	Perceptual Organization in an Interactive Sketch Editing Application.	Eric Saund,Thomas P. Moran	1995	The paper shows how techniques from computational vision can be deployed to support interactive sketch editing. While conventional computer supported drawing tools give users access to visible marks or image objects at a single level of abstraction, a human user's visual system rapidly constructs complex groupings and associations among image elements according to his or her immediate purposes. We have been exploring perceptually supported sketch editors in which computer vision algorithms run continuously, behind the scenes, to afford users efficient access to emergent visual objects in a drawing. We employ a flexible image interpretation architecture based on token grouping in a multiscale blackboard data structure. This organization supports multiple perceptual interpretations of line drawing data, domain specific knowledge bases for interpreting visual structures, and natural gesture based selection of visual objects.	ICCV	visu
3691	ICCV	Combining Color and Geometric Information for the Illumination Invariant Recognition of 3D Objects.	David Slater,Glenn Healey	1995	Combining Color and Geometric Information for the Illumination Invariant Recognition of 3D Objects.	ICCV	visu
3692	ICCV	Model-Based 2D&3D Dominant Motion Estimation for Mosaicing and Video Representation.	Harpreet S. Sawhney,Serge Ayer,Monika Gorkani	1995	Model-Based 2D&3D Dominant Motion Estimation for Mosaicing and Video Representation.	ICCV	visu
3693	ICCV	ASSET-2: Real-Time Motion Segmentation and Shape Tracking.	Stephen M. Smith	1995	The paper describes how image sequences taken by a moving video camera may be processed to detect and track moving objects against a moving background in real-time. The motion segmentation and shape tracking system as known as ASSET-2-A Scene Segmenter Establishing Tracking, Version 2. Motion is found by tracking image features, and segmentation is based on first-order (i.e., six parameter) flow fields. Shape tracking is performed using two dimensional radial map representation. The system runs in real-time, and is accurate and reliable. It requires no camera calibration and no knowledge of the camera's motion.	ICCV	visu
3694	ICCV	Dynamic Rigid Motion Estimation from Weak Perspective.	Stefano Soatto,Pietro Perona	1995	Weak perspective represents a simplified projection model that approximates the imaging process when the scene is viewed under a small viewing angle and its depth relief is small relative to its distance from the viewer. We study how to generate dynamic models for estimating rigid 3D motion from weak perspective. A crucial feature in dynamic visual motion estimation is to decouple structure from motion in the estimation model. The reasons are both geometric-to achieve global observability of the model-and practical, for a structure independent motion estimator allows us to deal with occlusions and appearance of new features in a principled way. It is also possible to push the decoupling even further, and isolate the motion parameters that are affected by the so called bas relief ambiguity from the ones that are not. We present a novel method for reducing the order of the estimator by decoupling portions of the state space from the time evolution of the measurement constraint. We use this method to construct an estimator of full rigid motion (modulo a scaling factor) on a six dimensional state space, an approximate estimator for a four dimensional subset of the motion space, and a reduced filter with only two states. The latter two are immune to the bas relief ambiguity. We compare strengths and weaknesses of each of the schemes on real and synthetic image sequences.	ICCV	visu
3695	ICCV	Limitations of Markov Random Fields as Models of Textured Images of Real Surfaces.	Athanasios Speis,Glenn Healey	1995	We investigate to what extent textures can be distinguished using conditional Markov fields and small samples. We establish that the least square (LS) estimator is the only reasonable choice for this task and we prove its asymptotic consistency and normality for a general class of random fields that include Gaussian Markov fields as a special case. The performance of this estimator when applied to textured images of real surfaces is poor if small boxes are used (20/spl times/20 or less). We investigate the nature of this problem by comparing the behavior predicted by the rigorous theory to the one that has been experimentally observed. Our analysis reveal that 20/spl times/20 samples contain enough information to distinguish between the textures in our experiments and that the poor performance mentioned above should be attributed to the fact that conditional Markov fields do not provide accurate models for textured images of many real surfaces. A more general model that exploits more efficiently the information contained in small samples is also suggested.	ICCV	visu
3696	ICCV	Complete Scene Structure from Four Point Correspondences.	Steven M. Seitz,Charles R. Dyer	1995	A technique is presented for computing 3D scene structure from point and line features in monocular image sequences. Unlike previous methods, the technique guarantees the completeness of the recovered scene, ensuring that every scene feature that is detected in each image is reconstructed. The approach relies on the presence of four or more reference features whose correspondences are known in all the images. Under an orthographic or affine camera model, the parallax of the reference features provides constraints that simplify the recovery of the rest of the visible scene. An efficient recursive algorithm is described that uses a unified framework for point and line features. The algorithm integrates the tasks of feature correspondence and structure recovery, ensuring that all reconstructible features are tracked. In addition, the algorithm is immune to outliers and feature drift, two weaknesses of existing structure from motion techniques. Experimental results are presented for real images.	ICCV	visu
3697	ICCV	Optimal Subpixel Matching of Contour Chains and Segments.	Bruno Serra,Marc Berthod	1995	This paper introduces a new general purpose algorithm that allows the optimal geometric match between contours to be determined, that is the transformation yielding a minimal deformation is obtained. The algorithm relies only on the geometric properties of the contours and does not call for any other constraint, so that it is particularly suitable when no parameterization of title deformation is available or desirable. Contour deformation is explicitly incorporated in the computation, allowing for a thorough use of all geometric information available. Moreover, no discretization is involved in the computation, resulting in two main advantages: first, the algorithm is robust to differences in the segmentation of contours and allows the matching of polygonal approximations of contours with very little loss of precision, second, subpixel precision matching can be achieved.	ICCV	visu
3698	ICCV	Accurate Internal Camera Calibration Using Rotation, with Analysis of Sources of Error.	Gideon P. Stein	1995	Describes a simple and accurate method for internal camera calibration based on tracking image features through a sequence of images while the camera undergoes pure rotation. A special calibration object is not required and the method can therefore be used both for laboratory calibration and for self calibration in autonomous robots. Experimental results with real images show that focal length and aspect ratio can be found to within 0.15 percent, and lens distortion error can be reduced to a fraction of a pixel. The location of the principal point and the location of the center of radial distortion can each be found to within a few pixels. We perform a simple analysis to show to what extent the various technical details affect the accuracy of the results. We show that having pure rotation is important if the features are derived from objects close to the camera. In the basic method accurate angle measurement is important. The need to accurately measure the angles can be eliminated by rotating the camera through a complete circle while taking an overlapping sequence of images and using the constraint that the sum of the angles must equal 960 degrees.	ICCV	visu
3699	ICCV	Robot Aerobics: Four Easy Steps to a More Flexible Calibration.	Daniel E. Stevenson,Margaret M. Fleck	1995	Presents a method for calibrating intrinsic and extrinsic camera parameters. This algorithm can easily be modified by other users to suit their particular calibration needs, without requiring a high-precision calibration target or complicated linear algebra. The algorithm uses controlled motions and a single light source to simulate calibration targets in convenient 3D locations. These convenient calibration targets enable us to simplify the calibration algorithm and gather dense data for lens distortion. Dense data makes the distortion correction more accurate than traditional low-order polynomial fits, and allows us to calibrate wide-angle lenses (	ICCV	visu
3700	ICCV	Expected Performance of Robust Estimators Near Discontinuities.	Charles V. Stewart	1995	In extracting a polynomial surface patch near an intensity or range discontinuity, a robust estimator must tolerate not only the truly random bad data (random outliers), but also the coherently structured points (pseudo outliers) that belong to a different surface. To characterize the performance of least median of squares, M estimators, Hough transforms, RANSAC, and MINPRAN on data containing both random and pseudo outliers, we develop two analytical measures, pseudo outlier bias and pseudo outlier breakdown. Using these measures, we find that each robust estimator has surprisingly poor performance, even under the best possible circumstances, implying that present estimators should be used with care and new estimators should be developed.	ICCV	visu
3701	ICCV	Motion Estimation with Quadtree Splines.	Richard Szeliski,Heung-Yeung Shum	1995	This paper presents a motion estimation algorithm based on a new multiresolution representation, the quadtree spline. This representation describes the motion field as a collection of smoothly connected patches of varying size, where the patch size is automatically adapted to the complexity of the underlying motion. The topology of the patches is determined by a quadtree data structure, and both split and merge techniques are developed for estimating this spatial subdivision. The quadtree spline is implemented using another novel representation, the adaptive hierarchical basis spline, and combines the advantages of adaptively-sized correlation windows with the speedups obtained with hierarchical basis preconditioners. Results are presented on some standard motion sequences.	ICCV	visu
3702	ICCV	A Geometric Criterion for Shape-Based Non-Rigid Correspondence.	Hemant Tagare,Don O'Shea,Anand Rangarajan	1995	A geometric criterion is developed for establishing shape based non rigid correspondence between plane curves. Unlike previous efforts, the criterion does not use rigid invariants of shape. Instead, shapes are compared non rigidly from the vantage point of the correspondence. Geometric invariants are proposed for curves whose shapes can be exactly matched by a non rigid correspondence. The invariants are based on angular deviations of convex and concave segments of the curves. Examples of correspondences between curves obtained from medical images are provided.	ICCV	visu
3703	ICCV	Curve and Surface Smoothing without Shrinkage.	Gabriel Taubin	1995	For a number of computational purposes, including visualization of scientific data and registration of multimodal medical data, smooth curves must be approximated by polygonal curves, and surfaces by polyhedral surfaces. An inherent problem of these approximation algorithms is that the resulting curves and surfaces appear faceted. Boundary-following and iso-surface construction algorithms are typical examples. To reduce the apparent faceting, smoothing methods are used. In this paper, we introduce a new method for smoothing piecewise linear shapes of arbitrary dimension and topology. This new method is in fact a linear low-pass filter that removes high-curvature variations, and does not produce shrinkage. Its computational complexity is linear in the number of edges or faces of the shape, and the required storage is linear in the number of vertices.	ICCV	visu
3704	ICCV	Estimating the Tensor of Curvature of a Surface from a Polyhedral Approximation.	Gabriel Taubin	1995	Estimating principal curvatures and principal directions of a surface from a polyhedral approximation with a large number of small faces, such as those produced by iso-surface construction algorithms, has become a basic step in many computer vision algorithms, particularly in those targeted at medical applications. We describe a method to estimate the tensor of curvature of a surface at the vertices of a polyhedral approximation. Principal curvatures and principal directions are obtained by computing in closed form the eigenvalues and eigenvectors of certain 3/spl times/3 symmetric matrices defined by integral formulas, and closely related to the matrix representation of the tensor of curvature. The resulting algorithm is linear, both in time and in space, as a function of the number of vertices and faces of the polyhedral surface.	ICCV	visu
3705	ICCV	Image Segmentation by Reaction-Diffusion Bubbles.	Hüseyin Tek,Benjamin B. Kimia	1995	Figure-ground segmentation is a fundamental problem in computer vision. The main difficulty is the integration of low-level, pixel-based local image features to obtain global object-based descriptions. Active contours in the form of snakes, balloons, and level-set modeling techniques have been proposed that satisfactorily address this question for certain applications. However, these methods require manual initialization, do not always perform well near sharp protrusions or indentations, or often cross gaps. We propose an approach inspired by these methods and a shock-based representation of shape in terms of parts, protrusions, and bends. Since initially it is not clear where the objects or their parts are, parts are hypothesized in the form of fourth order shocks randomly initialized in homogeneous areas of images. These shocks then form evolving contours, or bubbles, which grow, shrink, merge, split and disappear to capture the objects in the image. In the homogeneous areas of the image bubbles deform by a reaction-diffusion process. In the inhomogeneous areas, indicated by differential properties computed from low-level processes such as edge-detection, texture, optical-flow and stereo, etc., bubbles do not deform. As such, the randomly initialized bubbles integrate low-level information and, in the process, segment the figures from the ground.	ICCV	visu
3706	ICCV	Animat Vision: Active Vision in Artificial Animals.	Demetri Terzopoulos,Tamer F. Rabie	1995	We propose and demonstrate a new paradigm for active vision research that draws upon recent advances in the fields of artificial life and computer graphics. A software alternative to the prevailing hardware vision mindset, animat vision prescribes artificial animals, or animats, situated in physics-based virtual worlds as autonomous virtual robots possessing active perception systems. To be operative in its world, an animat must autonomously control its eyes and muscle-actuated body, applying computer vision algorithms to continuously analyze the retinal image streams acquired by its eyes in order to locomote purposefully through its world. We describe an initial animat vision implementation within lifelike artificial fishes inhabiting a physics-based, virtual marine world. Emulating the appearance, motion, and behavior of real fishes in their natural habitats, these animats are capable of spatially nonuniform retinal imaging, foveation, retinal image stabilization, color object recognition, and perceptually-guided navigation. These capabilities allow them to pursue moving targets such as fellow artificial fishes. Animat vision offers a fertile approach to the development, implementation, and evaluation of computational theories that profess sensorimotor competence for animal or robotic situated agents.	ICCV	visu
3707	ICCV	Recovering 3D Motion of Multiple Objects Using Adaptive Hough Transform.	Tina Yu Tian,Mubarak Shah	1995	Presents a method to determine the 3D motion of multiple objects from two perspective views. In our method, segmentation is determined based on a 3D rigidity constraint. We divide the input image into overlapping patches, and for each sample of the translation parameter space, we compute the rotation parameters of patches using a least-squares fit. Every patch votes for a sample in the translation and rotation parameter space. For a patch containing multiple motions, we use an M-estimator to compute rotation parameters of a dominant motion. We use the adaptive Hough transform to refine the relevant parameter space in a coarse-to-fine fashion. Applications of the proposed method to both synthetic and real images are demonstrated with promising results.	ICCV	visu
3708	ICCV	Computation of Coherent Optical Flow by Using Multiple Constraints.	Massimo Tistarelli	1995	The optical flow constitutes one of the most widely adopted representations to define and characterize the evolution of image features over time. In order to compute the velocity field, it is necessary to define a set of constraints on the temporal change of image features. We consider the implications in using multiple constraints arising from multiple data points. The first step is the analysis of differential constraints and how they can be applied, locally, to compute the image velocity. This analysis allows to relate each constraint to a particular gray level pattern. This approach is extended to multiple image points, allowing also the characterization of the temporal behaviour of the image features and to detect erroneous measurements due to occlusions, depth discontinuities or shadows. Several experiments are presented from real image sequences.	ICCV	visu
3709	ICCV	Robust Detection of Degenerate Configurations for the Fundamental Matrix.	Philip H. S. Torr,Andrew Zisserman,Stephen J. Maybank	1995	New methods are reported for the detection of multiple solutions (degeneracy) when estimating the fundamental matrix, with specific emphasis on robustness in the presence of data contamination (outliers). The fundamental matrix can be used as a first step in the recovery of structure from motion. If the set of correspondences is degenerate then this structure cannot be accurately recovered and many solutions will explain the data equally well. It is essential that we are alerted to such eventualities. However, current feature matchers are very prone to mismatching, giving a high rate of contamination within the data. Such contamination can make a degenerate data set appear non degenerate, thus the need for robust methods becomes apparent. The paper presents such methods with a particular emphasis on providing a method that will work on real imagery and with an automated (non perfect) feature detector and matcher. It is demonstrated that proper modelling of degeneracy in the presence of outliers enables the detection of outliers which would otherwise be missed. Results using real image sequences are presented. All processing, point matching, degeneracy detection and outlier detection is automatic.	ICCV	visu
3710	ICCV	Matching Constraints and the Joint Image.	Bill Triggs	1995	The paper studies the geometry of multi image perspective projection and the matching constraints that this induces on image measurements. The combined image projections define a 3D joint image subspace of the space of combined homogeneous image coordinates. This is a complete projective replica of the 3D world in image coordinates. Its location encodes the imaging geometry and is captured by the 4 index joint image Grassmannian tensor. Projective reconstruction in the joint image is a canonical process requiring only a simple rescaling of image coordinates. Reconstruction in world coordinates amounts to a choice of basis in the joint image. The matching constraints are multilinear tensorial equations in image coordinates that tell whether tokens in different images could be the projections of a single world token. For 2D images of 3D points there are exactly three basic types: the epipolar constraint, A. Shashua's (1995) trilinear one, and a new quadrilinear 4 image one. For images of lines, R. Hartley's (1994) trilinear constraint is the only type. The coefficients of the matching constraints are tensors built directly from the joint image Grassmannian. Their complex algebraic interdependency is captured by quadratic structural simplicity constraints on the Grassmannian.	ICCV	visu
3711	ICCV	Towards an Active Visual Observer.	Tomas Uhlin,Peter Nordlund,Atsuto Maki,Jan-Olof Eklundh	1995	We present a binocular active vision system that can attend to and fixate a moving target. Our system has an open and expandable design and it forms the first steps of a long term effort towards developing an active observer using vision to interact with the environment, in particular capable of figure-ground segmentation. We also present partial real-time implementations of this system and show their performance in real-world situations together with motor control. In pursuit we particularly focus on occlusions of other targets, both stationary and moving, and integrate three cues, ego-motion, target motion and target disparity, to obtain an overall robust behavior. An active vision system must be open, expandable, and operate with whatever data are available momentarily. It must also be equipped with means and methods to direct and change its attention. This system is therefore equipped with motion detection for changing attention and pursuit for maintaining attention, both of which run concurrently.	ICCV	visu
3712	ICCV	Motion Analysis with a Camera with Unknown, and Possibly Varying Intrinsic Parameters.	Thierry Viéville,Olivier D. Faugeras	1995	In the present paper we address the problem of computing structure and motion, given a set point correspondences in a monocular image sequence, considering small motions when the camera is not calibrated. We first set the equations defining the calibration, rigid motion and scene structure. We then review the motion equation, the structure from equation and the depth evolution equation, including the particular case of planar structures, considering a discrete displacement between two frames. A step further, we develop the first order expansion of these equations and analyse the observability of the related infinitesimal quantities. It is shown that we obtain a complete correspondence between these equations and the equation derived in the discrete case. However, in the case of infinitesimal displacements, the projection of the translation (focus of expansion or epipole) is clearly separated from the rotational component of the motion. This is an important advantage of the present approach. Using this last property, we propose a mechanism of image stabilization in which the rotational disparity is iteratively canceled. This allows a better estimation of the focus of expansion, and simplifies different aspects of the analysis of the equations: structure from motion equation, analysis of ambiguity, geometrical interpretation of the motion equation.	ICCV	visu
3713	ICCV	Invariant-Based Recognition of Complex Curved 3D Objects from Image Contours.	B. Vijayakumar,David J. Kriegman,Jean Ponce	1995	To recognize three-dimensional objects bounded by smooth curved surfaces from monocular image contours, viewpoint-dependent image features must be related to object geometry. Contour bitangents and inflections along with associated parallel tangents points are the projection of surface points that lie on the occluding contour for a five-parameter family of scaled orthographic projection viewpoints. An invariant representation can be computed from these image features and seen for modeling and recognizing objects. Modeling is achieved by moving an object in front of a camera to obtain a curve of possible invariants. The relative camera-object motion is not required, and 3D models are not utilized. At recognition time, invariants computed from a single image are used to index the model database. Using the matched features, independent qualitative and quantitative verification procedures eliminate potential false matches. Examples from an implementation are presented.	ICCV	visu
3714	ICCV	Alignment by Maximization of Mutual Information .	Paul A. Viola,William M. Wells III	1995	A new information-theoretic approach is presented for finding the pose of an object in an image. The technique does not require information about the surface properties of the object, besides its shape, and is robust with respect to variations of illumination. In our derivation, few assumptions are made about the nature of the imaging process. As a result, the algorithms are quite general and can foreseeably be used in a wide variety of imaging situations. Experiments are presented that demonstrate the approach in registering magnetic resonance images, aligning a complex 3D object model to real scenes including clutter and occlusion, tracking a human head in a video sequence and aligning a view-based 2D object model to real images. The method is based on a formulation of the mutual information between the model and the image. As applied in this paper, the technique is intensity-based, rather than feature-based. It works well in domains where edge or gradient-magnitude based methods have difficulty, yet it is more robust then traditional correlation. Additionally, it has an efficient implementation that is based on stochastic approximation.	ICCV	visu
3715	ICCV	Shape from Shading with Interreflections under Proximal Light Source: 3D Shape Reconstruction of Unfolded Book Surface from a Scanner Image.	Toshikazu Wada,Hiroyuki Ukida,Takashi Matsuyama	1995	We address the problem to recover the 3D shape of an unfolded book surface from the shading information in a scanner image. From a technical point of view, this shape from shading problem in real world environments is characterized by (1) proximal light source, (2) interreflections, (3) moving light source, (4) specular reflection, and (5) nonuniform albedo distribution. Taking all these factors into account, we first formulate the problem based on an iterative nonlinear optimization scheme. Then we introduce piecewise polynomial models of the 3D shape. Image restoration experiments for a real book surface demonstrated that geometric and photometric distortions are almost completely removed by the proposed method.	ICCV	visu
3716	ICCV	Region Correspondence by Inexact Attributed Planar Graph Matching.	Caihua Wang,Keiichi Abe	1995	An efficient graph matching approach is proposed for finding region correspondence between two images of the same scene but taken from different viewpoints. Regions and their relations in an image are represented with region adjacency graph (RAG), which is a kind of attributed planar graph. The problem to find an optimal region correspondence, which matches the regions in two images with maximal similarity in region features and region relations, is formulated into the problem to find the optimal inexact matching between two RAGs. The properties specific to planar graph and that of the region adjacency relations are utilized to invent an efficient algorithm to solve the problem. Experimental results on various kinds of images show the effectiveness of the method.	ICCV	visu
3717	ICCV	Rigid Body Segmentation and Shape Description from Dense Optical Flow under Weak Perspective.	Joseph Weber,Jitendra Malik	1995	We present an algorithm for identifying and tracking independently moving rigid objects from optical flow. The proposed method uses the fact that each distinct object has a unique epipolar constraint associated with its motion. This is in contrast to using local optical flow information for segmentation. Thus motion discontinuities based on self-occlusion are distinguished from those due to separate objects. The use of epipolar geometry allows for the determination of individual motion parameters for each object as well as the recovery of relative depth for each point on the object. The segmentation problem is formulated as a scene partitioning problem and a statistic-based algorithm which uses only nearest neighbor interactions and a finite number of iterations is developed. A Kalman filter based approach is used for tracking motion parameters with time. The algorithm assumes an affine camera where perspective effects are limited to changes in overall scale. No camera calibration parameters are required.	ICCV	visu
3718	ICCV	The Study of 3D-from-2D Using Elimination.	Michael Werman,Amnon Shashua	1995	The Study of 3D-from-2D Using Elimination.	ICCV	visu
3719	ICCV	Rendering Real-World Objects Using View Interpolation.	Tomás Werner,Roger D. Hersch,Václav Hlavác	1995	Presents a new approach to rendering arbitrary views of real-world 3D objects of complex shapes. We propose to represent an object by a sparse set of corresponding 2D views, and to construct any other view as a combination of these reference views. We show that this combination can be linear, assuming proximity of the views, and we suggest how the visibility of constructed points can be determined. Our approach makes it possible to avoid difficult 3D reconstruction, assuming only rendering is required. Moreover, almost no calibration of views is needed. We present preliminary results on real objects, indicating that the approach is feasible.	ICCV	visu
3720	ICCV	Algorithms for Implicit Deformable Models.	Ross T. Whitaker	1995	This paper presents a framework for implicit deformable models and a pair of new algorithms for solving the nonlinear partial differential equations that result from this framework. Implicit models offer a useful alternative to parametric models, particularly when dealing with the deformation of higher-dimensional objects. The basic expressions for the evolution of implicit models are relatively straightforward; they follow as a direct consequence of the chain rule for differentiation. More challenging, however, is the development of algorithms that are stable and efficient. The first algorithm is a viscosity approximation which gives solutions over a dense set in the range, providing a means of calculating the solutions of embedded families of contours simultaneously. The second algorithm incorporates sparse solutions for a discrete set of contours. This sparse-field method requires a fraction of the computation compared to the first but offers solutions only for a finite number of contours. Results from 3d medical data as well as video images are shown.	ICCV	visu
3721	ICCV	Closing the Loop on Multiple Motions.	Charles Wiles,Michael Brady	1995	We describe a number of advances in the analysis of road scenes when the scene contains multiple moving objects and is observed by a single nonsteerable camera mounted on the front of a vehicle. Our structure from motion approach to scene segmentation derives front the observed motions of independently moving objects and requires no prior knowledge. We describe a hierarchy of camera models for the analysis of the scene, the simpler models handle degeneracies that occur in the more complex models. The major technical contribution is the recursive computation of feature clusters, which are fed forward over time. This closed loop feature tracking generates extended feature trajectories which significantly improve the discriminating power of scene segmentation.	ICCV	visu
3722	ICCV	A Quantitative Analysis of View Degeneracy and its use for Active Focal Length control.	David Wilkes,Sven J. Dickinson,John K. Tsotsos	1995	We quantify the observation by Kender and Freudenstein (1987) that degenerate views occupy a significant fraction of the viewing sphere surrounding an object. This demonstrates that systems for recognition must explicitly account for the possibility of view degeneracy. We show that view degeneracy cannot be detected from a single camera viewpoint. As a result, systems designed to recognize objects from a single arbitrary viewpoint must be able to function in spite of possible undetected degeneracies, or else operate with imaging parameters that cause acceptably low probabilities of degeneracy. To address this need, we give a prescription for active control of focal length that allows a principled tradeoff between the camera field of view and probability of view degeneracy.	ICCV	visu
3723	ICCV	Stochastic Completion Fields: A Neural Model of Illusory Contour Shape and Salience.	Lance R. Williams,David W. Jacobs	1995	We describe an algorithm and representation level theory of illusory contour shape and salience. Unlike previous theories, our model is derived from a single assumption-namely, that the prior probability distribution of boundary completion shape can be modeled by a random walk in a lattice whose points are positions and orientations in the image plane (i.e. the space which one can reasonably assume is represented by neurons of the mammalian visual cortex). Our model does not employ numerical relaxation or other explicit minimization, but instead relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions. We show that for the random walk we define, the maximum likelihood paths are curves of least energy, that is, on average, random walks follow paths commonly assumed to model the shape of illusory contours. A computer model is demonstrated on numerous illusory contour stimuli from the literature.	ICCV	visu
3724	ICCV	A State-Based Technique for the Summarization and Recognition of Gesture.	Andrew D. Wilson,Aaron F. Bobick	1995	A State-Based Technique for the Summarization and Recognition of Gesture.	ICCV	visu
3725	ICCV	Relational Matching with Dynamic Graph Structures.	Richard C. Wilson,Edwin R. Hancock	1995	The paper describes a novel approach to relational matching problems in machine vision. Rather than matching static scene descriptions, the approach adopts an active representation of the data to be matched. This representation is iteratively reconfigured to increase its degree of topological congruency with the model relational structure in a reconstructive matching process. The active reconfiguration of relational structures is controlled by a MAP update process. The final restored graph representation is optimal in the sense that it has maximum a posteriori probability with respect to the available attributes for the objects under match. The benefits of the technique are demonstrated experimentally on the matching of cluttered synthetic aperture radar data to a model in the form of a digital map. The operational limits of the method are established in a simulation study.	ICCV	visu
3726	ICCV	Hypergeometric Filters for Optical Flow and Affine Matching.	Yalin Xiong,Steven A. Shafer	1995	This paper proposes new hypergeometric filters for the problem of image matching under the translational and affine model. This new set of filters has the following advantages: (1) High-precision registration of two images under the translational and affine model. Because the window effects are eliminated, we are able to achieve superb performance in both translational and affine matching. (2) Affine matching without exhaustive search or image warping. Due to the recursiveness of the filters in the spatial domain, we are able to analytically express the relation between filter outputs and the six affine parameters. This analytical relation enables us to directly compute these affine parameters. (3) Generality. The approach we demonstrate here can be applied to a broad class of matching problems, as long as the transformation between the two image patches can be mathematically represented in the frequency domain.	ICCV	visu
3727	ICCV	Region Competition: Unifying Snakes, Region Growing, Energy/Bayes/MDL for Multi-band Image Segmentation.	Song Chun Zhu,Tai Sing Lee,Alan L. Yuille	1995	We present a novel statistical and variational approach to image segmentation based on a new algorithm named region competition. This algorithm is derived by minimizing a generalized Bayes/MDL (Minimum Description Length) criterion using the variational principle. We show that existing techniques in early vision such as, snake/balloon models, region growing, and Bayes/MDL are addressing different aspects of the same problem and they can be unified within a common statistical framework which combines their advantages. We analyze how to optimize the precision of the resulting boundary location by studying the statistical properties of the region competition algorithm and discuss what are good initial conditions for the algorithm. Our method is generalized to color and texture segmentation and is demonstrated on grey level images, color images and texture images.	ICCV	visu
3728	ICCV	FORMS: A Flexible Object Recognition and Modelling System.	Song Chun Zhu,Alan L. Yuille	1995	We briefly describe a generic statistical framework for representing the shapes of animate objects using principal component analysis and stochastic shape grammars. Such a representation scheme gives a formalism for solving the inverse problem-object recognition. Then we show: how these representations can be extracted from 2D silhouettes by a novel method for skeleton extraction and shape segmentation; how a similarity metric can be defined on this shape space; and how we can perform recognition in a bottom up/top down loop. The system is demonstrated to be stable in the presence of noise, the absence of parts, the presence of additional parts, and considerable variations in articulation and viewpoint. Successful categorization is demonstrated on a dataset of seventeen categories of animate objects.	ICCV	visu
3729	ICCV	Class-Based Grouping in Perspective Images.	Andrew Zisserman,Joseph L. Mundy,David A. Forsyth,Jane Liu,Nic Pillow,Charlie Rothwell,Sven Utcke	1995	In any object recognition system a major and primary task is to associate those image features, within an image of a complex scene, that arise from an individual object. The key idea here is that a geometric class defined in 3D induces relationships in the image which must hold between points on the image outline (the perspective projection of the object). The resulting image constraints enable both identification and grouping of image features belonging to objects of that class. The classes include surfaces of revolution, canal surfaces (pipes) and polyhedra. Recognition proceeds by first recognising an object as belonging to one of the classes (for example a surface of revolution) and subsequently identifying the object (for example as a particular vase). This differs from conventional object recognition systems where recognition is generally targetted at particular objects. These classes also support the computation of 3D invariant descriptions including symmetry axes, canonical coordinate frames and projective signatures. The constraints and grouping methods are viewpoint invariant, and proceed with no information on object pose. We demonstrate the effectiveness of this class-based grouping on real, cluttered scenes using grouping algorithms developed for rotationally symmetric surfaces, canal-surfaces and polyhedra.	ICCV	visu
3730	ICCV	Estimating Motion and Structure from Correspondences of Line Segments between Two Perspective Images.	Zhengyou Zhang	1995	Presents an algorithm for determining 3D motion and structure from correspondences of line segments between two perspective images. To our knowledge, the paper is the first investigation of use of line segments in motion and structure from motion. Classical methods use their geometric abstraction, namely straight lines, but then three images are necessary for the motion and structure determination process. We show that two views are in general sufficient when we use line segments. The assumption we use is that two matched line segments contain the projection of a common part of the corresponding line segment in space. Indeed this is what we use to match line segments between different views. Both synthetic and real data have been used to test the proposed algorithm, and excellent results have been obtained with real data containing a relatively large set of line segments. The results are comparable with those obtained using stereo calibration.	ICCV	visu
3731	ICCV	Shape and Model from Specular Motion.	Jiang Yu Zheng,Yoshihiro Fukagawa,Norihiro Abe	1995	This work investigates visual characteristics of specular surfaces during rotation, and gives approaches to qualitatively identify and quantitatively recover shapes of these surfaces. Continuous images are taken when an object rotates. We look at specularly reflected patterns on the surfaces and their motion in the EPIs parallel to the rotation plane, from which estimation of each surface point and construction of the object model are carried out. We find very simple and direct methods to fulfill this objective; linear equations for multiple lights illumination, and a 1st-order differential equation for single light illumination. The motion of specular reflection has nice global characteristics in EPI. The surface types range from very shiny metal surfaces to surfaces with only week specular reflectance. We give both simulation and experiments on real objects.	ICCV	visu
3732	IEEE Visualization	An Extended Data-Flow Architecture for Data Analysis and Visualization.	Greg Abram,Lloyd Treinish	1995	Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer.	IEEE Visualizat	visu
3733	IEEE Visualization	Unsteady Flow Volumes.	Barry G. Becker,Nelson L. Max,David A. Lane	1995	Flow volumes [1] are extended for use in unsteady (time-dependent) flows. The resulting unsteady flow volumes are the 3 dimensional analog of streaklines. There are few examples where methods other than particle tracing have been used to visualize time varying flows. Since particle paths can become convoluted in time there are additional considerations to be made when extending any visualization technique to unsteady flows. We will present some solutions to the problems which occur in subdivision, rendering, and system design. We will apply the unsteady flow volumes to a variety of field types including moving multi-zoned curvilinear grids.	IEEE Visualizat	visu
3734	IEEE Visualization	Interval Set: A Volume Rendering Technique Generalizing Isosurface Extraction.	Baining Guo	1995	A scalar volume V = { (x, f(x)) | x in R } is described by a function f(x) defined over some region R of the three-dimensional space. This paper presents a simple technique for rendering interval sets of the form I(a, b) = { (x, f(x)) | a	IEEE Visualizat	visu
3735	IEEE Visualization	A Rule-Based Tool for Assisting Colormap Selection.	Lawrence D. Bergman,Bernice E. Rogowitz,Lloyd Treinish	1995	The paper presents an interactive approach for guiding the user's select of colormaps in visualization. PRAVDAColor, implemented as a module in the IBM Visualization Data Explorer, provides the user a selection of appropriate colormaps given the data type and spatial frequency, the user's task, and properties of the human perceptual system.	IEEE Visualizat	visu
3736	IEEE Visualization	Visualization of Biological Sequence Similarity Search Results.	Ed Huai-hsin Chi,Phillip Barry,Elizabeth Shoop,John V. Carlis,Ernest Retzel,John Riedl	1995	Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi-dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multi-dimensional data by enabling interactive investigation of the graphical representation.	IEEE Visualizat	visu
3737	IEEE Visualization	Interactive Realism for Visualization Using Ray Tracing.	Robert A. Cross	1995	Visual realism is necessary for many virtual reality applications. In order to convince the user that the virtual environment is real, the scene presented should faithfully model the expected actual environment. A highly accurate, fully modeled, interactive environment is thus seen as virtually real.This paper addresses the problem of interactive visual realism and discusses a possible solution: a hybrid rendering paradigm that ties distributed graphics hardware and ray tracing systems together for use in interactive, high visual realism applications.This new paradigm is examined in the context of a working rendering system. This system is capable of producing images of higher fidelity than possible through the use of graphics hardware alone, able both to render images at speeds useful for interactive systems and to progressively refine static, high quality snapshots.	IEEE Visualizat	visu
3738	IEEE Visualization	Using Spatial Access Methods to Support the Visualization of Environmental Data.	Charles Falkenberg,Ravi Kulkarni	1995	Using Spatial Access Methods to Support the Visualization of Environmental Data.	IEEE Visualizat	visu
3739	IEEE Visualization	Vector Plots for Irregular Grids.	Don Dovey	1995	A standard method for visualizing vector fields consists of drawing many small ``glyphs'' to represent the field. This paper extends the technique from regular to curvilinear and unstructured grids. In order to achieve a uniform density of vector glyphs on nonuniformly spaced grids, the paper describes two approaches to resampling the grid data. One of the methods, an element-based resampling, can be used to visualize vector fields at arbitrary surfaces within three-dimensional grids.	IEEE Visualizat	visu
3740	IEEE Visualization	A Visualization Tool for Studying the Development of the Moss Physcomitrella patens.	F. David Fracchia,Neil W. Ashton	1995	A Visualization Tool for Studying the Development of the Moss Physcomitrella patens.	IEEE Visualizat	visu
3741	IEEE Visualization	Interval Volume: A Solid Fitting Technique for Volumetric Data Display and Analysis.	Issei Fujishiro,Yuji Maeda,Hiroshi Sato	1995	Proposes as a generalization of isosurfaces, the 'interval volume', which is a new type of geometric model representing 3D subvolumes with field values belonging to a closed interval. A dominant surface fitting algorithm called 'marching cubes' is extended to obtain a solid fitting algorithm, which extracts from a given volumetric dataset a high-resolution polyhedral solid data structure of the interval volume. Rendering methods for the interval volume and principal related operations are also presented. The effectiveness of this approach is illustrated with 4D simulated data from atomic collision research.	IEEE Visualizat	visu
3742	IEEE Visualization	Direct Rendering of Laplacian Pyramid Compressed Volume Data.	Mohammad H. Ghavamnia,Xue D. Yang	1995	Volume rendering generates 2D images by ray tracing 3D volume data. This technique imposes considerable demands on storage space as the data set grows in size. In this paper we describe a method to render compressed volume data directly to reduce the memory requirements of the rendering process. The volume data was compressed by a technique called Laplacian pyramid. A compression ratio of 10:1 was achieved by uniform quantization over the Laplacian pyramid. The quality of the images obtained by this technique is virtually indistinguishable from that of the images generated from the uncompressed volume data. A significant improvement in computational performance was achieved by using a cache algorithm to temporarily retain the reconstructed voxels to be used by the adjacent rays.	IEEE Visualizat	visu
3743	IEEE Visualization	Subverting Structure: Data-Driven Diagram Generation.	Gene Golovchinsky,Klaus Reichenberger,Thomas Kamps	1995	Diagrams are data representations that convey information predominantly through combinations of graphical elements rather than through other channels such as text or interaction. We have implemented a prototype called AVE (Automatic Visualization Environment) that generates diagrams automatically based on a generative theory of diagram design. According to this theory, diagrams are constructed based on the data to be visualized rather than by selection from a predefined set of diagrams. This approach can be applied to knowledge represented by semantic networks. In this paper we give a brief introduction to the underlying theory, then describe the implementation and finally discuss strategies for extending the algorithm.	IEEE Visualizat	visu
3744	IEEE Visualization	Astronomers and their Shady Algorithms.	Richard Gooch	1995	The vast quantities of data which may be produced by modern radio telescopes have outstripped conventional visualisation techniques available to astronomers. While research in other areas of visualisation finds some application in astronomy, problems peculiar to the field require new techniques. This paper presents a brief overview of some of the problems of visualisation for astronomy and compares different shading algorithms.	IEEE Visualizat	visu
3745	IEEE Visualization	Visualization of High Speed Aerodynamic Configuration Design.	Monika Hannemann,Helmut Sobieczky	1995	Three topics of aerodynamic research at DLR are chosen to illustrate the need for visualization. These include aircraft configuration design variations, adaptation devices and unsteady flow simulation in the transonic, the supersonic and the hypersonic speed regime call for the combined use of a geometry generator, a powerful graphic system and video technology. Projects currently under investigation are illustrated and generic case studies are presented.	IEEE Visualizat	visu
3746	IEEE Visualization	Space Walking.	Andrew J. Hanson,Hui Ma	1995	We propose an interactive method for exploring topological spaces based on the natural local geometry of the space. Examples of spaces appropriate for this visualization approach occur in abundance in mathematical visualization, surface and volume visualization problems, and scientific applications such as general relativity. Our approach is based on using a controller to choose a direction in which to walk a manifold along a local geodesic path. The method automatically generates orientation changes that produce a maximal viewable region with each step of the walk. The proposed interaction framework has many natural properties to help the user develop a useful cognitive map of a space and is well-suited to haptic interfaces that may be incorporated into desktop virtual reality systems.	IEEE Visualizat	visu
3747	IEEE Visualization	Voxel Based Object Simplification.	Taosong He,Lichan Hong,Arie E. Kaufman,Amitabh Varshney,Sidney W. Wang	1995	Presents a simple, robust and practical method for object simplification for applications where gradual elimination of high-frequency details is desired. This is accomplished by sampling and low-pass filtering the object into multi-resolution volume buffers and applying the marching cubes algorithm to generate a multi-resolution triangle-mesh hierarchy. Our method simplifies the genus of objects and can also help existing object simplification algorithms achieve better results. At each level of detail, a multi-layered mesh can be used for an optional and efficient antialiased rendering.	IEEE Visualizat	visu
3748	IEEE Visualization	Qualitative Analysis of Invariant Tori in a Dynamical System.	Daryl H. Hepting,Gianne Derks,Kossi D. Edoh,Robert D. Russell	1995	Invariant tori are examples of invariant manifolds in dynamical systems. Usual tools in dynamical systems such as analysis and numerical simulations alone are often not sufficient to understand the complicated mechanisms that cause changes in these manifolds. Computer-graphical visualization is a natural and powerful addition to these tools used for the qualitative study of dynamical systems, especially for the study of invariant manifolds. The dynamics of two linearly coupled oscillators is the focus of this case study. With little or no coupling between the oscillators, an invariant torus is present but it breaks down for strong coupling. Visualization has been employed to gain a qualitative understanding of this breakdown process. The visualization has allowed key features of the tori to be recognized, and it has proven to be indispensable in developing and testing hypotheses about the tori.	IEEE Visualizat	visu
3749	IEEE Visualization	Interactive Visualization of Mixed Scalar and Vector Fields.	Lichan Hong,Xiaoyang Mao,Arie E. Kaufman	1995	This paper describes an approach for interactive visualization of mixed scalar and vector fields, in which vector icons are generated from pre-voxelized icon templates and volume-rendered together with the volumetric scalar data. This approach displays simultaneously the global structure of the scalar field and the detailed features of the vector field. Interactive visualization is achieved with incremental image update, by re-rendering only a small portion of the image wherever and whenever a change occurs. This technique supports a set of interactive visualization tools, including change of vector field visualization parameters, real-time animation of vector icons advected within the scalar field, a zooming lens, and a local probe. Subject Terms: data visualisation; interactive systems; graphical user interfaces; rendering (computer graphics); interactive visualization; scalar fields; vector fields; vector icons; pre-voxelized icon templates; volume-rendered; volumetric scalar data; incremental image update; real-time animation; zooming lens; local probe	IEEE Visualizat	visu
3750	IEEE Visualization	On Enhancing the Speed of Splatting with Indexing.	Insung Ihm,Rae Kyoung Lee	1995	Splatting is an object-space direct volume rendering algorithm that produces images of high quality, but is computationally expensive like many other volume rendering algorithms. This paper presents a new technique that enhances the speed of splatting without trading off image quality. This new method reduces rendering time by employing a simple indexing mechanism which allows to visit and splat only the voxels of interest. It is shown that this algorithm is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. We report experimental results on several test data sets of useful size and complexity, and discuss the cost/benefit trade-off of our method.	IEEE Visualizat	visu
3751	IEEE Visualization	Legibility Enhancement for Information Visualisation.	Rob Ingram,Steve Benford	1995	Navigation in computer generated information spaces may be difficult, resulting in users getting lost in hyperspace. This work aims to build on research from the area of city planning to try to solve this problem. We will introduce the concepts of legibility and cognitive maps and the five features of urban landscape with which they are associated. Following this will be descriptions of techniques and algorithms which we have developed to allow these features to be introduced to three dimensional spaces for information visualisation. Next we will describe a specific application of these techniques in the visualisation of the World Wide Web and conclude with a look at future development of the system.	IEEE Visualizat	visu
3752	IEEE Visualization	Enhancing Transparent Skin Surfaces with Ridge and Valley Lines.	Victoria Interrante,Henry Fuchs,Stephen M. Pizer	1995	There are many applications that can benefit from the simultaneous display of multiple layers of data. The objective in these cases is to render the layered surfaces in such a way that the outer structures can be seen and seen through at the same time. This paper focuses on the particular application of radiation therapy treatment planning, in which physicians need to understand the three-dimensional distribution of radiation dose in the context of patient anatomy. We describe a promising technique for communicating the shape and position of the transparent skin surface while at the same time minimally occluding underlying isointensity dose surfaces and anatomical objects: adding a sparse, opaque texture comprised of a small set of carefully-chosen lines. We explain the perceptual motivation for explicitly drawing ridge and valley curves on a transparent surface, describe straightforward mathematical techniques for detecting and rendering these lines, and propose a small number of reasonably effective methods for selectively emphasizing the most perceptually relevant lines in the display.	IEEE Visualizat	visu
3753	IEEE Visualization	An Integrated Approach for Steering, Visualization, and Analysis of Atmospheric Simulations.	Yves Jean,Thomas Kindler,William Ribarsky,Weiming Gu,Greg Eisenhauer,Karsten Schwan,Fred Alyea	1995	An Integrated Approach for Steering, Visualization, and Analysis of Atmospheric Simulations.	IEEE Visualizat	visu
3754	IEEE Visualization	Tensor Product Surfaces Guided by Minimal Surface Area Triangulations.	John K. Johnstone,Kenneth R. Sloan	1995	We present a method for constructing tensor product Bezier surfaces from contour (cross-section) data. Minimal area triangulations are used to guide the surface construction, and the final surface reflects the optimality of the triangulation. The resulting surface differs from the initial triangulation in two important ways: it is smooth (as opposed to the piecewise planar triangulation), and it is in tensor product form (as opposed to the irregular triangular mesh). The surface reconstruction is efficient because we do not require an exact minimal surface. The triangulations are used as strong hints, but no more than that. The method requires the computation of both open and closed isoparametric curves of the surface, using triangulations as a guide. These isoparametric curves form a tensor product Bezier surface. We show how to control sampling density by filling and pruning isoparametric curves, for accuracy and economy. A rectangular grid of points is produced that is compatible with the expected format for a tensor product surface interpolation, so that a host of well-supported methods are available to generate and manipulate the surface.	IEEE Visualizat	visu
3755	IEEE Visualization	Recursive Pattern: A Technique for Visualizing Very Large Amounts of Data.	Daniel A. Keim,Mihael Ankerst,Hans-Peter Kriegel	1995	An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called `recursive pattern' which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may largely influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the `recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our `recursive pattern ' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application.	IEEE Visualizat	visu
3756	IEEE Visualization	Optimization of Time-Dependent Particle Tracing Using Tetrahedral Decomposition.	David N. Kenwright,David A. Lane	1995	An efficient algorithm is presented for computing particle paths, streak lines and time lines in time-dependent flows with moving curvilinear grids. The integration, velocity interpolation, and step size control are all performed in physical space which avoids the need to transform the velocity field into computational space. This leads to higher accuracy because there are no Jacobian matrix approximations, and expensive matrix inversions are eliminated. Integration accuracy is maintained using an adaptive step size control scheme which is regulated by the path line curvature. The problem of point location and interpolation in physical space is simplified by decomposing hexahedral cells into tetrahedral cells. This enables the point location to be done analytically and substantially faster than with a Newton-Raphson iterative method. Results presented show this algorithm is up to six times faster than particle tracers which operate on hexahedral cells and produces almost identical traces.	IEEE Visualizat	visu
3757	IEEE Visualization	Visualization for Aerodynamic Design of Helicopter Rotor Blades.	G. David Kerlick	1995	Visualization, animation, and simulation techniques are applied to the problem of rotor design for helicopters. Periodic unsteady experimental velocity data (laser Doppler velocimetry or LDV) in two dimensions and velocity data derived from simulated vortex systems in three dimensions are compared using the same visual tools. Animations show the development of rotor wake systems and induced velocities over time. Modified particle trace integration schemes are used to calculate steady streamlines and unsteady particle paths for both kinds of data. In an extension of this work, a virtual environment (VE) system was used to view the wake vortex system and an interactive probe was used to explore the induced velocity field. Future work will enable interactive visual debugging and simulation steering.	IEEE Visualizat	visu
3758	IEEE Visualization	An Architecture for Retaining and Analyzing Visual Explorations of Databases.	John Peter Lee,Georges G. Grinstein	1995	A software architecture is presented to integrate a database management system with data visualization. One of it's primary objectives, the retention of user-data interactions, is detailed. By storing all queries over the data along with high-level descriptions of the query result and associated visualization, the process by wich a database is explored can be analyzed. This approach can lead to contributions in the development of user models as data explorers, metadata models for scientific databases, intelligent assistants, and data exploration services. We describe the underlying elements of this approach, specifically the visual database exploration model and the metadata objects that support the model.	IEEE Visualizat	visu
3759	IEEE Visualization	High-Speed Volume Rendering Using Redundant Block Compression.	Günter Knittel	1995	We present a novel volume rendering method which offers high rendering speed on standard workstations. It is based on a lossy data compression scheme which drastically reduces the memory bandwidth and computing requirements of perspective raycasting. Starting from classified and shaded data sets, we use Block Truncation Coding or Color Cell Compression to compress a block of 12 voxels into 32 bits. All blocks of the data set are processed redundantly, yielding a data structure which avoids multiple memory accesses per raypoint. As a side effect, the tri-linear interpolation of data coded in such a way is very much simplified. These techniques allow us to perform walk-throughs at interactive frame rates. Furthermore, the algorithm provides depth-cueing and the semi-transparent display of different materials. The algorithm achieves a sustained frame generation rate of about 2Hz for large data sets (~200^3) at an acceptable image quality on an SGI Indy workstation. A number of examples are shown.	IEEE Visualizat	visu
3760	IEEE Visualization	Enhanced Spot Noise for Vector Field Visualization.	Wim C. de Leeuw,Jarke J. van Wijk	1995	Spot noise is a technique for texture synthesis, which is very useful for vector field visualization. This paper describes improvements and extensions of the basic principle of spot noise. First, better visualization of highly curved vector fields with spot noise is achieved, by adapting the shape of the spots to the local velocity field. Second, filtering of spots is proposed to eliminate undesired low frequency components from the spot noise texture. Third, methods are described to utilize graphics hardware to generate the texture, and to produce variable viewpoint animations of spot noise on surfaces. And fourth, the synthesis of spot noise on grids with highly irregular cell sizes is described.	IEEE Visualizat	visu
3761	IEEE Visualization	Virtual GIS: A Real-Time 3D Geographic Information System.	David Koller,Peter Lindstrom,William Ribarsky,Larry F. Hodges,Nickolas Faust,Gregory A. Turner	1995	Virtual GIS: A Real-Time 3D Geographic Information System.	IEEE Visualizat	visu
3762	IEEE Visualization	Marching Through the Visible Man.	William E. Lorensen	1995	The National Library of Medicine is creating a digital atlas of the human body. This project, called the Visible Human, has already produced computed tomography, magnetic resonance imaging and physical cross-sections of a human male cadaver. This paper describes a methodology and results for extracting surfaces from the Visible Male's CT data. We use surface connectivity and isosurface extraction techniques to create polygonal models of the skin, bone, muscle and bowels. We also report early experiments with the physical cross-sections.	IEEE Visualizat	visu
3763	IEEE Visualization	3D Computational Steering with Parametrized Geometric Objects.	Jurriaan D. Mulder,Jarke J. van Wijk	1995	Computational Steering is the ultimate goal of interactive simulation: researchers change parameters of their simulation and immediately receive feedback on the effect. We present a general and flexible graphics tool that is part of an environment for Computational Steering developed at CWI. It enables the researcher to interactively develop his own interface with the simulation. This interface is constructed with 3D Parametrized Geometric Objects. The properties of the objects are parametrized to output data and input parameters of the simulation. The objects visualize the output of the simulation while the researcher can steer the simulation by direct manipulation of the objects. Several applications of 3D Computational Steering are presented.	IEEE Visualizat	visu
3764	IEEE Visualization	Pictorial Statistics - Visualization of High Dimensional Statistical Distributions.	Andreas Müller	1995	A general framework for visualization of statistical properties of high-dimensional pattern samples and the related computational steps are introduced. These procedures are exemplified on applications in anthropometrical research (shape information in faces) but can be easily generalized to various other morphometrical questions and data sets with pattern structure, e.g., data stemming from sensor arrays. Presently, the visualization techniques illustrated concentrate on (higher) moments of first order. It is suggested, how moments of second order can be visualized by animations and how this approach can be used in the context of comparative visualization.	IEEE Visualizat	visu
3765	IEEE Visualization	Splatting of Curvilinear Volumes.	Xiaoyang Mao,Lichan Hong,Arie E. Kaufman	1995	The paper presents a splatting algorithm for volume rendering of curvilinear grids. A stochastic sampling technique called Poisson sphere/ellipsoid sampling is employed to adaptively resample a curvilinear grid with a set of randomly distributed points whose energy support extents are well approximated by spheres and ellipsoids. Filter kernels corresponding to these spheres and ellipsoids are used to generate the volume rendered image of the curvilinear grid with a conventional footprint evaluation algorithm. Experimental results show that our approach can be regarded as an alternative to existing fast volume rendering techniques of curvilinear grids.	IEEE Visualizat	visu
3766	IEEE Visualization	Turbulent Flow Visualization in Computational and Experimental Hydraulics.	A. E. Mynett,I. Ari Sadarjoen,A. J. S. Hin	1995	Many practical problems in open channel hydraulics that were traditionally investigated in hydraulic model experiments, are nowadays being solved by using computational fluid dynamics. However, in order to interpret computational results, there is a clear preference among scientist and engineers for visualization in analogy with experimental techniques. One such technique, particle tracing, enables a dynamic (Lagrangian) interpretation of a statically (Eulerian) computed vector field. However, quite often the emphasis in particle tracing is only on the mean flow properties, while effects due to dispersion and mixing are often not accounted for. Hence turbulent flow characteristics have to be incorporated in a visualization system for practical hydraulic engineering problems. The particle tracing technique presented in this case study has been specifically developed to combine both mean and fluctuating velocity vectors, thus simulating stochastic perturbations around mean flow conditions. A number of cases are presented in this paper that demonstrate the practical applicability of advanced visualization techniques in realistic engineering studies.	IEEE Visualizat	visu
3767	IEEE Visualization	Interactive Maximum Projection Volume Rendering.	Michael D. McCool,Wolfgang Heidrich,John Stevens	1995	Interactive Maximum Projection Volume Rendering.	IEEE Visualizat	visu
3768	IEEE Visualization	An Illustrated Analysis of Sonification for Scientific Visualisation.	Rosane Minghim,A. Robin Forrest	1995	This paper presents an analysis of progress in the use of sound as a tool in support of visualisation and gives an insight into its development and future needs. Special emphasis is given to the use of sound in Scientific and Engineering Applications. A system developed to support surface data presentation and interaction by using sound is presented and discussed.	IEEE Visualizat	visu
3769	IEEE Visualization	Visualizing the Tracking and Diving Behavior of Marine Mammals.	Guy W. Oliver	1995	Visualizing the Tracking and Diving Behavior of Marine Mammals.	IEEE Visualizat	visu
3770	IEEE Visualization	Flow Visualization in a Hypersonic Fin/Ramp Flow.	Hans-Georg Pagendarm,Thomas Gerhold	1995	A recent study of a flow detail of an engine intake of future ground to orbit transport systems provided extremely complex data from numerical flow simulation and experimental flow visualization. The data posed a challenging problem to flow visualization, computational flow imaging (CFI), and the comparison of experimental imaging techniques versus computational imaging techniques. Some new visualization techniques have been implemented to provide compact representations of the complex features in the data. It turned out to be most useful to combine various specialized techniques for an icon-like representation of phenomena in a single image in order to study interaction of flow features. Some lessons were learned by simulating experimental visualization techniques on the numerical data.	IEEE Visualizat	visu
3771	IEEE Visualization	Iconic Techniques for Feature Visualization.	Frank J. Post,Theo van Walsum,Frits H. Post,Deborah Silver	1995	Iconic Techniques for Feature Visualization.	IEEE Visualizat	visu
3772	IEEE Visualization	Propositional n-traces: Visualizing a Problem in Philosophic Logic.	Nathalie Prevost,Ray E. Jennings,Loki Jorgenson,F. David Fracchia	1995	Propositional n-traces: Visualizing a Problem in Philosophic Logic.	IEEE Visualizat	visu
3773	IEEE Visualization	Interactive 3D Visualization of Actual Anatomy and Simulated Chemical Time-Course Data for Fish.	Penny Rheingans,John Nichols	1995	Interactive 3D Visualization of Actual Anatomy and Simulated Chemical Time-Course Data for Fish.	IEEE Visualizat	visu
3774	IEEE Visualization	Sweeping Simplices: A Fast Iso-Surface Extraction Algorithm for Unstructured Grids.	Han-Wei Shen,Christopher R. Johnson	1995	We present an algorithm that accelerates the extraction of iso-surfaces from unstructured grids by avoiding the traversal of the entire set of cells in the volume. The algorithm consists of a sweep algorithm and a data decomposition scheme. The sweep algorithm incrementally locates intersected elements, and the data decomposition scheme restricts the algorithm's worst-case performance. For data sets consisting of hundreds of thousands of elements, our algorithm can reduce the cell traversal time more than 90% over the naive iso-surface extraction algorithm, thus facilitating interactive probing of scalar fields for large-scale problems on unstructured three-dimensional grids.	IEEE Visualizat	visu
3775	IEEE Visualization	Fast Normal Estimation Using Surface Characteristics.	Byeong-Seok Shin,Yeong-Gil Shin	1995	To visualize the volume data acquired from computation or sampling, it is necessary to estimate normals at the points corresponding to object surfaces. Volume data does not holds the geometric information for the surface comprising points, so it is necessary to calculate normals using local information at each point. The existing normal estimation methods have some problems of estimating incorrect normals at discontinuous, aliased or noisy points. Yagel et al solved some of these problems using their context-sensitive method. However this method requires too much processing time and it loses some information on detailed parts of the object surfaces. This paper proposes the surface-characteristic-sensitive normal estimation method which applies different operators according to characteristics of each surface for the normal calculation. This method has the same advantages of the context-sensitive method, and also some other advantages such as the less processing time and the reduction of the information loss on detailed parts.	IEEE Visualizat	visu
3776	IEEE Visualization	Automatic Generation of Triangular Irregular Networks Using Greedy Cuts.	Cláudio T. Silva,Joseph S. B. Mitchell,Arie E. Kaufman	1995	Proposes a new approach to the automatic generation of triangular irregular networks (TINs) from dense terrain models. We have developed and implemented an algorithm based on the greedy principle used to compute minimum-link paths in polygons. Our algorithm works by taking greedy cuts (bites) out of a simple closed polygon that bounds the yet-to-be triangulated region. The algorithm starts with a large polygon, bounding the whole extent of the terrain to be triangulated, and works its way inward, performing at each step one of three basic operations: ear cutting, greedy biting, and edge splitting. We give experimental evidence that our method is competitive with current algorithms and has the potential to be faster and to generate many fewer triangles. Also, it is able to keep the structural terrain fidelity at almost no extra cost in running time and it requires very little memory beyond that for the input height array.	IEEE Visualizat	visu
3777	IEEE Visualization	A Hardware Acceleration Method for Volumetric Ray Tracing.	Lisa M. Sobierajski,Ricardo S. Avila	1995	In this paper we present an acceleration method for volumetric ray tracing which utilizes standard graphics hardware without compromising image accuracy. The graphics hardware is employed to identify those segments of each ray that could possibly contribute to the final image. A volumetric ray tracing algorithm is then used to compute the final image, traversing only the identified segments of the rays. This technique can be used to render volumetric isosurfaces as well as translucent volumes. In addition, this method can accelerate the traversal of shadow rays when performing recursive ray tracing.	IEEE Visualizat	visu
3778	IEEE Visualization	Fast Multiresolution Surface Meshing.	Oliver G. Staadt,Markus H. Gross,Roger Gatti	1995	Fast Multiresolution Surface Meshing.	IEEE Visualizat	visu
3779	IEEE Visualization	Automated Generation of Visual Simulation Databases Using Remote Sensing and GIS.	Martin Suter,Daniel Nüesch	1995	This paper reports on the development of a strategy to generate databases used for real-time interactive landscape visualization. The database construction from real world data is intended to be as automated as possible. The primary sources of information are remote sensing imagery recorded by Landsat's Thematic Mapper (TM) and digital elevation models (DEM). Additional datasets (traffic networks and buildings) are added to extend the database. In a first step the TM images are geocoded and then segmented into areas of different land coverage. During the visual simulation highly detailed photo textures are applied onto the terrain based on the classification results to increase the apparent amount of detail. The data processing and integration is carried out using custom image processing and geographic information systems (GIS) software. Finally, a sample visual simulation application is implemented. Emphasis is put on practical implementation to test the feasibility of the approach as a whole.	IEEE Visualizat	visu
3780	IEEE Visualization	Fast Algorithms for Visualizing Fluid Motion in Steady Flow on Unstructured Grids.	Shyh-Kuang Ueng,K. Sikorski,Kwan-Liu Ma	1995	The plotting of streamlines is an effective way of visualizing fluid motion in steady flows. Additional information about the flowfield, such as local rotation and expansion, can be shown by drawing in the form of a ribbon or tube. In this paper, we present efficient algorithms for the construction of streamlines, streamribbons and streamtubes on unstructured grids. A specialized version of the Runge-Kutta method has been developed to speed up the integration of particle pathes. We have also derived close-form solutions for calculating angular rotation rate and radius to construct streamribbons and streamtubes, respectively. According to our analysis and test results, these formulations are two to four times better in performance than previous numerical methods. As a large number of traces are calculated, the improved performance could be significant.	IEEE Visualizat	visu
3781	IEEE Visualization	Defining, Computing, and Visualizing Molecular Interfaces.	Amitabh Varshney,Frederick P. Brooks Jr.,David C. Richardson,William V. Wright,Dinesh Manocha	1995	Defining, Computing, and Visualizing Molecular Interfaces.	IEEE Visualizat	visu
3782	IEEE Visualization	A Model and a System for Data-Parallel Program Visualization.	Thomas A. Wagner,R. Daniel Bergeron	1995	Parallel program visualization and debugging require new techniques for gathering and displaying execution trace and profile data. Interaction with the program during execution is also required to facilitate parallel debugging. We discuss the difficulties associated with runtime user/program interaction and how the data-parallel programming paradigm facilitates much more liberal runtime interaction than typical MIMD-based models. We present a model for data-parallel program visualization that addresses both data collection/interaction and visualization issues. We follow our model presentation with the design and implementation of a subset of our visualization model. We discuss our preliminary findings and propose future research directions.	IEEE Visualizat	visu
3783	IEEE Visualization	High Dimensional Brushing for Interactive Exploration of Multivariate Data.	Matthew O. Ward,Allen R. Martin	1995	High Dimensional Brushing for Interactive Exploration of Multivariate Data.	IEEE Visualizat	visu
3784	IEEE Visualization	Compression Domain Rendering of Time-Resolved Volume Data.	Rüdiger Westermann	1995	An important challenge in the visualization of three dimensional volume data is the efficient processing and rendering of time-resolved sequences. Only the use of compression techniques, which allow the reconstruction of the original domain from the compressed one locally, makes it possible to evaluate these sequences in their entirety. In the following paper a new approach for the extraction and visualization of so called time-features from within time-resolved volume data will be presented. Based on the asymptotic decay of multiscale representations of spatially localized time evolutions of the data, singular points can be discriminated. Also the corresponding Lipschitz exponents, which describe the signals local regularity, can be determined, and can be taken as a measure of the variation in time. The compression ratio and the comprehension of the underlying signal will be improved, if we restore the extracted regions first, which contain the most important information.	IEEE Visualizat	visu
3785	IEEE Visualization	IFS Fractal Interpolation for 2D and 3D Visualization.	Craig M. Wittenbrink	1995	Reconstruction is used frequently in visualization of one, two, and three--dimensional data. Data uncertainty is typically ignored, and a deficiency of many interpolation schemes is smoothing which may indicate features or characteristics of the data that are not there. In this paper I investigate the use of iterated function systems (IFS's) for interpolation. I show new derivations for fractal interpolation in two and three-dimensional scalar data, and new point and polytope rendering algorithms with tremendous speed advantages over ray tracing. The interpolations may be used to give an indication of the uncertainty of the data, statistically represent the data at a variety of scales, allow tunability from the data, and may allow more accurate data analysis.	IEEE Visualizat	visu
3786	IEEE Visualization	Authenticity Analysis of Wavelet Approximations in Visualization.	Pak Chung Wong,R. Daniel Bergeron	1995	Wavelet transforms include data decompositions and reconstructions. This paper is concerned with the authenticity issues of the data decomposition, particularly for data visualization. A total of six datasets are used to clarify the approximation characteristics of compactly supported orthogonal wavelets. We present an error tracking mechanism, which uses the available wavelet resources to measure the quality of the wavelet approximations.	IEEE Visualizat	visu
3787	IEEE Visualization	Volume-Based Reasoning and Visualization of Diecastability.	Roni Yagel,Shao-Chiung Lu,Alec B. Rebello,R. A. Miller	1995	Because of the nature of the die casting process, the part geometry severely restricts the die geometry and hence affects the quality of the part. However, as is often the case in other manufacturing processes, diecastings are currently designed purely based on their function. The manufacturability of the diecastings is not considered until the design has been nearly completed and detailed. This is due to the design support limitations of current CAE tools. In this paper, we present a new volume-based approach to support diecastability evaluation, especially in preliminary design. Our approach can be applied to arbitrarily shaped parts without pre-defined feature libraries. The focus is on the identification of geometric characteristics, e.g. heavy mass regions, that could be responsible for thermal-related part defects. A distance transform with city-block metric is used to extract this geometric property. Volume visualization techniques are also adopted to allow users to visualize the results in a clear and precise way.	IEEE Visualizat	visu
3788	IEEE Visualization	IEEE Visualization '95, Proceedings, Atlanta, Georgia, USA, October 29 - November 3, 1995.		1995	IEEE Visualization '95, Proceedings, Atlanta, Georgia, USA, October 29 - November 3, 1995.	IEEE Visualizat	visu
3789	IEEE Trans. Vis. Comput. Graph.	A Predictor-Corrector Technique for Visualizing Unsteady Flow.	David C. Banks,Bart A. Singer	1995	We present a method for visualizing unsteady flow by displaying its vortices. The vortices are identified by using a vorticity-predictor pressure-corrector scheme that follows vortex cores. The cross-sections of a vortex at each point along the core can be represented by a Fourier series. A vortex can be faithfully reconstructed from the series as a simple quadrilateral mesh, or its reconstruction can be enhanced to indicate helical motion. The mesh can reduce the representation of the flow features by a factor of one thousand or more compared with the volumetric dataset. With this amount of reduction it is possible to implement an interactive system on a graphics workstation to permit a viewer to examine, in three dimensions, the evolution of the vortical structures in a complex, unsteady flow.	IEEE Trans. Vis	visu
3790	IEEE Trans. Vis. Comput. Graph.	Visualizing Network Data.	Richard A. Becker,Stephen G. Eick,Allan R. Wilks	1995	Networks are critical to modern society, and a thorough understanding of how they behave is crucial to their efficient operation. Fortunately, data on networks is plentiful; by visualizing this data, it is possible to greatly improve our understanding. Our focus is on visualizing the data associated with a network and not on simply visualizing the structure of the network itself. We begin with three static network displays; two of these use geographical relationships, while the third is a matrix arrangement that gives equal emphasis to all network links. Static displays can be swamped with large amounts of data; hence we introduce direct-manipulation techniques that permit the graphs to continue to reveal relationships in the context of much more data. In effect, the static displays are parameterized so that interesting views may easily be discovered interactively. The software to carry out this network visualization is called SeeNet.	IEEE Trans. Vis	visu
3791	IEEE Trans. Vis. Comput. Graph.	Line Art Rendering via a Coverage of Isoparametric Curves.	Gershon Elber	1995	Line Art Rendering via a Coverage of Isoparametric Curves.	IEEE Trans. Vis	visu
3792	IEEE Trans. Vis. Comput. Graph.	Optimal Sampling for Hemicubes.	Nelson L. Max	1995	The hemicube estimates of form factors are based on a finite set of sample directions. We obtain several optimal arrangements of sample directions, which minimize the variance of these estimates. They are based on changing the size or shape of the pixels or the shape of the hemicube, or using non-uniform pixel grids. The best reduces the variance by 43%.The variance calculation is based on the assumption that the errors in the estimate are caused by the projections of single polygon edges, and that the positions and orientations of these edges are random. This replaces the infinite dimensional space of possible environments by the two dimensional space of great circles on the unit sphere, making the numerical variance minimization possible.	IEEE Trans. Vis	visu
3793	IEEE Trans. Vis. Comput. Graph.	Specification by-Example of Virtual Agents Behavior.	Alberto Del Bimbo,Enrico Vicario	1995	The development of virtual agents running within graphic environments which emulate real-life contexts may largely benefit from the use of visual specification by-example. To support this specification, the development system must be able to interpret the examples and cast their underlying rules into an internal representation language. This language must find a suitable trade-off among a number of contrasting requirements regarding expressiveness, automatic executability, and suitability to the automatic representation of rules deriving from the analysis of examples.A language is presented which attains this trade-off by combining together an operational and a declarative fragment to separately represent the autonomous execution of each individual agent and its interaction with the environment, respectively. While the declarative part permits to capture interaction rules emerging from specification examples, the operational part supports the automatic execution in the operation of the virtual environment. A system is presented which embeds this language within a visual shell to support a behavioral training in which the animation rules of virtual agents are defined through visual examples.	IEEE Trans. Vis	visu
3794	IEEE Trans. Vis. Comput. Graph.	Using Line Integral Convolution for Flow Visualization: Curvilinear Grids, Variable-Speed Animation, and Unsteady Flows.	Lisa K. Forssell,Scott D. Cohen	1995	Line Integral Convolution (LIC), introduced by Cabral and Leedom in SIGGRAPH ¿93, is a powerful technique for imaging and animating vector fields. We extend the LIC technique in three ways:1. The existing algorithm is limited to vector fields over a regular Cartesian grid. We extend the algorithm and the animation techniques possible with it to vector fields over curvilinear surfaces, such as those found in computational fluid dynamics simulations.2. We introduce a technique to visualize vector magnitude as well as vector direction, i.e., variable-speed flow animation.3. We show how to modify LIC to visualize unsteady (time dependent) flows.Our implementation utilizes texture-mapping hardware to run in real time, which allows our algorithms to be included in interactive applications.	IEEE Trans. Vis	visu
3795	IEEE Trans. Vis. Comput. Graph.	Editorials.		1995	Editorials.	IEEE Trans. Vis	visu
3796	IEEE Trans. Vis. Comput. Graph.	Modeling and Visualization of Knitwear.	Eduard Gröller,René T. Rau,Wolfgang Straßer	1995	Visualization and modeling of textile materials has already been investigated in detail in the computer graphics literature. Most of the work, however, concentrates on woven fabrics. In this paper we present a novel approach to the modeling and rendering of knitwear. After the topological specification of a knitting pattern a subdivision into basic elements is done. The yarn microstructure within basic elements is approximated by volume data sets. The repetitive structure of knitted fabrics allows an efficient rendering technique. Resulting images are given that demonstrate the feasibility of our approach.	IEEE Trans. Vis	visu
3797	IEEE Trans. Vis. Comput. Graph.	Visualization of Multidimensional Shape and Texture Features in Laser Range Data Using Complex-Valued Gabor Wavelets.	Markus H. Gross,Rolf M. Koch	1995	This paper describes a new method for visualization and analysis of multivariate laser range data using complex-valued non-orthogonal Gabor wavelets, principal component analysis and a topological mapping network. The initial data set that provides both shape and texture information is encoded in terms of both amplitude and phase of a complex valued 2D image function. A set of carefully designed oriented Gabor filters performs a decomposition of the data and allows for retrieving local shape and texture features. The feature vector obtained from this method is multidimensional and in order to evaluate similar data features, further subspace methods to transform the data onto visualizable attributes, such as R, G, B, have to be determined. For this purpose, a feature-based visualization pipeline is proposed consisting of principal component analysis, normalization and a topological mapping network. This process finally renders a R, G, B subspace representation of the multidimensional feature vector. Our method is primarily applied to the visual analysis of features in human faces_but is not restricted to that.	IEEE Trans. Vis	visu
3798	IEEE Trans. Vis. Comput. Graph.	Exploiting Triangulated Surface Extraction Using Tetrahedral Decomposition.	André Guéziec,Robert A. Hummel	1995	Beginning with digitized volumetric data, we wish to rapidly and efficiently extract and represent surfaces defined as isosurfaces in the interpolated data. The Marching Cubes algorithm is a standard approach to this problem. We instead perform a decomposition of each 8-cell associated with a voxel into five tetrahedra. Following the ideas of Kalvin et al. [18], Thirion and Gourdon [30], and extending the work of Doi and Koide [5], we guarantee the resulting surface representation to be closed and oriented, defined by a valid triangulation of the surface of the body, which in turn is presented as a collection of tetrahedra. The entire surface is ¿wrapped¿ by a collection of triangles, which form a graph structure, and where each triangle is contained within a single tetrahedron. The representation is similar to the homology theory that uses simplices embedded in a manifold to define a closed curve within each tetrahedron.We introduce data structures based upon a new encoding of the tetrahedra that are at least four times more compact than the standard data structures using vertices and triangles. For parallel computing and improved cache performance, the vertex information is stored local to the tetrahedra. We can distribute the vertices in such a way that no tetrahedron ever contains more than one vertex.We give methods to evaluate surface curvatures and principal directions at each vertex, whenever these quantities are defined. Finally, we outline a method for simplifying the surface, that is reducing the vertex count while preserving the geometry. We compare the characteristics of our methods with an 8-cell based method, and show results of surface extractions from CT-scans and MR-scans at full resolution.	IEEE Trans. Vis	visu
3799	IEEE Trans. Vis. Comput. Graph.	Editorial.		1995	Editorial.	IEEE Trans. Vis	visu
3800	IEEE Trans. Vis. Comput. Graph.	A Multiscale Model for Structure-Based Volume Rendering.	Baining Guo	1995	A scalar volume V={(x, f(x)) | x ¿R} is described by a function f(x) defined over some region R of the 3D space. In this paper, we present a simple technique for rendering multiscale interval sets of the form ${\cal I}_{\mbi s}$(a, b) = {(x, fs(x)) |a¿gs(x) ¿b}, where a and b are either real numbers or infinities, and fs(x) is a smoothed version of f(x). At each scale s, the constraint a¿gs (x) ¿b identifies a subvolume in which the most significant variations of V are found. We use dyadic wavelet transform to construct gs(x) from f(x) and derive subvolumes with the following attractive properties: 1) the information contained in the subvolumes are sufficient for reconstructing the entire V, and 2) the shapes of the subvolumes provide a hierarchical description of the geometric structures of V. Numerically, the reconstruction in 1) is only an approximation, but it is visually accurate as errors reside at fine scales where our visual sensitivity is not so acute. We triangulate interval sets as ¿-shapes, which can be efficiently rendered as semi-transparent clouds. Because interval sets are extracted in the object space, their visual display can respond to changes of the view point or transfer function quite fast. The result is a volume rendering technique that provides faster, more effective user interaction with practically no loss of information from the original data. The hierarchical nature of multiscale interval sets also makes it easier to understand the usual complicated structures in scalar volumes.	IEEE Trans. Vis	visu
3801	IEEE Trans. Vis. Comput. Graph.	On Particle Path Generation Based on Quadrilinear Interpolation and Bernstein-Bézier Polynomials.	Bernd Hamann,Donghua Wu,Robert J. Moorhead II	1995	On Particle Path Generation Based on Quadrilinear Interpolation and Bernstein-Bézier Polynomials.	IEEE Trans. Vis	visu
3802	IEEE Trans. Vis. Comput. Graph.	In Memoriam: Dr. Wolfgang Krueger.	Pat Hanrahan	1995	In Memoriam: Dr. Wolfgang Krueger.	IEEE Trans. Vis	visu
3803	IEEE Trans. Vis. Comput. Graph.	Quaternion Frame Approach to Streamline Visualization.	Andrew J. Hanson,Hui Ma	1995	Curves in space are difficult to perceive and analyze, especially when they form dense sets as in typical 3D flow and volume deformation applications. We propose a technique that exposes essential properties of space curves by attaching an appropriate moving coordinate frame to each point, reexpressing that moving frame as a unit quaternion, and supporting interaction with the resulting quaternion field. The original curves in three-space are associated with piecewise continuous four-vector quaternion fields, which map into new curves lying in the unit three-sphere in four-space. Since four-space clusters of curves with similar moving frames occur independently of the curves¿ original proximity in three-space, a powerful analysis tool results. We treat two separate moving-frame formalisms, the Frenet frame and the parallel-transport frame, and compare their properties. We describe several flexible approaches for interacting with and exploiting the properties of the four-dimensional quaternion fields.	IEEE Trans. Vis	visu
3804	IEEE Trans. Vis. Comput. Graph.	Collision Detection for Interactive Graphics Applications.	Philip M. Hubbard	1995	Solid objects in the real world do not pass through each other when they collide. Enforcing this property of ``solidness'''' is important in many interactive graphics applications; for example, solidness makes virtual reality more believable, and solidness is essential for the correctness of vehicle simulators. These applications use a collision-detection algorithm to enforce the solidness of objects. Unfortunately, previous collision-detection algorithms do not adequately address the needs of interactive applications. To work in these applications, a collision-detection algorithm must run at real-time rates, even when many objects can collide, and it must tolerate objects whose motion is specified ``on the fly'''' by a user. This dissertation describes a new collision-detection algorithm that meets these criteria through approximation and graceful degradation, elements of ``time-critical computing.'''' The algorithm is not only fast but also interruptible, allowing an application to trade accuracy for speed as needed. The algorithm uses two forms of approximate geometry. The first is a four-dimensional structure called a ``space-time bound.'''' This structure provides a conservative estimate of where an object may be in the immediate future based on estimates of the object''s acceleration. The algorithm uses space-time bounds to focus its attention on objects that are likely to collide. The second form of approximate geometry is a ``sphere-tree.'''' This structure contains a hierarchy of unions of spheres, each union approximating the three-dimensional surface of an object at a different level of detail. Sphere-trees allow the algorithm to quickly find approximate contacts between objects, and they allow the application to interrupt the algorithm in order to meet real-time performance goals. Automatically building sphere-trees is an interesting problem in itself, and this dissertation describes several approaches. The simplest approach is based on octrees, and more sophisticated approaches use simulated annealing and approximate medial-axis surfaces. Several of the steps in these algorithms are themselves significant. One step is a simple algorithm for checking whether a union of two-dimensional shapes covers a polygon. Another step builds Voronoi diagrams for three-dimensional data points, and does so more robustly and accurately than previous algorithms. An implementation of the collision-detection algorithm runs significantly faster than a previous algorithm in empirical tests. In particular, this implementation allows real-time performance in a sample application (a simple flight simulator) that is too slow with the previous algorithm; in some cases, the performance improves by more than two orders of magnitude. Experience with this sample application suggests that time-critical computing is not always simple to apply, but it provides enough benefits that it deserves further exploration in other contexts.	IEEE Trans. Vis	visu
3805	IEEE Trans. Vis. Comput. Graph.	Automatic Isosurface Propagation Using an Extrema Graph and Sorted Boundary Cell Lists.	Takayuki Itoh,Koji Koyamada	1995	A high-performance algorithm for generating isosurfaces is presented. In our method, guides to searching for cells intersected by an isosurface are generated as a pre-process. These guides are two kinds of cell lists: an extrema graph, and sorted lists of boundary cells. In an extrema graph, extremum points are connected by arcs, and each arc has a list of cells through which it passes. At the same time, all boundary cells are sorted according to their minimum and maximum values, and two sorted lists are then generated. Isosurfaces are generated by visiting adjacent intersected cells in order. Here, the starting cells for this process are found by searching in an extrema graph and in sorted boundary cell lists. In this process, isosurfaces appear to propagate themselves. Our algorithm is efficient, since it visits only cells that are intersected by an isosurface and cells whose IDs are included in the guides. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described in this paper show the efficiency of the algorithm.	IEEE Trans. Vis	visu
3806	IEEE Trans. Vis. Comput. Graph.	Optical Models for Direct Volume Rendering.	Nelson L. Max	1995	This tutorial survey paper reviews several different models for light interaction with volume densities of absorbing, glowing, reflecting, and/or scattering material. They are, in order of increasing realism, absorption only, emission only, emission and absorption combined, single scattering of external illumination without shadows, single scattering with shadows, and multiple scattering. For each model I give the physical assumptions, describe the applications for which it is appropriate, derive the differential or integral equations for light transport, present calculation methods for solving them, and show output images for a data set representing a cloud. Special attention is given to calculation methods for the multiple scattering model.	IEEE Trans. Vis	visu
3807	IEEE Trans. Vis. Comput. Graph.	Multiscale Volume Representation by a DoG Wavelet.	Shigeru Muraki	1995	This article presents a method for decomposing volume data into 3D DoG (difference of Gaussians) functions by using the frame theory [1] of nonorthogonal wavelets. Since we can think of a DoG function as a pair of Gaussian functions, we can consider this method an automatic generation of Blinn¿s blobby objects [2]. We can also use this representation method for data compression by neglecting the insignificant coefficients, since the wavelet coefficients have significant values only where the volume density changes. Further, since the DoG function closely approximates a ¿2G (Laplacian of Gaussian) function, the representation can be considered a hierarchy of the 3D edges on different resolution spaces. Using the spherically symmetric feature of the 3D DoG function, we can easily visualize the 3D edge structure by the density reprojection method [3], [4]. We will apply our representation method to medical CT volume data and show its efficiency in describing the spatial structure of the volume.	IEEE Trans. Vis	visu
3808	IEEE Trans. Vis. Comput. Graph.	Obliq-3D: A High-Level, Fast-Turnaround 3D Animation System.	Marc Najork,Marc H. Brown	1995	This paper describes Obliq-3D, a high-level, fast-turnaround system for building 3D animations. Obliq-3D consists of an interpreted language that is embedded into a 3D animation library. This library is based on a few simple, yet powerful constructs that allow programmers to describe three-dimensional scenes and animations of such scenes. By virtue of its interpretive nature, Obliq-3D provides a fast-turnaround environment. The combination of simplicity and fast turnaround allows programmers to construct nontrivial animations quickly and easily.The paper is divided into three major parts. The first part introduces the basic concepts of Obliq-3D, using a series of graduated examples. The second part shows how the system can be used to implement Cone Trees. The third part develops a complete animation of Dijkstra¿s shortest-path algorithm.	IEEE Trans. Vis	visu
3809	IEEE Trans. Vis. Comput. Graph.	Visualization Takes its Place in the Scientific Community.	Gregory M. Nielson	1995	Visualization Takes its Place in the Scientific Community.	IEEE Trans. Vis	visu
3810	IEEE Trans. Vis. Comput. Graph.	Competent, Compact, Comparative Visualization of a Vortical Flow Field.	Hans-Georg Pagendarm,Birgit Walter	1995	In computational fluid dynamics, visualization is a frequently used tool for data evaluation, understanding of flow characteristics, and qualitative comparison to flow visualizations originating from experiments. Building on an existing visualization software system that allows for a careful selection of state-of-the-art visualization techniques and some extensions, it became possible to present various features of the data in a single image. The visualization shows vortex position and rotation as well as skin-friction lines, experimental oil-flow traces, shock-wave positions, and time surfaces. Animation provides natural perception of flow in combination with abstract representation of phenomena. By adding experimental flow visualization, a comparison between numerical simulation and wind-tunnel flow becomes possible up to a high level of detail. Since some of the underlying algorithms are not yet described in detail in the visualization literature, some experiences gained from the implementation are illustrated. The dedicated techniques which are illustrated here address specific properties of vector quantities in the flow field, such as the velocity vector or the friction vector. Image complexity is reduced by employing complex visualization methods. Thus, the room is created which is necessary to study the interaction of various phenomena.	IEEE Trans. Vis	visu
3811	IEEE Trans. Vis. Comput. Graph.	Real Time Responsive Animation with Personality.	Ken Perlin	1995	Building on principles from our prior work on procedural texture synthesis, we are able to create remarkably lifelike, responsively animated characters in real time. Rhythmic and stochastic noise functions are used to define time varying parameters that drive computer generated puppets. Because we are conveying just the ¿texture¿ of motion, we are able to avoid computation of dynamics and constraint solvers.The subjective impression of dynamics and other subtle influences on motion can be conveyed with great visual realism by properly tuned expressions containing pseudo-random noise functions. For example, we can make a character appear to be dynamically balancing herself, to appear nervous, or to be gesturing in a particular way.Each move has an internal rhythm, and transitions between moves are temporally constrained so that ¿impossible¿ transitions are precluded. For example, if while the character is walking we specify a dance turn, the character will always step into the turn onto the correct weight-bearing foot. An operator can make a character perform a properly connected sequence of actions, while conveying particular moods and attitudes, merely by pushing buttons at a high level.Potential uses of such high level ¿textural¿ approaches to computer graphic simulation include role playing games, simulated conferences, ¿clip animation,¿ graphical front ends for MUDs [15], [6], and synthetic performances.	IEEE Trans. Vis	visu
3812	IEEE Trans. Vis. Comput. Graph.	Dynamic Color Quantization of Video Sequences.	Evgeny Roytman,Craig Gotsman	1995	Dynamic Color Quantization of Video Sequences.	IEEE Trans. Vis	visu
3813	IEEE Trans. Vis. Comput. Graph.	A Unified Hierarchical Algorithm for Global Illumination with Scattering Volumes and Object Clusters.	François X. Sillion	1995	A Unified Hierarchical Algorithm for Global Illumination with Scattering Volumes and Object Clusters.	IEEE Trans. Vis	visu
3814	IEEE Trans. Vis. Comput. Graph.	Vision - An Architecture for Global Illumination Calculations.	Philipp Slusallek,Hans-Peter Seidel	1995	So far, the problem of global illumination calculation has almost exclusively been approached from an algorithmic point of view. In this paper we propose an architectural approach to global illumination. The proposed rendering architecture Vision is derived from a model of the physical rendering process, which is subsequently mapped onto an object-oriented hierarchy of classes. This design is powerful and flexible enough to support and exploit a large body of existing illumination algorithms for the simulation of various aspects of the underlying physical model. Additionally, the Vision architecture offers a platform for developing new algorithms and for combining them to create new rendering solutions.We discuss both abstract design as well as implementation issues. In particular, we give a detailed description of the global Lighting subsystem and show how algorithms for path tracing, bidirectional estimators, irradiance caching, hierarchical radiosity, wavelet radiosity, and wavelet radiance have been implemented within Vision.	IEEE Trans. Vis	visu
3815	IEEE Trans. Vis. Comput. Graph.	Visualization of Geometric Algorithms.	Ayellet Tal,David P. Dobkin	1995	This paper investigates the visualization of geometric algorithms. We discuss how limiting the domain makes it possible to create a system that enables others to use it easily. Knowledge about the domain can be very helpful in building a system which automates large parts of the user¿s task. A system can be designed to isolate the user from any concern about how graphics is done. The application need only specify ¿what¿ happens and need not be concerned with ¿how¿ to make it happen on the screen. We develop a conceptual model and a framework for experimenting with it. We also present a system, GASP, which implements this model. GASP allows quick generation of three-dimensional geometric algorithm visualizations, even for highly complex algorithms. It also provides a visual debugging facility for geometric computing. We show the utility of GASP by presenting a variety of examples.	IEEE Trans. Vis	visu
3816	IEEE Trans. Vis. Comput. Graph.	Calibration Requirements and Procedures for a Monitor-Based Augmented Reality System.	Mihran Tuceryan,Douglas S. Greer,Ross T. Whitaker,David E. Breen,Eric Rose,Klaus H. Ahlers,Chris Crampton	1995	Calibration Requirements and Procedures for a Monitor-Based Augmented Reality System.	IEEE Trans. Vis	visu
3817	IEEE Trans. Vis. Comput. Graph.	Octree-R: An Adaptive Octree for Efficient Ray Tracing.	Kyu-Young Whang,Ju-Won Song,Ji-Woong Chang,Ji-Yun Kim,Wan-Sup Cho,Chong-Mok Park,Il-Yeol Song	1995	Ray tracing requires many ray-obect intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many non-overlapping subregions, called voxels, and to construct an octree for the subdivided space. In this paper, we propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves.	IEEE Trans. Vis	visu
3818	IEEE Trans. Vis. Comput. Graph.	Grouping Volume Renderers for Enhanced Visualization in Computational Fluid Dynamics.	Roni Yagel,David S. Ebert,James N. Scott,Yair Kurzion	1995	This paper advocates the use of a group of renderers rather than any specific rendering method. We describe a bundle containing four alternative approaches to visualizing volume data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations. The second uses ray casting that is based on a simpler illumination model and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple illumination model and rapid rendering mechanisms to provide efficient preview capabilities. The last one reduces data magnitude by displaying the most visible components and exploits rendering hardware to provide real time browsing capabilities. We show that each rendering tool provides a unique service and demonstrate the combined utility of our group of volume renderers in computational fluid dynamic (CFD) visualization. While one tool allows the explorer to render rapidly for navigation through the data, another tool allows one to emphasize data features (e.g., shock waves), and yet another tool allows one to realistically render the data. We believe that only through the deployment of groups of renderers will the scientist be well served and equipped to form numerous perspectives of the same dataset, each providing different insights into the data.	IEEE Trans. Vis	visu
3819	IEEE Trans. Vis. Comput. Graph.	Hybrid Scan-Conversion of Circles.	Chengfu Yao,Jon G. Rokne	1995	Conventional algorithms for scan-conversion of circles select one pixel in each iteration. Run-length slice circle algorithms have therefore been suggested. These algorithms determine a run of pixels in each iteration. The speed of scan-conversion is therefore increased due to I/O. A hybrid approach to the scan-conversion of circles is presented. The new approach combines the advantages of the two methods into a hybrid algorithm. Speedup is achieved in the hybrid algorithm not only due to the reduction in the number of I/O operations, but also due to a reduction in the number of arithmetic operations.	IEEE Trans. Vis	visu
3820	IEEE Trans. Vis. Comput. Graph.	Volume Rendering of DCT-Based Compressed 3D Scalar Data.	Boon-Lock Yeo,Bede Liu	1995	This paper proposes a scheme to perform volume rendering from compressed scalar data. Instead of decompressing the entire data set before rendering, blocks of data are decompressed as needed. Discrete cosine transform based compression technique is used to illustrate the method. The data is partitioned into overlapping blocks to permit local rendering and allow easy parallelization. Compression by factor of 20 to 30 produces rendering virtually indistinguishable from rendering using the original uncompressed data. Speedup is obtained by making use of spatial homogeneity detected in the transform domain. Rendering time using the proposed approach is less than that of direct rendering from the entire uncompressed data. The proposed method thus offers an attractive option to reduce storage, computation, and transmission overhead of otherwise huge data sets.	IEEE Trans. Vis	visu
3821	KDD	The Quest Data Mining System.	Rakesh Agrawal,Manish Mehta,John C. Shafer,Ramakrishnan Srikant,Andreas Arning,Toni Bollinger	1996	The Quest Data Mining System.	KDD	datamining
3822	KDD	Developing Tightly-Coupled Data Mining Applications on a Relational Database System.	Rakesh Agrawal,Kyuseok Shim	1996	Developing Tightly-Coupled Data Mining Applications on a Relational Database System.	KDD	datamining
3823	KDD	A Linear Method for Deviation Detection in Large Databases.	Andreas Arning,Rakesh Agrawal,Prabhakar Raghavan	1996	A Linear Method for Deviation Detection in Large Databases.	KDD	datamining
3824	KDD	Exploiting Background Knowledge in Automated Discovery.	John M. Aronis,Foster J. Provost,Bruce G. Buchanan	1996	Exploiting Background Knowledge in Automated Discovery.	KDD	datamining
3825	KDD	Using a Hybrid Neural/Expert System for Data Base Mining in Market Survey Data.	Victor Ciesielski,Gregory Palstra	1996	Using a Hybrid Neural/Expert System for Data Base Mining in Market Survey Data.	KDD	datamining
3826	KDD	Mining Knowledge in Noisy Audio Data.	Andrzej Czyzewski	1996	Mining Knowledge in Noisy Audio Data.	KDD	datamining
3827	KDD	Sharing Learned Models among Remote Database Partitions by Local Meta-Learning.	Philip K. Chan,Salvatore J. Stolfo	1996	Sharing Learned Models among Remote Database Partitions by Local Meta-Learning.	KDD	datamining
3828	KDD	Growing Simpler Decision Trees to Facilitate Knowledge Discovery.	Kevin J. Cherkauer,Jude W. Shavlik	1996	Growing Simpler Decision Trees to Facilitate Knowledge Discovery.	KDD	datamining
3829	KDD	Maintenance of Discovered Knowledge: A Case in Multi-Level Association Rules.	David Wai-Lok Cheung,Vincent T. Y. Ng,Benjamin W. Tam	1996	Maintenance of Discovered Knowledge: A Case in Multi-Level Association Rules.	KDD	datamining
3830	KDD	Linear-Time Rule Induction.	Pedro Domingos	1996	Linear-Time Rule Induction.	KDD	datamining
3831	KDD	Efficient Specific-to-General Rule Induction.	Pedro Domingos	1996	Efficient Specific-to-General Rule Induction.	KDD	datamining
3832	KDD	Local Induction of Decision Trees: Towards Interactive Data Mining.	Truxton Fulton,Simon Kasif,Steven Salzberg,David L. Waltz	1996	Local Induction of Decision Trees: Towards Interactive Data Mining.	KDD	datamining
3833	KDD	Mining Entity-Identification Rules for Database Integration.	M. Ganesh,Jaideep Srivastava,Travis Richardson	1996	Mining Entity-Identification Rules for Database Integration.	KDD	datamining
3834	KDD	Planning Tasks for Knowledge Discovery in Databases; Performing Task-Oriented User-Guidance.	Robert Engels	1996	Planning Tasks for Knowledge Discovery in Databases; Performing Task-Oriented User-Guidance.	KDD	datamining
3835	KDD	A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.	Martin Ester,Hans-Peter Kriegel,Jörg Sander,Xiaowei Xu	1996	A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.	KDD	datamining
3836	KDD	Data Mining with Sparse and Simplified Interaction Selection.	Gerald Fahner	1996	Data Mining with Sparse and Simplified Interaction Selection.	KDD	datamining
3837	KDD	Combining Data Mining and Machine Learning for Effective User Profiling.	Tom Fawcett,Foster J. Provost	1996	Combining Data Mining and Machine Learning for Effective User Profiling.	KDD	datamining
3838	KDD	KDD for Science Data Analysis: Issues and Examples.	Usama M. Fayyad,David Haussler,Paul E. Stolorz	1996	KDD for Science Data Analysis: Issues and Examples.	KDD	datamining
3839	KDD	Knowledge Discovery and Data Mining: Towards a Unifying Framework.	Usama M. Fayyad,Gregory Piatetsky-Shapiro,Padhraic Smyth	1996	Knowledge Discovery and Data Mining: Towards a Unifying Framework.	KDD	datamining
3840	KDD	Learning from Biased Data Using Mixture Models.	A. J. Feelders	1996	Learning from Biased Data Using Mixture Models.	KDD	datamining
3841	KDD	Harnessing the Human in Knowledge Discovery.	Georges G. Grinstein	1996	Harnessing the Human in Knowledge Discovery.	KDD	datamining
3842	KDD	Data Mining and Tree-Based Optimization.	Robert L. Grossman,Haim Bodek,Dave Northcutt,Vince Poor	1996	Data Mining and Tree-Based Optimization.	KDD	datamining
3843	KDD	Mining Associations in Text in the Presence of Background Knowledge.	Ronen Feldman,Haym Hirsh	1996	Mining Associations in Text in the Presence of Background Knowledge.	KDD	datamining
3844	KDD	A Genetic Algorithm-Based Approach to Data Mining.	Ian W. Flockhart,Nicholas J. Radcliffe	1996	A Genetic Algorithm-Based Approach to Data Mining.	KDD	datamining
3845	KDD	DBMiner: A System for Mining Knowledge in Large Relational Databases.	Jiawei Han,Yongjian Fu,Wei Wang,Jenny Chiang,Wan Gong,Krzysztof Koperski,Deyi Li,Yijun Lu,Amynmohamed Rajan,Nebojsa Stefanovic,Betty Xia,Osmar R. Zaïane	1996	DBMiner: A System for Mining Knowledge in Large Relational Databases.	KDD	datamining
3846	KDD	Knowledge Discovery in RNA Sequence Families of HIV Using Scalable Computers.	Ivo L. Hofacker,Martijn A. Huynen,Peter F. Stadler,Paul E. Stolorz	1996	Knowledge Discovery in RNA Sequence Families of HIV Using Scalable Computers.	KDD	datamining
3847	KDD	Inferring Hierarchical Clustering Structures by Deterministic Annealing.	Thomas Hofmann,Joachim M. Buhmann	1996	Inferring Hierarchical Clustering Structures by Deterministic Annealing.	KDD	datamining
3848	KDD	Discovering Knowledge in Commercial Databases Using Modern Heuristic Techniques.	Beatriz de la Iglesia,Justin C. W. Debuse,Victor J. Rayward-Smith	1996	Discovering Knowledge in Commercial Databases Using Modern Heuristic Techniques.	KDD	datamining
3849	KDD	DataMine: Application Programming Interface and Query Language for Database Mining.	Tomasz Imielinski,Aashu Virmani,Amin Abdulghani	1996	DataMine: Application Programming Interface and Query Language for Database Mining.	KDD	datamining
3850	KDD	Discovery of Relevant New Features by Generating Non-Linear Decision Trees.	Andreas Ittner,Michael Schlosser	1996	Discovery of Relevant New Features by Generating Non-Linear Decision Trees.	KDD	datamining
3851	KDD	Static Versus Dynamic Sampling for Data Mining.	George H. John,Pat Langley	1996	Static Versus Dynamic Sampling for Data Mining.	KDD	datamining
3852	KDD	Evaluating the Interestingness of Characteristic Rules.	Micheline Kamber,Rajjan Shinghal	1996	Evaluating the Interestingness of Characteristic Rules.	KDD	datamining
3853	KDD	A Method for Reasoning with Structured and Continuous Attributes in the INLEN-2 Multistrategy Knowledge Discovery System.	Kenneth A. Kaufman,Ryszard S. Michalski	1996	A Method for Reasoning with Structured and Continuous Attributes in the INLEN-2 Multistrategy Knowledge Discovery System.	KDD	datamining
3854	KDD	Analysing Binary Associations.	Arno J. Knobbe,Pieter W. Adriaans	1996	Analysing Binary Associations.	KDD	datamining
3855	KDD	Extraction of Spatial Proximity Patterns by Concept Generalization.	Edwin M. Knorr,Raymond T. Ng	1996	Extraction of Spatial Proximity Patterns by Concept Generalization.	KDD	datamining
3856	KDD	Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid.	Ron Kohavi	1996	Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid.	KDD	datamining
3857	KDD	Error-Based and Entropy-Based Discretization of Continuous Features.	Ron Kohavi,Mehran Sahami	1996	Error-Based and Entropy-Based Discretization of Continuous Features.	KDD	datamining
3858	KDD	Predictive Data Mining with Finite Mixtures.	Petri Kontkanen,Petri Myllymäki,Henry Tirri	1996	Predictive Data Mining with Finite Mixtures.	KDD	datamining
3859	KDD	Efficient Search for Strong Partial Determinations.	Stefan Kramer,Bernhard Pfahringer	1996	Efficient Search for Strong Partial Determinations.	KDD	datamining
3860	KDD	Self-Organizing Maps of Document Collections: A New Approach to Interactive Exploration.	Krista Lagus,Timo Honkela,Samuel Kaski,Teuvo Kohonen	1996	Self-Organizing Maps of Document Collections: A New Approach to Interactive Exploration.	KDD	datamining
3861	KDD	Imputation of Missing Data Using Machine Learning Techniques.	Kamakshi Lakshminarayan,Steven A. Harp,Robert P. Goldman,Tariq Samad	1996	Imputation of Missing Data Using Machine Learning Techniques.	KDD	datamining
3862	KDD	An Empirical Test of the Weighted Effect Approach to Generalized Prediction Using Recursive Neural Nets.	Rense Lange	1996	An Empirical Test of the Weighted Effect Approach to Generalized Prediction Using Recursive Neural Nets.	KDD	datamining
3863	KDD	Induction of Condensed Determinations.	Pat Langley	1996	Induction of Condensed Determinations.	KDD	datamining
3864	KDD	An Overview of Issues in Developing Industrial Data Mining and Knowledge Discovery Applications.	Gregory Piatetsky-Shapiro,Ronald J. Brachman,Tom Khabaza,Willi Klösgen,Evangelos Simoudis	1996	An Overview of Issues in Developing Industrial Data Mining and Knowledge Discovery Applications.	KDD	datamining
3865	KDD	Reverse Engineering Databases for Knowledge Discovery.	Stephen McKearney,Huw Roberts	1996	Reverse Engineering Databases for Knowledge Discovery.	KDD	datamining
3866	KDD	Discovering Generalized Episodes Using Minimal Occurrences.	Heikki Mannila,Hannu Toivonen	1996	Discovering Generalized Episodes Using Minimal Occurrences.	KDD	datamining
3867	KDD	Multiple Uses of Frequent Sets and Condensed Representations (Extended Abstract).	Heikki Mannila,Hannu Toivonen	1996	Multiple Uses of Frequent Sets and Condensed Representations (Extended Abstract).	KDD	datamining
3868	KDD	A Comparison of Approaches for Maximizing Business Payoff of Prediction Models.	Brij M. Masand,Gregory Piatetsky-Shapiro	1996	A Comparison of Approaches for Maximizing Business Payoff of Prediction Models.	KDD	datamining
3869	KDD	The Field Matching Problem: Algorithms and Applications.	Alvaro E. Monge,Charles Elkan	1996	The Field Matching Problem: Algorithms and Applications.	KDD	datamining
3870	KDD	Rethinking the Learning of Belief Network Probabilities.	Ron Musick	1996	Rethinking the Learning of Belief Network Probabilities.	KDD	datamining
3871	KDD	Pattern Discovery in Temporal Databases: A Temporal Logic Approach.	Balaji Padmanabhan,Alexander Tuzhilin	1996	Pattern Discovery in Temporal Databases: A Temporal Logic Approach.	KDD	datamining
3872	KDD	Parallel Halo Finding in N-Body Cosmology Simulations.	David W. Pfitzner,John K. Salmon	1996	Parallel Halo Finding in N-Body Cosmology Simulations.	KDD	datamining
3873	KDD	Performing Effective Feature Selection by Investigating the Deep Structure of the Data.	Marco Richeldi,Pier Luca Lanzi	1996	Performing Effective Feature Selection by Investigating the Deep Structure of the Data.	KDD	datamining
3874	KDD	Data Mining and Model Simplicity: A Case Study in Diagnosis.	Gregory M. Provan,Moninder Singh	1996	Data Mining and Model Simplicity: A Case Study in Diagnosis.	KDD	datamining
3875	KDD	SE-Trees Outperform Decision Trees in Noisy Domains.	Ron Rymon	1996	SE-Trees Outperform Decision Trees in Noisy Domains.	KDD	datamining
3876	KDD	Deriving Queries from Results Using Genetic Programming.	Tae-Wan Ryu,Christoph F. Eick	1996	Deriving Queries from Results Using Genetic Programming.	KDD	datamining
3877	KDD	Learning Limited Dependence Bayesian Classifiers.	Mehran Sahami	1996	Learning Limited Dependence Bayesian Classifiers.	KDD	datamining
3878	KDD	Discovering Classification Knowledge in Databases Using Rough Sets.	Ning Shan,Wojciech Ziarko,Howard J. Hamilton,Nick Cercone	1996	Discovering Classification Knowledge in Databases Using Rough Sets.	KDD	datamining
3879	KDD	Scalable Exploratory Data Mining of Distributed Geoscientific Data.	Eddie C. Shek,Richard R. Muntz,Edmond Mesrobian,Kenneth W. Ng	1996	Scalable Exploratory Data Mining of Distributed Geoscientific Data.	KDD	datamining
3880	KDD	Metapattern Generation for Integrated Data Mining.	Wei-Min Shen,Bing Leng	1996	Metapattern Generation for Integrated Data Mining.	KDD	datamining
3881	KDD	Clustering Using Monte Carlo Cross-Validation.	Padhraic Smyth	1996	Clustering Using Monte Carlo Cross-Validation.	KDD	datamining
3882	KDD	Harnessing Graphical Structure in Markov Chain Monte Carlo Learning.	Paul E. Stolorz,Philip C. Chew	1996	Harnessing Graphical Structure in Markov Chain Monte Carlo Learning.	KDD	datamining
3883	KDD	Quakefinder: A Scalable Data Mining System for Detecting Earthquakes from Space.	Paul E. Stolorz,Christopher Dean	1996	Quakefinder: A Scalable Data Mining System for Detecting Earthquakes from Space.	KDD	datamining
3884	KDD	Exceptional Knowledge Discovery in Databases Based on Information Theory.	Einoshin Suzuki,Masamichi Shimura	1996	Exceptional Knowledge Discovery in Databases Based on Information Theory.	KDD	datamining
3885	KDD	Undiscovered Public Knowledge: A Ten-Year Update.	Don R. Swanson,Neil R. Smalheiser	1996	Undiscovered Public Knowledge: A Ten-Year Update.	KDD	datamining
3886	KDD	Interactive Knowledge Discovery from Marketing Questionnaire Using Simulated Breeding and Inductive Learning Methods.	Takao Terano,Yoko Ishino	1996	Interactive Knowledge Discovery from Marketing Questionnaire Using Simulated Breeding and Inductive Learning Methods.	KDD	datamining
3887	KDD	Automated Discovery of Medical Expert System Rules from Clinical Databases Based on Rough Sets.	Shusaku Tsumoto,Hiroshi Tanaka	1996	Automated Discovery of Medical Expert System Rules from Clinical Databases Based on Rough Sets.	KDD	datamining
3888	KDD	Efficient Implementation of Data Cubes Via Materialized Views.	Jeffrey D. Ullman	1996	Efficient Implementation of Data Cubes Via Materialized Views.	KDD	datamining
3889	KDD	RITIO - Rule Induction Two In One.	David Urpani,Xindong Wu,Jim Sykes	1996	RITIO - Rule Induction Two In One.	KDD	datamining
3890	KDD	Automated Discovery of Active Motifs in Multiple RNA Secondary Structures.	Jason Tsong-Li Wang,Bruce A. Shapiro,Dennis Shasha,Kaizhong Zhang,Chia-Yo Chang	1996	Automated Discovery of Active Motifs in Multiple RNA Secondary Structures.	KDD	datamining
3891	KDD	Representing Discovered Patterns Using Attributed Hypergraph.	Yang Wang,Andrew K. C. Wong	1996	Representing Discovered Patterns Using Attributed Hypergraph.	KDD	datamining
3892	KDD	Detecting Early Indicator Cars in an Automotive Database: A Multi-Strategy Approach.	Rüdiger Wirth,Thomas P. Reinartz	1996	Detecting Early Indicator Cars in an Automotive Database: A Multi-Strategy Approach.	KDD	datamining
3893	KDD	Extensibility in Data Mining Systems.	Stefan Wrobel,Dietrich Wettschereck,Edgar Sommer,Werner Emde	1996	Extensibility in Data Mining Systems.	KDD	datamining
3894	KDD	Automated Pattern Mining with a Scale Dimension.	Jan M. Zytkow,Robert Zembowicz	1996	Automated Pattern Mining with a Scale Dimension.	KDD	datamining
3895	KDD	Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD-96), Portland, Oregon, USA	Evangelos Simoudis,Jiawei Han,Usama M. Fayyad	1996	Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD-96), Portland, Oregon, USA	KDD	datamining
3896	ICDE	VISUAL: A Graphical Icon-Based Query Language.	Nevzat Hurkan Balkir,Eser Sükan,Gultekin Özsoyoglu,Z. Meral Özsoyoglu	1996	VISUAL: A Graphical Icon-Based Query Language.	ICDE	database
3897	ICDE	Tioga-2: A Direct Manipulation Database Visualization Environment.	Alexander Aiken,Jolly Chen,Michael Stonebraker,Allison Woodruff	1996	This paper reports on user experience with Tioga, a DBMS-centric visualization tool developed at Berkeley. Based on this experience, we have designed Tioga-2 as a direct manipulation system that is more powerful and much easier to program. A detailed design of the revised system is presented, together with an extensive example of its application.	ICDE	database
3898	ICDE	Advanced Transaction Models in Workflow Contexts.	Gustavo Alonso,Divyakant Agrawal,Amr El Abbadi,Mohan Kamath,Roger Günthör,C. Mohan	1996	In recent years, numerous transaction models have been proposed to address the problems posed by advanced database applications, but only a few of these models are being used in commercial products. In this paper, we make the case that such models may be too centered around databases to be useful in real environments. Advanced applications raise a variety of issues that are not addressed at all by transaction models. These same issues, however, are the basis for existing workflow systems, which are having considerable success as commercial products in spite of not having a solid theoretical foundation. We explore some of these issues and show that, in many aspects, workflow models are a superset of transaction models and have the added advantage of incorporating a variety of ideas that to this date have remained outside the scope of traditional transaction processing.	ICDE	database
3899	ICDE	Prefetching from Broadcast Disks.	Swarup Acharya,Michael J. Franklin,Stanley B. Zdonik	1996	Broadcast Disks have been proposed as a means to efficiently deliver data to clients in ``asymmetric'' environments where the available bandwidth from the server to the clients greatly exceeds the bandwidth in the opposite direction. A previous study investigated the use of cost-based caching to improve performance when clients access the broadcast in a demand-driven manner [. achas 95 .]. Such demand-driven access however, does not fully exploit the dissemination-based nature of the broadcast, which is particularly conducive to client {\em prefetching}. With a Broadcast Disk, pages continually flow past the clients so that, in contrast to traditional environments, prefetching can be performed without placing additional load on shared resources. We argue for the use of a simple prefetch heuristic called \PT{} and show that \PT{} balances the cache residency time of a data item with its bandwidth allocation. Because of this tradeoff, \PT{} is very tolerant of variations in the broadcast program. We describe an implementable approximation for \PT{} and examine its sensitivity to access probability estimation errors. The results show that the technique is effective even when the probability estimation is substantially different from the actual values.	ICDE	database
3900	ICDE	A Proposed Method for Creating VCR Functions using MPEG Streams.	David B. Andersen	1996	The development of video-on-demand (VOD) systems for movie delivery requires that the user be able to perform VCR functions over a broadband network system. These functions include Play, Pause, Fast Forward, and Fast Rewind. No standard method exists between content developers, server manufacturers and client applications to provide these functions. This paper proposes a standard method for implementing these functions using MPEG streams and discusses some of the important tradeoffs. The encoding and distribution of content has become one of the most important issues facing video information providers. Today, in the case of movies, every service provider must encode the material for the specific equipment being deployed in the network. Therefore, the ease of use and speed of the algorithms employed to encode the material are extremely important. In the future, the creator of the content may encode the material once and distribute it to the service providers in compressed form, but this is not the case today due to the lack of standards.	ICDE	database
3901	ICDE	Dynamic Optimization of Index Scans Restricted by Booleans.	Gennady Antoshenkov	1996	Dynamic Optimization of Index Scans Restricted by Booleans.	ICDE	database
3902	ICDE	Order Preserving Compression.	Gennady Antoshenkov,David B. Lomet,James Murray	1996	Order-preserving compression can improve sorting and searching performance, and hence the performance of database systems. We describe a new parsing (tokenization) technique that can be applied to variable-length keys, producing substantial compression. It can both compress and decompress data, permitting variable lengths for dictionary entries and compressed forms. The key notion is to partition the space of strings into ranges, encoding the common prefix of each range. We illustrate our method with padding character compression for multi-field keys, demonstrating the dramatic gains possible. A specific version of the method has been implemented in Digital's Rdb relational database system to enable effective multi-field compression.	ICDE	database
3903	ICDE	The Gold Text Indexing Engine.	Daniel Barbará,Sharad Mehrotra,Padmavathi Vallabhaneni	1996	The proliferation of electronic communication including computer mail, faxes, voice mail, and net news has led to a variety of disjoint applications and usage paradigms that forces users to deal with multiple different user interfaces and access related information arriving over the different communication media separately. To enable users to cope with the overload of information arriving over heterogeneous communication media, we have developed the Gold document handling system that allows users to access all of these forms of communication at once, or to intermix them. The Gold system provides users with an integrated way to send and recieve messages using different media, efficiently store the messages, retrieve the messages based on their contents, and to access a variety of other sources of useful information. At the center of the Gold document handling system is the Gold Text Indexing Engine (GTIE) that provides a full text index over the documents. The paper describes our implementation of GTIE and the concurrency control protocols to ensure consistency of the index in the presence of concurrent operations.	ICDE	database
3904	ICDE	OLE DB: A Component DBMS Architecture.	José A. Blakeley	1996	The article describes an effort at Microsoft whose primary goal is to enable applications to have uniform access to data stored in diverse DBMS and non DBMS information containers. Applications continue to take advantage of the benefits of database technology such as declarative queries, transactional access, and security without having to transfer data from its place of origin to a DBMS. Our approach consists of defining an open, extensible collection of interfaces that factor and encapsulate orthogonal, independently reusable portions of DBMS functionality. These interfaces define the boundaries of DBMS components arch as record containers, and query processors that enable uniform, transactional access to data among such components. The proposed interfaces extend Microsoft's OLE Component Object Model (COM) with database functionality, hence these interfaces are collectively referred to as OLE DB. The OLE DB functional areas include data access and updates (rowsets), query processing, catalog information, notifications, transactions, security, and distribution. The article presents an overview of the OLE DB approach and its areas of componentization.	ICDE	database
3905	ICDE	ODMG Update.	Dirk Bartels	1996	The Object Database Management Group (ODMG) is a consortium of the leading Object Database (ODMBS) vendors. The consortium was formed in 1992 with the objective to define a standard for the emerging ODBMS industry. Within 18 months, the first release of the standard, so called ODMG-93 was published in October 1993. The following abstract gives a comprehensive overview of the standard and the extension that have been made since the initial publishing. The overview includes the ODMG Object Model, the ODMG Object Definition Language (ODL), the ODMG Object Query Language (OQL), the ODMG C++ binding and the ODMG Smalltalk binding.	ICDE	database
3906	ICDE	Title, General Chairs' Message, Program Chairs' Message, In Memoriam, Committees, Referees, Author Index.		1996	Title, General Chairs' Message, Program Chairs' Message, In Memoriam, Committees, Referees, Author Index.	ICDE	database
3907	ICDE	Speculative Data Dissemination and Service to Reduce Server Load, Network Traffic and Service Time in Distributed Information Systems.	Azer Bestavros	1996	We present two server-initiated protocols to improve the performance of distributed information systems WWW. Our first protocol is a hierarchical data dissemination mechanism that allows information to propagate from its producers to servers that are closer to its consumers. This dissemination reduces network traffic and balances load amongst servers by exploiting geographic and temporal locality of reference properties exhibited in client access patterns. Our second protocol relies on speculative service, whereby a request for a document is serviced by sending, in addition to the document requested, a number of other documents that the server speculates will be requested in the near future. This speculation reduces service time by exploiting the spatial locality of reference property. We present results of trace-driven simulations that quantify the attainable performance gains for both protocols.	ICDE	database
3908	ICDE	Efficient Processing of Outer Joins and Aggregate Functions.	Gautam Bhargava,Piyush Goel,Balakrishna R. Iyer	1996	Removal of redundant outer joins is essential for the reassociation of outer joins with other binary operations. In this paper we present a set of comprehensive algorithms that employ the properties of strong predicates along with the properties of aggregation, intersection, union, and except operations to remove redundant outer joins from a query. For the purpose of query simplification, we generate additional projections by determining the keys. Our algorithm for generating keys is based on a novel concept of weak bindings that is essential for queries containing outer joins. Our algorithm for converting outer joins to joins is based on a novel concept of join-reducibility.	ICDE	database
3909	ICDE	Parallel Processing of Spatial Joins Using R-trees.	Thomas Brinkhoff,Hans-Peter Kriegel,Bernhard Seeger	1996	Fachgebiet Informatik, Universität Marburg, Marburg, GermanyIn this paper, we show that spatial joins are very suitable to be processed on a parallel hardware platform. The parallel system is equipped with a so-called shared virtual memory which is well-suited for the design and implementation of parallel spatial join algorithms. We start with an algorithm that consists of three phases: task creation, task assignment and parallel task execution. In order to reduce CPU- and I/O-cost, the three phases are processed in a fashion that preserves spatial locality. Dynamic load balancing is achieved by splitting tasks into smaller ones and reassigning some of the smaller tasks to idle processors. In an experimental performance comparison, we identify the advantages and disadvantages of several variants of our algorithm. The most efficient one shows an almost optimal speed-up under the assumption that the number of disks is sufficiently large.	ICDE	database
3910	ICDE	Parallel Pointer-Based Join Algorithms in Memory-mapped Environments.	Peter A. Buhr,Anil K. Goel,Naomi Nishimura,Prabhakar Ragde	1996	Three pointer-based parallel join algorithms are presented and analyzed for environments in which secondary storage is made transparent to the programmer through memory mapping. Buhr, Goel, and Wai have shown that data structures such as B-Trees, R-Trees and graph data structures can be implemented as efficiently and effectively in this environment as in a traditional environment using explicit I/O. Here we show how higher-order algorithms, in particular parallel join algorithms, behave in a memory mapped environment. A quantitative analytical model has been developed to conduct performance analysis of the parallel join algorithms. The model has been validated by experiments.	ICDE	database
3911	ICDE	A Toolkit for Constraint Management in Heterogeneous Information Systems.	Sudarshan S. Chawathe,Hector Garcia-Molina,Jennifer Widom	1996	We present a framework and a toolkit to monitor and enforce distributed integrity constraints in loosely coupled heterogeneous information systems. Our framework enables and formalizes weakened notions of consistency, which are essential in such environments. Our framework is used to describe (1) intelfaces provided by a database for the data items involved in inter-site constraints; (2) strategies for monitoring and enforcing such constraints, (3) guarantees regarding the level of consistency the system can provide. Our toolkit uses this framework to provide a set of configurable modules thatare used to monitorand en- force constraints spanning loosely coupled heterogeneous information systems.	ICDE	database
3912	ICDE	An Executable Graphical Representation of Mediatory Information Systems.	Jacques Calmet,Dirk Debertin,Sebastian Jekutsch,Joachim Schü	1996	In this paper we present an approach towards a unified modeling and query-processing tool for mediatory information systems. Based upon Coloured Petri nets we are able to model the integration of parametric data (external, uncertain and temporal informations) and to visualize the dataflow in mediatory information systems.	ICDE	database
3913	ICDE	Query Answering Using Discovered Rules.	I-Min A. Chen	1996	Query Answering Using Discovered Rules.	ICDE	database
3914	ICDE	Transaction Coordination for the New Millennium: SQL Server Meets OLE Transactions.	David Campbell	1996	Transaction Coordination for the New Millennium: SQL Server Meets OLE Transactions.	ICDE	database
3915	ICDE	Secure Mediated Databases.	K. Selçuk Candan,Sushil Jajodia,V. S. Subrahmanian	1996	With the evolution of the information superhighway, there is now an immense amount of information available in a wide variety of databases. Furthermore, users often have the ability to access legacy software packages developed by external sources. However, sometimes both the information provided by a data source, as well as one or more of the functions available through a software package may be sensitive-in such cases, organizations require that access by users be controlled. HERMES (HEterogeneous Reasoning and MEdiator System) is a platform that has been developed at the University of Maryland within which mediators may be designed and implemented. HERMES has already been used for a number of applications. In this paper, we provide a formal model of security in mediated systems. We then develop techniques that are sound and complete and respect security constraints of packages/databases participating in the mediated system. The security constraints described an this paper have been implemented, and we describe the existing implementation.	ICDE	database
3916	ICDE	A Transactional Nested Process Management System.	Qiming Chen,Umeshwar Dayal	1996	Providing flexible transaction semantics and incorporating activities, data and agents are the key issues in workflow system development. Unfortunately, most of the commercial workflow systems lack the advanced features of transaction models, and an individual transaction model with specific emphasis lacks sufficient coverage for business process management.This report presents our solutions to the above problems in developing Open Process Management System (OPMS) at HP Labs. OPMS is based on nested activity modeling with the following extensions and constraints: in-process open nesting} for extending closed/open nesting to accommodate applications that require improved process-wide concurrency without sacrificing top-level atomicity; confined open as a constraint on open and in-process open activities for avoiding the semantic inconsistencies in activity triggering and compensation; and two-phase remedy as a generalized hierarchical approach for handling failures.	ICDE	database
3917	ICDE	Database Research: Lead, Follow, or Get Out of the Way? - Panel Abstract.	Surajit Chaudhuri,Ashok K. Chandra,Umeshwar Dayal,Jim Gray,Michael Stonebraker,Gio Wiederhold,Moshe Y. Vardi	1996	Database Research: Lead, Follow, or Get Out of the Way? - Panel Abstract.	ICDE	database
3918	ICDE	Maintenance of Discovered Association Rules in Large Databases: An Incremental Updating Technique.	David Wai-Lok Cheung,Jiawei Han,Vincent T. Y. Ng,C. Y. Wong	1996	An incremental updating technique is developed for maintenance of the association rules discovered by database mining. There have been many studies on efficient discovery of association rules in large databases. However, it is nontrivial to maintain such discovered rules in large databases because a database may allow frequent or occasional updates and such updates may not only invalidate some existing strong association rules but also turn some weak rules into strong ones. In this study, an incremental updating technique is proposed for efficient maintenance of discovered association rules when new transaction data are added to a transaction database.	ICDE	database
3919	ICDE	Deferred Updates and Data Placement in Distributed Databases.	Parvathi Chundi,Daniel J. Rosenkrantz,S. S. Ravi	1996	Commercial distributed database systems generally support an optional protocol that provides loose consistency of replicas, allowing replicas to be inconsistent for some time. In such a protocol, each replicated data item is assigned a primary copy site. Typically, a transaction updates only the primary copies of data items, with updates to other copies deferred until after the transaction commits. After a transaction commits, its updates to primary copies are sent transactionally to the other sites containing secondary copies. We investigate the transaction model underlying the above protocol. We show that global serializability in such a system is a property of the placement of primary and secondary copies of replicated data items. We present a polynomial time algorithm to assign primary sites to data items so that the resulting topology ensures serializability.	ICDE	database
3920	ICDE	Database Extensions for Complex Domains	Samuel DeFazio,Jagannathan Srinivasan	1996	Future versions of the Oracle Server will provide an open and extensible framework for supporting complex data domains including, but not limited to, text, image, spatial, video, and OLAP. This framework encompasses features for defining, storing, updating, indexing, and retrieving complex forms of data with full transaction semantics. The underpinning for these features is an extended Oracle Server that is an object-relational database management system (ORDBMS).	ICDE	database
3921	ICDE	Reusing (Shrink Wrap) Schemas by Modifying Concept Schemas.	Lois M. L. Delcambre,Jimmy Langston	1996	A shrink wrap schema is a well-crafted, complete, global schema that represents an application. A concept schema is a subset of the shrink wrap schema that addresses one particular point of view in an application. We define schema modification operations to customize each concept schema, to match the designer's perception of the application. We maintain the integrated, customized user schema. We enforce consistency checks to provide feedback to the designer about interactions among the concept schemas. We embody these mechanisms in an interactive system that aids in shrink wrap schema-based design. The shrink wrap schema approach promotes reuse of past design efforts; prior approaches to schema reuse do not attempt to reuse an entire schema nor do they focus on local customization. The focus of this paper is on the definition of concept schemas and their corresponding modification operations.	ICDE	database
3922	ICDE	SONET Configuration Management with OpenPM.	Weimin Du,Ming-Chien Shan,Chris Whitney	1996	SONET (Synchronous Optical NETwork) has been proposed as the backbone of future information superhighway infrastructure. SONET network management, however, is a complex process that involves many heterogeneous systems and applications, as well as human interactions. In this paper, we describe a prototype system developed at Hewlett-Packard (HP) that provides a service for configuring large SONET networks. The prototype differs from the existing systems in that it employs the HP OpenPM (Open Process Management) workflow system to define, execute and monitor network management processes. Using OpenPM (a middleware service that enables the automation of activities supporting complex enterprise business processes in a distributed heterogeneous computing environment) as a reliable and efficient workflow execution engine, this prototype supports efficient distributed network management and easy integration of legacy applications. The paper describes how an example network configuration management process is modeled, executed and monitored using OpenPM.	ICDE	database
3923	ICDE	Authorization and Access Control in IRO-DB.	Wolfgang Eßmayr,Fritz Kastner,Günther Pernul,Stefan Preishuber,A. Min Tjoa	1996	Authorization and Access Control in IRO-DB.	ICDE	database
3924	ICDE	A Log-Structured Organization for Tertiary Storage.	Daniel Alexander Ford,Jussi Myllymaki	1996	We present the design of a log-structured tertiary storage system (LTS). The advantage of this approach is that it allows the system to hide the details of juke-box robotics and media characteristics behind a uniform, random access, block-oriented interface. It also allows the system to avoid media mount operations for writes, giving write performance similar to that of secondary storage.	ICDE	database
3925	ICDE	Relaxed Index Consistency for a Client-Server Database.	Vibby Gottemukkala,Edward Omiecinski,Umakishore Ramachandran	1996	Client-Server systems cache data in client buffers to deliver good performance. Several efficient protocols have been proposed to maintain the coherence of the cached data. However, none of the protocols distinguish between index pages and data pages. We propose a new coherence protocol, called Relaxed Index Consistency, that exploits the inherent differences in the coherence and concurrency-control (C&CC) requirements for index and data pages. The key idea is to incur a small increase in computation time at the clients to gain a significant reduction in the number of messages exchanged between the clients and the servers. The protocol uses the concurrency control on data pages to maintain coherence of index pages. A performance-conscious implementation of the protocol that makes judicious use of version numbers is proposed. We show, through both qualitative and quantitative analysis, the performance benefits of making the distinction between index pages and data pages for the purposes of C&CC. Our simulation studies show that the Relaxed Index Consistency protocol improves system throughput by as much as 15% to 88%, based on the workload.	ICDE	database
3926	ICDE	The Microsoft Relational Engine.	Goetz Graefe	1996	The Microsoft Relational Engine.	ICDE	database
3927	ICDE	Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Total.	Jim Gray,Adam Bosworth,Andrew Layman,Hamid Pirahesh	1996	Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Total.	ICDE	database
3928	ICDE	A Uniform Indexing Scheme for Object-Oriented Databases.	Ehud Gudes	1996	The performance of Object-oriented databases (OODB) is a critical factor hindering their current use. Several indexing schemes have been proposed in the literature for enhancing OODB performance and they are briefly reviewed here. In this paper a new and uniform indexing scheme is proposed. This scheme is based on a single B-tree and combines both the hierarchical and nested indexing schemes \cite{Bertino,Kim}. The uniformity of this scheme enables compact and optimized code dealing with a large range of queries on the one hand, and flexibility in adding and removing indexed paths on the other hand. The performance of the scheme is about the same as existing schemes for single-class, exact match or range queries, and much better for multi-class and other complex queries and update.	ICDE	database
3929	ICDE	Hypermedia Database ``Himotoki'' and Its Applications.	Yoshinori Hara,Kyoji Hirata,Hajime Takano,Shigehito Kawasaki	1996	This paper describes the design concept of a hypermedia database Himotoki and its navigational capabilities. A hypermedia database is a system that integrates hypermedia operations with database models. Advantages are: (a) its structured design can improve authoring and browsing capabilities for large hypermedia applications, (b) nodes and links can be automatically generated under a certain condition, (c) navigational data interface for DBMS is obtained, etc.For providing cost-effective operations as hypermedia databases, we introduce a set-to-set linking and the navigational functions, i.e., media-based navigation, schema navigation, moving hot-spot navigation. These functional capabilities make media contents well-organized so as to improve the human-machine interactive interface. Implemented applications such as Electronic Aquatic Life and Hypermedia Museum demonstrate the usefulness of Himotoki navigational functions and customizability of its architectural design.	ICDE	database
3930	ICDE	Knowledge Discovery from Telecommunication Network Alarm Databases.	Kimmo Hätönen,Mika Klemettinen,Heikki Mannila,Pirjo Ronkainen,Hannu Toivonen	1996	A telecommunication network produces daily large amounts of alarm data. The data contains hidden valuable knowledge about the behavior of the network. This knowledge can be used in filtering redundant alarms, locating problems in, the network, and possibly in predicting severe faults. We describe the TASA (Telecommunication Network Alarm Sequence Analyzer) system for discovering and browsing knowledge from large alarm databases. The system is built on the basis of viewing knowledge discovery as an interactive and iterative process, containing data collection, pattern discovery, rule postprocessing, etc. The system uses a novel framework for locating frequently occurring episodes from sequential data. The TASA system offers a variety of selection and ordering criteria for episodes, and supports iterative retrieval from the discovered knowledge. This means that a large part of the iterative nature of the KDD process can be replaced by iteration in the rule postprocessing stage. The user interface is based on dynamically generated HTML. The system is in experimental use, and the results are encouraging: some of the discovered knowledge is being integrated into the alarm handling software of telecommunication operators.	ICDE	database
3931	ICDE	Improving the Performance of Multi-Dimensional Access Structures Based on k-d-Trees.	Andreas Henrich	1996	In recent years, various k-d-tree based multi-dimensional access structures have been proposed. All these structures share an average bucket utilization of at most ln 2 (about 69.3 %). In this paper we present two algorithms which perform local redistributions of objects to improve the storage utilization of these access structures. We show that under fair conditions a good improvement algorithm can save up to 20 % of space and up to 15 % of query processing time. On the other hand we also show that a local redistribution scheme designed without care, can improve the storage utilization and at the same time worsen the performance of range queries drastically. Furthermore we show the dependencies between split strategies and local redistribution schemes and the general limitations which can be derived from these dependencies.	ICDE	database
3932	ICDE	Mining Knowledge Rules from Databases: A Rough Set Approach.	Xiaohua Hu,Nick Cercone	1996	In this paper, the principle and experimental results of an attribute-oriented rough set approach for knowledge discovery in databases are described. Our method integrates the database operation, rough set theory and machine learning techniques. In our method, we consider the learning procedure consists of two phases: data generalization and data reduction. In data generalization phase, the attribute-oriented induction is performed attribute by attribute using attribute removal and concept ascension, some undesirable attributes to the discovery task are removed and the primitive data is generalized to the desirable level, thus a set of tuples may be generalized to the same generalized tuple, this procedure substantially reduces the computational complexity of the database learning process. Subsequently, in data reduction phase, the rough set method is applied to the generalized relation to find a minimal attribute set relevant to the learning task. The generalized relation is reduced further by removing those attributes which are irrelevant and/or unimportant to the learning task. Finally the tuples in the reduced relation are transformed into different knowledge rules based on different knowledge discovery algorithms. Based upon these principles, a prototype knowledge discovery system DBROUGH has been constructed. In DBROUGH, a variety of knowledge discovery algorithms are incorporated and different kinds of knowledge rules, such as characteristic rules, classification rules, decisions rules, maximal generalized rules can be discovered efficiently and effectively from large databases.	ICDE	database
3933	ICDE	HiTi Graph Model of Topographical Roadmaps in Navigation Systems.	Sungwon Jung,Sakti Pramanik	1996	In navigation systems, a primary task is to compute the minimum cost route from the current location to the destination. One of the major problems for navigation systems is that a significant amount of computation time is required to find a minimum cost path when the topographical road map is large. Since navigation systems are real time systems, it is critical that the path be computed while satisfying a time constraint. In this paper, we propose a new graph model named HiTi (Hierarchical mulTi graph model), for efficiently computing an optimal minimum cost path. Based on HiTi graph model, we propose a new single pair minimum cost path algorithm. We empirically show that our proposed algorithm performs far better than the traditional A* algorithm. Further, we empirically analyze our algorithm by varying both edge cost distribution and hierarchical level number of HiTi graphs.	ICDE	database
3934	ICDE	A Next Generation Industry Multimedia Database System.	Hiroshi Ishikawa,Koki Kato,Miyuki Ono,Naomi Yoshikawa,Kazumi Kubota,Akiko Kondo	1996	New multimedia applications have emerged on top of information infrastructures, such as on-demand services, digital libraries and museums, online shopping, and document management, which require new databases. That is, next-generation database systems must enable users to efficiently and flexibly develop and execute such advanced multimedia applications. We focus on development of a database system which enables flexible and efficient acquisition, storage, access and retrieval, and distribution and presentation of large amounts of heterogeneous media data. We take an approach based on an object-oriented database, which is more suitable for description of media structures and operations than a traditional relational database. And we extend the object-oriented approach by providing temporal and spatial operators, and control of distributing computing and QOS (quality of service). In this paper, we describe a multimedia data model and its efficient implementation.	ICDE	database
3935	ICDE	Refined Triggering Graphs: A Logic-Based Approach to Termination Analysis in an Active Object-Oriented Database.	Anton P. Karadimce,Susan Darling Urban	1996	We present the notion of refined triggering graphs (RTG) for analyzing termination of active rules in object-oriented databases (OODBs). The RTG method consists of mapping the possibility that one active rule can trigger another to the satisfiability of a well-defined logic formula called a triggering formula. The unsatisfiability of the triggering formula is then an indication that the rule triggering possibility is nil. We identify three increasingly more powerful types of triggering formulae and give pointers to the corresponding satisfiability procedures.	ICDE	database
3936	ICDE	Electronic Catalogs - Panel.	Arthur M. Keller,Don Brown,Anna-Lena Neches,Sherif Danish,Daniel Barbará	1996	Electronic Catalogs - Panel.	ICDE	database
3937	ICDE	Towards Eliminating Random I/O in Hash Joins.	Ming-Ling Lo,Chinya V. Ravishankar	1996	The widening performance gap between CPU and disk is significant for hash join performance. Most current hash join methods try to reduce the volume of data transferred between memory and disk. In this paper, we try to reduce hash-join times by reducing random I/O. We study how current algorithms incur random I/O, and propose a new hash join method, Seq+, that converts much of the random I/O to sequential I/O. Seq+ uses a new organization for hash buckets on disk, and larger input and output buffer sizes. We introduce the technique of batch writes to reduce the bucket-write cost, and the concepts of write- and read-groups of hash buckets to reduce the bucket-read cost. We derive a cost model for our method, and present formulas for choosing various algorithm parameters, including input and output buffer sizes. Our performance study shows that the new hash join method performs many times better than current algorithms under various environments. Since our cost functions under-estimate the cost of current algorithms and over-estimate the cost of Seq+, the actual performance gain of Seq+ is likely to be even greater.	ICDE	database
3938	ICDE	DB2 LOBs: The Teenage Years.	Tobin J. Lehman,Patrick Gainer	1996	Previous versions of DB2 Common Server had large objects (LOBs) that were neither large nor functional. Their size was limited to 32,700 bytes and, until recently when support for SUBSTR and CONCAT was added, there was no function available on these objects at all. DB2 LOBs were infants. However, with the latest release of DB2 Common Server, Version 2.1, LOBs have matured considerably, supporting significantly larger sizes and many new language features. To give the reader a feeling for the extent of this new language support, we compare our new SQL LOB language features with that of three other major Relational database competitors: Sybase, Informix and Oracle. Users will find the new DB2 LOBS easy to load and store, easy to search, and easy to integrate into the DB2 user-defined functions (UDFs) and user-defined types (UDTs). In addition, when used in serial mode, the performance of LOB I/O rivals that of file systems and, when used in parallel mode, is a clear winner. DB2 LOBs have now entered the teenage years.	ICDE	database
3939	ICDE	Using Object-Oriented Principles to Optimize Update Propagation to Materialized Views.	Harumi A. Kuno,Elke A. Rundensteiner	1996	View materialization is known to be a valuable technique for performance optimization in relational databases, and much work has been done addressing the problem of consistently maintaining relational views under update operations. However, little progress has been made thus far regarding the topic of view materialization in object-oriented databases (OODBs). In this paper, we demonstrate that there are several significant differences between the relational and object-oriented paradigms that can be exploited when addressing the object-oriented view materialization problem. We can use the subsumption relationships between classes to identify branches of classes to which we do not need to propagate updates. Similarly, we can use encapsulated interfaces combined with the fact that any unique database property is inherited from a single location to provide a ``registration/notification'' service for optimizing incremental view updates. We have successfully implemented all proposed techniques in the MultiView system, which provides updatable materialized classes and virtual schemata on top of the GemStone OODBMS. We also report results from the experimental studies we have run on the MultiView system measuring the impact of various optimization strategies incorporated into our materialization update algorithms.	ICDE	database
3940	ICDE	HierarchyScan: A Hierarchical Similarity Search Algorithm for Databases of Long Sequences.	Chung-Sheng Li,Philip S. Yu,Vittorio Castelli	1996	We present a hierarchical algorithm, HierarchyScan, that efficiently locates one-dimensional subsequences within a collection of sequences of arbitrary length. The subsequences identified by HierarchyScan match a given template pattern in a scale- and phase-independent fashion. The idea is to perform correlation between the stored sequences and the template in the transformed domain hierarchically. Only those subsequences whose maximum correlation value is higher than a predefined threshold will be selected. The performance of this approach is compared to the sequential scanning and an order-of-magnitude speedup is observed.	ICDE	database
3941	ICDE	The Ode Active Database: Trigger Semantics and Implementation.	Daniel F. Lieuwen,Narain H. Gehani,Robert M. Arlein	1996	Triggers are the basic ingredient of active databases. Ode triggers are event-action pairs. An event can be a composite event (i.e., an event composed from other events). Composite events are detected by translating the event specifications into finite state machines. In this paper, we describe the integration and implementation of composite event based triggers into the Ode object database. We focus on implementation details such as the basic trigger events supported, the efficient posting of these events, the handling of transaction-related events, and the integration of triggers into a real database. We also describe the run-time facilities used to support trigger processing and describe some experiences we gained while implementing triggers. We illustrate Ode trigger facilities with a credit card example.	ICDE	database
3942	ICDE	A Distributed Query Processing Strategy Using Placement Dependency.	Chengwen Liu,Hao Chen,Warren Krueger	1996	We present an algorithm to make use of placement dependency information to process distributed queries. Our algorithm first partitions the referenced relations of a given query into a number of non-exclusive subsets such that the fragmented relations within a subset have placement dependency and the join operation(s) associated with the relations in the subset can be locally processed without data transfer. Each subset is associated with a set of sites and can be used to generate an execution plan for the given query by keeping the fragmented relations in the subset fragmented at the sites where they are situated while replicating the other referenced relations at each of the processing sites. Among the alternatives, our algorithm picks the plan that gives the minimum response time. Our experimental results show that our algorithm improves response time significantly.	ICDE	database
3943	ICDE	Are We Moving Toward an Information SuperHighway or a Tower of Babel? The Challenge of Large-Scale Semantic Heterogeneity.	Stuart E. Madnick	1996	The popularity and growth of the Information Super Highway have dramatically increased the number of information sources available for use. Unfortunately, there are significant challenges to be overcome. One particular problem is context interchange, whereby each source of information and potential receiver of that information may operate with a different context, leading to large-scale semantic heterogeneity. A context is the collection of implicit assumptions about the context definition (i.e., meaning) and context characteristics (i.e., quality) of the information. This paper describes various forms of context challenges and examples of potential context mediation services, such as data semantics acquisition, data quality attributes, and evolving semantics and quality, that can mitigate the problem.	ICDE	database
3944	ICDE	ActionWorkflow in Use: Clark County Department of Business License.	Raul Medina-Mora,Kelly W. Cartron	1996	In this paper we present the basic concepts of ActionWorkflow and a study of a successful implementation in Clark County Department of Business License. The Image/Workflow System reengineers a labyrinthine licensing system into simplistic processes that are more customer oriented, yield superior productivity, establish a work-in-progress tracking mechanism, and archive the resulting licensing processes permanently on an unalterable optical storage system.	ICDE	database
3945	ICDE	SQL3 Update.	Jim Melton	1996	The third major generation of the standard for the SQL database language, known as SQL3, is nearing completion. Many significant new features have been added to SQL, both in areas traditionally addressed by SQL and in pursuit of adding object technology to the language. The standard has been partitioned into a number of distinct parts, each of which may progress at its own rate. Publication of SQL3 as a replacement for the current version of the standard, SQL-92, is expected no sooner than 1998.	ICDE	database
3946	ICDE	Performance Analysis of Several Algorithms for Processing Joins between Textual Attributes.	Weiyi Meng,Clement T. Yu,Wei Wang,Naphtali Rishe	1996	Three algorithms for processing joins on attributes of textual type are presented and analyzed in this paper. Since such joins often involve document collections of very large size, it is very important to find efficient algorithms to process them. The three algorithms differ on whether the documents themselves or the inverted files on the documents are used to process the join. Our analysis and the simulation results indicate that the relative performance of these algorithms depends on the input document collections, system characteristics and the input query. For each algorithm, the type of input document collections with which the algorithm is likely to perform well is identified.	ICDE	database
3947	ICDE	A Groupware Benchmark Based on Lotus Notes.	Kenneth Moore,Michelle Peterson	1996	In this paper, we propose a new benchmark for groupware systems. It incorporates elements of previous messaging, text retrieval, and database benchmarks. The benchmark is based on groupware functions found in Lotus Notes, but should be adaptable by any groupware system.	ICDE	database
3948	ICDE	Automating the Assembly of Presentations from Multimedia Databases.	Gultekin Özsoyoglu,Veli Hakkoymaz,Joel Kraft	1996	A multimedia presentation refers to the presentation of multimedia data using output devices such as monitors for text and video, and speakers for audio. Each presentation consists of multimedia segments which are obtained from a multimedia data model. In this paper, we propose to express semantic coherency of a multimedia presentation in terms of presentation inclusion and exclusion constraints that are incorporated into the multimedia data model. Thus, when a user specifies a set of segments for a presentation, the DBMS adds segments into and/or deletes segments from the set in order to satisfy the inclusion and exclusion constraints. To automate the assembly of a presentation with concurrent presentation streams, we also propose presentation organization constraints that are incorporated into the multimedia data model, independent of any presentation. We give two algorithms for automated presentation assembly and discuss their complexity. We discuss the satisfiability of inclusion and exclusion constraints when negation is allowed. And, we briefly describe a prototype system that is being developed for automated presentation assembly.	ICDE	database
3949	ICDE	Auditory Browsing for Acquisition of Information in Cyberspace.	Naoto Oki,Kunio Teramoto,Ken-ichi Okada,Yutaka Matsushita	1996	Today, various novel telecommunication systems have been proposed. The idea of a virtual communication space shared by multiple distributed users via networks, so-called cyberspace, has received considerable communication. In cyberspace, there are tremendously many users, on-line services, and much information, and users have great opportunity to encounter all of these. We think the most serious problem in cyberspace is the great risk that a user might miss a chance to get relevant or important information. In this paper, we propose a strategy for auditory browsing to address this problem, using a spatial sound interface. We implemented VCP (Virtual Cocktail Party), an experimental system for achieving efficient and flexible telecommunication and data retrieval, which takes advantage of human auditory capability. This system can support a number of physically separated users in a single shared sound cyberspace and consists of distributed terminals with a spatial sound interface.	ICDE	database
3950	ICDE	Client-Based Logging for High Performance Distributed Architectures.	Euthimios Panagos,Alexandros Biliris,H. V. Jagadish,Rajeev Rastogi	1996	In this paper, we propose logging and recovery algorithms for distributed architectures that use local disk space to provide transactional facilities locally. Each node has its own log file where all log records for updates to locally cached pages are written. Transaction rollback and node crash recovery are handled exclusively by each node and log files are not merged at any time. Our algorithms do not require any form of time synchronization between nodes and nodes can take checkpoints independently of each other. Finally, our algorithms make possible a new paradigm for distributed transaction management that has the potential to exploit all available resources and improve scalability and performance.	ICDE	database
3951	ICDE	MedMaker: A Mediation System Based on Declarative Specifications.	Yannis Papakonstantinou,Hector Garcia-Molina,Jeffrey D. Ullman	1996	Mediators are used for integration of heterogeneous information sources. We present a system for declaratively specifying mediators. It is targeted for integration of sources with unstructured or semi-structured data and/or sources with changing schemas. We illustrate the main features of the Mediator Specification Language (MSL), show how they facilitate integration, and describe the implementation of the system that interprets the MSL specifications.	ICDE	database
3952	ICDE	A Directory Service for a Federation of CIM Databases with Migrating Objects.	Ajit K. Patankar,Arie Segev,J. George Shanthikumar	1996	We propose a novel directory scheme for a large federation of databases where object migration is in response to manufacturing events. In our directory scheme, objects report their location to a directory server instead of the traditional method of the directory servers polling sites in the network. The directory is distributed among multiple servers to avoid bottleneck during query processing. A distributed Linear Hashing algorithm is proposed for efficiently determining an appropriate server for an object. Finally, a stochastic dynamic programming model is proposed for minimizing the number of database transactions.	ICDE	database
3953	ICDE	Towards the Reverse Engineering of Denormalized Relational Databases.	Jean-Marc Petit,Farouk Toumani,Jean-François Boulicaut,Jacques Kouloumdjian	1996	This paper describes a method to cope with denormalized relational schemas in a database reverse engineering process. We propose two main steps to improve the understanding of data semantics. Firstly we extract inclusion dependencies by analyzing the equi-join queries embedded in application programs and by querying the database extension. Secondly we show how to discover only functional dependencies which influence the way attributes should be restructured. The method is interactive since an expert user has to validate the presumptions on the elicited dependencies. Moreover, a restructuring phase leads to a relational schema in third normal form provided with key dependencies and referential integrity constraints. Finally, we sketch how an Entity-Relationship schema can be derived from such information.	ICDE	database
3954	ICDE	Query Folding.	Xiaolei Qian	1996	Query folding refers to the activity of determining if and how a query can be answered using a given set of resources, which might be materialized views, cached results of previous queries, or queries answerable by other databases. We investigate query folding in the context where queries and resources are conjunctive queries. We develop an exponential-time algorithm that finds all complete or partial foldings, and a polynomial-time algorithm for the subclass of acyclic conjunctive queries. Our results can be applied to query optimization in centralized databases, to query processing in distributed databases, and to query answering in federated databases.	ICDE	database
3955	ICDE	A Hybrid Object Clustering Strategy for Large Knowledge-Based Systems.	Arun Ramanujapuram,Jim E. Greer	1996	Object bases underlying knowledge-based applications tend to be complex and require management. This research aims at improving the performance of object bases underlying a class of large knowledge-based systems that utilize object-oriented technology to engineer the knowledge base. In this paper, a hybrid clustering strategy that beneficially combines semantic clustering and iterative graph-paritioning techniques has been developed and evaluated for use in knowledge bases storing information in the form of object graphs. It is demonstrated via experimentation that such a technique is useful and feasible in realistic object bases. A semantic specification mechanism similar to placement trees has been developed for specifying the clustering. The workload and the nature of object graphs in knowledge bases differ significantly from those present in conventional object-oriented databases. Therefore, the evaluation has been performed by building a new benchmark called the Granularity Benchmark. A segmented storage scheme for the knowledge base using large object storage mechanisms of existing storage managers is also examined.	ICDE	database
3956	ICDE	Evaluation and Optimization of the LIVING IN A LATTICE Rule Language.	Holger Riedel,Andreas Heuer	1996	We introduce an evaluation technique for a declarative OODB query language. The query language is rule-based and can be evaluated and optimized using an appropriate object algebra. We introduce a new framework which uses concepts of the object-oriented data model to define adequate accesses to the database. Additionally, the problems according to the evaluation of recursive queries are discussed.	ICDE	database
3957	ICDE	Complex Query Decorrelation.	Praveen Seshadri,Hamid Pirahesh,T. Y. Cliff Leung	1996	Complex queries used in decision support applications use multiple correlated subqueries and table expressions, possibly across several levels of nesting. It is usually inefficient to directly execute a correlated query; consequently, algorithms have been proposed to decorrelate the query, i.e., to eliminate the correlation by rewriting the query. This paper explains the issues involved in decorrelation, and surveys existing algorithms. It presents an efficient and flexible algorithm called magic decorrelation which is superior to existing algorithms both in terms of the generality of application, and the efficiency of the rewritten query. The algorithm is described in the context of its implementation in the Starburst Extensible Database System, and its performance is compared with other decorrelation techniques. The paper also explains why magic decorrelation is not merely applicable, but crucial in a parallel database system.	ICDE	database
3958	ICDE	Approximate Queries and Representations for Large Data Sequences.	Hagit Shatkay,Stanley B. Zdonik	1996	Many new database application domains such as experimental sciences and medicine are characterized by large sequences as their main form of data. Using approximate representation can significantly reduce the required storage and search space. A good choice of representation, can support a broad new class of approximate queries, needed in these domains. These queries are concerned with application-dependent features of the data as opposed to the actual sampled points. We introduce a new notion of generalized approximate queries and a general divide and conquer approach that supports them. This approach uses families of real-valued functions as an approximate representation. We present an algorithm for realizing our technique, and the results of applying it to medical cardiology data.	ICDE	database
3959	ICDE	DSDT: Durable Scripts Containing Database Transactions.	Betty Salzberg,Dimitri Tombroff	1996	DSDT is a proposed method for creating durable scripts which contain short ACID transactions as components. Workflow scripts are an example. The context of the script is made durable by writing a log record whenever an event occurs which cannot be replayed. Log checkpoints are used to minimize recovery time. DSDT can be written in stand-alone mode communicating with DBMSs by transactional remote procedure calls and maintaining its own logging system or it can be made part of a DBMS by modifying the DBMS transaction manager source code. DSDT provides a panic button (signal-exit) and the ability to specify what action should be taken on restart after system failure. The programmer can also specify actions such as compensation transactions to be taken after another signal (signal-cancel) arrives. DSDT enables most extended transaction models to be expressed in scripts modulo the guarantees of compensation. Recovery after system failure is shown to be correct.	ICDE	database
3960	ICDE	Workflow and Data Management in InConcert.	Sunil K. Sarin	1996	InConcert is an object-oriented client-server workflow management system. An overview is provided of the functionality of InConcert and how it is implemented on an underlying relational database management system. Data management issues in supporting distributed workflow are briefly reviewed.	ICDE	database
3961	ICDE	What's in a WWW Link? - Panel.	Amit P. Sheth,Robert Meersman,Erich J. Neuhold,Calton Pu,V. S. Subrahmanian	1996	What's in a WWW Link? - Panel.	ICDE	database
3962	ICDE	A Graph-Theoretic Approach to Indexing in Object-Oriented Databases.	Boris Shidlovsky,Elisa Bertino	1996	A graph-theoretic approach to the path indexing problem is proposed. We represent the indexing relationships supported by indices allocated in the classes in the path in the form of a directed graph. All the previous approaches directly fit into the scheme and form a hierarchy of complexity with respect to the time required for selection of the optimal index configuration. Based on the general scheme, we develop a new approach to the path indexing problem exploiting the notion of visibility graph. We introduce a generalized nested-inherited index, give algorithms for retrieval and update operations and compare the behavior of the new structure with previous approaches.	ICDE	database
3963	ICDE	Data Replication in Mariposa.	Jeff Sidell,Paul M. Aoki,Adam Sah,Carl Staelin,Michael Stonebraker,Andrew Yu	1996	The Mariposa distributed data manager uses an economic model for managing the allocation of both storage objects and queries to servers. We present extensions to the economic model which support replica management, as well as our mechanisms for propagating updates among replicas. We show how our replica control mechanism can be used to provide consistent, although potentially stale, views of data across many machines without expensive per-transaction synchronization. We present a rule-based conflict resolution mechanism, which can be used to enhance traditional time-stamp serialization. We discuss the effects of our replica system on query processing for both read-only and read-write queries. We further demonstrate how the replication model and mechanisms naturally support name service in Mariposa.	ICDE	database
3964	ICDE	Synthesizing Distributed Constrained Events from Transactional Workflow.	Munindar P. Singh	1996	Workflows are the semantically appropriate composite activities in heterogeneous computing environments. Such environments typically comprise a great diversity of locally autonomous databases, applications, and interfaces. Much good research has focused on the semantics of workflows, and how to capture them in different extended transaction models. Here we address the complementary issues pertaining to how workflows may be declaratively specified, and how distributed constraints may be derived from those specifications to enable local control, thus obviating a centralized scheduler. Previous approaches to this problem were limited and often lacked a formal semantics.	ICDE	database
3965	ICDE	Using Partial Differencing for Efficient Monitoring of Deferred Complex Rule Conditions.	Martin Sköld,Tore Risch	1996	Presents a difference calculus for determining changes to rule conditions in an active DBMS. The calculus has been used for implementing an algorithm to efficiently monitor rules with complex conditions. The calculus is based on partial differencing of queries derived from rule conditions. For each rule condition, several partially differentiated queries are generated that each considers changes to a single base relation or view that the condition depends on. The calculus considers both insertions and deletions. The algorithm is optimized for deferred rule condition monitoring in transactions with few updates. The calculus allows us to optimize both space and time. Space optimization is achieved since the calculus and the algorithm does not presuppose materialization of monitored conditions to find its previous state. This is achieved by using a breadth-first, bottom-up propagation algorithm and by calculating previous states by doing a logical rollback. Time optimization is achieved through incremental evaluation techniques. The algorithm has been implemented and a performance study is presented at the end of the paper.	ICDE	database
3966	ICDE	Consistency and Performance of Concurrent Interactive Database Applications.	Konstantinos Stathatos,Stephen Kelley,Nick Roussopoulos,John S. Baras	1996	In many modern database applications, there is an emerging need for interactive environments where users directly manipulate the contents of the database. Graphical user interfaces (GUIs) display images of the database which must reflect a consistent up--to--date state of the data with minimum perceivable delay to the user. Moreover, the possibility of several applications concurrently displaying different views of the same database increases the overall system complexity. In this paper, we show how design, performance and concurrency issues can be addressed by adapting existing database techniques. We propose the use of suitable display schemas whose instances compose active views of the database, an extended client caching scheme which is expected to yield significant performance benefits and a locking mechanism that maintains consistency between the GUIs and the database.	ICDE	database
3967	ICDE	High Availability in Clustered Multimedia Servers.	Renu Tewari,Daniel M. Dias,Rajat Mukherjee,Harrick M. Vin	1996	Clustered multimedia servers, consisting of interconnected nodes and disks, have been proposed for large scale servers, that are capable of supporting multiple concurrent streams which access the video objects stored in the server. As the number of disks and nodes in the cluster increases, so does the probability of a failure. With data striped across all disks in a cluster, the failure of a single disk or node, results in the disruption of many or all streams in the system. Guaranteeing high availability in such a cluster becomes a primary requirement, to ensure continuous service. In this paper, we study mirroring and software RAID schemes with different placement strategies, that guarantee high availability in the event of disk and node failures, while satisfying the real-time requirements of the streams. We examine various declustering techniques for spreading the redundant information across disks and nodes and show that random declustering has good real-time performance. Finally, we compare the overall cost per stream for different system configurations. We derive the parameter space where mirroring and software RAID apply, and determine optimal parity group sizes.	ICDE	database
3968	ICDE	Delta-Sets for Optimized Reactive Adaptive Playout Management in Distributed Multimedia Database Systems.	Heiko Thimm,Wolfgang Klas	1996	A novel database system service called playout management service which performs multimedia presentations was proposed recently. In distributed multimedia database systems without end-to-end guarantees, such a playout management service faces the potential problem that system performance can become insufficient when realizing a stored presentation. This problem can be overcome by making the playout management service reactive such that it balances the data amount to be fetched from a remote multimedia database with the system performance available. For the users this means that, a running presentation is adapted by the playout management service. In this paper, we propose the concept of delta-set to adapt the execution of arbitrary multimedia presentations in an optimized way. We show a heuristic scheme to identify the most adequate delta-set with respect to (1) the actual system state, (2) the user preferences, and (3) the specific properties of multimedia presentations.	ICDE	database
3969	ICDE	PICSDesk: A Case Study on Business Process Re-engineering.	Manolis M. Tsangaris,Madhur Kohli,Shamim A. Naqvi,Richard Nunziata,Yatin P. Saraiya	1996	Presents first-hand experiences from an actual re-engineering project. Business re-engineering is a process affecting not only the software system involved, but the underlying business model as well. Indeed, it is the changed business model along with the new technologies that determine the design of the new system. This paper is a walkthrough of the design of PICSDESK, a prototype incorporating some modern technologies to support the old business model of its predecessor and its evolution to a new business model. PICSDESK may be thought of as an example of a new breed of inventory control systems.	ICDE	database
3970	ICDE	Applying a Flexible OODBMS-IRS-Coupling for Structured Document Handling.	Marc Volz,Karl Aberer,Klemens Böhm	1996	In document management systems it is desirable to provide content-based access to documents going beyond regular expression search in addition to access based on structural characteristics or associated attributes. We present a new approach for coupling OODBMSs (Object Oriented Database Management Systems) and IRSs (Information Retrieval Systems) that provides enhanced flexibility and functionality as compared to coupling approaches reported from the literature. Our approach allows to decide freely to which document collections, that are used as retrieval context, document objects belong, which text contents they provide for retrieval and how they derive their associated retrieval values, either directly from the retrieval machine or from the values of related objects. Especially, we show how in this approach different strategies can be applied to hierarchically structured documents, possibly avoiding redundancy and IRS or OODBMS peculiarities. Content-based and structural queries can be freely combined within the OODBMS query language.	ICDE	database
3971	ICDE	The Mentor Project: Steps Toward Enterprise-Wide Workflow Management.	Dirk Wodtke,Jeanine Weißenfels,Gerhard Weikum,Angelika Kotz Dittrich	1996	Enterprise-wide workflow management where workflows may span multiple organizational units require particular consideration of scalability, heterogeneity, and availability issues. The Mentor project which is introduced in this paper aims to reconcile a rigorous workflow specification method with a distributed middleware architecture as a step towards enterprise-wide solutions. The project uses the formalism of state and activity charts and a commercial tool, Statemate, for workflow specification. A first prototype of Mentor has been built which allows executing specifications in a distributed manner A major contribution of this paper is the method for transforming a centralized state chart spectfication into a form that is amenable to a distributed execution and to incorporate the necessary synchronization between different processing entities. Fault tolerance issues are addressed by coupling Mentor with the Tuxedo TP monitor.	ICDE	database
3972	ICDE	Representing Retroactive and Proactive Versions in Bi-Temporal Databases.	Jongho Won,Ramez Elmasri	1996	Bi-Temporal databases allow users to record retroactive (past) and proactive (future planned) versions of an entity, and to retrieve the appropriate versiosns for bi-temporal queries that involve both valid-time and transaction-time. Currently used timestamp representations are mainly for either valid-time or transaction-time databases. In this paper, we first categorize the types of problems that can occur in existing models. These are (1) ambiguity, (2) priority specification, and (3) lost information. We then propose a 2TDB model that allows both retroactive and proactive versions, overcomes the identified problems, and permits the correction of recorded facts.	ICDE	database
3973	ICDE	Energy-Efficient Caching for Wireless Mobile Computing.	Kun-Lung Wu,Philip S. Yu,Ming-Syan Chen	1996	Caching can reduce the bandwidth requirement in a mobile computing environment. However, due to battery power limitations, a wireless mobile computer may often be forced to operate in a doze or even totally disconnected mode. As a result, the mobile computer may miss some cache invalidation reports broadcasted by a server, forcing it to discard the entire cache contents after waking up. In this paper, we present an energy-efficient cache invalidation method, called GCORE, that allows a mobile computer to operate in a disconnected mode to save battery while still retaining most of the caching benefits after a reconnection. We present an efficient implementation of GCORE and conduct simulations to evaluate its caching effectiveness. The results show that GCORE can substantially improve mobile caching by reducing the communication bandwidth (or energy consumption) for query processing.	ICDE	database
3974	ICDE	Similarity Indexing with the SS-tree.	David A. White,Ramesh Jain	1996	Efficient indexing of high dimensional feature vectors is important to allow visual information systems and a number other applications to scale up to large databases. In this paper, we define this problem as similarity indexing and describe the fundamental types of similarity queries that we believe should be supported. We also propose a new dynamic structure for similarity indexing called the similarity search tree or SS-tree. In nearly every test we performed on high dimensional data, we found that this structure performed better than the R*-tree. Our tests also show that the SS-tree is much better suited for approximate queries than the R*-tree.	ICDE	database
3975	ICDE	Search and Ranking Algorithms for Locating Resources on the World Wide Web.	Budi Yuwono,Dik Lun Lee	1996	Applying information retrieval techniques to the World Wide Web (WWW) environment is a challenge, mostly because of its hypertext/hypermedia nature and the richness of the meta-information it provides. We present four keyword-based search and ranking algorithms for locating relevant WWW pages with respect to user queries. The first algorithm, Boolean Spreading Activation, extends the notion of word occurrence in the Boolean retrieval model by propagating the occurrence of a query word in a page to other pages linked to it. The second algorithm, Most-cited, uses the number of citing hyperlinks between potentially relevant WWW pages to increase the relevance scores of the referenced pages over the referencing pages. The third algorithm, TFxIDF vector space model, is based on word distribution statistics. The last algorithm, Vector Spreading Activation, combines TFxIDF with the spreading activation model. We conducted an experiment to evaluate the retrieval effectiveness of these algorithms. From the results of the experiment, we draw conclusions regarding the nature of the WWW environment with respect to document ranking strategies.	ICDE	database
3976	ICDE	Transaction Management for a Distributed Object Storage System WAKASHI - Design, Implementation and Performance.	Ge Yu,Kunihiko Kaneko,Guangyi Bai,Akifumi Makinouchi	1996	This paper presents the transaction management in a high performance distributed object storage system WAKASHI. Unlike other systems that use centralized client/server architecture and offer conventional buffer management for distributed persistent object management, WAKASHI is based on symmetric peer-peer architecture and employs memory-mapping and distributed shared virtual memory techniques. Several novel techniques on transaction management for WAKASHI are developed. First, a multi-threaded transaction manager offers ``multi-threaded connection'' so that data control and transaction operations can be performed in parallel manner. Secondly, a concurrency control mechanism supports transparent page-level locks to reduce the complexity of user programs and locking overhead. Thirdly, a ``compact commit'' method is proposed to minimize the communication cost by reducing the amount of data and the number of connections. Fourthly, a redo-only recovery method is implemented by ``shadowed cache'' method to minimize the logging cost, and to allow fast recovery and system restart. Moreover, the system offers ``hierarchical'' control to support nested transactions. A performance evaluation by the OO7 benchmark is presented, as well.	ICDE	database
3977	SIGMOD Conference	A Super Scalar Sort Algorithm for RISC Processors.	Ramesh C. Agarwal	1996	The compare and branch sequences required in a traditional sort algorithm can not efficiently exploit multiple execution units present in currently available high performance RISC processors. This is because of the long latency of the compare instructions and the sequential algorithm used in sorting. With the increased level of integration on a chip, this trend is expected to continue. We have developed new sort algorithms which eliminate almost all the compares, provide functional parallelism which can be exploited by multiple execution units, significantly reduce the number of passes through keys, and improve data locality. These new algorithms outperform traditional sort algorithms by a large factor.For the Datamation disk to disk sort benchmark (one million 100-byte records), at SIGMOD'94, Chris Nyberg et al presented several new performance records using DEC alpha processor based systems.We have implemented the Datamation sort benchmark using our new sort algorithm on a desktop IBM RS/6000 model 39H (66.6 MHz) with 8 IBM SSA 7133 disk drives (total cost $73K). The total elapsed time for the 100 MB sort was 5.1 seconds (vs the old uni-processor record of 9.1 seconds). We have also established a new price performance record (0.2&cent; vs the old record of 0.9&cent;, as the cost of the sort). The entire sort processing was overlapped with I/O. During the read phase, we achieved a sustained BW of 47 MB/sec and during the write phase, we achieved a sustained BW of 39 MB/sec. Key extraction and sorting of one million 10-byte keys took only 0.6 second of CPU time. The rest of the CPU time was used in moving records, servicing I/O, and other overheads.Algorithmic details leading to this level of performance are described in this paper. A detailed analysis of the CPU time spent during various phases of the sort algorithm and I/O is also provided.	SIGMOD Conferen	database
3978	SIGMOD Conference	Two Techniques for On-Line Index Modification in Shared Nothing Parallel Databases.	Kiran J. Achyutuni,Edward Omiecinski,Shamkant B. Navathe	1996	Whenever data is moved across nodes in the parallel database system, the indexes need to be modified too. Index modification overhead can be quite severe because there can be a large number of indexes on a relation. In this paper, we study two alternatives to index modification, namely OAT (One-At-a-Time page movement) and BULK (bulk page movement). OAT and BULK are two extremes on the spectrum of the granularity of data movement. OAT and BULK differ in two respects: first, OAT uses very little additional disk space (at most one extra page), whereas BULK uses a large amount of disk space. Second, BULK uses sequential prefetch I/O to optimize on the number of I/Os during index modification, while OAT does not. Using an experimental testbed, we show that BULK is an order of magnitude faster than OAT. In terms of the impact on transaction performance during reorganization, BULK and OAT perform differently: when the number of indexes to be modified is either one or two, OAT has a lesser impact on the transaction performance degradation. However, when the number of indexes is greater than two, both techniques have the same impact on transaction performance.	SIGMOD Conferen	database
3979	SIGMOD Conference	Query Caching and Optimization in Distributed Mediator Systems.	Sibel Adali,K. Selçuk Candan,Yannis Papakonstantinou,V. S. Subrahmanian	1996	Query processing and optimization in mediator systems that access distributed non-proprietary sources pose many novel problems. Cost-based query optimization is hard because the mediator does not have access to source statistics information and furthermore it may not be easy to model the source's performance. At the same time, querying remote sources may be very expensive because of high connection overhead, long computation time, financial charges, and temporary unavailability. We propose a cost-based optimization technique that caches statistics of actual calls to the sources and consequently estimates the cost of the possible execution plans based on the statistics cache. We investigate issues pertaining to the design of the statistics cache and experimentally analyze various tradeoffs. We also present a query result caching mechanism that allows us to effectively use results of prior queries when the source is not readily available. We employ the novel invariants mechanism, which shows how semantic information about data sources may be used to discover cached query results of interest.	SIGMOD Conferen	database
3980	SIGMOD Conference	Data Mining Techniques.	Jiawei Han	1996	Data mining, or knowledge discovery in databases, has been popularly recognized as an important research issue with broad applications. We provide a comprehensive survey, in database perspective, on the data mining techniques developed recently. Several major kinds of data mining methods, including generalization, characterization, classification, clustering, association, evolution, pattern matching, data visualization, and meta-rule guided mining, will be reviewed. Techniques for mining knowledge in different kinds of databases, including relational, transaction, object-oriented, spatial, and active databases, as well as global information systems, will be examined. Potential data mining applications and some research issues will also be discussed.	SIGMOD Conferen	database
3981	SIGMOD Conference	Repository System Engineering.	Philip A. Bernstein	1996	Repository System Engineering.	SIGMOD Conferen	database
3982	SIGMOD Conference	BeSS: Storage Support for Interactive Visualization Systems.	Alexandros Biliris,Thomas A. Funkhouser,William O'Connell,Euthimios Panagos	1996	BeSS: Storage Support for Interactive Visualization Systems.	SIGMOD Conferen	database
3983	SIGMOD Conference	Data Access for the Masses through OLE DB.	José A. Blakeley	1996	This paper presents an overview of OLE DB, a set of interfaces being developed at Microsoft whose goal is to enable applications to have uniform access to data stored in DBMS and non-DBMS information containers. Applications will be able to take advantage of the benefits of database technology without having to transfer data from its place of origin to a DBMS. Our approach consists of defining an open, extensible Collection of interfaces that factor and encapsulate orthogonal, reusable portions of DBMS functionality. These interfaces define the boundaries of DBMS components such as record containers, query processors, and transaction coordinators that enable uniform, transactional access to data among such components. The proposed interfaces extend Microsoft's OLE/COM object services framework with database functionality, hence these interfaces are collectively referred to as OLE DB. The OLE DB functional areas include data access and updates (rowsets), query processing, schema information, notifications, transactions, security, and access to remote data. In a sense, OLE DB represents an effort to bring database technology to the masses. This paper presents an overview of the OLE DB approach and its areas of componentization.	SIGMOD Conferen	database
3984	SIGMOD Conference	An Open Storage System for Abstract Objects.	Stephen Blott,Lukas Relly,Hans-Jörg Schek	1996	An Open Storage System for Abstract Objects.	SIGMOD Conferen	database
3985	SIGMOD Conference	HyperStorM - Administering Structured Documents Using Object-Oriented Database Technology.	Klemens Böhm,Karl Aberer	1996	HyperStorM - Administering Structured Documents Using Object-Oriented Database Technology.	SIGMOD Conferen	database
3986	SIGMOD Conference	Goal-Oriented Buffer Management Revisited.	Kurt P. Brown,Michael J. Carey,Miron Livny	1996	In this paper we revisit the problem of achieving multi-class workload response time goals by automatically adjusting the buffer memory allocations of each workload class. We discuss the virtues and limitations of previous work with respect to a set of criteria we lay out for judging the success of any goal-oriented resource allocation algorithm. We then introduce the concept of hit rate concavity and develop a new goal-oriented buffer allocation algorithm, called Class Fencing, that is based on this concept. Exploiting the notion of hit rate concavity results in an algorithm that not only is as accurate and stable as our previous work, but also more responsive, more robust, and simpler to implement.	SIGMOD Conferen	database
3987	SIGMOD Conference	A Query Language and Optimization Techniques for Unstructured Data.	Peter Buneman,Susan B. Davidson,Gerd G. Hillebrand,Dan Suciu	1996	A new kind of data model has recently emerged in which the database is not constrained by a conventional schema. Systems like ACeDB, which has become very popular with biologists, and the recent Tsimmis proposal for data integration organize data in tree-like structures whose components can be used equally well to represent sets and tuples. Such structures allow great flexibility y in data representation.What query language is appropriate for such structures? Here we propose a simple language UnQL for querying data organized as a rooted, edge-labeled graph. In this model, relational data may be represented as fixed-depth trees, and on such trees UnQL is equivalent to the relational algebra. The novelty of UnQL consists in its programming constructs for arbitrarily deep data and for cyclic structures. While strictly more powerful than query languages with path expressions like XSQL, UnQL can still be efficiently evaluated. We describe new optimization techniques for the deep or vertical dimension of UnQL queries. Furthermore, we show that known optimization techniques for operators on flat relations apply to the horizontal dimension of UnQL.	SIGMOD Conferen	database
3988	SIGMOD Conference	Optimizing Queries over Multimedia Repositories.	Surajit Chaudhuri,Luis Gravano	1996	Repositories of multimedia objects having multiple types of attributes (e.g., image, text) are becoming increasingly common. A selection on these attributes will typically produce not just a set of objects, as in the traditional relational query model (filtering), but also a grade of match associated with each object, indicating how well the object matches the selection condition (ranking). Also, multimedia repositories may allow access to the attributes of each object only through indexes. We investigate how to optimize the processing of queries over multimedia repositories. A key issue is the choice of the indexes used to search the repository. We define an execution space that is search-minimal, i.e., the set of indexes searched is minimal. Although the general problem of picking an optimal plan in the search-minimal execution space is NP-hard, we solve the problem efficiently when the predicates in the query are independent. We also show that the problem of optimizing queries that ask for a few top-ranked objects can be viewed, in many cases, as that of evaluating selection conditions. Thus, both problems can be viewed together as an extended filtering problem.	SIGMOD Conferen	database
3989	SIGMOD Conference	Change Detection in Hierarchically Structured Information.	Sudarshan S. Chawathe,Anand Rajaraman,Hector Garcia-Molina,Jennifer Widom	1996	Detecting and representing changes to data is important for active databases, data warehousing, view maintenance, and version and configuration management. Most previous work in change management has dealt with flat-file and relational data; we focus on hierarchically structured data. Since in many cases changes must be computed from old and new versions of the data, we define the hierarchical change detection problem as the problem of finding a minimum-cost edit script that transforms one data tree to another, and we present efficient algorithms for computing such an edit script. Our algorithms make use of some key domain characteristics to achieve substantially better performance than previous, general-purpose algorithms. We study the performance of our algorithms both analytically and empirically, and we describe the application of our techniques to hierarchically structured documents.	SIGMOD Conferen	database
3990	SIGMOD Conference	Rule Languages and Internal Algebras for Rule-Based Optimizers.	Mitch Cherniack,Stanley B. Zdonik	1996	Rule-based optimizers and optimizer generators use rules to specify query transformations. Rules act directly on query representations, which typically are based on query algebras. But most algebras complicate rule formulation, and rules over these algebras must often resort to calling to externally defined bodies of code. Code makes rules difficult to formulate, prove correct and reason about, and therefore compromises the effectiveness of rule-based systems.In this paper we present KOLA: a combinator-based algebra designed to simplify rule formulation. KOLA is not a user language, and KOLA's variable-free queries are difficult for humans to read. But KOLA is an effective internal algebra because its combinator-style makes queries manipulable and structurally revealing. As a result, rules over KOLA queries are easily expressed without the need for supplemental code. We illustrate this point, first by showing some transformations that despite their simplicity, require head and body routines when expressed over algebras that include variables. We show that these transformations are expressible without supplemental routines in KOLA. We then show complex transformations of a class of nested queries expressed over KOLA. Nested query optimization, while having been studied before, have seriously challenged the rule-based paradigm.	SIGMOD Conferen	database
3991	SIGMOD Conference	Prospector: A Content-Based Multimedia Server for Massively Parallel Architectures.	S. Choo,William O'Connell,G. Linderman,H. Chen,K. Ganapathi,Alexandros Biliris,Euthimios Panagos,David Schrader	1996	The Prospector Multimedia Object Manager prototype is a general-purpose content analysis multimedia server designed for massively parallel processor environments. Prospector defines and manipulates user defined functions which are invoked in parallel to analyze/manipulate the contents of multimedia objects. Several computationally intensive applications of this technology based on large persistent datasets include: fingerprint matching, signature verification, face recognition, and speech recognition/translation [OIS96].	SIGMOD Conferen	database
3992	SIGMOD Conference	Evaluating Queries with Generalized Path Expressions.	Vassilis Christophides,Sophie Cluet,Guido Moerkotte	1996	In the past few years, query languages featuring generalized path expressions have been proposed. These languages allow the interrogation of both data and structure. They are powerful and essential for a number of applications. However, until now, their evaluation has relied on a rather naive and inefficient algorithm.In this paper, we extend an object algebra with two new operators and present some interesting rewriting techniques for queries featuring generalized path expressions. We also show how a query optimizer can integrate the new techniques.	SIGMOD Conferen	database
3993	SIGMOD Conference	Algorithms for Deferred View Maintenance.	Latha S. Colby,Timothy Griffin,Leonid Libkin,Inderpal Singh Mumick,Howard Trickey	1996	Materialized views and view maintenance are important for data warehouses, retailing, banking, and billing applications. We consider two related view maintenance problems: 1) how to maintain views after the base tables have already been modified, and 2) how to minimize the time for which the view is inaccessible during maintenance.Typically, a view is maintained immediately, as a part of the transaction that updates the base tables. Immediate maintenance imposes a significant overhead on update transactions that cannot be tolerated in many applications. In contrast, deferred maintenance allows a view to become inconsistent with its definition. A refresh operation is used to reestablish consistency. We present new algorithms to incrementally refresh a view during deferred maintenance. Our algorithms avoid a state bug that has artificially limited techniques previously used for deferred maintenance.Incremental deferred view maintenance requires auxiliary tables that contain information recorded since the last view refresh. We present three scenarios for the use of auxiliary tables and show how these impact per-transaction overhead and view refresh time. Each scenario is described by an invariant that is required to hold in all database states. We then show that, with the proper choice of auxiliary tables, it is possible to lower both per-transaction overhead and view refresh time.	SIGMOD Conferen	database
3994	SIGMOD Conference	Semi-automatic, Self-adaptive Control of Garbage Collection Rates in Object Databases.	Jonathan E. Cook,Artur Klauser,Alexander L. Wolf,Benjamin G. Zorn	1996	A fundamental problem in automating object database storage reclamation is determining how often to perform garbage collection. We show that the choice of collection rate can have a significant impact on application performance and that the best rate depends on the dynamic behavior of the application, tempered by the particular performance goals of the user. We describe two semi-automatic, self-adaptive policies for controlling collection rate that we have developed to address the problem. Using trace-driven simulations, we evaluate the performance of the policies on a test database application that demonstrates two distinct reclustering behaviors. Our results show that the policies are effective at achieving user-specified levels of I/O operations and database garbage percentage. We also investigate the sensitivity of the policies over a range of object connectivities. The evaluation demonstrates that semi-automatic, self-adaptive policies are a practical means for flexibly controlling garbage collection rate.	SIGMOD Conferen	database
3995	SIGMOD Conference	METU Interoperable Database System.	Asuman Dogac,Ugur Halici,Ebru Kilic,Gökhan Özhan,Fatma Ozcan,Sena Nural,Cevdet Dengi,Sema Mancuhan,Ismailcem Budak Arpinar,Pinar Koksal,Cem Evrendilek	1996	METU Interoperable Database System.	SIGMOD Conferen	database
3996	SIGMOD Conference	Structures for Manipulating Proposed Updates in Object-Oriented Databases.	Michael Doherty,Richard Hull,Mohammed Rupawalla	1996	Support for virtual states and deltas between them is useful for a variety of database applications, including hypothetical database access, version management, simulation, and active databases. The Heraclitus paradigm elevates delta values to be first-class citizens in database programming languages, so that they can be explicitly created, accessed and manipulated.A fundamental issue concerns the trade-off between the accuracy or robustness of a form of delta representation, and the ease of access and manipulation of that form. At one end of the spectrum, code-blocks could be used to represent delta values, resulting in a more accurate capture of the intended meaning of a proposed update, at the cost of more expensive access and manipulation. In the context of object-oriented databases, another point on the spectrum is attribute-granularity deltas which store the net changes to each modified attribute value of modified objects.This paper introduces a comprehensive framework for specifying a broad array of forms for representing deltas for complex value types (tuple, set, bag, list, o-set and dictionary). In general, the granularity of such deltas can be arbitrarily deep within the complex value structure. Applications of this framework in connection with hypothetical access to, and merging of, proposed updates are discussed.	SIGMOD Conferen	database
3997	SIGMOD Conference	The Ins and Outs (and Everthing in Between) of Data Warehousing.	Phillip M. Fernandez,Donovan A. Schneider	1996	The Ins and Outs (and Everthing in Between) of Data Warehousing.	SIGMOD Conferen	database
3998	SIGMOD Conference	Performance Tradeoffs for Client-Server Query Processing.	Michael J. Franklin,Björn Þór Jónsson,Donald Kossmann	1996	The construction of high-performance database systems that combine the best aspects of the relational and object-oriented approaches requires the design of client-server architectures that can fully exploit client and server resources in a flexible manner. The two predominant paradigms for client-server query execution are data-shipping and query-shipping We first define these policies in terms of the restrictions they place on operator site selection during query optimization. We then investigate the performance tradeoffs between them for bulk query processing. While each strategy has advantages, neither one on its own is efficient across a wide range of circumstances. We describe and evaluate a more flexible policy called hybrid-shipping, which can execute queries at clients, servers, or any combination of the two. Hybrid-shipping is shown to at least match the best of the two pure policies, and in some situations, to perform better than both. The implementation of hybrid-shipping raises a number of difficult problems for query optimization. We describe an initial investigation into the use of a 2-step query optimization strategy as a way of addressing these issues.	SIGMOD Conferen	database
3999	SIGMOD Conference	Data Mining Using Two-Dimensional Optimized Accociation Rules: Scheme, Algorithms, and Visualization.	Takeshi Fukuda,Yasuhiko Morimoto,Shinichi Morishita,Takeshi Tokuyama	1996	We discuss data mining based on association rules for two numeric attributes and one Boolean attribute. For example, in a database of bank customers, Age and Balance are two numeric attributes, and CardLoan is a Boolean attribute. Taking the pair (Age, Balance) as a point in two-dimensional space, we consider an association rule of the form((Age, Balance) &isin; P) &rArr; (CardLoan = Yes),which implies that bank customers whose ages and balances fall in a planar region P tend to use card loan with a high probability. We consider two classes of regions, rectangles and admissible (i.e. connected and x-monotone) regions. For each class, we propose efficient algorithms for computing the regions that give optimal association rules for gain, support, and confidence, respectively. We have implemented the algorithms for admissible regions, and constructed a system for visualizing the rules.	SIGMOD Conferen	database
4000	SIGMOD Conference	SONAR: System for Optimized Numeric AssociationRules.	Takeshi Fukuda,Yasuhiko Morimoto,Shinichi Morishita,Takeshi Tokuyama	1996	SONAR: System for Optimized Numeric AssociationRules.	SIGMOD Conferen	database
4001	SIGMOD Conference	Is GUI Programming a Database Research Problem?	Nita Goyal,Charles Hoch,Ravi Krishnamurthy,Brian Meckler,Michael Suckow	1996	Programming nontrivial GUI applications is currently an arduous task. Just as the use of a declarative language simplified the programming of database applications, we ask whether we can do the same for GUI programming? Can we then import a large body of knowledge from database research? We answer these questions by describing our experience in building nontrivial GUI applications initially using C++ programming and subsequently using Logic++, a higher order Horn clause logic language on complex objects with object-oriented features. We abstract a GUI application as a set of event handlers. Each event handler can be conceptualized as a transition from the old screen/program state to a new screen/program state. We use a data centric view of the screen/program state (i.e., every entity on the screen corresponds to proxy datum in the program) and express each event handler as a query dependent update, albeit a complicated one. To express such complicated updates we use Logic++. The proxy data are expressed as derived views that are materialized on the screen. Therefore, the system must be active in maintaining these materialized views. Consequently, each event handler is conceptually an update followed by a fixpoint computation of the proxy data. Based on our experience in building the GUI system, we observe that many database techniques such as view maintenance, active DB, concurrency control, recovery, optimization as well as language concepts such as higher order logic are useful in the context of GUI programming.	SIGMOD Conferen	database
4002	SIGMOD Conference	Spatial Hash-Joins.	Ming-Ling Lo,Chinya V. Ravishankar	1996	We examine how to apply the hash-join paradigm to spatial joins, and define a new framework for spatial hash-joins. Our spatial partition functions have two components: a set of bucket extents and an assignment function, which may map a data item into multiple buckets. Furthermore, the partition functions for the two input datasets may be different.We have designed and tested a spatial hash-join method based on this framework. The partition function for the inner dataset is initialized by sampling the dataset, and evolves as data are inserted. The partition function for the outer dataset is immutable, but may replicate a data item from the outer dataset into multiple buckets. The method mirrors relational hash-joins in other aspects. Our method needs no pre-computed indices. It is therefore applicable to a wide range of spatial joins.Our experiments show that our method outperforms current spatial join algorithms based on tree matching by a wide margin. Further, its performance is superior even when the tree-based methods have pre-computed indices. This makes the spatial hash-join method highly competitive both when the input datasets are dynamically generated and when the datasets have pre-computed indices.	SIGMOD Conferen	database
4003	SIGMOD Conference	Bifocal Sampling for Skew-Resistant Join Size Estimation.	Sumit Ganguly,Phillip B. Gibbons,Yossi Matias,Abraham Silberschatz	1996	This paper introduces bifocal sampling, a new technique for estimating the size of an equi-join of two relations. Bifocal sampling classifies tuples in each relation into two groups, sparse and dense, based on the number of tuples with the same join value. Distinct estimation procedures are employed that focus on various combinations for joining tuples (e.g., for estimating the number of joining tuples that are dense in both relations). This combination of estimation procedures overcomes some well-known problems in previous schemes, enabling good estimates with no a priori knowledge about the data distribution. The estimate obtained by the bifocal sampling algorithm is proven to lie with high probability within a small constant factor of the actual join size, regardless of the skew, as long as the join size is &Omega;(n lg n), for relations consisting of n tuples. The algorithm requires a sample of size at most O(&radic;n lg n). By contrast, previous algorithms using a sample of similar size may require the join size to be &Omega;(n&radic;n) to guarantee an accurate estimate. Experimental results support the theoretical claims and show that bifocal sampling is practical and effective.	SIGMOD Conferen	database
4004	SIGMOD Conference	Multi-dimensional Resource Scheduling for Parallel Queries.	Minos N. Garofalakis,Yannis E. Ioannidis	1996	Scheduling query execution plans is an important component of query optimization in parallel database systems. The problem is particularly complex in a shared-nothing execution environment, where each system node represents a collection of time-shareable resources (e.g., CPU(s), disk(s), etc.) and communicates with other nodes only by message-passing. Significant research effort has concentrated on only a subset of the various forms of intra-query parallelism so that scheduling and synchronization is simplified. In addition, most previous work has focused its attention on one-dimensional models of parallel query scheduling, effectively ignoring the potential benefits of resource sharing. In this paper, we develop an approach that is more general in both directions, capturing all forms of intra-query parallelism and exploiting sharing of multi-dimensional resource nodes among concurrent plan operators. This allows scheduling a set of independent query tasks (i.e., operator pipelines) to be seen as an instance of the multi-dimensional bin-design problem. Using a novel quantification of coarse grain parallelism, we present a list scheduling heuristic algorithm that is provably near-optimal in the class of coarse grain parallel executions (with a worst-case performance ratio that depends on the number of resources per node and the granularity parameter). We then extend this algorithm to handle the operator precedence constraints in a bushy query plan by splitting the execution of the plan into synchronized phases. Preliminary performance results confirm the effectiveness of our scheduling algorithm compared both to previous approaches and the optimal solution. Finally, we present a technique that allows us to relax the coarse granularity restriction and obtain a list scheduling method that is provably near-optimal in the space of all possible parallel schedules.	SIGMOD Conferen	database
4005	SIGMOD Conference	The Dangers of Replication and a Solution.	Jim Gray,Pat Helland,Patrick E. O'Neil,Dennis Shasha	1996	Update anywhere-anytime-anyway transactional replication has unstable behavior as the workload scales up: a ten-fold increase in nodes and traffic gives a thousand fold increase in deadlocks or reconciliations. Master copy replication (primary copy) schemes reduce this problem. A simple analytic model demonstrates these results. A new two-tier replication algorithm is proposed that allows mobile (disconnected) applications to propose tentative update transactions that are later applied to a master copy. Commutative update transactions avoid the instability of other replication schemes.	SIGMOD Conferen	database
4006	SIGMOD Conference	SQL Query Optimization: Reordering for a General Class of Queries.	Piyush Goel,Balakrishna R. Iyer	1996	The strength of commercial query optimizers like DB2 comes from their ability to select an optimal order by generating all equivalent reorderings of binary operators. However, there are no known methods to generate all equivalent reorderings for a SQL query containing joins, outer joins, and groupby aggregations. Consequently, some of the reorderings with significantly lower cost may be missed. Using hypergraph model and a set of novel identities, we propose a method to reorder a SQL query containing joins, outer joins, and groupby aggregations. While these operators are sufficient to capture the SQL semantics, it is during their reordering that we identify a powerful primitive needed for a dbms. We report our findings of a simple, yet fundamental operator, generalized selection, and demonstrate its power to solve the problem of reordering of SQL queries containing joins, outer joins, and groupby aggregations.	SIGMOD Conferen	database
4007	SIGMOD Conference	DBMiner: Interactive Mining of Multiple-Level Knowledge in Relational Databases.	Jiawei Han,Yongjian Fu,Wei Wang,Jenny Chiang,Osmar R. Zaïane,Krzysztof Koperski	1996	Based on our years-of-research, a data mining system, DB-Miner, has been developed for interactive mining of multiple-level knowledge in large relational databases. The system implements a wide spectrum of data mining functions, including generalization, characterization, association, classification, and prediction. By incorporation of several interesting data mining techniques, including attribute-oriented induction, progressive deepening for mining multiple-level rules, and meta-rule guided knowledge mining, the system provides a user-friendly, interactive data mining environment with good performance.	SIGMOD Conferen	database
4008	SIGMOD Conference	Implementing Data Cubes Efficiently.	Venky Harinarayan,Anand Rajaraman,Jeffrey D. Ullman	1996	Decision support applications involve complex queries on very large databases. Since response times should be small, query optimization is critical. Users typically view the data as multidimensional data cubes. Each cell of the data cube is a view consisting of an aggregation of interest, like total sales. The values of many of these cells are dependent on the values of other cells in the data cube. A common and powerful query optimization technique is to materialize some or all of these cells rather than compute them from raw data each time. Commercial systems differ mainly in their approach to materializing the data cube. In this paper, we investigate the issue of which cells (views) to materialize when it is too expensive to materialize all views. A lattice framework is used to express dependencies among views. We present greedy algorithms that work off this lattice and determine a good set of views to materialize. The greedy algorithm performs within a small constant factor of optimal under a variety of models. We then consider the most common case of the hypercube lattice and examine the choice of materialized views for hypercubes in detail, giving some good tradeoffs between the space used and the average time to answer a query.	SIGMOD Conferen	database
4009	SIGMOD Conference	Query Execution Techniques for Caching Expensive Methods.	Joseph M. Hellerstein,Jeffrey F. Naughton	1996	Object-Relational and Object-Oriented DBMSs allow users to invoke time-consuming (expensive) methods in their queries. When queries containing these expensive methods are run on data with duplicate values, time is wasted redundantly computing methods on the same value. This problem has been studied in the context of programming languages, where memoization is the standard solution. In the database literature, sorting has been proposed to deal with this problem. We compare these approaches along with a third solution, a variant of unary hybrid hashing which we call Hybrid Cache. We demonstrate that Hybrid Cache always dominates memoization, and significantly outperforms sorting in many instances. This provides new insights into the tradeoff between hashing and sorting for unary operations. Additionally, our Hybrid Cache algorithm includes some new optimization for unary hybrid hashing, which can be used for other applications such as grouping and duplicate elimination. We conclude with a discussion of techniques for caching multiple expensive methods in a single query, and raise some new optimization problems in choosing caching techniques.	SIGMOD Conferen	database
4010	SIGMOD Conference	Random I/O Scheduling in Online Tertiary Storage Systems.	Bruce Hillyer,Abraham Silberschatz	1996	New database applications that require the storage and retrieval of many terabytes of data are reaching the limits for disk-based storage systems, in terms of both cost and scalability. These limits provide a strong incentive for the development of databases that augment disk storage with technologies better suited to large volumes of data. In particular, the seamless incorporation of tape storage into database systems would be of great value. Tape storage is two orders of magnitude more efficient than disk in terms of cost per terabyte and physical volume per terabyte; however, a key problem is that the random access latency of tape is three to four orders of magnitude slower than disk. Thus, to incorporate a tape bulk store in an online storage system, the problem of tape access latency must be solved. One approach to reducing the latency is careful I/O scheduling. The focus of this paper is on efficient random I/O scheduling for tape drives that use a serpentine track layout, such as the Quantum DLT and the IBM 3480 and 3590. For serpentine tape, I/O scheduling is problematic because of the complex relationships between logical block numbers, their physical positions on tape, and the time required for tape positioning between these physical positions. The results in this paper show that our scheduling schemes provide a significant improvement in the latency of random access to serpentine tape.	SIGMOD Conferen	database
4011	SIGMOD Conference	A Framework for Supporting Data Integration Using the Materialized and Virtual Approaches.	Richard Hull,Gang Zhou	1996	This paper presents a framework for data integration currently under development in the Squirrel project. The framework is based on a special class of mediators, called Squirrel integration mediators. These mediators can support the traditional virtual and materialized approaches, and also hybrids of them.In the Squirrel mediators, a relation in the integrated view can be supported as (a) fully materialized, (b) fully virtual, or (c) partially materialized (i.e., with some attributes materialized and other attributes virtual). In general, (partially) materialized relations of the integrated view are maintained by incremental updates from the source databases. Squirrel mediators provide two approaches for doing this: (1) materialize all needed auxiliary data, so that data sources do not have to be queried when processing the incremental updates; or (2) leave some or all of the auxiliary data virtual, and query selected source databases when processing incremental updates.The paper presents formal notions of consistency and freshness for integrated views defined over multiple autonomous source databases. It is shown that Squirrel mediators satisfy these properties.	SIGMOD Conferen	database
4012	SIGMOD Conference	CapBasED-AMS: A Capability-based and Event-driven Activity Management System.	Patrick C. K. Hung,Helen P. Yeung,Kamalakar Karlapalem	1996	CapBasED-AMS: A Capability-based and Event-driven Activity Management System.	SIGMOD Conferen	database
4013	SIGMOD Conference	Databases and Visualization.	Daniel A. Keim	1996	Databases and Visualization.	SIGMOD Conferen	database
4014	SIGMOD Conference	Estimating Alphanumeric Selectivity in the Presence of Wildcards.	P. Krishnan,Jeffrey Scott Vitter,Balakrishna R. Iyer	1996	Success of commercial query optimizers and database management systems (object-oriented or relational) depend on accurate cost estimation of various query reordering [BGI]. Estimating predicate selectivity, or the fraction of rows in a database that satisfy a selection predicate, is key to determining the optimal join order. Previous work has concentrated on estimating selectivity for numeric fields [ASW, HaSa, IoP, LNS, SAC, WVT]. With the popularity of textual data being stored in databases, it has become important to estimate selectivity accurately for alphanumeric fields. A particularly problematic predicate used against alphanumeric fields is the SQL like predicate [Dat]. Techniques used for estimating numeric selectivity are not suited for estimating alphanumeric selectivity.In this paper, we study for the first time the problem of estimating alphanumeric selectivity in the presence of wildcards. Based on the intuition that the model built by a data compressor on an input text encapsulates information about common substrings in the text, we develop a technique based on the suffix tree data structure to estimate alphanumeric selectivity. In a statistics generation pass over the database, we construct a compact suffix tree-based structure from the columns of the database. We then look at three families of methods that utilize this structure to estimate selectivity during query plan costing, when a query with predicates on alphanumeric attributes contains wildcards in the predicate.We evaluate our methods empirically in the context of the TPC-D benchmark. We study our methods experimentally against a variety of query patterns and identify five techniques that hold promise.	SIGMOD Conferen	database
4015	SIGMOD Conference	DBSim: A Simulation Tool for Predicting Database Performance.	Mike Lefler,Mark Stokrp,Craig Wong	1996	DBSim: A Simulation Tool for Predicting Database Performance.	SIGMOD Conferen	database
4016	SIGMOD Conference	A Query Language for Multidimensional Arrays: Design, Implementation, and Optimization Techniques.	Leonid Libkin,Rona Machlin,Limsoon Wong	1996	While much recent research has focussed on extending databases beyond the traditional relational model, relatively little has been done to develop database tools for querying data organized in (multidimensional) arrays. The scientific computing community has made little use of available database technology. Instead, multidimensional scientific data is typically stored in local files conforming to various data exchange formats and queried via specialized access libraries tied in to general purpose programming languages.To allow such data to be queried using known database techniques, we design and implement a query language for multidimensional arrays. Our main design decision is to treat arrays as functions from index sets to values rather than as collection types. This leads to clean syntax and semantics as well as simple but powerful optimization rules.We present a calculus for arrays that extends standard calculi for complex objects. We derive a higher-level comprehension style query language based on this calculus and describe its implementation, including a data driver for the NetCDF data exchange format. Next, we explore some optimization rules obtained from the equational laws of our core calculus. Finally, we study the expressiveness of our calculus and prove that it essentially corresponds to adding ranking to a query language for complex objects.	SIGMOD Conferen	database
4017	SIGMOD Conference	Safe and Efficient Sharing of Persistent Objects in Thor.	Barbara Liskov,Atul Adya,Miguel Castro,Mark Day,Sanjay Ghemawat,Robert Gruber,Umesh Maheshwari,Andrew C. Myers,Liuba Shrira	1996	Safe and Efficient Sharing of Persistent Objects in Thor.	SIGMOD Conferen	database
4018	SIGMOD Conference	Towards Effective and Efficient Free Space Management.	Mark L. McAuliffe,Michael J. Carey,Marvin H. Solomon	1996	An important problem faced by many database management systems is the online object placement problem--the problem of choosing a disk page to hold a newly allocated object. In the absence of clustering criteria, the goal is to maximize storage utilization. For main-memory based systems, simple heuristics exist that provide reasonable space utilization in the worst case and excellent utilization in typical cases. However, the storage management problem for databases includes significant additional challenges, such as minimizing I/O traffic, coping with crash recovery, and gracefully integrating space management with locking and logging.We survey several object placement algorithms, including techniques that can be found in commercial and research database systems. We then present a new object placement algorithm that we have designed for use in Shore, an object-oriented database system under development at the University of Wisconsin--Madison. Finally, we present results from a series of experiments involving actual Shore implementations of some of these algorithms. Our results show that while current object placement algorithms have serious performance deficiencies, including excessive CPU or main memory overhead, I/O traffic, or poor disk utilization, our new algorithm consistently excellent performance in all of these areas.	SIGMOD Conferen	database
4019	SIGMOD Conference	Hot Mirroring: A Study to Hide Parity Upgrade Penalty and Degradations During Rebuilds for RAID5.	Kazuhiko Mogi,Masaru Kitsuregawa	1996	Hot Mirroring: A Study to Hide Parity Upgrade Penalty and Degradations During Rebuilds for RAID5.	SIGMOD Conferen	database
4020	SIGMOD Conference	State of the Art in Workflow Management Research and Products.	C. Mohan	1996	In the last few years, workflow management has become a hot topic in the research community and, especially, in the commercial arena. Workflow management is multidisciplinary in nature encompassing many aspects of computing: database management, distributed client-server systems, transaction management, mobile computing, business process reengineering, integration of legacy and new applications, and heterogeneity of hardware and software. Many academic and industrial research projects are underway. Numerous successful products have been released. Standardization efforts are in progress under the auspices of the Workflow Management Coalition. As has happened in the RDBMS area with respect to some topics, in the workflow area also, some of the important real-life problems faced by customers and product developers are not being tackled by researchers. This tutorial will survey the state of the art in workflow management research and products.	SIGMOD Conferen	database
4021	SIGMOD Conference	Maintaining Database Consistency in Presence of Value Dependencies in Multidatabase Systems.	Claire Morpain,Michèle Cart,Jean Ferrié,Jean-François Pons	1996	The emergence of new criteria specifically adapted to multidatabase systems, in response to constraints imposed by global serializability, leads to restrictive hypotheses in order to ensure correctness of executions. This is the case with the two level serializability presented in [6], that ensures strongly correct executions if transaction programs are Local Database Preserving (LDP). The main drawback of the LDP hypothesis is that it relies on rigorous programming. The principal objective of this paper has been to suppress this drawback while conserving the strong correctness of 2LSR executions We propose defining precisely the notion of value dependencies, and managing them so as not to impose the LDP property.	SIGMOD Conferen	database
4022	SIGMOD Conference	Accessing Relational Databases from the World Wide Web.	Tam Nguyen,V. Srinivasan	1996	With the growing popularity of the internet and the World Wide Web (Web), there is a fast growing demand for access to database management systems (DBMS) from the Web. We describe here techniques that we invented to bridge the gap between HTML, the standard markup language of the Web, and SQL, the standard query language used to access relational DBMS. We propose a flexible general purpose variable substitution mechanism that provides cross-language variable substitution between HTML input and SQL query strings as well as between SQL result rows and HTML output thus enabling the application developer to use the full capabilities of HTML for creation of query forms and reports, and SQL for queries and updates. The cross-language variable substitution mechanism has been used in the design and implementation of a system called DB2 WWW Connection that enables quick and easy construction of applications that access relational DBMS data from the Web. An end user of these DB2 WWW applications sees only the forms for his or her requests and resulting reports. A user fills out the forms, points and clicks to navigate the forms and to access the database as determined by the application.	SIGMOD Conferen	database
4023	SIGMOD Conference	A Content-Based Multimedia Server for Massively Parallel Architectures.	William O'Connell,Ion Tim Ieong,David Schrader,C. Watson,Grace Au,Alexandros Biliris,S. Choo,P. Colin,G. Linderman,Euthimios Panagos,J. Wang,T. Walters	1996	A Content-Based Multimedia Server for Massively Parallel Architectures.	SIGMOD Conferen	database
4024	SIGMOD Conference	Fault-tolerant Architectures for Continuous Media Servers.	Banu Özden,Rajeev Rastogi,Prashant J. Shenoy,Abraham Silberschatz	1996	Continuous media servers that provide support for the storage and retrieval of continuous media data (e.g., video, audio) at guaranteed rates are becoming increasingly important. Such servers, typically, rely on several disks to service a large number of clients, and are thus highly susceptible to disk failures. We have developed two fault-tolerant approaches that rely on admission control in order to meet rate guarantees for continuous media requests. The schemes enable data to be retrieved from disks at the required rate even if a certain disk were to fail. For both approaches, we present data placement strategies and admission control algorithms. We also present design techniques for maximizing the number of clients that can be supported by a continuous media server. Finally, through extensive simulations, we demonstrate the effectiveness of our schemes.	SIGMOD Conferen	database
4025	SIGMOD Conference	Improved Histograms for Selectivity Estimation of Range Predicates.	Viswanath Poosala,Yannis E. Ioannidis,Peter J. Haas,Eugene J. Shekita	1996	Improved Histograms for Selectivity Estimation of Range Predicates.	SIGMOD Conferen	database
4026	SIGMOD Conference	LORE: A Lightweight Object REpository for Semistructured Data.	Dallan Quass,Jennifer Widom,Roy Goldman,Kevin Haas,Qingshan Luo,Jason McHugh,Svetlozar Nestorov,Anand Rajaraman,Hugo Rivero,Serge Abiteboul,Jeffrey D. Ullman,Janet L. Wiener	1996	LORE: A Lightweight Object REpository for Semistructured Data.	SIGMOD Conferen	database
4027	SIGMOD Conference	Partition Based Spatial-Merge Join.	Jignesh M. Patel,David J. DeWitt	1996	This paper describes PBSM (Partition Based Spatial-Merge), a new algorithm for performing spatial join operation. This algorithm is especially effective when neither of the inputs to the join have an index on the joining attribute. Such a situation could arise if both inputs to the join are intermediate results in a complex query, or in a parallel environment where the inputs must be dynamically redistributed. The PBSM algorithm partitions the inputs into manageable chunks, and joins them using a computational geometry based plane-sweeping technique. This paper also presents a performance study comparing the the traditional indexed nested loops join algorithm, a spatial join algorithm based on joining spatial indices, and the PBSM algorithm. These comparisons are based on complete implementations of these algorithms in Paradise, a database system for handling GIS applications. Using real data sets, the performance study examines the behavior of these spatial join algorithms in a variety of situations, including the cases when both, one, or none of the inputs to the join have an suitable index. The study also examines the effect of clustering the join inputs on the performance of these join algorithms. The performance comparisons demonstrates the feasibility, and applicability of the PBSM join algorithm.	SIGMOD Conferen	database
4028	SIGMOD Conference	Thinksheet: A Tool for Tailoring Complex Documents.	Peter Piatko,Roman Yangarber,Dao-I Lin,Dennis Shasha	1996	Thinksheet: A Tool for Tailoring Complex Documents.	SIGMOD Conferen	database
4029	SIGMOD Conference	Providing Better Support for a Class of Decision Support Queries.	Sudhir Rao,Antonio Badia,Dirk Van Gucht	1996	Relational database systems do not effectively support complex queries containing quantifiers (quantified queries) that are increasingly becoming important in decision support applications. Generalized quantifiers provide an effective way of expressing such queries naturally. In this paper, we consider the problem of processing quantified queries within the generalized quantifier framework. We demonstrate that current relational systems are ill-equipped, both at the language and at the query processing level, to deal with such queries. We also provide insights into the intrinsic difficulties associated with processing such queries. We then describe the implementation of a quantified query processor, Q2P, that is based on multidimensional and boolean matrix structures. We provide results of performance experiments run on Q2P that demonstrate superior performance on quantified queries. Our results indicate that it is feasible to augment relational systems with query subsystems like Q2P for significant performance benefits for quantified queries in decision support applications.	SIGMOD Conferen	database
4030	SIGMOD Conference	IDEA: Interactive Data Exploration and Analysis.	Peter G. Selfridge,Divesh Srivastava,Lynn O. Wilson	1996	The analysis of business data is often an ill-defined task characterized by large amounts of noisy data. Because of this, business data analysis must combine two kinds of intertwined tasks: exploration and analysis. Exploration is the process of finding the appropriate subset of data to analyze, and analysis is the process of measuring the data to provide the business answer. While there are many tools available both for exploration and for analysis, a single tool or set of tools may not provide full support for these intertwined tasks. We report here on a project that set out to understand a specific business data analysis problem and build an environment to support it. The results of this understanding are, first of all, a detailed list of requirements of this task; second, a set of capabilities that meet these requirements; and third, an implemented client-server solution that addresses many of these requirements and identifies others for future work. Our solution incorporates several novel perspectives on data analysis and combines a history mechanism with a graphical, re-usable representation of the analysis and exploration process. Our approach emphasizes using the database itself to represent as many of these functions as possible.	SIGMOD Conferen	database
4031	SIGMOD Conference	Materialized View Maintenance and Integrity Constraint Checking: Trading Space for Time.	Kenneth A. Ross,Divesh Srivastava,S. Sudarshan	1996	We investigate the problem of incremental maintenance of an SQL view in the face of database updates, and show that it is possible to reduce the total time cost of view maintenance by materializing (and maintaining) additional views. We formulate the problem of determining the optimal set of additional views to materialize as an optimization problem over the space of possible view sets (which includes the empty set). The optimization problem is harder than query optimization since it has to deal with multiple view sets, updates of multiple relations, and multiple ways of maintaining each view set for each updated relation.We develop a memoing solution for the problem; the solution can be implemented using the expression DAG representation used in rule-based optimizers such as Volcano. We demonstrate that global optimization cannot, in general, be achieved by locally optimizing each materialized subview, because common subexpressions between different materialized subviews can allow nonoptimal local plans to be combined into an optimal global plan. We identify conditions on materialized subviews in the expression DAG when local optimization is possible. Finally, we suggest heuristics that can be used to efficiently determine a useful set of additional views to materialize.Our results are particularly important for the efficient checking of assertions (complex integrity constraints) in the SQL-92 standard, since the incremental checking of such integrity constraints is known to be essentially equivalent to the view maintenance problem.	SIGMOD Conferen	database
4032	SIGMOD Conference	The Garlic Project.	Mary Tork Roth,Manish Arya,Laura M. Haas,Michael J. Carey,William F. Cody,Ronald Fagin,Peter M. Schwarz,Joachim Thomas II,Edward L. Wimmers	1996	The goal of the Garlic [1] project is to build a multimedia information system capable of integrating data that resides in different database systems as well as in a variety of non-database data servers. This integration must be enabled while maintaining the independence of the data servers, and without creating copies of their data. Multimedia should be interpreted broadly to mean not only images, video, and audio, but also text and application specific data types (e.g., CAD drawings, medical objects, &hellip;). Since much of this data is naturally modeled by objects, Garlic provides an object-oriented schema to applications, interprets object queries, creates execution plans for sending pieces of queries to the appropriate data servers, and assembles query results for delivery back to the applications. A significant focus of the project is support for intelligent data servers, i.e., servers that provide media-specific indexing and query capabilities [2]. Database optimization technology is being extended to deal with heterogeneous collections of data servers so that efficient data access plans can be employed for multi-repository queries.A prototype of the Garlic system has been operational since January 1995. Queries are expressed in an SQL-like query language that has been extended to include object-oriented features such as reference-valued attributes and nested sets. In addition to a C++ API, Garlic supports a novel query/browser interface called PESTO [3]. This component of Garlic provides end users of the system with a friendly, graphical interface that supports interactive browsing, navigation, and querying of the contents of Garlic databases. Unlike existing interfaces to databases, PESTO allows users to move back and forth seamlessly between querying and browsing activities, using queries to identify interesting subsets of the database, browsing the subset, querying the content of a set-valued attribute of a particularly interesting object in the subset, and so on.	SIGMOD Conferen	database
4033	SIGMOD Conference	Cost-Based Optimization for Magic: Algebra and Implementation.	Praveen Seshadri,Joseph M. Hellerstein,Hamid Pirahesh,T. Y. Cliff Leung,Raghu Ramakrishnan,Divesh Srivastava,Peter J. Stuckey,S. Sudarshan	1996	Magic sets rewriting is a well-known optimization heuristic for complex decision-support queries. There can be many variants of this rewriting even for a single query, which differ greatly in execution performance. We propose cost-based techniques for selecting an efficient variant from the many choices.Our first contribution is a practical scheme that models magic sets rewriting as a special join method that can be added to any cost-based query optimizer. We derive cost formulas that allow an optimizer to choose the best variant of the rewriting and to decide whether it is beneficial. The order of complexity of the optimization process is preserved by limiting the search space in a reasonable manner. We have implemented this technique in IBM's DB2 C/S V2 database system. Our performance measurements demonstrate that the cost-based magic optimization technique performs well, and that without it, several poor decisions could be made.Our second contribution is a formal algebraic model of magic sets rewriting, based on an extension of the multiset relational algebra, which cleanly defines the search space and can be used in a rule-based optimizer. We introduce the multiset &theta;-semijoin operator, and derive equivalence rules involving this operator. We demonstrate that magic sets rewriting for non-recursive SQL queries can be modeled as a sequential composition of these equivalence rules.	SIGMOD Conferen	database
4034	SIGMOD Conference	The MultiView Project: Object-Oriented View Technology and Applications.	Elke A. Rundensteiner,Harumi A. Kuno,Young-Gook Ra,Viviane Crestana-Taube,Matthew C. Jones,Pedro José Marrón	1996	The MultiView Project: Object-Oriented View Technology and Applications.	SIGMOD Conferen	database
4035	SIGMOD Conference	Fundamental Techniques for Order Optimization.	David E. Simmen,Eugene J. Shekita,Timothy Malkemus	1996	Fundamental Techniques for Order Optimization.	SIGMOD Conferen	database
4036	SIGMOD Conference	Static Detection of Security Flaws in Object-Oriented Databases.	Keishi Tajima	1996	Access control in function granularity is one of the features of many object-oriented databases. In those systems, the users are granted rights to invoke composed functions instead of rights to invoke primitive operations. Although primitive operations are invoked inside composed functions, the users can invoke them only through the granted functions. This achieves access control in abstract operation level. Access control utilizing encapsulated functions, however, easily causes many security flaws through which malicious users can bypass the encapsulation and can abuse the primitive operations inside the functions. In this paper, we develop a technique to statically detect such security flaws. First, we design a framework to describe security requirements that should be satisfied. Then, we develop an algorithm that syntactically analyzes program code of the functions and determines whether given security requirements are satisfied or not. This algorithm is sound, that is, whenever there is a security flaw, it detects it.	SIGMOD Conferen	database
4037	SIGMOD Conference	Mining Quantitative Association Rules in Large Relational Tables.	Ramakrishnan Srikant,Rakesh Agrawal	1996	We introduce the problem of mining association rules in large relational tables containing both quantitative and categorical attributes. An example of such an association might be 10% of married people between age 50 and 60 have at least 2 cars. We deal with quantitative attributes by fine-partitioning the values of the attribute and then combining adjacent partitions as necessary. We introduce measures of partial completeness which quantify the information lost due to partitioning. A direct application of this technique can generate too many similar rules. We tackle this problem by using a greater-than-expected-value interest measure to identify the interesting rules in the output. We give an algorithm for mining such quantitative association rules. Finally, we describe the results of using this approach on a real-life dataset.	SIGMOD Conferen	database
4038	SIGMOD Conference	Rapid Bushy Join-order Optimization with Cartesian Products.	Bennet Vance,David Maier	1996	Query optimizers often limit the search space for join orderings, for example by excluding Cartesian products in subplans or by restricting plan trees to left-deep vines. Such exclusions are widely assumed to reduce optimization effort while minimally affecting plan quality. However, we show that searching the complete space of plans is more affordable than has been previously recognized, and that the common exclusions may be of little benefit.We start by presenting a Cartesian product optimizer that requires at most a few seconds of workstation time to search the space of bushy plans for products of up to 15 relations. Building on this result, we present a join-order optimizer that achieves a similar level of performance, and retains the ability to include Cartesian products in subplans wherever appropriate. The main contribution of the paper is in fully separating join-order enumeration from predicate analysis, and in showing that the former problem in particular can be solved swiftly by novel implementation techniques. A secondary contribution is to initiate a systematic approach to the benchmarking of join-order optimization, which we apply to the evaluation of our method.	SIGMOD Conferen	database
4039	SIGMOD Conference	BIRCH: An Efficient Data Clustering Method for Very Large Databases.	Tian Zhang,Raghu Ramakrishnan,Miron Livny	1996	Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle noise (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.	SIGMOD Conferen	database
4040	SIGMOD Conference	On-line Reorganization of Sparsely-populated B+trees.	Chendong Zou,Betty Salzberg	1996	In this paper, we present an efficient method to do online reorganization of sparsely-populated B+-trees. It reorganizes the leaves first, compacting in short operations groups of leaves with the same parent. After compacting, optionally, the new leaves may swap locations or be moved into empty pages so that they are in key order on the disk. After the leaves are reorganized, the method shrinks the tree by making a copy of the upper part of the tree while leaving the leaves in place. A new concurrency method is introduced so that only a minimum number of pages are locked during reorganization. During leaf reorganization, Forward Recovery is used to save all work already done while maintaining consistency after system crashes. A heuristic algorithm is developed to reduce the number of swaps needed during leaf reorganization, so that better concurrency and easier recovery can be achieved. A detailed description of switching from the old B+-tree to the new B+-tree is described for the first time.	SIGMOD Conferen	database
4041	VLDB	On the Computation of Multidimensional Aggregates.	Sameet Agarwal,Rakesh Agrawal,Prasad Deshpande,Ashish Gupta,Jeffrey F. Naughton,Raghu Ramakrishnan,Sunita Sarawagi	1996	On the Computation of Multidimensional Aggregates.	VLDB	database
4042	VLDB	Disseminating Updates on Broadcast Disks.	Swarup Acharya,Michael J. Franklin,Stanley B. Zdonik	1996	Disseminating Updates on Broadcast Disks.	VLDB	database
4043	VLDB	The XPS Approach to Loading and Unloading Terabyte Databases.	Sanket Atal	1996	The XPS Approach to Loading and Unloading Terabyte Databases.	VLDB	database
4044	VLDB	Performance of Future Database Systems: Bottlenecks and Bonananzas	Chaitanya K. Baru	1996	Performance of Future Database Systems: Bottlenecks and Bonananzas	VLDB	database
4045	VLDB	Supporting Periodic Authorizations and Temporal Reasoning in Database Access Control.	Elisa Bertino,Claudio Bettini,Elena Ferrari,Pierangela Samarati	1996	Supporting Periodic Authorizations and Temporal Reasoning in Database Access Control.	VLDB	database
4046	VLDB	TPC-D: The Challenges, Issues and Results.	Ramesh Bhashyam	1996	TPC-D: The Challenges, Issues and Results.	VLDB	database
4047	VLDB	The X-tree : An Index Structure for High-Dimensional Data	Stefan Berchtold,Daniel A. Keim,Hans-Peter Kriegel	1996	The X-tree : An Index Structure for High-Dimensional Data	VLDB	database
4048	VLDB	Query Processing Techniques for Multiversion Access Methods.	Jochen Van den Bercken,Bernhard Seeger	1996	Query Processing Techniques for Multiversion Access Methods.	VLDB	database
4049	VLDB	Coalescing in Temporal Databases.	Michael H. Böhlen,Richard T. Snodgrass,Michael D. Soo	1996	Coalescing in Temporal Databases.	VLDB	database
4050	VLDB	Of Objects and Databases: A Decade of Turmoil	Michael J. Carey,David J. DeWitt	1996	Of Objects and Databases: A Decade of Turmoil	VLDB	database
4051	VLDB	PESTO : An Integrated Query/Browser for Object Databases.	Michael J. Carey,Laura M. Haas,Vivekananda Maganty,John H. Williams	1996	PESTO : An Integrated Query/Browser for Object Databases.	VLDB	database
4052	VLDB	Dynamic Load Balancing in Hierarchical Parallel Database Systems.	Luc Bouganim,Daniela Florescu,Patrick Valduriez	1996	Dynamic Load Balancing in Hierarchical Parallel Database Systems.	VLDB	database
4053	VLDB	The Query Optimizer in Tandem's new ServerWare SQL Product.	Pedro Celis	1996	The Query Optimizer in Tandem's new ServerWare SQL Product.	VLDB	database
4054	VLDB	Querying Multiple Features of Groups in Relational Databases.	Damianos Chatziantoniou,Kenneth A. Ross	1996	Querying Multiple Features of Groups in Relational Databases.	VLDB	database
4055	VLDB	Optimization of Queries with User-defined Predicates	Surajit Chaudhuri,Kyuseok Shim	1996	Relational databases provide the ability to store user-defined functions and predicates which can be invoked in SQL queries. When evaluation of a user-defined predicate is relatively expensive, the traditional method of evaluating predicates as early as possible is no longer a sound heuristic. There are two previous approaches for optimizing such queries. However, neither is able to guarantee the optimal plan over the desired execution space. We present efficient techniques that are able to guarantee the choice of an optimal plan over the desired execution space. The optimization algorithm with complete rank-ordering improves upon the naive optimization algorithm by exploiting the nature of the cost formulas for join methods and is polynomial in the number of user-defined predicates (for a given number of relations.) We also propose pruning rules that significantly reduce the cost of searching the execution space for both the naive algorithm as well as for the optimization algorithm with complete rank-ordering, without compromising optimality. We also propose a conservative local heuristic that is simpler and has low optimization overhead. Although it is not always guaranteed to find the optimal plans, it produces close to optimal plans in most cases. We discuss how, depending on application requirements, to determine the algorithm of choice. It should be emphasized that our optimization algorithms handle user-defined selections as well as user-defined join predicates uniformly. We present complexity analysis and experimental comparison of the algorithms.	VLDB	database
4056	VLDB	Integrating Triggers and Declarative Constraints in SQL Database Sytems.	Roberta Cochrane,Hamid Pirahesh,Nelson Mendonça Mattos	1996	Integrating Triggers and Declarative Constraints in SQL Database Sytems.	VLDB	database
4057	VLDB	Querying a Multilevel Database: A Logical Analysis.	Frédéric Cuppens	1996	Querying a Multilevel Database: A Logical Analysis.	VLDB	database
4058	VLDB	Semantic Data Caching and Replacement.	Shaul Dar,Michael J. Franklin,Björn Þór Jónsson,Divesh Srivastava,Michael Tan	1996	Semantic Data Caching and Replacement.	VLDB	database
4059	VLDB	Clustering Techniques for Minimizing External Path Length.	Ajit A. Diwan,Sanjeeva Rane,S. Seshadri,S. Sudarshan	1996	Clustering Techniques for Minimizing External Path Length.	VLDB	database
4060	VLDB	Large Databases for Remote Sensing and GIS.	A. R. Dasgupta	1996	Large Databases for Remote Sensing and GIS.	VLDB	database
4061	VLDB	Information Retrieval from an Incomplete Data Cube.	Curtis E. Dyreson	1996	Information Retrieval from an Incomplete Data Cube.	VLDB	database
4062	VLDB	Analysis of n-Dimensional Quadtrees using the Hausdorff Fractal Dimension	Christos Faloutsos,Volker Gaede	1996	Analysis of n-Dimensional Quadtrees using the Hausdorff Fractal Dimension	VLDB	database
4063	VLDB	Modeling Skewed Distribution Using Multifractals and the `80-20' Law.	Christos Faloutsos,Yossi Matias,Abraham Silberschatz	1996	Modeling Skewed Distribution Using Multifractals and the `80-20' Law.	VLDB	database
4064	VLDB	Scalablity and Availability in Oracle7 7.3.	Dieter Gawlick	1996	Scalablity and Availability in Oracle7 7.3.	VLDB	database
4065	VLDB	Constructing Efficient Decision Trees by Using Optimized Numeric Association Rules.	Takeshi Fukuda,Yasuhiko Morimoto,Shinichi Morishita,Takeshi Tokuyama	1996	Constructing Efficient Decision Trees by Using Optimized Numeric Association Rules.	VLDB	database
4066	VLDB	Cost-based Selection of Path Expression Processing Algorithms in Object-Oriented Databases.	Georges Gardarin,Jean-Robert Gruser,Zhao-Hui Tang	1996	Cost-based Selection of Path Expression Processing Algorithms in Object-Oriented Databases.	VLDB	database
4067	VLDB	Calibrating the Query Optimizer Cost Model of IRO-DB, an Object-Oriented Federated Database System.	Georges Gardarin,Fei Sha,Zhao-Hui Tang	1996	Calibrating the Query Optimizer Cost Model of IRO-DB, an Object-Oriented Federated Database System.	VLDB	database
4068	VLDB	The Changing Landscape of the Software Industry and its Implications for India	Umang Gupta	1996	The Changing Landscape of the Software Industry and its Implications for India	VLDB	database
4069	VLDB	What is the Data Warehousing Problem? (Are Materialized Views the Answer?)	Ashish Gupta,Inderpal Singh Mumick	1996	What is the Data Warehousing Problem? (Are Materialized Views the Answer?)	VLDB	database
4070	VLDB	Using Referential Integrity To Easily Define Consistent Subset Replicas.	Brad Hammond	1996	Using Referential Integrity To Easily Define Consistent Subset Replicas.	VLDB	database
4071	VLDB	Very Large Databases in a Commercial Application Environment	Karl-Heinz Hess	1996	Very Large Databases in a Commercial Application Environment	VLDB	database
4072	VLDB	ZOO : A Desktop Experiment Management Environment.	Yannis E. Ioannidis,Miron Livny,Shivani Gupta,Nagavamsi Ponnekanti	1996	ZOO : A Desktop Experiment Management Environment.	VLDB	database
4073	VLDB	Practical Issues with Commercial Use of Federated Databases.	Jim Kleewein	1996	Practical Issues with Commercial Use of Federated Databases.	VLDB	database
4074	VLDB	Cache Coherency in Oracle Parallel Server.	Boris Klots	1996	Cache Coherency in Oracle Parallel Server.	VLDB	database
4075	VLDB	Fast Nearest Neighbor Search in Medical Image Databases.	Flip Korn,Nikolaos Sidiropoulos,Christos Faloutsos,Eliot Siegel,Zenon Protopapas	1996	Fast Nearest Neighbor Search in Medical Image Databases.	VLDB	database
4076	VLDB	Efficient Snapshot Differential Algorithms for Data Warehousing.	Wilburt Labio,Hector Garcia-Molina	1996	Efficient Snapshot Differential Algorithms for Data Warehousing.	VLDB	database
4077	VLDB	SchemaSQL - A Language for Interoperability in Relational Multi-Database Systems.	Laks V. S. Lakshmanan,Fereidoon Sadri,Iyer N. Subramanian	1996	SchemaSQL - A Language for Interoperability in Relational Multi-Database Systems.	VLDB	database
4078	VLDB	Further Improvements on Integrity Constraint Checking for Stratifiable Deductive Databases.	Sin Yeung Lee,Tok Wang Ling	1996	Further Improvements on Integrity Constraint Checking for Stratifiable Deductive Databases.	VLDB	database
4079	VLDB	Obtaining Complete Answers from Incomplete Databases.	Alon Y. Levy	1996	Obtaining Complete Answers from Incomplete Databases.	VLDB	database
4080	VLDB	Querying Heterogeneous Information Sources Using Source Descriptions	Alon Y. Levy,Anand Rajaraman,Joann J. Ordille	1996	Querying Heterogeneous Information Sources Using Source Descriptions	VLDB	database
4081	VLDB	Database Management Systems and the Internet	Susan Malaika	1996	Database Management Systems and the Internet	VLDB	database
4082	VLDB	Supporting Procedural Constructs in SQL Compilers.	Nelson Mendonça Mattos	1996	Supporting Procedural Constructs in SQL Compilers.	VLDB	database
4083	VLDB	EROC: A Toolkit for Building NEATO Query Optimizers.	William J. McKenna,Louis Burger,Chi Hoang,Melissa Truong	1996	EROC: A Toolkit for Building NEATO Query Optimizers.	VLDB	database
4084	VLDB	A New SQL-like Operator for Mining Association Rules.	Rosa Meo,Giuseppe Psaila,Stefano Ceri	1996	A New SQL-like Operator for Mining Association Rules.	VLDB	database
4085	VLDB	MineSet(tm): A System for High-End Data Mining and Visualization.		1996	MineSet(tm): A System for High-End Data Mining and Visualization.	VLDB	database
4086	VLDB	DWMS: Data Warehouse Management System.	Narendra Mohan	1996	DWMS: Data Warehouse Management System.	VLDB	database
4087	VLDB	DISNIC-PLAN: A NICNET Based Distributed Database for Micro-level Planning in India.	M. Moni	1996	DISNIC-PLAN: A NICNET Based Distributed Database for Micro-level Planning in India.	VLDB	database
4088	VLDB	Effective & Efficient Document Ranking without using a Large Lexicon.	Yasushi Ogawa	1996	Effective & Efficient Document Ranking without using a Large Lexicon.	VLDB	database
4089	VLDB	Extracting Large Data Sets using DB2 Parallel Edition.	Sriram Padmanabhan	1996	Extracting Large Data Sets using DB2 Parallel Edition.	VLDB	database
4090	VLDB	Object Fusion in Mediator Systems.	Yannis Papakonstantinou,Serge Abiteboul,Hector Garcia-Molina	1996	Object Fusion in Mediator Systems.	VLDB	database
4091	VLDB	Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing.	Viswanath Poosala,Yannis E. Ioannidis	1996	Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing.	VLDB	database
4092	VLDB	Loading the Data Warehouse Across Various Parallel Architectures	Vijay V. Raghavan	1996	Loading the Data Warehouse Across Various Parallel Architectures	VLDB	database
4093	VLDB	Modeling Design Versions.	R. Ramakrishnan,D. Janaki Ram	1996	Modeling Design Versions.	VLDB	database
4094	VLDB	How System 11 SQL Server Became Fast.	T. K. Rengarajan	1996	How System 11 SQL Server Became Fast.	VLDB	database
4095	VLDB	Intra-Transaction Parallelism in the Mapping of an Object Model to a Relational Multi-Processor System.	Michael Rys,Moira C. Norrie,Hans-Jörg Schek	1996	Intra-Transaction Parallelism in the Mapping of an Object Model to a Relational Multi-Processor System.	VLDB	database
4096	VLDB	The Structured Information Manager: A Database System for SGML Documents.	Ron Sacks-Davis	1996	The Structured Information Manager: A Database System for SGML Documents.	VLDB	database
4097	VLDB	Reordering Query Execution in Tertiary Memory Databases.	Sunita Sarawagi,Michael Stonebraker	1996	Reordering Query Execution in Tertiary Memory Databases.	VLDB	database
4098	VLDB	WATCHMAN : A Data Warehouse Intelligent Cache Manager.	Peter Scheuermann,Junho Shim,Radek Vingralek	1996	WATCHMAN : A Data Warehouse Intelligent Cache Manager.	VLDB	database
4099	VLDB	The Design and Implementation of a Sequence Database System.	Praveen Seshadri,Miron Livny,Raghu Ramakrishnan	1996	The Design and Implementation of a Sequence Database System.	VLDB	database
4100	VLDB	Filter Trees for Managing Spatial Data over a Range of Size Granularities	Kenneth C. Sevcik,Nick Koudas	1996	Filter Trees for Managing Spatial Data over a Range of Size Granularities	VLDB	database
4101	VLDB	SPRINT: A Scalable Parallel Classifier for Data Mining	John C. Shafer,Rakesh Agrawal,Manish Mehta	1996	SPRINT: A Scalable Parallel Classifier for Data Mining	VLDB	database
4102	VLDB	Bellcore's ADAPT/X Harness System for Managing Information on Internet and Intranets.	Amit P. Sheth	1996	Bellcore's ADAPT/X Harness System for Managing Information on Internet and Intranets.	VLDB	database
4103	VLDB	Supporting State-Wide Immunisation Tracking Using Multi-Paradigm Workflow Technology.	Amit P. Sheth,Krys Kochut,John A. Miller,Devashish Worah,Souvik Das,Chenye Lin,Devanand Palaniswami,John Lynch,Ivan Shevchenko	1996	Supporting State-Wide Immunisation Tracking Using Multi-Paradigm Workflow Technology.	VLDB	database
4104	VLDB	Storage Estimation for Multidimensional Aggregates in the Presence of Hierarchies.	Amit Shukla,Prasad Deshpande,Jeffrey F. Naughton,Karthikeyan Ramasamy	1996	Storage Estimation for Multidimensional Aggregates in the Presence of Hierarchies.	VLDB	database
4105	VLDB	Answering Queries with Aggregation Using Views.	Divesh Srivastava,Shaul Dar,H. V. Jagadish,Alon Y. Levy	1996	Answering Queries with Aggregation Using Views.	VLDB	database
4106	VLDB	Incremental Maintenance of Externally Materialized Views.	Martin Staudt,Matthias Jarke	1996	Incremental Maintenance of Externally Materialized Views.	VLDB	database
4107	VLDB	Query Decomposition and View Maintenance for Query Languages for Unstructured Data.	Dan Suciu	1996	Query Decomposition and View Maintenance for Query Languages for Unstructured Data.	VLDB	database
4108	VLDB	Implementation and Analysis of a Parallel Collection Query Language.	Dan Suciu	1996	Implementation and Analysis of a Parallel Collection Query Language.	VLDB	database
4109	VLDB	Tribeca: A Stream Database Manager for Network Traffic Analysis.	Mark Sullivan	1996	Tribeca: A Stream Database Manager for Network Traffic Analysis.	VLDB	database
4110	VLDB	Sampling Large Databases for Association Rules.	Hannu Toivonen	1996	Sampling Large Databases for Association Rules.	VLDB	database
4111	VLDB	The Role of Integrity Constraints in Database Interoperation.	Mark W. W. Vermeer,Peter M. G. Apers	1996	The Role of Integrity Constraints in Database Interoperation.	VLDB	database
4112	VLDB	Applying Data Mining Techniques to a Health Insurance Information System.	Marisa S. Viveros,John P. Nearhos,Michael J. Rothman	1996	Applying Data Mining Techniques to a Health Insurance Information System.	VLDB	database
4113	SIGMOD Record	ACT-NET - The Active Database Management System Manifesto: A Rulebase of ADBMS Features.		1996	ACT-NET - The Active Database Management System Manifesto: A Rulebase of ADBMS Features.	SIGMOD Record	database
4114	SIGMOD Record	Workshop Report: The First International Workshop on Active and Real-Time Database Systems (ARTDB-95).	Mikael Berndtsson,Jörgen Hansson	1996	Workshop Report: The First International Workshop on Active and Real-Time Database Systems (ARTDB-95).	SIGMOD Record	database
4115	SIGMOD Record	An Orthogonally Persistent Java.	Malcolm P. Atkinson,Laurent Daynès,Mick J. Jordan,Tony Printezis,Susan Spence	1996	The language Java is enjoying a rapid rise in popularity as an application programming language. For many applications an effective provision of database facilities is required. Here we report on a particular approach to providing such facilities, called &ldquo;orthogonal persistence&rdquo;. Persistence allows data to have lifetimes that vary from transient to (the best approximation we can achieve to) indefinite. It is orthogonal persistence if the available lifetimes are the same for all kinds of data. We aim to show that the programmer productivity gains and possible performance gains make orthogonal persistence a valuable augmentation of Java.	SIGMOD Record	database
4116	SIGMOD Record	Overview of the STanford Real-time Information Processor (STRIP).	Brad Adelberg,Ben Kao,Hector Garcia-Molina	1996	We believe that the greatest growth potential for soft real-time databases is not as isolated monolithic databases but as components in open systems consisting of many heterogenous databases. In such environments, the flexibility to deal with unpredictable situations and the ability to cooperate with other databases (often non-real-time databases) is just as important as the guarantee of stringent timing constraints. In this paper, we describe a database designed explicitly for heterogeneous environments, the STanford Real-time Information Processor (STRIP). STRIP, which runs on standard Posix Unix, is a soft real-time main memory database with special facilities for importing and exporting data as well as handling derived data. We will describe the architecture of STRIP, its unique features, and its potential uses in overall system architectures.	SIGMOD Record	database
4117	SIGMOD Record	Spotfire: An Information Exploration Environment.	Christopher Ahlberg	1996	In this paper we examine the issues involved in developing information visualisation systems and present a framework for their construction. The framework addresses the components which must be considered in providing effective visualisations. The framework is specified using a declarative object oriented language; the resulting object model may be mapped to a variety of graphical user interface development platforms. This provides general support to developers of visualisation systems. A prototype system exists which allows the investigation of alternative visualisations for a range of data sources.	SIGMOD Record	database
4118	SIGMOD Record	Advances in Real-Time Database Systems Research.	Azer Bestavros	1996	Advances in Real-Time Database Systems Research.	SIGMOD Record	database
4119	SIGMOD Record	Report on First International Workshop on Real-Time Database Systems.	Azer Bestavros,Kwei-Jay Lin,Sang Hyuk Son	1996	Report on First International Workshop on Real-Time Database Systems.	SIGMOD Record	database
4120	SIGMOD Record	TCP-D - The Challenges, Issues and Results.	Ramesh Bhashyam	1996	TCP-D - The Challenges, Issues and Results.	SIGMOD Record	database
4121	SIGMOD Record	DeeDS Towards a Distributed and Active Real-Time Database System.	Sten Andler,Jörgen Hansson,Joakim Eriksson,Jonas Mellin,Mikael Berndtsson,Bengt Eftring	1996	DeeDS Towards a Distributed and Active Real-Time Database System.	SIGMOD Record	database
4122	SIGMOD Record	The BeSS Object Storage Manager: Architecture Overview.	Alexandros Biliris,Euthimios Panagos	1996	The BeSS Object Storage Manager: Architecture Overview.	SIGMOD Record	database
4123	SIGMOD Record	MQSeries and CICS Link for Lotus Notes.		1996	MQSeries and CICS Link for Lotus Notes.	SIGMOD Record	database
4124	SIGMOD Record	Integrating Contents and Structure in Text Retrieval.	Ricardo A. Baeza-Yates,Gonzalo Navarro	1996	The purpose of a textual database is to store textual documents. These documents have not only textual contents, but also structure. Many traditional text database systems have focused only on querying by contents or by structure. Recently, a number of models integrating both types of queries have appeared. We argue in favor of that integration, and focus our attention on these recent models, covering a representative sampling of the proposals in the field. We pay special attention to the tradeoffs between expressiveness and efficiency, showing the compromises taken by the models. We argue in favor of achieving a good compromise, since being weak in any of these two aspects makes the model useless for many applications.	SIGMOD Record	database
4125	SIGMOD Record	Control Strategies for Complex Relational Query Processing in Shared Nothing Systems.	Lionel Brunie,Harald Kosch	1996	In this paper, we present an original and complete methodology for supervising relational query processing in shared nothing systems. A new control mechanism is introduced which allows the detection and the correction of optimizer estimation errors and load imbalance. We especially focus on the management of intraprocessor communication and on the overlapping of communication and computation. Performance evaluations on an hypercube and a grid interconnection machine show the efficiency and the robustness of the proposed methods.	SIGMOD Record	database
4126	SIGMOD Record	OLAP, Relational, and Multidimensional Database Systems.	George Colliat	1996	OLAP, Relational, and Multidimensional Database Systems.	SIGMOD Record	database
4127	SIGMOD Record	Domains, Relations and Religious Wars.	Rafael Camps	1996	Domains, Relations and Religious Wars.	SIGMOD Record	database
4128	SIGMOD Record	Information Visualization, Guest Editors' Foreword.	Tiziana Catarci,Isabel F. Cruz	1996	Information Visualization, Guest Editors' Foreword.	SIGMOD Record	database
4129	SIGMOD Record	3D Geographic Network Displays.	Kenneth C. Cox,Stephen G. Eick,Taosong He	1996	Many types of information may be represented as graphs or networks with the nodes corresponding to entities and the links to relationships between entities. Often there is geographical information associated with the network. The traditional way to visualize geographical networks employs node and link displays on a two-dimensional map. These displays are easily overwhelmed, and for large networks become visually cluttered and confusing. To overcome these problems we have invented five novel network views that generalize the traditional displays. Two of the views show the complete network, while the other three concentrate on a portion of a larger network defined by connectivity to a given node. Our new visual metaphors retain many of the well-known advantages of the traditional network maps, while exploiting three-dimensional graphics to address some of the fundamental problems limiting the scalability of two-dimensional displays.	SIGMOD Record	database
4130	SIGMOD Record	UniSQL's Next-Generation Object-Relational Database Management System.	Albert D'Andrea,Phil Janus	1996	Object-Relational DBMSs have been receiving a great deal of attention from industry analysts and press as the next generation of database management systems. The motivation for a next generation DBMS is driven by the reality of shortened business cycles. This dynamic environment demands fast, cost-effective, time-to-market of new or modified business processes, services, and products. To support this important business need, the next generation DBMS must: 1. leverage the large investments made in existing relational technology, both in data and skill set; 2. Take advantage of the flexibility, productivity, and performance benefits of OO modeling; and 3. Integrate robust DBMS services for production quality systems. The objective of this article is to provide a brief overview of UniSQL's commercial object-relational database management system.	SIGMOD Record	database
4131	SIGMOD Record	In Reply to Domains, relations and Religious Wars.	Hugh Darwen	1996	In Reply to Domains, relations and Religious Wars.	SIGMOD Record	database
4132	SIGMOD Record	A Response to R. Camps' Article ``Domains, Relations and Religious Wars''.	C. J. Date	1996	A Response to R. Camps' Article ``Domains, Relations and Religious Wars''.	SIGMOD Record	database
4133	SIGMOD Record	Middle East Technical University Software Research and Development Center.	Asuman Dogac	1996	Middle East Technical University (METU) is the leading technical university in Turkey. The Software Research and Development Center was established by the Scientific and Technical Research Council of Turkey (TUBITAK) at the Department of Computer Engineering of METU in October 1991. The aim of this center is twofold: to lead large scale software research and development projects, and to foster international cooperation. SRDC is involved in a number of research and development projects supported by the government, industrial companies and international organizations. Although SRDC projects also cover other fields of computer science, the main emphasis is on database systems. SRDC is organized around the ongoing projects and several engineers and graduate students work in these projects: M. Altinel, B. Arpinar, I. Cingil, Y. Ceken, C. Dengi, E. Gokkoca, C. Evrendilek, P. Karagoz, E. Kilic, P. Koksal, S. Mancuhan, S. Nural, F. Ozcan, G. Ozhan, V. Sadjadi, N. Tatbul. Its infrastructure includes a LAN with Sun Workstations and PCs and commercial software like Oracle7, Sybase, Informix, Adabas D, Ingres and DEC's ObjectBroker. SRDC is a beta test site for several products including SunSoft's Joe and Concerto and Orbix's Object Transaction Service. The remainder of this report describes the main projects.	SIGMOD Record	database
4134	SIGMOD Record	New Standard for Stored Procedures in SQL.	Andrew Eisenberg	1996	New Standard for Stored Procedures in SQL.	SIGMOD Record	database
4135	SIGMOD Record	Lifestreams: A Storage Model for Personal Data.	Eric Freeman,David Gelernter	1996	Conventional software systems, such as those based on the &ldquo;desktop metaphor,&rdquo; are ill-equipped to manage the electronic information and events of the typical computer user. We introduce a new metaphor, Lifestreams, for dynamically organizing a user's personal workspace. Lifestreams uses a simple organizational metaphor, a time-ordered stream of documents, as an underlying storage system. Stream filters are used to organize, monitor and summarize information for the user. Combined, they provide a system that subsumes many separate desktop applications. This paper describes the Lifestreams model and our prototype system.	SIGMOD Record	database
4136	SIGMOD Record	Illustra's Web DataBlade Module.	John Gaffney	1996	Illustra's Web DataBlade Module.	SIGMOD Record	database
4137	SIGMOD Record	Real-Time Index Concurrency Control.	Jayant R. Haritsa,S. Seshadri	1996	Real-Time Index Concurrency Control.	SIGMOD Record	database
4138	SIGMOD Record	Open Issues in Parallel Query Optimization.	Waqar Hasan,Daniela Florescu,Patrick Valduriez	1996	We provide an overview of query processing in parallel database systems and discuss several open issues in the optimization of queries for parallel machines.	SIGMOD Record	database
4139	SIGMOD Record	Applying database Visualization to the World Wide Web.	Masum Z. Hasan,Alberto O. Mendelzon,Dimitra Vista	1996	In this paper, we present visualizations of parts of the network of documents comprising the World Wide Web. We describe how we are using the Hy+ visualization system to visualize the portion of the World Wide Web explored during a browsing session. As the user browses, the web browser communicates the URL and title of each document fetched as well as all the anchors contained in the document. Hy+ displays graphically the history of the navigation and multiple views of the structure of that portion of the web.	SIGMOD Record	database
4140	SIGMOD Record	On the Cost of Monitoring and Reorganization of Object Bases for Clustering.	Carsten Andreas Gerlhof,Alfons Kemper,Guido Moerkotte	1996	Clustering is one of the most effective means to enhance the performance of object base applications. Consequently, many proposals exist for algorithms computing good object placements depending on the application profile. However, in an effective object base reorganization tool the clustering algorithm is only one constituent. In this paper, we report on our object base reorganization tool that covers all stages of reorganizing the objects: the application profile is determined by a monitoring tool, the object placement is computed from the monitored access statistics utilizing a variety of clustering algorithms and, finally, the reorganization tool restructures the object base accordingly. The costs as well as the effectiveness of these tools is quantitatively evaluated on the basis of the OO1-benchmark.	SIGMOD Record	database
4141	SIGMOD Record	Dynamic Information Visualization.	Yannis E. Ioannidis	1996	Dynamic queries constitute a very powerful mechanism for information visualization; some universe of data is visualized, and this visualization is modified on-the-fly as users modify the range of interest within the domains of the various attributes of the visualized information. In this paper, we analyze dynamic queries and offer some natural generalizations of the original concept by establishing a connection to SQL. We also discuss some implementation ideas that should make these generalizations efficient as well.	SIGMOD Record	database
4142	SIGMOD Record	Pixel-oriented Database Visualizations.	Daniel A. Keim	1996	In this paper, we provide an overview of several pixel-oriented visualization techniques which have been developed over the last years to support an effective querying and exploration of large databases. Pixel-oriented techniques use each pixel of the display to visualize one data value and therefore allow the visualization of the largest amount of data possible. The techniques may be divided into query-independent techniques which directly visualize the data (or a certain portion of it) and query-dependent techniques which visualize the relevance of the data with respect to a specific query. An example for the class of query-independent techniques is the recursive pattern technique which is based on a generic recursive scheme generalizing a wide range of pixel-oriented arrangements for visualizing large databases. Examples for the class of query-dependent techniques are the generalized spiral and circle-segments techniques, which visualize the distance with respect to a database query and arrange the most relevant data items in the center of the display.	SIGMOD Record	database
4143	SIGMOD Record	A Framework for Information Visualisation.	Jessie B. Kennedy,Kenneth J. Mitchell,Peter J. Barclay	1996	In this paper we examine the issues involved in developing information visualisation systems and present a framework for their construction. The framework addresses the components which must be considered in providing effective visualisations. The framework is specified using a declarative object oriented language; the resulting object model may be mapped to a variety of graphical user interface development platforms. This provides general support to developers of visualisation systems. A prototype system exists which allows the investigation of alternative visualisations for a range of data sources.	SIGMOD Record	database
4144	SIGMOD Record	Enhancing External Consistency in Real-Time Transactions.	Kwei-Jay Lin,Shing-Shan Peng	1996	Enhancing External Consistency in Real-Time Transactions.	SIGMOD Record	database
4145	SIGMOD Record	Real-Time Database - Similarity Semantics and Resource Scheduling.	Tei-Wei Kuo,Aloysius K. Mok	1996	Real-Time Database - Similarity Semantics and Resource Scheduling.	SIGMOD Record	database
4146	SIGMOD Record	Much Ado About Shared-Nothing.	Michael G. Norman,Thomas Zurek,Peter Thanisch	1996	In a 'shared-nothing' parallel computer, each processor has its own memory and disks and processors communicate by passing messages through an interconnect. Many academic researchers, and some vendors, assert that shared-nothingness is the 'consensus' architecture for parallel DBMSs. This alleged consensus is used as a justification for simulation models, algorithms, research prototypes and even marketing campaigns. We argue that shared-nothingness is no longer the consensus hardware architecture and that hardware resource sharing is a poor basis for categorising parallel DBMS software architectures if one wishes to compare the performance characteristics of parallel DBMS products.	SIGMOD Record	database
4147	SIGMOD Record	Database Research at the Indian Institute of Technology, Bombay.	D. B. Phatak,Nandlal L. Sarda,S. Seshadri,S. Sudarshan	1996	Database Research at the Indian Institute of Technology, Bombay.	SIGMOD Record	database
4148	SIGMOD Record	Shutdown, Budget, and Funding.	Xiaolei Qian	1996	There are few new funding announcements and requests for proposals, mostly due to the partial government shutdown and the budget impasse. We will report on the potential impact on NSF of the government shutdown and a 7-year balanced budget. We then briefly discuss some BAAs from ARPA, Rome Laboratory, and the Air Force.	SIGMOD Record	database
4149	SIGMOD Record	Scientist's Called Upon to Take Actions.	Xiaolei Qian	1996	Scientist's Called Upon to Take Actions.	SIGMOD Record	database
4150	SIGMOD Record	New Programs at DARPA and NSF.	Xiaolei Qian	1996	We will share with readers some good news on NSF and Defense budget, and report on several interesting new programs at DARPA and NSF.	SIGMOD Record	database
4151	SIGMOD Record	The Aggregate Data Problem: A System for their Definition and Management.	Maurizio Rafanelli,Antonia Bezenchek,Leonardo Tininini	1996	In this paper we describe the fundamental components of a database management system for the definition, storage, manipulation and query of aggregate data, i.e. data which are obtained by applying statistical aggregations and statistical analysis functions over raw data. In particular, the attention has been focused on: (1) a data structure for the efficient storage and manipulation of aggregate data, called ADaS; (2) the graphical structures of the aggregate data model ADAMO for a more user-friendly definition and query of aggregate data; (3) a graphical user interface which enables a straightforward specification of the ADAMO structures; (4) a textual declarative query language to retrieve data from the aggregate database, called ADQUEL.	SIGMOD Record	database
4152	SIGMOD Record	Integrating Temporal, Real-Time, and Active Databases.	Krithi Ramamritham,Rajendran M. Sivasankaran,John A. Stankovic,Donald F. Towsley,Ming Xiong	1996	To meet the needs of many real-world control applications, concepts from Temporal, Real-Time, and Active Databases must be integrated: Since the system's data is supposed to reflect the environment being controlled, they must be updated frequently to maintain temporal validity; Many activities, including those that perform the updates, work under time constraints; The occurrence of events, for example, emergency events, trigger actions. In these systems, meeting timeliness, predictability, and QoS guarantee requirements &mdash; through appropriate resource and overload management &mdash; become very important. So, algorithms and protocols for concurrency control, recovery, and scheduling are needed. These algorithms must exploit semantics of the data and the transactions to be responsive and efficient. Whereas time cognizant scheduling, concurrency control and conflict resolution have been studied in the literature, recovery issues have not. We have developed strategies for data placement at the appropriate level of memory hierarchy, for avoiding undoing/redoing by exploiting data/transaction characteristics, and for placing logs at the appropriate level in the memory hierarchy. Another issue that we have studied deals with the assignment of priority to transactions in active real-time database systems. We are also studying concurrency control for temporal and multi-media data. We have built RADEx, a simulation environment to evaluate our solutions.	SIGMOD Record	database
4153	SIGMOD Record	To Table or Not to Table: a Hypertabular Answer.	Giuseppe Santucci,Laura Tarantino	1996	Suitable data set organizers are necessary to help users assimilating information retrieved from a database. In this paper we present (1) a general hypertextual framework for the interaction with tables, and (2) a specialization of the framework in order to present in hypertextual format the results of queries expressed in terms of a visual semantic query language.	SIGMOD Record	database
4154	SIGMOD Record	Report from the NSF Workshop on Workflow and Process Automation in Information Systems.	Amit P. Sheth,Dimitrios Georgakopoulos,Stef Joosten,Marek Rusinkiewicz,Walt Scacchi,Jack C. Wileden,Alexander L. Wolf	1996	An interdisciplinary research community needs to address challenging issues raised by applying workflow management technology in information systems. This conclusion results from the NSF workshop on Workflow and Process Automation in Information Systems which was held at the State Botanical Garden of Georgia during May 8-10, 1996. The workshop brought together active researchers and practitioners from several communities, with significant representation from database and distributed systems, software process and software engineering, and computer supported cooperative work. The presentations given at the workshop are available in the form of an electronic proceedings of this workshop at http://lsdis.cs.uga.edu/activities/). This report is the joint work of selected representatives from the workshop and it documents the results of significant group discussions and exchange of ideas.	SIGMOD Record	database
4155	SIGMOD Record	The Mariposa Distributed Database Management System.	Jeff Sidell	1996	The Mariposa Distributed Database Management System.	SIGMOD Record	database
4156	SIGMOD Record	Database Research: Achievements and Opportunities Into the 21st Century.	Abraham Silberschatz,Michael Stonebraker,Jeffrey D. Ullman	1996	In May, 1995 an NSF workshop on the future of database management systems research was convened. This paper reports the conclusions of that meeting. Among the most important directions for future DBMS research recommended by the panel are: support for multimedia objects; managing distributed and loosely coupled information, as on the world-wide web; supporting new database applications such as data mining and warehousing; workflow and other complex transaction-management problems, and enhancing the ease-of-use of DBMS''s for both users and system managers.	SIGMOD Record	database
4157	SIGMOD Record	Incremental data Structures and Algorithms for Dynamic Query Interfaces.	Egemen Tanin,Richard Beigel,Ben Shneiderman	1996	Dynamic query interfaces (DQIs) form a recently developed method of database access that provides continuous realtime feedback to the user during the query formulation process. Previous work shows that DQIs are elegant and powerful interfaces to small databases. Unfortunately, when applied to large databases, previous DQI algorithms slow to a crawl. We present a new approach to DQI algorithms that works well with large databases.	SIGMOD Record	database
4158	SIGMOD Record	Improving Timeliness in Real-Time Secure Database Systems.	Sang Hyuk Son,Rasikan David,Bhavani M. Thuraisingham	1996	Database systems for real-time applications must satisfy timing constraints associated with transactions, while maintaining data consistency. In addition to real-time requirements, security is usually required in many applications. Multilevel security requirements introduce a new dimension to transaction processing in real-time database systems. In this paper, we argue that because of the complexities involved, trade-offs need to be made between security and timeliness. We briefly present the secure two-phase locking protocol and discuss an adaptive method to support trading off security for timeliness, depending on the current state of the system. The performance of the adaptive secure two-phase locking protocol shows improved timeliness. We also discuss future research direction to improve timeliness of secure database systems.	SIGMOD Record	database
4159	SIGMOD Record	Temporal Database Bibliography Update.	Vassilis J. Tsotras,Anil Kumar	1996	Temporal Database Bibliography Update.	SIGMOD Record	database
4160	SIGMOD Record	Exploiting Main Memory DBMS Features to Improve Real-Time Concurrency Control Protocols.	Özgür Ulusoy,Alejandro P. Buchmann	1996	Exploiting Main Memory DBMS Features to Improve Real-Time Concurrency Control Protocols.	SIGMOD Record	database
4161	SIGMOD Record	Database Research at Arizona State University.	Susan Darling Urban,Suzanne W. Dietrich,Forouzan Golshani	1996	Database Research at Arizona State University.	SIGMOD Record	database
4162	SIGMOD Record	Object Query Standards.	Andrew E. Wade	1996	As object technology is adopted by software systems for analysis and design, language, GUI, and frameworks, the database community also is working to support objects, and to develop standards for that support. A key benefit of object technology is the ability for different objects and object tools to interoperate, so it's critical that such DBMS object standards interoperate with those of the rest of the object world. Starting with a discussion of the new issues objects bring to query standards, we present the efforts of various groups relevant to this, including ODMG, OMG, ANSI X3H2 (SQL3), and recent merger efforts feeding into SQL3. What's different with Objects? ODMG's OQL OMG's Query Service SQL3's Object extensions Efforts to merge	SIGMOD Record	database
4163	SIGMOD Record	Editor's Notes.	Jennifer Widom	1996	Editor's Notes.	SIGMOD Record	database
4164	SIGMOD Record	Editor's Notes.	Jennifer Widom	1996	Editor's Notes.	SIGMOD Record	database
4165	SIGMOD Record	Editor's Notes.	Jennifer Widom	1996	Editor's Notes.	SIGMOD Record	database
4166	SIGMOD Record	Guidelines for Presentation and Comparison of Indexing Techniques.	Justin Zobel,Alistair Moffat,Kotagiri Ramamohanarao	1996	Descriptions of new indexing techniques are a common outcome of database research, but these descriptions are sometimes marred by poor methodology and a lack of comparison to other schemes. In this paper we describe a framework for presentation and comparison of indexing schemes that we believe sets a minimum standard for development and dissemination of research results in this area.	SIGMOD Record	database
4167	Artificial Intelligence in Medicine	Generating recipient-centered explanations about drug prescription.	Berardina De Carolis,Fiorella de Rosis,Floriana Grasso,A. Rossiello,Dianne C. Berry,T. Gillie	1996	Generating recipient-centered explanations about drug prescription.	Artificial Inte	medical
4168	Artificial Intelligence in Medicine	An expert system for the detection of cervical cancer cells using knowledge-based image analyzer.	S. W. Chan,Kwong-Sak Leung,W. S. Wong	1996	An expert system for the detection of cervical cancer cells using knowledge-based image analyzer.	Artificial Inte	medical
4169	Artificial Intelligence in Medicine	Deep assessment of machine learning techniques using patient treatment in acute abdominal pain in children.	Michalis Blazadonakis,Vassilis Moustakis,Giorgos Charissis	1996	Deep assessment of machine learning techniques using patient treatment in acute abdominal pain in children.	Artificial Inte	medical
4170	Artificial Intelligence in Medicine	Retrieval of clinical science information using an interactive activation and competition network.	K. J. Cheng	1996	Retrieval of clinical science information using an interactive activation and competition network.	Artificial Inte	medical
4171	Artificial Intelligence in Medicine	Modifying an expert system construction to pattern recognition solution.	Yrjö Auramo,Martti Juhola	1996	Modifying an expert system construction to pattern recognition solution.	Artificial Inte	medical
4172	Artificial Intelligence in Medicine	Determining and classifying the region of interest in ultrasonic images of the breast using neural networks.	D. Buller,Andrzej Buller,Peter R. Innocent,W. Pawlak	1996	Determining and classifying the region of interest in ultrasonic images of the breast using neural networks.	Artificial Inte	medical
4173	Artificial Intelligence in Medicine	On the interpretation of certainty factors in expert systems.	G. P. Amata Cruz,Gleb Beliakov	1996	On the interpretation of certainty factors in expert systems.	Artificial Inte	medical
4174	Artificial Intelligence in Medicine	Fuzzy gating and the problem of screening.	G. P. Amata Cruz,Gleb Beliakov	1996	Fuzzy gating and the problem of screening.	Artificial Inte	medical
4175	Artificial Intelligence in Medicine	Don't care values in induction.	N. A. Diamantidis,Emmanouel A. Giakoumakis	1996	Inductive learning algorithms are powerful tools for the extraction of knowledge from data. Their success in medical domains is well-known. In medical diagnosis domains and generally in real-world applications among other problems, inductive learning algorithms have to deal with unknown values. In most cases unknown values are treated as missing ones. i.e. unknown values which are related to the class of training examples, but are missing due to lack of measurements. In this paper we address the problem of don't care values, which are unknown, because they are irrelevant to the class of the examples. The distinction of don't care values and missing ones is important in medical domains. With this distinction the experts are able to relate each diagnosis to the appropriate subset of attributes. We present techniques for dealing efficiently with don't care values in the induction of decision trees. Furthermore, we examine the importance of the distinction between missing and don't care values and we investigate the existence of don't care values instead of missing ones, in medical and non-medical real-world datasets.	Artificial Inte	medical
4176	Artificial Intelligence in Medicine	Concept formation vs. logistic regression: predicting death in trauma patients.	Mirsad Hadzikadic,A. Hakenewerth,Benjamin F. Bohren,J. Norton,B. Mehta,C. Andrews	1996	This study compares two classification models used to predict survival of injured patients entering the emergency department. Concept formation is a machine learning technique that summarizes known examples/cases in the form of a tree. After the tree is constructed, it can then be used to predict the classification of new cases. Logistic regression, on the other hand, is a statistical model that allows for a quantitative relationship for a dichotomous event with several independent variables. The outcome (dependent) variable must have only two choices, e.g. does or does not occur, alive or dead. etc. The result of this model is an equation which is then used to predict the probability of class membership of a new case. The two models were evaluated on a trauma registry database composed of information on all trauma patients admitted in 1992 to a Level I trauma center. A total of 2155 records, representing all trauma patients admitted for more than 24 h or who died in the Emergency Department, were grouped into two databases as follows: (1) discharge status of 'died' (containing 151 records), and (2) any discharge status other than 'died' (containing 2004 records). Both databases contained the same variables.	Artificial Inte	medical
4177	Artificial Intelligence in Medicine	Application of the fuzzy ARTMAP neural network model to medical pattern classification tasks.	Joseph Downs,Robert F. Harrison,R. Lee Kennedy,Simon S. Cross	1996	Application of the fuzzy ARTMAP neural network model to medical pattern classification tasks.	Artificial Inte	medical
4178	Artificial Intelligence in Medicine	Managing temporal worlds for medical trend diagnosis.	Ira J. Haimowitz,Isaac S. Kohane	1996	Managing temporal worlds for medical trend diagnosis.	Artificial Inte	medical
4179	Artificial Intelligence in Medicine	Temporal reasoning in medicine.	Elpida T. Keravnou	1996	Temporal reasoning in medicine.	Artificial Inte	medical
4180	Artificial Intelligence in Medicine	Temporal diagnostic reasoning based on time-objects.	Elpida T. Keravnou	1996	Temporal diagnostic reasoning based on time-objects.	Artificial Inte	medical
4181	Artificial Intelligence in Medicine	Sleep classification in infants by decision tree-based neural networks.	I. Koprinska,Gert Pfurtscheller,Doris Flotzinger	1996	Sleep classification in infants by decision tree-based neural networks.	Artificial Inte	medical
4182	Artificial Intelligence in Medicine	Modelling ECG signals with hidden Markov models.	A. Koski	1996	In this paper, we have studied the use of continuous probability density function hidden Markov models for the ECG signal analysis problem. Our previous work has focused on syntactic pattern recognition methods in signal processing. Hidden Markov model is basically a non-deterministic probabilistic finite state machine, which can be constructed inductively. It has been widely used in speech recognition and DNA modelling. We have found that hidden Markov models are very suitable for ECG recognition and analysis problems and that they are able to model accurately segmented ECG signals.	Artificial Inte	medical
4183	Artificial Intelligence in Medicine	Machine learning in prognosis of the femoral neck fracture recovery.	Matjaz Kukar,Igor Kononenko,T. Silvester	1996	We compare the performance of several machine learning algorithms in the problem of prognostics of the femoral neck fracture recovery: the K-nearest neighbours algorithm, the semi-naive Bayesian classifier, backpropagation with weight elimination learning of the multilayered neural networks, the LFC (lookahead feature construction) algorithm, and the Assistant-I and Assistant-R algorithms for top down induction of decision trees using information gain and RELIEFF as search heuristics, respectively. We compare the prognostic accuracy and the explanation ability of different classifiers. Among the different algorithms the semi-naive Bayesian classifier and Assistant-R seem to be the most appropriate. We analyze the combination of decisions of several classifiers for solving prediction problems and show that the combined classifier improves both performance and the explanation ability.	Artificial Inte	medical
4184	Artificial Intelligence in Medicine	Machine learning techniques in early screening for gastric and oesophageal cancer.	Wei Zhong Liu,Allan P. White,M. T. Hallissey,J. W. Fielding	1996	Machine learning techniques in early screening for gastric and oesophageal cancer.	Artificial Inte	medical
4185	Artificial Intelligence in Medicine	Temporal reasoning for diagnosis in a causal probabilistic knowledge base.	William J. Long	1996	Temporal reasoning for diagnosis in a causal probabilistic knowledge base.	Artificial Inte	medical
4186	Artificial Intelligence in Medicine	Utilizing temporal data abstraction for data validation and therapy planning for artificially ventilated newborn infants.	Silvia Miksch,Werner Horn,Christian Popow,Franz Paky	1996	Utilizing temporal data abstraction for data validation and therapy planning for artificially ventilated newborn infants.	Artificial Inte	medical
4187	Artificial Intelligence in Medicine	Synthesis of an anaesthetic agent administration system using fuzzy inductive reasoning.	Àngela Nebot,François E. Cellier,Derek A. Linkens	1996	Synthesis of an anaesthetic agent administration system using fuzzy inductive reasoning.	Artificial Inte	medical
4188	Artificial Intelligence in Medicine	A computerized induction analysis of possible co-variations among different elements in human tooth enamel.	T. Nilsson,T. Lundgren,H. Odelius,R. Sillen,J. G. Noren	1996	A computerized induction analysis of possible co-variations among different elements in human tooth enamel.	Artificial Inte	medical
4189	Artificial Intelligence in Medicine	Evaluation of automatic knowledge acquisition techniques in the diagnosis of acute abdominal pain - Acute Abdominal Pain Study Group.	Christian Ohmann,Vassilis Moustakis,Q. Yang,Konrad Lang	1996	Evaluation of automatic knowledge acquisition techniques in the diagnosis of acute abdominal pain - Acute Abdominal Pain Study Group.	Artificial Inte	medical
4190	Artificial Intelligence in Medicine	Learning temporal probabilistic causal models from longitudinal data.	Alberto Riva,Riccardo Bellazzi	1996	Learning temporal probabilistic causal models from longitudinal data.	Artificial Inte	medical
4191	Artificial Intelligence in Medicine	An intelligent system for the diagnosis of complex images.	Ovidio Salvetti,Giovanni Braccini,R. Evangelista,M. Freschi	1996	An intelligent system for the diagnosis of complex images.	Artificial Inte	medical
4192	Artificial Intelligence in Medicine	Extracting rules from pruned networks for breast cancer diagnosis.	Rudy Setiono	1996	Extracting rules from pruned networks for breast cancer diagnosis.	Artificial Inte	medical
4193	Artificial Intelligence in Medicine	Knowledge-based temporal abstraction in clinical domains.	Yuval Shahar,Mark A. Musen	1996	Knowledge-based temporal abstraction in clinical domains.	Artificial Inte	medical
4194	Artificial Intelligence in Medicine	Introducing spatio-temporal reasoning into the inverse problem in electroencephalography.	Pridi Siregar,Jean-Paul Sinteff	1996	Introducing spatio-temporal reasoning into the inverse problem in electroencephalography.	Artificial Inte	medical
4195	Artificial Intelligence in Medicine	The interpretation of time-varying data with DIAMON-1.	Friedrich Steimann	1996	The interpretation of time-varying data with DIAMON-1.	Artificial Inte	medical
4196	Artificial Intelligence in Medicine	Structure discovery in medical databases: a conceptual clustering approach.	F. A. da Veiga	1996	Clustering is an important data analysis tool for discovering structure in data sets. Although research on conceptual clustering has produced algorithms showing significant advantages over earlier numerical ones, existing methods still present some limitations regarding applicability to biomedical domains. In this paper we describe ADAGIO, a conceptual clustering algorithm combining a low-cost preordering process with a breadth-first incremental control strategy that incorporates merging and splitting operators. Experimental evaluation indicated that the algorithm achieves a good balance between structure discovery performance and computational efficiency, and demonstrated the comparative effectiveness of its missing information handling process. ADAGIO is able to handle qualitative, quantitative and mixed-type data. An application example to a cancer domain is given, where the algorithm was able to suggest interesting epidemiological interpretations.	Artificial Inte	medical
4197	FOCS	New Coding Techniques for Improved Bandwidth Utilization.	Micah Adler	1996	The introduction of parallel models that account for communication between processors has shown that interprocessor bandwidth is often the limiting factor in parallel computing. In this paper, we introduce a new coding technique for transmitting the XOR of carefully selected patterns of bits to be communicated which greatly reduces bandwidth requirements in some settings. This technique has broader applications. For example, we demonstrate that the coding technique has a surprising application to a simple I/O (Input/Output) complexity problem related to finding the transpose of a matrix. Our main results are developed in the PRAM(M) model, a limited bandwidth PRAM model where P processors communicate through a small globally shared memory of M bits. We provide new algorithms for the problems of sorting and permutation routing. For the concurrent read PRAM(M), as P grows with M held constant, our sorting algorithm outperforms any previous algorithm by O(logc P) for any constant c. The combination of a known lower bound for sorting in the exclusive read PRAM(M) model and this algorithm implies that the concurrent read PRAM(M) is strictly more powerful than the exclusive read PRAM(M).	FOCS	theory
4198	FOCS	Binary Search Partitions for Fat Rectangles.	Pankaj K. Agarwal,Edward F. Grove,T. M. Murali,Jeffrey Scott Vitter	1996	We consider the practical problem of constructing binary space partitions (BSPs) for a set S of n orthogonal, nonintersecting, two-dimensional rectangles in ${\Bbb R}^3$ such that the aspect ratio of each rectangle in $S$ is at most $\alpha$, for some constant $\alpha \geq 1$. We present an $n2^{O(\sqrt{\log n})}$-time algorithm to build a binary space partition of size $n2^{O(\sqrt{\log n})}$ for $S$. We also show that if $m$ of the $n$ rectangles in $S$ have aspect ratios greater than $\alpha$, we can construct a BSP of size $n\sqrt{m}2^{O(\sqrt{\log n})}$ for $S$ in $n\sqrt{m}2^{O(\sqrt{\log n})}$ time. The constants of proportionality in the big-oh terms are linear in $\log \alpha$. We extend these results to cases in which the input contains nonorthogonal or intersecting objects.	FOCS	theory
4199	FOCS	The Boolean Isomorphism Problem.	Manindra Agrawal,Thomas Thierauf	1996	The Boolean Isomorphism Problem.	FOCS	theory
4200	FOCS	Polynomial Simulations of Decohered Quantum Computers.	Dorit Aharonov,Michael Ben-Or	1996	Recently it has become clear, that a key issue in quantum computation is understanding how interaction with the environment, or decoherence, affects the computational power of quantum computers. We adopt the standard physical method of describing systems which are interwound with their environment by density matrices, and within this framework define a model of decoherence in quantum computation. Our results show that the computational power of decohered quantum computers depends strongly on the amount of parallelism in the computation. We first present a simulation of decohered sequential quantum computers, on a classical probabilistic Turing machine, and prove that the expected slowdown of this simulation is polynomial in time and space of the quantum computation, for any non zero decoherence rate. Similar results hold for quantum computers that are allowed to operate on logarithmic number of qubits at a time. For decohered quantum circuits (with local gates), the situation is more subtle and depends on the decoherence rate, /spl eta/. We find that our simulation is efficient for circuits with decoherence rate /spl eta/ higher than some constant /spl eta//sub 1/ but exponential for a general (random) circuit subjected to decoherence rate lower than some constant /spl eta//sub 2/. The transition from exponential cost to polynomial cost happens in a short range of decoherence rates. We use computer experiments to exhibit the phase transitions in various quantum circuits.	FOCS	theory
4201	FOCS	The Geometry of Coin-Weighing Problems.	Noga Alon,Dmitry N. Kozlov,Van H. Vu	1996	The Geometry of Coin-Weighing Problems.	FOCS	theory
4202	FOCS	Potential of the Approximation Method (extended abstract).	Kazuyuki Amano,Akira Maruoka	1996	Potential of the Approximation Method (extended abstract).	FOCS	theory
4203	FOCS	Tree Data Structures for N-Body Simulation.	Richard J. Anderson	1996	In this paper, we study data structures for use in N-body simulation. We concentrate on the spatial decomposition tree used in particle-cluster force evaluation algorithms such as the Barnes-Hut algorithm. We prove that a k-d tree is asymptotically inferior to a spatially balanced tree. We show that the worst case complexity of the force evaluation algorithm using a k-d tree is T(n log3 n log L) compared with T (n log L) for an oct-tree. (L is the separation ratio of the set of points.) We also investigate improving the constant factor of the algorithm, and present several methods which improve over the standard oct-tree decomposition. Finally, we consider whether or not the bounding box of a point set should be tight, and show that it is only safe to use tight bounding boxes for binary decompositions. The results are all directly applicable to practical implementations of N-body algorithms.	FOCS	theory
4204	FOCS	Faster Deterministic Sorting and Searching in Linear Space.	Arne Andersson	1996	We present a significant improvement on linear space deterministic sorting and searching. On a unit-cost RAM with word size w, an ordered set of n w-bit keys (viewed as binary strings or integers) can be maintained in O(min{[/spl radic/(logn)][logn/logw+loglogn][logwloglogn]}) time per operation, including insert, delete, member search, and neighbour search. The cost for searching is worst-case while the cost for updates is amortized. As an application, n keys can be sorted in linear at O(n/spl radic/(logn)) worst-case cost. The best previous method for deterministic sorting and searching in linear space has been the fusion trees which supports updates and queries in O(logn/loglogn) amortized time and sorting in O(nlogn/loglogn) worst-case time. We also make two minor observations on adapting our data structure to the input distribution and on the complexity of perfect hashing.	FOCS	theory
4205	FOCS	Static Dictionaries on AC RAMs: Query Time Theta(sqrt(log n/log log n)) is Necessary and Sufficient.	Arne Andersson,Peter Bro Miltersen,Søren Riis,Mikkel Thorup	1996	Static Dictionaries on AC RAMs: Query Time Theta(sqrt(log n/log log n)) is Necessary and Sufficient.	FOCS	theory
4206	FOCS	Universal Stability Results for Greedy Contention-Resolution Protocols.	Matthew Andrews,Baruch Awerbuch,Antonio Fernández,Jon M. Kleinberg,Frank Thomson Leighton,Zhiyong Liu	1996	Universal Stability Results for Greedy Contention-Resolution Protocols.	FOCS	theory
4207	FOCS	New Algorithms for the Disk Scheduling Problem.	Matthew Andrews,Michael A. Bender,Lisa Zhang	1996	Processor speed and memory capacity are increasing several times faster than disk speed. This disparity suggests that disk I/O performance will become an important bottleneck. Methods are needed for using disks more efficiently. Past analysis of disk scheduling algorithms has largely been experimental and little attempt has been made to develop algorithms with provable performance guarantees. We consider the following disk scheduling problem. Given a set of requests on a computer disk and a convex reachability function which determines how fast the disk head travels between tracks, our goal is to schedule the disk head so that it services all the requests in the shortest time possible. We present a 3/2-approximation algorithm (with a constant additive term). For the special case in which the reachability function is linear we present an optimal polynomial-time solution. The disk scheduling problem is related to the special case of the asymmetric Traveling Salesman Problem with the triangle inequality (ATSP-/spl Delta/) in which all distances are either 0 or some constant /spl alpha/. We show how to find the optimal tour in polynomial time and describe how this gives another approximation algorithm for the disk scheduling problem. Finally we consider the on-line version of the problem in which uniformly-distributed requests arrive over time. We present an algorithm (related to the above ATSP-/spl Delta/) that appears to give higher throughput than previously existing head scheduling algorithms.	FOCS	theory
4208	FOCS	Optimal Dynamic Interval Management in External Memory (extended abstract).	Lars Arge,Jeffrey Scott Vitter	1996	Optimal Dynamic Interval Management in External Memory (extended abstract).	FOCS	theory
4209	FOCS	Discrepancy Sets and Pseudorandom Generators for Combinatorial Rectangles.	Roy Armoni,Michael E. Saks,Avi Wigderson,Shiyu Zhou	1996	A common subproblem of DNF approximate counting and derandomizing RL is the discrepancy problem for combinatorial rectangles. We explicitly construct a poly(n)-size sample space that approximates the volume of any combinatorial rectangle in [n]/sup n/ to within o(1) error. The construction extends the previous techniques for the analogous hitting set problem, most notably via discrepancy preserving reductions.	FOCS	theory
4210	FOCS	Polynomial Time Approximation Schemes for Euclidean TSP and Other Geometric Problems.	Sanjeev Arora	1996	We present a polynomial time approximation scheme for Euclidean TSP in /spl Rfr//sup 2/. Given any n nodes in the plane and /spl epsiv/>0, the scheme finds a (1+/spl epsiv/)-approximation to the optimum traveling salesman tour in time n/sup 0(1//spl epsiv/)/. When the nodes are in /spl Rfr//sup d/, the running time increases to n(O/spl tilde/(log/sup d-2/n)//spl epsiv//sup d-1/) The previous best approximation algorithm for the problem (due to Christofides (1976)) achieves a 3/2-approximation in polynomial time. We also give similar approximation schemes for a host of other Euclidean problems, including Steiner Tree, k-TSP, Minimum degree-k, spanning tree, k-MST, etc. (This list may get longer; our techniques are fairly general.) The previous best approximation algorithms for all these problems achieved a constant-factor approximation. All our algorithms also work, with almost no modification, when distance is measured using any geometric norm (such as l/sub p/ for p/spl ges/1 or other Minkowski norms).	FOCS	theory
4211	FOCS	A New Rounding Procedure for the Assignment Problem with Applications to Dense Graph Arrangement Problems.	Sanjeev Arora,Alan M. Frieze,Haim Kaplan	1996	A New Rounding Procedure for the Assignment Problem with Applications to Dense Graph Arrangement Problems.	FOCS	theory
4212	FOCS	Fault Tolerant Data Structures.	Yonatan Aumann,Michael A. Bender	1996	The authors consider the tolerance of data structures to memory faults. They observe that many pointer-based data structures (e.g. linked lists, trees, etc.) are highly nonresilient to faults. A single fault in a linked list or tree may result in the loss of the entire set of data. They present a formal framework for studying the fault tolerance properties of pointer-based data structures, and provide fault tolerant versions of the stack, the linked list, and the dictionary tree.	FOCS	theory
4213	FOCS	Probabilistic Approximations of Metric Spaces and Its Algorithmic Applications.	Yair Bartal	1996	This paper provides a novel technique for the analysis of randomized algorithms for optimization problems on metric spaces, by relating the randomized performance ratio for any, metric space to the randomized performance ratio for a set of simple metric spaces. We define a notion of a set of metric spaces that probabilistically-approximates another metric space. We prove that any metric space can be probabilistically-approximated by hierarchically well-separated trees (HST) with a polylogarithmic distortion. These metric spaces are simple as being: (1) tree metrics; (2) natural for applying a divide-and-conquer algorithmic approach. The technique presented is of particular interest in the context of on-line computation. A large number of on-line algorithmic problems, including metrical task systems, server problems, distributed paging, and dynamic storage rearrangement are defined in terms of some metric space. Typically for these problems, there are linear lower bounds on the competitive ratio of deterministic algorithms. Although randomization against an oblivious adversary has the potential of overcoming these high ratios, very little progress has been made in the analysis. We demonstrate the use of our technique by obtaining substantially improved results for two different on-line problems.	FOCS	theory
4214	FOCS	Simplified and Improved Resolution Lower Bounds.	Paul Beame,Toniann Pitassi	1996	We give simple new lower bounds on the lengths of resolution proofs for the pigeonhole principle and for randomly generated formulas. For random formulas, our bounds significantly extend the range of formula sizes for which non-trivial lower bounds are known. For example, we show that with probability approaching 1, any resolution refutation of a randomly chosen 3-CNF formula with at most n/sup 6/5-/spl epsiv// clauses requires exponential size. Previous bounds applied only when the number of clauses was at most linear in the number of variables. For the pigeonhole principle our bound is a small improvement over previous bounds. Our proofs are more elementary than previous arguments, and establish a connection between resolution proof size and maximum clause size.	FOCS	theory
4215	FOCS	On the Applications of Multiplicity Automata in Learning.	Amos Beimel,Francesco Bergadano,Nader H. Bshouty,Eyal Kushilevitz,Stefano Varricchio	1996	On the Applications of Multiplicity Automata in Learning.	FOCS	theory
4216	FOCS	Pseudorandom Functions Revisited: The Cascade Construction and Its Concrete Security.	Mihir Bellare,Ran Canetti,Hugo Krawczyk	1996	Pseudorandom function families are a powerful cryptographic primitive, yielding, in particular simple solutions for the main problems in private key cryptography. Their existence based on general assumptions (namely the existence of one-way functions) has been established. The authors investigate new ways of designing pseudorandom function families. The goal is to find constructions that are both efficient and secure, and thus eventually to bring the benefits of pseudorandom functions to practice. The basic building blocks in the design are certain limited versions of pseudorandom function families, called finite length input pseudorandom function families, for which very efficient realizations exist impractical cryptography. Thus rather than starting from one-way functions, they propose constructions of full-fledged pseudorandom function families from these limited ones. In particular they propose the cascade construction, and provide a concrete security analysis which relates the strength of the cascade to that of the underlying finite pseudorandom function family in a precise and quantitative way.	FOCS	theory
4217	FOCS	A Polynomial-Time Algorithm for Learning Noisy Linear Threshold Functions.	Avrim Blum,Alan M. Frieze,Ravi Kannan,Santosh Vempala	1996	A Polynomial-Time Algorithm for Learning Noisy Linear Threshold Functions.	FOCS	theory
4218	FOCS	A General Approach to Dynamic Packet Routing with Bounded Buffers (extended abstract).	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1996	A General Approach to Dynamic Packet Routing with Bounded Buffers (extended abstract).	FOCS	theory
4219	FOCS	Approximating Minimum-Size k-Connected Spanning Subgraphs via Matching (extended abstract).	Joseph Cheriyan,Ramakrishna Thurimella	1996	Approximating Minimum-Size k-Connected Spanning Subgraphs via Matching (extended abstract).	FOCS	theory
4220	FOCS	Incoercible Multiparty Computation (extended abstract).	Ran Canetti,Rosario Gennaro	1996	Incoercible Multiparty Computation (extended abstract).	FOCS	theory
4221	FOCS	Approximate Option Pricing.	Prasad Chalasani,Somesh Jha,Isaac Saias	1996	Approximate Option Pricing.	FOCS	theory
4222	FOCS	Universal Data Compression and Portfolio Selection.	Thomas M. Cover	1996	The authors consider universal data compression, universal portfolio selection (online portfolio algorithms) and the relationship of both to information theory. Apparently the fundamental minimax redundancy game in data compression and the minimax regret game for the growth rate of wealth in investment have the same answer. There is also a duality between entropy rate and the growth rate of wealth.	FOCS	theory
4223	FOCS	The Optimal Path-Matching Problem.	William H. Cunningham,James F. Geelen	1996	We describe a common generalization of the weighted matching problem and the weighted matroid intersection problem. In this context we present results implying the polynomial-time solvability of the two problems. We also use our results to give the first strongly polynomial separation algorithm for the convex hull of matchable sets of a graph, and the first polynomial-time algorithm to compute the rank of a certain matrix of indeterminates. Our algorithmic results are based on polyhedral characterizations, and on the equivalence of separation and optimization.	FOCS	theory
4224	FOCS	All Pairs Almost Shortest Paths.	Dorit Dor,Shay Halperin,Uri Zwick	1996	Let G=(V,E) be an unweighted undirected graph on n vertices. A simple argument shows that computing all distances in G with an additive one-sided error of at most 1 is as hard as Boolean matrix multiplication. Building on recent work of Aingworth et al. [SIAM J. Comput., 28 (1999), pp. 1167--1181], we describe an $\Ot(\min\{n^{3/2}m^{1/2},n^{7/3}\})$-time algorithm APASP2 for computing all distances in G with an additive one-sided error of at most 2. Algorithm APASP2 is simple, easy to implement, and faster than the fastest known matrix-multiplication algorithm. Furthermore, for every even k>2, we describe an ${\tilde{O}}(\min\{n^{2-{2}/{(k+2)}}m^{{2}/{(k+2)}}, n^{2+{2}/{(3k-2)}}\})$-time algorithm APASPk for computing all distances in G with an additive one-sided error of at most k. We also give an ${\tilde{O}}(n^2)$-time algorithm ${\bf APASP}_\infty$ for producing stretch 3 estimated distances in an unweighted and undirected graph on n vertices. No constant stretch factor was previously achieved in ${\tilde{O}}(n^2)$ time.We say that a weighted graph F=(V,E') k-emulates an unweighted graph G=(V,E) if for every $u,v\in V$ we have $\delta_G(u,v)\le \delta_F(u,v)\le \delta_G(u,v)+k$. We show that every unweighted graph on n vertices has a 2-emulator with ${\tilde{O}}(n^{3/2})$ edges and a 4-emulator with ${\tilde{O}}(n^{4/3})$ edges. These results are asymptotically tight.Finally, we show that any weighted undirected graph on n vertices has a 3-spanner with ${\tilde{O}}(n^{3/2})$ edges and that such a 3-spanner can be built in ${\tilde{O}}(mn^{1/2})$ time. We also describe an ${\tilde{O}}(n(m^{2/3}+n))$-time algorithm for estimating all distances in a weighted undirected graph on n vertices with a stretch factor of at most 3.	FOCS	theory
4225	FOCS	Median Selection Requires (2+epsilon)n Comparisons.	Dorit Dor,Uri Zwick	1996	Improving a long standing result of Bent and John [Proceedings of the 17th Annual ACM Symposium on Theory of Computing, Providence, RI, 1985, pp. 213--216], and extending a recent result of Dor, Håstad, Ulfberg, and Zwick [ SIAM J. Discrete Math., 14 (2001), pp. 299--311], we obtain a $(2{+}\epsilon)n$ lower bound (for some fixed $\epsilon>0$) on the number of comparisons required, in the worst case, for selecting the median of n elements.	FOCS	theory
4226	FOCS	A Decision Procedure for Unitary Linear Quantum Cellular Automata.	Christoph Dürr,Miklos Santha	1996	Linear quantum cellular automata were introduced recently as one of the models of quantum computing. A basic postulate of quantum mechanics imposes a strong constraint on any quantum machine: it has to be unitary; that is, its time evolution operator has to be a unitary transformation. In this paper we give an efficient algorithm to decide if a linear quantum cellular automaton is unitary. The complexity of the algorithm is O(n(3r-1)/(r+1)) = O(n3) in the algebraic computational model if the automaton has a continuous neighborhood of size r, where n is the size of the input.	FOCS	theory
4227	FOCS	Approximate Checking of Polynomials and Functional Equations (extended abstract).	Funda Ergün,Ravi Kumar,Ronitt Rubinfeld	1996	Approximate Checking of Polynomials and Functional Equations (extended abstract).	FOCS	theory
4228	FOCS	Better Lower Bounds for Halfspace Emptiness.	Jeff Erickson	1996	Better Lower Bounds for Halfspace Emptiness.	FOCS	theory
4229	FOCS	Efficient Information Gathering on the Internet (extended abstract).	Oren Etzioni,Steve Hanks,Tao Jiang,Richard M. Karp,Omid Madani,Orli Waarts	1996	Efficient Information Gathering on the Internet (extended abstract).	FOCS	theory
4230	FOCS	An 8-Approximation Algorithm for the Subset Feedback Vertex Set Problem.	Guy Even,Joseph Naor,Leonid Zosin	1996	An 8-Approximation Algorithm for the Subset Feedback Vertex Set Problem.	FOCS	theory
4231	FOCS	Learning Linear Transformations.	Alan M. Frieze,Mark Jerrum,Ravi Kannan	1996	Learning Linear Transformations.	FOCS	theory
4232	FOCS	The Regularity Lemma and Approximation Schemes for Dense Problems.	Alan M. Frieze,Ravi Kannan	1996	The Regularity Lemma and Approximation Schemes for Dense Problems.	FOCS	theory
4233	FOCS	A 3-Approximation for the Minimum Tree Spanning k Vertices.	Naveen Garg	1996	In this paper we give a 3-approximation algorithm for the problem of finding a minimum tree spanning any k-vertices in a graph. Our algorithm extends to a 3-approximation algorithm for the minimum tour that visits any k-vertices.	FOCS	theory
4234	FOCS	Property Testing and Its Connection to Learning and Approximation.	Oded Goldreich,Shafi Goldwasser,Dana Ron	1996	In this paper, we consider the question of determining whether a function f has property P or is &egr;-far from any function with property P. A property testing algorithm is given a sample of the value of f on instances drawn according to some distribution. In some cases, it is also allowed to query f on instances of its choice. We study this question for different properties and establish some connections to problems in learning theory and approximation.In particular, we focus our attention on testing graph properties. Given access to a graph G in the form of being able to query whether an edge exists or not between a pair of vertices, we devise algorithms to test whether the underlying graph has properties such as being bipartite, k-Colorable, or having a p-Clique (clique of density p with respect to the vertex set). Our graph property testing algorithms are probabilistic and make assertions that are correct with high probability, while making a number of queries that is independent of the size of the graph. Moreover, the property testing algorithms can be used to efficiently (i.e., in time linear in the number of vertices) construct partitions of the graph that correspond to the property being tested, if it holds for the input graph.	FOCS	theory
4235	FOCS	Equivalence in Finite-Variable Logics is Complete for Polynomial Time.	Martin Grohe	1996	How difficult is it to decide whether two finite structures can be distinguished in a given logic? For first order logic, this question is equivalent to the graph isomorphism problem with its well-known complexity theoretic difficulties. Somewhat surprisingly, the situation is much clearer when considering the fragments L/sup k/ of first-order logic whose formulae contain at most k (free or bound) variables (for some k/spl ges/1). We show that for each k/spl ges/2, equivalence in the k-variable logic L/sup k/ is complete for polynomial time under quantifier-free reductions (a weak form of NC/sub 0/ reductions). Moreover, we show that the same completeness result holds for the powerful extension C/sup k/ of L/sup k/ with counting quantifiers (for every k/spl ges/2).	FOCS	theory
4236	FOCS	Deterministic Routing with Bounded Buffers: Turning Offline into Online Protocols.	Friedhelm Meyer auf der Heide,Christian Scheideler	1996	Deterministic Routing with Bounded Buffers: Turning Offline into Online Protocols.	FOCS	theory
4237	FOCS	Computing Vertex Connectivity: New Bounds from Old Techniques.	Monika Rauch Henzinger,Satish Rao,Harold N. Gabow	1996	Computing Vertex Connectivity: New Bounds from Old Techniques.	FOCS	theory
4238	FOCS	Clique is Hard to Approximate Within n.	Johan Håstad	1996	Clique is Hard to Approximate Within n.	FOCS	theory
4239	FOCS	Solving Systems of Polynomial Congruences Modulo a Large Prime (extended abstract).	Ming-Deh A. Huang,Yiu-Chung Wong	1996	Solving Systems of Polynomial Congruences Modulo a Large Prime (extended abstract).	FOCS	theory
4240	FOCS	Sampling According to the Multivariate Normal Density.	Ravi Kannan,Guangxing Li	1996	This paper deals with the normal density of n dependent random variables. This is a function of the form: ce(-x/sup T/Ax) where A is an n/spl times/n positive definite matrix, a: is the n-vector of the random variables and c is a suitable constant. The first problem we consider is the (approximate) evaluation of the integral of this function over the positive orthant /spl int/(x/sub 1/=0)/sup /spl infin///spl int/(x/sub 2/=0)/sup /spl infin///spl middot//spl middot//spl middot//spl int/(x/sub n/=0)/sup /spl infin//ce(-x/sup T/Ax). This problem has a long history and a substantial literature. Related to it is the problem of drawing a sample from the positive orthant with probability density (approximately) equal to ce(-x/sup T/Ax). We solve both these problems here in polynomial time using rapidly mixing Markov Chains. For proving rapid convergence of the chains to their stationary distribution, we use a geometric property called the isoperimetric inequality. Such an inequality has been the subject of recent papers for general log-concave functions. We use these techniques, but the main thrust of the paper is to exploit the special property of the normal density to prove a stronger inequality than for general log-concave functions. We actually consider first the problem of drawing a sample according to the normal density with A equal to the identity matrix from a convex set K in R/sup n/ which contains the unit ball. This problem is motivated by the problem of computing the volume of a convex set in a way we explain later. Also, the methods used in the solution of this and the orthant problem are similar.	FOCS	theory
4241	FOCS	Approximate Strip Packing.	Claire Kenyon,Eric Rémila	1996	Approximate Strip Packing.	FOCS	theory
4242	FOCS	Near-Optimal Parallel Prefetching and Caching.	Tracy Kimbrel,Anna R. Karlin	1996	Recently there has been a great deal of interest in the operating systems research community in prefetching and caching data from parallel disks, as a technique for enabling serial applications to improve input--output (I/O) performance. In this paper, algorithms are considered for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). The integration of caching and prefetching with a single disk was previously considered by Cao, Felten, Karlin, and Li. Here, it is shown that the natural extension of their aggressive algorithm to the parallel disk case is suboptimal by a factor near the number of disks in the worst case. The main result is a new algorithm, reverse aggressive, with near-optimal performance for integrated prefetching and caching in the presence of multiple disks.	FOCS	theory
4243	FOCS	Single-Source Unsplittable Flow.	Jon M. Kleinberg	1996	The max-flow min-cut theorem of Ford and Fulkerson is based on an even more foundational result, namely Menger's theorem on graph connectivity Menger's theorem provides a good characterization for the following single-source disjoint paths problem: given a graph G, with a source vertex s and terminals t1,...,tk, decide whether there exist edge-disjoint s-ti paths for i=1,...,k.We consider a natural, NP-hard generalization of this problem, which we call the single-source unsplittable flow problem. We are given a source and terminals as before; but now each terminal ti has a demand pi = 1, and each edge e of G has a capacity ce = 1. The problem is to decide whether one can choose a single s-ti path for each i, so that the resulting set of paths respects the capacity constraints-the total amount of demand routed across any edge e must be bounded by the capacity ce. The main results of this paper are constant-factor approximation algorithms for three natural optimization versions of this problem, in arbitrary directed and undirected graphs. The development of these algorithms requires a number of new techniques for rounding fractional solutions to network flow problems; for two of the three problems we consider, there were no previous techniques capable of providing an approximation in the general case, and for the third, the randomized rounding algorithm of Raghavan and Thompson provides a logarithmic approximation. Our techniques are also of interest from the perspective of a family of NP-hard load balancing and machine scheduling problems that can be reduced to the single-source unsplittable flow problem.	FOCS	theory
4244	FOCS	Short Paths in Expander Graphs.	Jon M. Kleinberg,Ronitt Rubinfeld	1996	Graph expansion has proved to be a powerful general tool for analyzing the behavior of routing algorithms and the inter-connection networks on which they run. We develop new routing algorithms and structural results for bounded-degree expander graphs. Our results are unified by the fact that they are all based upon, and extend, a body of work: asserting that expanders are rich in short, disjoint paths. In particular, our work has consequences for the disjoint paths problem, multicommodity flow, and graph minor containment. We show:(i) A greedy algorithm for approximating the maximum disjoint paths problem achieves a polylogarithmic approximation ratio in bounded-degree expanders. Although our algorithm is both deterministic and on-line, its performance guarantee is an improvement over previous bounds in expanders. (ii) For a multicommodity flow problem with arbitrary demands on a bounded-degree expander there is a (1 + )-optimal solution using only flow paths of polylogarithmic length. It follows that the multicommodity flow algorithm of Awerbuch and Leighton runs in nearly linear time per commodity in expanders. Our analysis is based on establishing the following: given edge weights on an expander G, one can increase some of the weights very slightly so the resulting shortest-path metric is smooth-the min-weight path between any pair of nodes uses a polylogarithmic number of edges. (iii) Every bounded-degree expander on n nodes contains every graph with O(n/log0(1) n) nodes and edges as a minor.	FOCS	theory
4245	FOCS	Efficient Self-Testing/Self-Correction of Linear Recurrences.	Ravi Kumar,D. Sivakumar	1996	Efficient Self-Testing/Self-Correction of Linear Recurrences.	FOCS	theory
4246	FOCS	Computing Permanents over Fields of Characteristic 3: Where and Why It Becomes Difficult (extended abstract).	Grigory Kogan	1996	Computing Permanents over Fields of Characteristic 3: Where and Why It Becomes Difficult (extended abstract).	FOCS	theory
4247	FOCS	Factoring Graphs to Bound Mixing Rates.	Neal Madras,Dana Randall	1996	This paper develops a new technique for bounding the mixing rate of a Markov chain by decomposing the state space into factors. The first application is an efficient Monte Carlo Markov chain algorithm for generating random three-colorings of 2-dimensional lattice regions. This provides a rigorous tool for studying some properties of the 3-state Potts model and the ice model from statistical mechanics. As a second application, we develop similar techniques to bound the mixing rate of a Metropolis sampling algorithm by a type of temperature factorization. Both factorization theorems work by using known mixing properties of related Markov chains to establish the efficiency of a new sampling algorithm.	FOCS	theory
4248	FOCS	Load Balancing and Density Dependent Jump Markov Processes (extended abstract).	Michael Mitzenmacher	1996	Load Balancing and Density Dependent Jump Markov Processes (extended abstract).	FOCS	theory
4249	FOCS	On the Knowledge Complexity of NP.	Erez Petrank,Gábor Tardos	1996	On the Knowledge Complexity of NP.	FOCS	theory
4250	FOCS	Fast Fault-Tolerant Concurrent Access to Shared Objects.	C. Greg Plaxton,Rajmohan Rajaraman	1996	We consider a synchronous model of distributed computation in which n nodes communicate via point-to-point messages, subject to the following constraints: (i) in a single step, a node can only send or receive log n words, and (ii) communication is unreliable in that a constant fraction of all messages may be lost at each step due to node and/or link failures. We design and analyze a simple local protocol for providing fast concurrent access to shared objects in this faulty network environment. In our protocol, clients use a hashing-based method to access shared objects. When a large number of clients attempt to read a given object at the same time, the object is rapidly replicated to an appropriate number of servers. Once the necessary level of replication has been achieved, each remaining request for the object is serviced within O (1) expected steps. Our protocol has practical potential for supporting high levels of concurrency in distributed file systems over wide area networks.	FOCS	theory
4251	FOCS	Path Coloring on the Mesh.	Yuval Rabani	1996	In the minimum path coloring problem, we are given a list of pairs of vertices of a graph. We are asked to connect each pair by a colored path. Paths of the same color must be edge disjoint. Our objective is to minimize the number of colors used. This problem was raised by A. Aggarwal et al. (1994) and P. Raghavan and E. Upfal (1994) as a model for routing in all-optical networks. It is also related to questions in circuit routing. In this paper, we improve the O(ln N) approximation result of J. Kleinberg and E. Tardos (1995) for path coloring on the N/spl times/N mesh. We give an O(1) approximation algorithm to the number of colors needed, and a poly(ln ln N) approximation algorithm to the choice of paths and colors. To the best of our knowledge, these are the first sub-logarithmic bounds for any network other than trees, rings, or trees of rings. Our results are based on developing new techniques for randomized rounding. These techniques iteratively improve a fractional solution until it approaches integrality. They are motivated by the method used by F.T. Leighton, B.M. Maggs, and S.B. Rao (1994) for packet routing.	FOCS	theory
4252	FOCS	Computationally Hard Algebraic Problems (extended abstract).	Michael O. Rabin	1996	Computationally Hard Algebraic Problems (extended abstract).	FOCS	theory
4253	FOCS	Verifying Identities (extended abstract).	Sridhar Rajagopalan,Leonard J. Schulman	1996	Verifying Identities (extended abstract).	FOCS	theory
4254	FOCS	Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm (extended abstract).	Süleyman Cenk Sahinalp,Uzi Vishkin	1996	Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm (extended abstract).	FOCS	theory
4255	FOCS	Fault-Tolerant Quantum Computation.	Peter W. Shor	1996	It has recently been realized that use of the properties of quantum mechanics might speed up certain computations dramatically. Interest in quantum computation has since been growing. One of the main difficulties in realizing quantum computation is that decoherence tends to destroy the information in a superposition of states in a quantum computer making long computations impossible. A further difficulty is that inaccuracies in quantum state transformations throughout the computation accumulate, rendering long computations unreliable. However, these obstacles may not be as formidable as originally believed. For any quantum computation with t gates, we show how to build a polynomial size quantum circuit that tolerates O(1/logc t) amounts of inaccuracy and decoherence per gate, for some constant c; the previous bound was O(1/t). We do this by showing that operations can be performed on quantum data encoded by quantum error-correcting codes without decoding this data.	FOCS	theory
4256	FOCS	Highly Fault-Tolerant Parallel Computation (extended abstract).	Daniel A. Spielman	1996	Highly Fault-Tolerant Parallel Computation (extended abstract).	FOCS	theory
4257	FOCS	Spectral Partitioning Works: Planar Graphs and Finite Element Meshes.	Daniel A. Spielman,Shang-Hua Teng	1996	Spectral partitioning methods use the Fiedler vector---the eigenvector of the second-smallest eigenvalue of the Laplacian matrix---to find a small separator of a graph. These methods are important components of many scientific numerical algorithms and have been demonstrated by experiment to work extremely well. In this paper, we show that spectral partitioning methods work well on bounded-degree planar graphs and finite element meshes--- the classes of graphs to which they are usually applied. While naive spectral bisection does not necessarily work, we prove that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is $\O{\sqrt{n}}$ for bounded-degree planar graphs and two-dimensional meshes and $\O{n^{1/d}}$ for well-shaped $d$-dimensional meshes. The heart of our analysis is an upper bound on the second-smallest eigenvalues of the Laplacian matrices of these graphs.	FOCS	theory
4258	FOCS	Maximum Likelihood Decoding of Reed Solomon Codes.	Madhu Sudan	1996	Maximum Likelihood Decoding of Reed Solomon Codes.	FOCS	theory
4259	FOCS	Temporal Logic and Semidirect Products: An Effective Characterization of the Until Hierarchy.	Denis Thérien,Thomas Wilke	1996	We reveal an intimate connection between semidirect products of finite semigroups and substitution of formulas in linear temporal logic. We use this connection to obtain an algebraic characterization of the until hierarchy of linear temporal logic. (The kth level of that hierarchy is comprised of all temporal properties that are expressible by a formula of nesting depth k in the until operator.) Applying deep results from finite semigroup theory we are able to prove that each level of the until hierarchy is decidable. By means of Ehrenfeucht--Fraissé games, we extend the results from linear temporal logic over finite sequences to linear temporal logic over infinite sequences.	FOCS	theory
4260	FOCS	Gadgets, Approximation, and Linear Programming (extended abstract).	Luca Trevisan,Gregory B. Sorkin,Madhu Sudan,David P. Williamson	1996	Gadgets, Approximation, and Linear Programming (extended abstract).	FOCS	theory
4261	FOCS	An Efficient Algorithm for Constructing Minimal Trellises for Codes over Finite Abelian Groups.	Vijay V. Vazirani,Huzur Saran,B. Sundar Rajan	1996	An Efficient Algorithm for Constructing Minimal Trellises for Codes over Finite Abelian Groups.	FOCS	theory
4262	FOCS	37th Annual Symposium on Foundations of Computer Science, FOCS '96, Burlington, Vermont, USA, 14-16 October, 1996		1996	37th Annual Symposium on Foundations of Computer Science, FOCS '96, Burlington, Vermont, USA, 14-16 October, 1996	FOCS	theory
4263	SODA	Fast Estimation of Diameter and Shortest Paths (without Matrix Multiplication).	Donald Aingworth,Chandra Chekuri,Rajeev Motwani	1996	Fast Estimation of Diameter and Shortest Paths (without Matrix Multiplication).	SODA	theory
4264	SODA	Efficient Generation of k-Directional Assembly Sequences.	Pankaj K. Agarwal,Mark de Berg,Dan Halperin,Micha Sharir	1996	Efficient Generation of k-Directional Assembly Sequences.	SODA	theory
4265	SODA	On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics).	Richa Agarwala,Vineet Bafna,Martin Farach,Babu O. Narayanan,Mike Paterson,Mikkel Thorup	1996	On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics).	SODA	theory
4266	SODA	An Empirical Study of Dynamic Graph Algorithms (Extended Abstract).	David Alberts,Giuseppe Cattaneo,Giuseppe F. Italiano	1996	An Empirical Study of Dynamic Graph Algorithms (Extended Abstract).	SODA	theory
4267	SODA	Optimization Problems Related to Zigzag Pocket Machining (Extended Abstract).	Esther M. Arkin,Martin Held,Christopher L. Smith	1996	Optimization Problems Related to Zigzag Pocket Machining (Extended Abstract).	SODA	theory
4268	SODA	Polynomial-Time Solutions to Image Segmentation.	Tetsuo Asano,Danny Z. Chen,Naoki Katoh,Takeshi Tokuyama	1996	Polynomial-Time Solutions to Image Segmentation.	SODA	theory
4269	SODA	On-line Generalized Steiner Problem.	Baruch Awerbuch,Yossi Azar,Yair Bartal	1996	The generalized Steiner problem (GSP) is defined as follows. We are given a graph with non-negative edge weights and a set of pairs of vertices. The algorithm has to construct minimum weight subgraph such that the two nodes of each pair are connected by a path.Off-line GSP approximation algorithms were given in Agarwal et al. (SIAM J. Comput. 24(3) (1995) 440) and Goemans and Williamson (SIAM J. Comput. 24(2) (1995) 296). We consider the on-line GSP, in which pairs of vertices arrive on-line and are needed to be connected immediately.We show that the online Min-Cost (i.e. greedy) strategy for this problem has O(log2 n) competitive ratio. The previous best algorithm was O(√nlog n) competitive (Workshop on Algorithms and Data Structures, 1993, pp. 622-633). Following this work a different (non-greedy) algorithm has been shown to achieve an O(log n) competitive ratio (Proceedings of the 29th ACM Symposium on Theory of Computing, 1997, pp. 344-353).We also consider the network connectivity leasing problem which is a generalization of the GSP. Here, edges of the graph can be either bought or leased for different costs. We provide simple randomized algorithm based on on-line generalized Steiner algorithms whose competitive ratio is within a constant factor of the best competitive algorithm for the on-line GSP.	SODA	theory
4270	SODA	Distributed Paging for General Networks.	Baruch Awerbuch,Yair Bartal,Amos Fiat	1996	Distributed Paging for General Networks.	SODA	theory
4271	SODA	Multiplicative Equations over Commuting Matrices.	László Babai,Robert Beals,Jin-yi Cai,Gábor Ivanyos,Eugene M. Luks	1996	We consider the solvability of the equation A_1^x_1 * ... * X_k^x_k = B and generalizations, where the A_i and B are given commuting matrices over an algebraic number field F. In the semigroup membership problem, the variables x_i are constrained to be nonnegative integers. While this problem is NP-complete for variable k, we give a polynomial time algorithm if k is fixed. In the group membership problem, the matrices are assumed to be invertible, and the variables x_i may take on negative values. In this case we give a polynomial time algorithm for variable k and give an explicit description of the set of all solutions (as an affine lattice). The results generalize recent work of Cai, Lipton, and Zalcstein [CLZ] where the case k=2 is solved using Jordan Normal Forms (JNF). We achieve greater clarity simplicity, and generality by eliminating the use of JNF''s and referring to elementary concepts of the structure theory of algebras instead (notably, the radical and the local decomposition. Partial solutions are combined using algorithms for (affine lattices. The special case of 1*1 matrices was recently solved by G. Ge and we heavily rely on his results.	SODA	theory
4272	SODA	Multiprocessor Scheduling with Rejection.	Yair Bartal,Stefano Leonardi,Alberto Marchetti-Spaccamela,Jiri Sgall,Leen Stougie	1996	We consider a version of multiprocessor scheduling with the special feature that jobs may be rejected at a certain penalty. An instance of the problem is given by $m$ identical parallel machines and a set of $n$ jobs, with each job characterized by a processing time and a penalty. In the on-line version the jobs become available one by one and we have to schedule or reject a job before we have any information about future jobs. The objective is to minimize the makespan of the schedule for accepted jobs plus the sum of the penalties of rejected jobs.The main result is a $1+\phi\approx 2.618$ competitive algorithm for the on-line version of the problem, where $\phi$ is the golden ratio. A matching lower bound shows that this is the best possible algorithm working for all $m$. For fixed $m$ we give improved bounds; in particular, for $m=2$ we give a $\phi\approx 1.618$ competitive algorithm, which is best possible.For the off-line problem we present a fully polynomial approximation scheme for fixed $m$ and a polynomial approximation scheme for arbitrary $m$. Moreover, we present an approximation algorithm which runs in time $O(n\log n)$ for arbitrary $m$ and guarantees a $2-\frac{1}{m}$ approximation ratio.	SODA	theory
4273	SODA	Randomized Robot Navigation Algorithms.	Piotr Berman,Avrim Blum,Amos Fiat,Howard J. Karloff,Adi Rosén,Michael E. Saks	1996	Randomized Robot Navigation Algorithms.	SODA	theory
4274	SODA	The Complexity of Flat Origami.	Marshall W. Bern,Barry Hayes	1996	The Complexity of Flat Origami.	SODA	theory
4275	SODA	Worst-Case Efficient Priority Queues.	Gerth Stølting Brodal	1996	Worst-Case Efficient Priority Queues.	SODA	theory
4276	SODA	An Efficient Algorithm for the Vertex-Disjoint Paths Problem in Random Graphs.	Andrei Z. Broder,Alan M. Frieze,Stephen Suen,Eli Upfal	1996	An Efficient Algorithm for the Vertex-Disjoint Paths Problem in Random Graphs.	SODA	theory
4277	SODA	Selecting Training Inputs via Greedy Rank Covering.	Adam L. Buchsbaum,Jan P. H. van Santen	1996	Selecting Training Inputs via Greedy Rank Covering.	SODA	theory
4278	SODA	A Better Approximation Algorithm for Finding Planar Subgraphs.	Gruia Calinescu,Cristina G. Fernandes,Ulrich Finkler,Howard J. Karloff	1996	A Better Approximation Algorithm for Finding Planar Subgraphs.	SODA	theory
4279	SODA	Isomorphism Testing and Display of Symmetries in Dynamic Trees.	Siu-Wing Cheng,Moon-Pun Ng	1996	Isomorphism Testing and Display of Symmetries in Dynamic Trees.	SODA	theory
4280	SODA	Improving Biconnectivity Approximation via Local Optimization.	Ka Wong Chong,Tak Wah Lam	1996	Improving Biconnectivity Approximation via Local Optimization.	SODA	theory
4281	SODA	Efficient Suffix Trees on Secondary Storage (extended Abstract).	David R. Clark,J. Ian Munro	1996	Efficient Suffix Trees on Secondary Storage (extended Abstract).	SODA	theory
4282	SODA	An O(n log n) Algorithm for the Maximum Agreement Subtree Problem for Binary Trees.	Richard Cole,Ramesh Hariharan	1996	An O(n log n) Algorithm for the Maximum Agreement Subtree Problem for Binary Trees.	SODA	theory
4283	SODA	Preemptive Scheduling of Parallel Jobs on Multiprocessors.	Xiaotie Deng,Nian Gu,Tim Brecht,KaiCheng Lu	1996	We study the problem of processor scheduling for n parallel jobs applying the method of competitive analysis. We prove that for jobs with a single phase of parallelism, a preemptive scheduling algorithm without information about job execution time can achieve a mean completion time within $2-{2\over n+1}$ times the optimum. In other words, we prove a competitive ratio of $2-{2\over n+1}$. The result is extended to jobs with multiple phases of parallelism (which can be used to model jobs with sublinear speedup) and to interactive jobs (with phases during which the job has no CPU requirements) to derive solutions guaranteed to be within $4-{4\over n+1}$ times the optimum. In comparison with previous work, our assumption that job execution times are unknown prior to their completion is more realistic, our multiphased job model is more general, and our approximation ratio (for jobs with a single phase of parallelism) is tighter and cannot be improved. While this work presents theoretical results obtained using competitive analysis, we believe that the results provide insight into the performance of practical multiprocessor scheduling algorithms that operate in the absence of complete information.	SODA	theory
4284	SODA	Optimal Placement of Convex Polygons to Maximize Point Containment.	Matthew Dickerson,Daniel Scharstein	1996	Optimal Placement of Convex Polygons to Maximize Point Containment.	SODA	theory
4285	SODA	Fast String Searching in Secondary Storage: Theoretical Developments And Experimental Results.	Paolo Ferragina,Roberto Grossi	1996	Fast String Searching in Secondary Storage: Theoretical Developments And Experimental Results.	SODA	theory
4286	SODA	Increasing the Weight of Minimum Spanning Trees.	Greg N. Frederickson,Roberto Solis-Oba	1996	Increasing the Weight of Minimum Spanning Trees.	SODA	theory
4287	SODA	Fully Dynamic Output Bounded Single Source Shortest Path Problem (Extended Abstract).	Daniele Frigioni,Alberto Marchetti-Spaccamela,Umberto Nanni	1996	Fully Dynamic Output Bounded Single Source Shortest Path Problem (Extended Abstract).	SODA	theory
4288	SODA	Perfect Arborescence Packing in Preflow Mincut Graphs.	Harold N. Gabow	1996	Perfect Arborescence Packing in Preflow Mincut Graphs.	SODA	theory
4289	SODA	An Improved Approximation Ratio for the Minimum Latency Problem.	Michel X. Goemans,Jon M. Kleinberg	1996	An Improved Approximation Ratio for the Minimum Latency Problem.	SODA	theory
4290	SODA	Analysis of Practical Backoff Protocols for Contention Resolution with Multiple Servers.	Leslie Ann Goldberg,Philip D. MacKenzie	1996	Analysis of Practical Backoff Protocols for Contention Resolution with Multiple Servers.	SODA	theory
4291	SODA	Limit Theorems for Minimum-Weight Triangulations, Other Euclidean Functionals, and Probabilistic Recurrence Relations (Extended Abstract).	Mordecai J. Golin	1996	Limit Theorems for Minimum-Weight Triangulations, Other Euclidean Functionals, and Probabilistic Recurrence Relations (Extended Abstract).	SODA	theory
4292	SODA	Fixed-Dimensional Parallel Linesr Programming via epsilon-Relative-Approximations.	Michael T. Goodrich	1996	Fixed-Dimensional Parallel Linesr Programming via epsilon-Relative-Approximations.	SODA	theory
4293	SODA	Scheduling to Minimize Average Completion Time: Off-line and On-line Algorithms.	Leslie A. Hall,David B. Shmoys,Joel Wein	1996	Scheduling to Minimize Average Completion Time: Off-line and On-line Algorithms.	SODA	theory
4294	SODA	Optimal randomized EREW PRAM Algorithms for Finding Spanning Forests and for other Basic Graph Connectivity Problems.	Shay Halperin,Uri Zwick	1996	Optimal randomized EREW PRAM Algorithms for Finding Spanning Forests and for other Basic Graph Connectivity Problems.	SODA	theory
4295	SODA	To Cut... or Not to Cut (Applications of Comparative Physical Maps in Molecular Evolution).	Sridhar Hannenhalli,Pavel A. Pevzner	1996	To Cut... or Not to Cut (Applications of Comparative Physical Maps in Molecular Evolution).	SODA	theory
4296	SODA	Constructing a Tree from Homeomorphic Subtrees, with Applications to Computational Evolutionary Biology.	Monika Rauch Henzinger,Valerie King,Tandy Warnow	1996	Constructing a Tree from Homeomorphic Subtrees, with Applications to Computational Evolutionary Biology.	SODA	theory
4297	SODA	Interpolation of Sparse Multivariate Polynomials over Large Finite Fields with Applications.	Ming-Deh A. Huang,Ashwin J. Rao	1996	Interpolation of Sparse Multivariate Polynomials over Large Finite Fields with Applications.	SODA	theory
4298	SODA	Scheduling with Conflicts, and Applications to Traffic Signal Control.	Sandy Irani,Vitus J. Leung	1996	Scheduling with Conflicts, and Applications to Traffic Signal Control.	SODA	theory
4299	SODA	A Capacity Scaling Algorithm for Convex Cost Submodular Flows.	Satoru Iwata	1996	A Capacity Scaling Algorithm for Convex Cost Submodular Flows.	SODA	theory
4300	SODA	Asymptotic Experimental Analysis for the Held-Karp Traveling Salesman Bound.	David S. Johnson,Lyle A. McGeoch,Edward E. Rothberg	1996	Asymptotic Experimental Analysis for the Held-Karp Traveling Salesman Bound.	SODA	theory
4301	SODA	Games, Computers, and O.R.	Ehud Kalai	1996	Games, Computers, and O.R.	SODA	theory
4302	SODA	Routing and Admission Control in General Topology Networks with Poisson Arrivals.	Anil Kamath,Omri Palmon,Serge A. Plotkin	1996	Emerging high speed networks will carry traffic for services such as video-on-demand and video teleconferencing -- that require resource reservation along the path on which the traffic is sent. High bandwidth-delay product of these networks prevents circuit rerouting, i.e. once a circuit is routed on a certain path, the bandwidth taken by this circuit remains unavailable for the duration (holding time) of this circuit. As a result, such networks will need effective routing and admission control strategies. Recently developed online routing and admission control strategies have logarithmic competitive ratios with respect to the admission ratio (the fraction of admitted circuits). Such guarantees on performance are rather weak in the most interesting case where the rejection ratio of the optimum algorithm is very small or even 0. Unfortunately, these guarantees can not be improved in the context of the considered models, making it impossible to use these models to identify algorithms that are going to perform well in practice. In this paper we develop routing and admission control strategies for a more realistic model, where the requests for virtual circuits between any two points arrive according to a Poisson process and where the circuit holding times are exponentially distributed. Our model is close to the one that was developed to analyse and tune the (currently used) strategies for managing traffic in long-distance telephone networks. We strengthen this model by assuming that the rates of the Poisson processes (the ``traffic matrix'''') are unknown to the algorithm and are chosen by the adversary. Our strategy is competitive with respect to the expected rejection ratio. More precisely, it achieves expected rejection ratio of at most R+epsilon, where R is the optimum expected rejection ratio. The expectations are taken over the distribution of the request sequences, and epsilon=Sqrt(r log n), where r is the maximum fraction of an edge bandwidth that can be requested by a single circuit.	SODA	theory
4303	SODA	Error-Resilient DNA Computation.	Richard M. Karp,Claire Kenyon,Orli Waarts	1996	Error-Resilient DNA Computation.	SODA	theory
4304	SODA	Sequential and Parallel Subquadratic Work Algorithms for Constructing Approximately Optimal Binary Search Trees.	Marek Karpinski,Lawrence L. Larmore,Wojciech Rytter	1996	Sequential and Parallel Subquadratic Work Algorithms for Constructing Approximately Optimal Binary Search Trees.	SODA	theory
4305	SODA	Best-Fit Bin-Packing with Random Order.	Claire Kenyon	1996	Best-Fit Bin-Packing with Random Order.	SODA	theory
4306	SODA	Biased Random Walks, Lyapunov Functions, and Stochastic Analysis of Best Fit Bin Packing (Preliminary Version).	Claire Kenyon,Yuval Rabani,Alistair Sinclair	1996	Biased Random Walks, Lyapunov Functions, and Stochastic Analysis of Best Fit Bin Packing (Preliminary Version).	SODA	theory
4307	SODA	On Certificates and Lookahead in Dynamic Graph Problems.	Sanjeev Khanna,Rajeev Motwani,Randall H. Wilson	1996	On Certificates and Lookahead in Dynamic Graph Problems.	SODA	theory
4308	SODA	Matching Nuts and Bolts in O(n log n) Time (Extended Abstract).	János Komlós,Yuan Ma,Endre Szemerédi	1996	Matching Nuts and Bolts in O(n log n) Time (Extended Abstract).	SODA	theory
4309	SODA	Quasi-Greedy Triangulations Approximating the Minimum Weight Triangulation.	Christos Levcopoulos,Drago Krznaric	1996	Quasi-Greedy Triangulations Approximating the Minimum Weight Triangulation.	SODA	theory
4310	SODA	A Commercial Application of Survivable Network Design: ITP/INPLANS CCS Network Topology Analyzer.	Milena Mihail,David Shallcross,Nate Dean,Marco Mostrel	1996	A Commercial Application of Survivable Network Design: ITP/INPLANS CCS Network Topology Analyzer.	SODA	theory
4311	SODA	Guillotine Subdivisions Approximate Polygonal Subdivisions: A Simple New Method for the Geometric k-MST Problem.	Joseph S. B. Mitchell	1996	Guillotine Subdivisions Approximate Polygonal Subdivisions: A Simple New Method for the Geometric k-MST Problem.	SODA	theory
4312	SODA	Data Collection for the Sloan Digital Sky Survey - A Network-Flow Heuristic.	Robert Lupton,F. Miller Maley,Neal E. Young	1996	Data Collection for the Sloan Digital Sky Survey - A Network-Flow Heuristic.	SODA	theory
4313	SODA	Time and Space Efficient Method-Lookup for Object-Oriented Programs (Extended Abstract).	S. Muthukrishnan,Martin Müller	1996	Time and Space Efficient Method-Lookup for Object-Oriented Programs (Extended Abstract).	SODA	theory
4314	SODA	Self-Stabilizing Algorithms for Synchronous Unidirectional Rings.	Alain J. Mayer,Rafail Ostrovsky,Moti Yung	1996	Self-Stabilizing Algorithms for Synchronous Unidirectional Rings.	SODA	theory
4315	SODA	A Polynomial Algorithm for Abstract Maximum Flow.	S. Thomas McCormick	1996	A Polynomial Algorithm for Abstract Maximum Flow.	SODA	theory
4316	SODA	A Polynomial Time Primal Network Simplex Algorithm for Minimum Cost Flows (An Extended Abstract).	James B. Orlin	1996	A Polynomial Time Primal Network Simplex Algorithm for Minimum Cost Flows (An Extended Abstract).	SODA	theory
4317	SODA	A New Approach to Parallel Computation of Polynomial GCD and to Related Parallel Computations over Fields and Integer Rings.	Victor Y. Pan	1996	A New Approach to Parallel Computation of Polynomial GCD and to Related Parallel Computations over Fields and Integer Rings.	SODA	theory
4318	SODA	Electrostatic Fields without Singularities: Theory and Algorithms.	Marco Pellegrini	1996	Electrostatic Fields without Singularities: Theory and Algorithms.	SODA	theory
4319	SODA	Depth Optimal Sorting Networks Resistant to k Passive Faults.	Marek Piotrów	1996	We study the problem of constructing a sorting network that is tolerant to faults and whose running time (i.e., depth) is as small as possible. We consider the scenario of worst-case comparator faults and follow the model of passive comparator failure proposed by Yao and Yao SIAM J. Comput., 14 (1985), pp. 120--128], in which a faulty comparator outputs its inputs directly without comparison. Our main result is the first construction of an N-input k-fault-tolerant sorting network with an asymptotically optimal depth $\theta$(log N + k). That improves over the result of Leighton and Ma [Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, Velen, Germany, 1993, ACM, New York, pp. 30--41], whose network is of depth O(log N + klog\frac{log N}{log k})$.Actually, we present a fault-tolerant correction network that can be added after any N-input sorting network to correct its output in the presence of at most k faulty comparators. Since the depth of the network is O(log N + k) and the constants hidden behind the O notation are small, the construction can be of practical use.Developing the techniques necessary to show the main result, we construct a fault-tolerant network for the insertion problem. As a by-product, we get an N-input O(log N)-depth INSERT-network that is tolerant to random faults, thereby answering a question posed by Ma in his Ph. D. thesis [Fault-Tolerant Sorting Network, Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, 1994].The results are based on a new notion of constant delay comparator networks, that is, networks in which each register is used (compared) only in a period of time of a constant length. Copies of such networks can be pipelined with only a constant increase in the total depth per copy.	SODA	theory
4320	SODA	Tiling a Figure Using a Height in a Tree.	Eric Rémila	1996	Tiling a Figure Using a Height in a Tree.	SODA	theory
4321	SODA	An Extension of the Lovász Local Lemma, and its Applications to Integer Programming.	Aravind Srinivasan	1996	An Extension of the Lovász Local Lemma, and its Applications to Integer Programming.	SODA	theory
4322	SODA	On RAM Priority Queues.	Mikkel Thorup	1996	Priority queues are some of the most fundamental data structures. For example, they are used directly for task scheduling in operating systems. Moreover, they are essential to greedy algorithms. We study the complexity of integer priority queue operations on a RAM with arbitrary word size, modeling the possibilities in standard imperative programming languages such as C. We present exponential improvements over previous bounds, and we show tight relations to sorting.Our first result is a RAM priority queue supporting find-min in constant time and insert and delete-min in time O(log log n), where n is the current number of keys in the queue. This is an exponential improvement over the $O(\sqrt{\log n})$ bound of Fredman and Willard [ Proceedings of the 22nd ACM Symposium on the Theory of Computing, Baltimore, MD, pp. 1--7]. Plugging this priority queue into Dijkstra's algorithm gives an O(mlog log m) algorithm for the single source shortest path problem on a graph with m edges, as compared with the previous $O(m\sqrt{\log m})$ bound based on Fredman and Willard's priority queue. The above bounds assume $O(n 2^{{\varepsilon} w})$ space, where w is the word length and ${\varepsilon}>0$. They can, however, be achieved in linear space using randomized hashing.Our second result is a general equivalence between sorting and priority queues. A priority queue is monotone if the minimum is nondecreasing over time, as in many greedy algorithms. We show that on a RAM, the amortized operation cost of a monotone priority queue is equivalent to the per-key cost of sorting. For example, the equivalence implies that the single source shortest paths problem on a graph with m edges is no harder than that of sorting m keys. With the current RAM sorting, this gives an O(m log log m) time bound, as above, but the relation holds regardless of the future developments in RAM sorting.From the equivalence result, for any fixed ${\varepsilon}>0$, we derive a randomized monotone $O(\sqrt{\log n}^{1+{\varepsilon}})$ priority queue with expected constant time decrease-key. Plugging this into Dijkstra's algorithm gives an $O(n\sqrt{\log n}^{1+{\varepsilon}}+m)$ algorithm for the single source shortest path problem on a graph with n nodes and m edges, complementing the above O(mlog log m) algorithm if $m\gg n$. This improves the O(nlog n/log log n + m) bound by Fredman and Willard [Proceedings of the 31st IEEE Symposium on the Foundations of Computer Science, St. Louis, MO, 1990, pp. 719--725], based on their O(log n/log log n) priority queue with constant decrease-key.	SODA	theory
4323	SODA	An O(log* n) Approximation Algorithm for the Asymmetric p-Center Problem.	Sundar Vishwanathan	1996	An O(log* n) Approximation Algorithm for the Asymmetric p-Center Problem.	SODA	theory
4324	SODA	Approximation Algorithms for Curvature-Constrained Shortest Paths.	Hongyan Wang,Pankaj K. Agarwal	1996	Approximation Algorithms for Curvature-Constrained Shortest Paths.	SODA	theory
4325	SODA	Reconstructing the Evolutionary History of Natural Languages.	Tandy Warnow,Donald Ringe,Ann Taylor	1996	Reconstructing the Evolutionary History of Natural Languages.	SODA	theory
4326	SODA	How to Get an Exact Sample From a Generic Markov Chain and Sample a Random Spanning Tree From a Directed Graph, Both Within the Cover Time.	David Bruce Wilson,James Gary Propp	1996	How to Get an Exact Sample From a Generic Markov Chain and Sample a Random Spanning Tree From a Directed Graph, Both Within the Cover Time.	SODA	theory
4327	SODA	RNC Algorithms for the Uniform Generation of Combinatorial Structures.	Michele Zito,Ida Pu,Martyn Amos,Alan Gibbons	1996	RNC Algorithms for the Uniform Generation of Combinatorial Structures.	SODA	theory
4328	SODA	Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, 28-30 January 1996, Atlanta, Georgia.	Éva Tardos	1996	Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, 28-30 January 1996, Atlanta, Georgia.	SODA	theory
4329	STOC	Generating Hard Instances of Lattice Problems (Extended Abstract).	Miklós Ajtai	1996	Generating Hard Instances of Lattice Problems (Extended Abstract).	STOC	theory
4330	STOC	Modular Coloring Formulas Are Hard for Cutting Planes Proofs.	Xudong Fu	1996	Modular Coloring Formulas Are Hard for Cutting Planes Proofs.	STOC	theory
4331	STOC	Convergence Complexity of Optimistic Rate Based Flow Control Algorithms (Extended Abstract).	Yehuda Afek,Yishay Mansour,Zvi Ostfeld	1996	Convergence Complexity of Optimistic Rate Based Flow Control Algorithms (Extended Abstract).	STOC	theory
4332	STOC	The Complexity of Matrix Rank and Feasible Systems of Linear Equations (Extended Abstract).	Eric Allender,Robert Beals,Mitsunori Ogihara	1996	The Complexity of Matrix Rank and Feasible Systems of Linear Equations (Extended Abstract).	STOC	theory
4333	STOC	The Space Complexity of Approximating the Frequency Moments.	Noga Alon,Yossi Matias,Mario Szegedy	1996	The Space Complexity of Approximating the Frequency Moments.	STOC	theory
4334	STOC	Node-Disjoint Paths on the Mesh and a New Trade-Off in VLSI Layout.	Alok Aggarwal,Jon M. Kleinberg,David P. Williamson	1996	A number of basic models for VLSI layout are based on the construction of node-disjoint paths between terminals on a multilayer grid. In this setting, one is interested in minimizing both the number of layers required and the area of the underlying grid. Building on work of Cutler and Shiloach [ Networks, 8 (1978), pp. 253--278], Aggarwal et al. [ Proc. 26th IEEE Symposium on Foundations of Computer Science , Portland, OR, 1985; Algorithmica, 6 (1991), pp. 241--255], and Aggarwal, Klawe, and Shor [ Algorithmica}, 6 (1991), pp. 129--151], we prove an upper-bound trade-off between these two quantities in a general multilayer grid model. As a special case of our main result, we obtain significantly improved bounds for the problem of routing a full permutation on the mesh using node-disjoint paths; our new bound here is within polylogarithmic factors of the bisection bound. Our algorithms involve some new techniques for analyzing the structure of node-disjoint paths in planar graphs and indicate some respects in which this problem, at least in the planar case, is fundamentally different from its edge-disjoint counterpart.	STOC	theory
4335	STOC	Automatic Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract).	Matthew Andrews,Frank Thomson Leighton,Panagiotis Takis Metaxas,Lisa Zhang	1996	Automatic Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract).	STOC	theory
4336	STOC	Robot Navigation with Range Queries.	Dana Angluin,Jeffery Westbrook,Wenhong Zhu	1996	Robot Navigation with Range Queries.	STOC	theory
4337	STOC	Modular Competitiveness for Distributed Algorithms.	James Aspnes,Orli Waarts	1996	Modular Competitiveness for Distributed Algorithms.	STOC	theory
4338	STOC	Making Commitments in the Face of Uncertainty: How to Pick a Winner Almost Every Time (Extended Abstract).	Baruch Awerbuch,Yossi Azar,Amos Fiat,Frank Thomson Leighton	1996	Making Commitments in the Face of Uncertainty: How to Pick a Winner Almost Every Time (Extended Abstract).	STOC	theory
4339	STOC	Extremal Bipartite Graphs and Superpolynomial Lower Bounds for Monotone Span Programs.	László Babai,Anna Gál,János Kollár,Lajos Rónyai,Tibor Szabó,Avi Wigderson	1996	Extremal Bipartite Graphs and Superpolynomial Lower Bounds for Monotone Span Programs.	STOC	theory
4340	STOC	Lower Bounds for On-line Graph Problems with Application to On-line Circuit and Optical Routing.	Yair Bartal,Amos Fiat,Stefano Leonardi	1996	We present lower bounds on the competitive ratio of randomized algorithms for a wide class of on-line graph optimization problems, and we apply such results to on-line virtual circuit and optical routing problems. Lund and Yannakakis [The approximation of maximum subgraph problems, in Proceedings of the 20th International Colloquium on Automata, Languages and Programming, 1993, pp. 40-51] give inapproximability results for the problem of finding the largest vertex induced subgraph satisfying any nontrivial, hereditary property pi--e.g., independent set, planar, acyclic, bipartite. We consider the on-line version of this family of problems, where some graph G is fixed and some subgraph H of G is presented on-line, vertex by vertex. The on-line algorithm must choose a subset of the vertices of H, choosing or rejecting a vertex when it is presented, whose vertex induced subgraph satisfies property pi. Furthermore, we study the on-line version of graph coloring whose off-line version has also been shown to be inapproximable [C. Lund and M. Yannakakis, On the hardness of approximating minimization problems, in Proceedings of the 25th ACM Symposium on Theory of Computing, 1993], on-line max edge-disjoint paths, and on-line path coloring problems. Irrespective of the time complexity, we show an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for any of these problems. As a consequence, we obtain an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for virtual circuit routing on general networks, in contrast to the known results for some specific networks. Similar lower bounds are obtained for on-line optical routing as well.	STOC	theory
4341	STOC	On Bounding the Betti Numbers and Computing the Euler Characteristic of Semi-Algebraic Sets.	Saugata Basu	1996	On Bounding the Betti Numbers and Computing the Euler Characteristic of Semi-Algebraic Sets.	STOC	theory
4342	STOC	Computing Roadmaps of Semi-Algebraic Sets (Extended Abstract).	Saugata Basu,Richard Pollack,Marie-Françoise Roy	1996	Computing Roadmaps of Semi-Algebraic Sets (Extended Abstract).	STOC	theory
4343	STOC	Correlated Pseudorandomness and the Complexity of Private Computations.	Donald Beaver	1996	Correlated Pseudorandomness and the Complexity of Private Computations.	STOC	theory
4344	STOC	Adaptive Zero Knowledge and Computational Equivocation (Extended Abstract).	Donald Beaver	1996	Adaptive Zero Knowledge and Computational Equivocation (Extended Abstract).	STOC	theory
4345	STOC	A Constant-factor Approximation Algorithm for the MST Problem (Extended Abstract).	Avrim Blum,R. Ravi,Santosh Vempala	1996	A Constant-factor Approximation Algorithm for the MST Problem (Extended Abstract).	STOC	theory
4346	STOC	Approximating Minimum Cuts in () Time.	András A. Benczúr,David R. Karger	1996	Approximating Minimum Cuts in () Time.	STOC	theory
4347	STOC	Learning Sat--DNF Formulas from Membership Queries.	Francesco Bergadano,Dario Catalano,Stefano Varricchio	1996	Learning Sat--DNF Formulas from Membership Queries.	STOC	theory
4348	STOC	Reconstructing a Three-Dimensional Model with Arbitrary Errors.	Bonnie Berger,Jon M. Kleinberg,Frank Thomson Leighton	1996	A number of current technologies allow for the determination of interatomic distance information in structures such as proteins and RNA. Thus, the reconstruction of a three-dimensional set of points using information about its interpoint distances has become a task of basic importance in determining molecular structure. The distance measurements one obtains from techniques such as NMR are typically sparse and error-prone, greatly complicating the reconstruction task. Many of these errors result in distance measurements that can be safely assumed to lie within certain fixed tolerances. But a number of sources of systematic error in these experiments lead to inaccuracies in the data that are very hard to quantify; in effect, one must treat certain entries of the measured distance matrix as being arbitrarily &ldquo;corrupted.&rdquo;The existence of arbitrary errors leads to an interesting sort of error-correction problem&mdash;how many corrupted entries in a distance matrix can be efficiently corrected to produce a consistent three-dimensional structure? For the case of an n &times; n matrix in which every entry is specified, we provide a randomized algorithm running in time O(n log n) that enumerates all structures consistent with at most (1/2-&egr;)n errors per row, with high probability. In the case of randomly located errors, we can correct errors of the same density in a sparse matrix-one in which only a &bgr; fraction of the entries in each row are given, for any constant &bgr;gt;0.	STOC	theory
4349	STOC	Constructing Evolutionary Trees in the Presence of Polymorphic Characters.	Maria Luisa Bonet,Cynthia A. Phillips,Tandy Warnow,Shibu Yooseph	1996	Most phylogenetics literature and construction methods based upon characters presume monomorphism (one state per character per species), yet polymorphism (multiple states per character per species) is well documented in both biology and historical linguistics. In this paper we consider the problem of inferring evolutionary trees for polymorphic characters. We show efficient algorithms for the construction of perfect phylogenies from polymorphic data. These methods have been used to help construct the evolutionary tree proposed by Warnow, Ringe, and Taylor for the Indo-European family of languages and presented by invitation at the National Academy of Sciences in November 1995.	STOC	theory
4350	STOC	Pushing Disks Together - The Continuous-Motion Case.	Marshall W. Bern,Amit Sahai	1996	Pushing Disks Together - The Continuous-Motion Case.	STOC	theory
4351	STOC	Adversarial Queueing Theory.	Allan Borodin,Jon M. Kleinberg,Prabhakar Raghavan,Madhu Sudan,David P. Williamson	1996	We consider packet routing when packets are injected continuously into a network. We develop an adversarial theory of queuing aimed at addressing some of the restrictions inherent in probabilistic analysis and queuing theory based on time-invariant stochastic generation. We examine the stability of queuing networks and policies when the arrival process is adversarial, and provide some preliminary results in this direction. Our approach sheds light on various queuing policies in simple networks, and paves the way for a systematic study of queuing with few or no probabilistic assumptions.	STOC	theory
4352	STOC	Dynamic Deflection Routing on Arrays (Preliminary Version).	Andrei Z. Broder,Eli Upfal	1996	Dynamic Deflection Routing on Arrays (Preliminary Version).	STOC	theory
4353	STOC	Towards the Learnability of DNF Formulae.	Nader H. Bshouty	1996	Towards the Learnability of DNF Formulae.	STOC	theory
4354	STOC	Noise-Tolerant Distribution-Free Learning of General Geometric Concepts.	Nader H. Bshouty,Sally A. Goldman,H. David Mathias,Subhash Suri,Hisao Tamaki	1996	We present an efficient algorithm for PAC-learning a very general class of geometric concepts over R d for fixed d. More specifically, let T be any set of s halfspaces. Let x =(x1, &hellip;, xd) be an arbitrary point in R d. With each t&isin;T we associate a boolean indicator function It(x) which is 1 if and only if x is in the halfspace t. The concept class, Cds , that we study consists of all concepts formed by any Boolean function over It1, &hellip;, Its for ti &isin;T . This class is much more general than any geometric concept class known to be PAC-learnable. Our results can be extended easily to learn efficiently any Boolean combination of a polynomial number of concepts selected from any concept class C over R given that the VC-dimension of C has dependence only on d and there is a polynomial time algorithm to determine if there is a concept from C consistent with a given set of labeled examples. We also present a statistical query version of our algorithm that can tolerate random classification noise. Finally we present a generalization of the standard &egr;-net result of Haussler and Welzl [1987] and apply it to give an alternative noise-tolerant algorithm for d = 2 based on geometric subdivisions.	STOC	theory
4355	STOC	Adaptively Secure Multi-Party Computation.	Ran Canetti,Uriel Feige,Oded Goldreich,Moni Naor	1996	A fundamental problem in designing secure multi-party protocols is how to deal with adaptive adversaries (i.e., adversaries that may choose the corrupted parties during the course of the computation), in a setting where the channels are insecure and secure communication is achieved by cryptographic primitives based on computational limitations of the adversary. It turns out that the power of an adaptive adversary is greatly affected by the amount of information gathered upon the corruption of the party. This amount of information models the extent to which uncorrupted parties are trusted to carry out instructions that cannot be externally verified, such as erasing records of past configurations. It has been shown that if the parties are trusted to erase such records, then adaptivity secure computation can be carried out using known primitives. However, this total trust in parties may be unrealistic in many scenarios. An important question, open since 1986, is whether adaptively secure multi-party computation can be carried out in the insecure channel setting, even if no party is thoroughly trusted. Our main result is an affirmative resolution of this question for the case where even uncorrupted parties may deviate from the protocol by keeping record of all past configurations. We first propose a novel property of encryption protocols and show that if an encryption protocol enjoying this property is used, instead of a standard encryption scheme, then known constructions become adaptively secure. Next we constructed, based on standard RSA assumption, an encryption protocol that enjoys this property. We also consider parties that, even when corrupted, may internally deviate from their protocols in arbitrary ways, as long as no external test can detect faulty behavior. We show that in this case no non-trivial protocol can be proven adaptively secure using black-box simulation. This holds even if the communication channels are totally secure.	STOC	theory
4356	STOC	Noise-Tolerant Learning Near the Information-Theoretic Bound.	Nicolò Cesa-Bianchi,Eli Dichterman,Paul Fischer,Hans-Ulrich Simon	1996	Noise-Tolerant Learning Near the Information-Theoretic Bound.	STOC	theory
4357	STOC	Deterministic Restrictions in Circuit Complexity.	Shiva Chaudhuri,Jaikumar Radhakrishnan	1996	Deterministic Restrictions in Circuit Complexity.	STOC	theory
4358	STOC	Fast Algorithms for -Shredders and -Node Connectivity Augmentation (Extended Abstract).	Joseph Cheriyan,Ramakrishna Thurimella	1996	Fast Algorithms for -Shredders and -Node Connectivity Augmentation (Extended Abstract).	STOC	theory
4359	STOC	Using the Groebner Basis Algorithm to Find Proofs of Unsatisfiability.	Matthew Clegg,Jeff Edmonds,Russell Impagliazzo	1996	Using the Groebner Basis Algorithm to Find Proofs of Unsatisfiability.	STOC	theory
4360	STOC	Universal Algorithms for Store-and-Forward and Wormhole Routing.	Robert Cypher,Friedhelm Meyer auf der Heide,Christian Scheideler,Berthold Vöcking	1996	Universal Algorithms for Store-and-Forward and Wormhole Routing.	STOC	theory
4361	STOC	Algorithms for Manifolds and Simplicial Complexes in Euclidean 3-Space (Preliminary Version).	Tamal K. Dey,Sumanta Guha	1996	Algorithms for Manifolds and Simplicial Complexes in Euclidean 3-Space (Preliminary Version).	STOC	theory
4362	STOC	Towards an Analysis of Local Optimization Algorithms.	Tassos Dimitriou,Russell Impagliazzo	1996	Towards an Analysis of Local Optimization Algorithms.	STOC	theory
4363	STOC	Digital Signets: Self-Enforcing Protection of Digital Information (Preliminary Version).	Cynthia Dwork,Jeffrey B. Lotspiech,Moni Naor	1996	Digital Signets: Self-Enforcing Protection of Digital Information (Preliminary Version).	STOC	theory
4364	STOC	An ( )-Size Fault-Tolerant Sorting Network (Extended Abstract).	Yuan Ma	1996	An ( )-Size Fault-Tolerant Sorting Network (Extended Abstract).	STOC	theory
4365	STOC	Lower Bounds for Noisy Boolean Decision Trees.	William S. Evans,Nicholas Pippenger	1996	We present a new method for deriving lower bounds to the expected number of queries made by noisy decision trees computing Boolean functions. The new method has the feature that expectations are taken with respect to a uniformly distributed random input, as well as with respect to the random noise, thus yielding stronger lower bounds. It also applies to many more functions than do previous results. The method yields a simple proof of the result (previously established by Reischuk and Schmeltz) that almost all Boolean functions of n arguments require Omega(n log n) queries, and strengthens this bound from the worst-case over inputs to the average over inputs. The method also yields bounds for specific Boolean functions in terms of their spectra (their Fourier transforms). The simplest instance of this spectral bound yields the result (previously established by Feige, Peleg, Raghavan and Upfal) that the parity function of n arguments requires Omega(n log n) queries, and again strengthens this bound from the worst-case over inputs to the average over inputs. In its full generality, the spectral bound applies to the highly resilient functions introduced by Chor, Friedman, Goldreich, Hastad, Rudich and Smolensky, and it yields non-linear lower bounds whenever the resiliency is asymptotic to the number of arguments.	STOC	theory
4366	STOC	Efficient Algorithms for Inverting Evolution.	Martin Farach,Sampath Kannan	1996	Evolution can be mathematically modelled by a stochastic process that operates on the DNA of species. Such models are based on the established theory that the DNA sequences, or genomes, of all extant species have been derived from the genome of the common ancestor of all species by a process of random mutation and natural selection.A stochastic model of evolution can be used to construct phylogenies, or evolutionary trees, for a set of species. Maximum Likelihood Estimation (MLE) methods seek the evolutionary tree which is most likely to have produced the DNA under consideration. While these methods are intellectually satisfying, they have not been widely accepted because of their computational intractability.In this paper, we address the intractability of MLE methods as follows: We introduce a metric on stochastic process models of evolution. We show that this metric is meaningful by proving that in order for any algorithm to distinguish between two stochastic models that are close according to this metric, it needs to be given many observations. We complement this result with a simple and efficient algorithm for inverting the stochastic process of evolution, that is, for building a tree from observations on two-state characters. (We will use the same techniques in a subsequent paper to solve the problem for multistate characters, and hence for building a tree from DNA sequence data.) The tree we build is provably close, in our metric, to the tree generating the data and gets closer as more observations become available.Though there have been many heuristics suggested for the problem of finding good approximations to the most likely tree, our algorithm is the first one with a guaranteed convergence rate, and further, this rate is within a polynomial of the lower-bound rate we establish. Ours is also the first polynomial-time algorithm that is proven to converge at all to the correct tree.	STOC	theory
4367	STOC	A Threshold of ln for Approximating Set Cover (Preliminary Version).	Uriel Feige	1996	A Threshold of ln for Approximating Set Cover (Preliminary Version).	STOC	theory
4368	STOC	Witness-Based Cryptographic Program Checking and Robust Function Sharing.	Yair Frankel,Peter Gemmell,Moti Yung	1996	Witness-Based Cryptographic Program Checking and Robust Function Sharing.	STOC	theory
4369	STOC	Computing Betti Numbers via Combinatorial Laplacians.	Joel Friedman	1996	Computing Betti Numbers via Combinatorial Laplacians.	STOC	theory
4370	STOC	Communication-Efficient Parallel Sorting (Preliminary Version).	Michael T. Goodrich	1996	Communication-Efficient Parallel Sorting (Preliminary Version).	STOC	theory
4371	STOC	A Lower Bound for Randomized Algebraic Decision Trees.	Dima Grigoriev,Marek Karpinski,Friedhelm Meyer auf der Heide,Roman Smolensky	1996	We extend the lower bounds on the depth of algebraic decision trees to the case of randomized algebraic decision trees (with two-sided error) for languages being finite unions of hyperplanes and the intersections of halfspaces. As an application, among other things, we derive, for the first time, $\Omega(n^2)$ randomized lower bound for the {\em knapsack problem} (which was previously only known for deterministic algebraic decision trees).	STOC	theory
4372	STOC	A Fast Quantum Mechanical Algorithm for Database Search.	Lov K. Grover	1996	A Fast Quantum Mechanical Algorithm for Database Search.	STOC	theory
4373	STOC	Testing of the Long Code and Hardness for Clique.	Johan Håstad	1996	Testing of the Long Code and Hardness for Clique.	STOC	theory
4374	STOC	Nondeterministic Communication with a Limited Number of Advice Bits.	Juraj Hromkovic,Georg Schnitger	1996	We present a new technique for differentiating deterministic from nondeterministic communication complexity. As a consequence we give almost tight lower bounds for the nondeterministic communication complexity with a restricted number of advice bits. In particular, for any function $t : \mathbb{N} \rightarrow \mathbb{N}$ with $t(n) \leq n/2$ we construct a family $(L_{n,t(n)} : n \in \mathbb{N})$ of languages such that $L_{n,t(n)} \subseteq \{0,1\}^{2n}$, ${\rm nc}(L_{n,t(n)}) = O(t(n) \cdot \log_2 \frac{n}{t(n)})$ and ${\rm nc}(\overline{L_{n,t(n)}}) = O\bigl(\frac{n}{t(n) \cdot \log_2 \frac{n}{t(n)}} + \log_2 t(n)\bigr)$, but ${\rm nc}_{o(t(n))}(L_{n,t(n)}) = \Omega\bigl(\frac{n}{\log_2 \frac{n}{t(n)}}\bigr)$. Here ${\rm nc}_r(L)$ is the nondeterministic communication complexity of L, assuming that at most r advice bits are utilized. Thus, in contrast to probabilistic communication complexity, a small reduction in the number of advice bits results in almost maximal communication. As a special case we obtain a family $L_n \subseteq \{0,1\}^{2n}$ of languages with {\rm nc}_{o(\sqrt{n}/\log_2 n)}(L_n) &=& \Omega\biggl(\frac{n}{\log_2 n}\biggr),\\ {\rm nc}(L_n) + {\rm nc}(\overline{L_n}) &=& O(\sqrt{n}), and hence nondeterministic communication with slightly restricted access to advice bits is almost quadratically weaker than nondeterminism that always gives correct answers (from the set {yes, no, ?}). As a consequence we obtain an almost optimal separation between Monte-Carlo communication and correct nondeterminism and answer a question of Beame and Lawry.	STOC	theory
4375	STOC	Purely Functional Representations of Catenable Sorted Lists.	Haim Kaplan,Robert Endre Tarjan	1996	The power of purely functional programming in the construction of data structures has received much attention, not only because functional languages have many desirable properties, but because structures built purely functionally are automatically {\em fully persistent}: any and all versions of a structure can coexist indefinitely. Recent results illustrate the surprising power of pure functionality. One such result was the development of a representation of double-ended queues with catenation that supports all operations, including catenation, in worst-case constant time~\cite{KaTar}. This paper is a continuation of our study of pure functionality, especially as it relates to persistence. For one purposes, a purely functional data structure is one built only with the LISP functions car, cons, cdr. We explore purely functional representations of sorted lists, implemented as finger search trees. We describe three implementations. The most efficient of these achieves logarithmic access, insertion, and deletion time, and double-logarithmic catenation time. It uses one level of structural bootstrapping to obtain its efficiency. The bounds for find, insert, and delete are the same as the best known bounds for an ephemeral implementation of these operations using finger search trees. The representations we present are the first that address the issues of persistence and pure functionality, and the first for which fast implementations of catenation and split are presented. They are simple to implement and could be efficient in practice, especially for applications that require worst-case time bounds or persistence.	STOC	theory
4376	STOC	Sparsity Considerations in Dixon Resultants.	Deepak Kapur,Tushar Saxena	1996	Sparsity Considerations in Dixon Resultants.	STOC	theory
4377	STOC	Minimum Cuts in Near-Linear Time.	David R. Karger	1996	We significantly improve known time bounds for solving the minimum cut problem on undirected graphs. We use a semiduality between minimum cuts and maximum spanning tree packings combined with our previously developed random sampling techniques. We give a randomized (Monte Carlo) algorithm that finds a minimum cut in an m-edge, n-vertex graph with high probability in O(m log3 n) time. We also give a simpler randomized algorithm that finds all minimum cuts with high probability in O(m log3 n) time. This variant has an optimal RNC parallelization. Both variants improve on the previous best time bound of O(n2 log3 n). Other applications of the tree-packing approach are new, nearly tight bounds on the number of near-minimum cuts a graph may have and a new data structure for representing them in a space-efficient manner.	STOC	theory
4378	STOC	How Good is the Goemans-Williamson MAX CUT Algorithm?	Howard J. Karloff	1996	The celebrated semidefinite programming algorithm for MAX CUT introduced by Goemans and Williamson was known to have a performance ratio of at least $\alpha=\frac 2 {\pi} \min_{0	STOC	theory
4379	STOC	On the Boosting Ability of Top-Down Decision Tree Learning Algorithms.	Michael J. Kearns,Yishay Mansour	1996	On the Boosting Ability of Top-Down Decision Tree Learning Algorithms.	STOC	theory
4380	STOC	Approximability and Nonapproximability Results for Minimizing Total Flow Time on a Single Machine.	Hans Kellerer,Thomas Tautenhahn,Gerhard J. Woeginger	1996	We consider the problem of scheduling n jobs that are released over time on a single machine in order to minimize the total flow time. This problem is well known to be NP-complete, and the best polynomial-time approximation algorithms constructed so far had (more or less trivial) worst-case performance guarantees of O(n). In this paper, we present one positive and one negative result on polynomial-time approximations for the minimum total flow time problem: The positive result is the first approximation algorithm with a sublinear worst-case performance guarantee of $O(\sqrt{n})$. This algorithm is based on resolving the preemptions of the corresponding optimum preemptive schedule. The performance guarantee of our approximation algorithm is not far from best possible, as our second, negative result demonstrates: Unless P=NP, no polynomial-time approximation algorithm for minimum total flow time can have a worst-case performance guarantee of $O(n^{1/2-\eps})$ for any $\eps>0$.	STOC	theory
4381	STOC	Towards a Syntactic Characterization of PTAS.	Sanjeev Khanna,Rajeev Motwani	1996	Towards a Syntactic Characterization of PTAS.	STOC	theory
4382	STOC	Efficient Approximation Algorithms for Semidefinite Programs Arising from MAX CUT and COLORING.	Philip N. Klein,Hsueh-I Lu	1996	The best known approximation algorithm for graph MAX CUT, due to Goemans and Williamson, first finds the optimal solution a semidefinite program and then derives a graph cut from that solution. Building on this result, Karger, Motwani, and Sudan gave an approximation algorithm for graph coloring that also involves solving a semidefinite program. Solving these semidefinite programs using known methods (ellipsoid, interior-point), though polynomial-time, is quite expensive. We show how they can be approximately solved in $\tilde O(nm)$ time for graphs with $n$ nodes and $m$ edges.	STOC	theory
4383	STOC	Large-Scale Assembly of DNA Strings and Space-Efficient Construction of Suffix Trees (Correction).	S. Rao Kosaraju,Arthur L. Delcher	1996	Large-Scale Assembly of DNA Strings and Space-Efficient Construction of Suffix Trees (Correction).	STOC	theory
4384	STOC	The Linear-Array Conjecture in Communication Complexity is False.	Eyal Kushilevitz,Nathan Linial,Rafail Ostrovsky	1996	The Linear-Array Conjecture in Communication Complexity is False.	STOC	theory
4385	STOC	Characterizing Linear Size Circuits in Terms of Privacy.	Eyal Kushilevitz,Rafail Ostrovsky,Adi Rosén	1996	Characterizing Linear Size Circuits in Terms of Privacy.	STOC	theory
4386	STOC	Non-Expansive Hashing.	Nathan Linial,Ori Sasson	1996	Non-Expansive Hashing.	STOC	theory
4387	STOC	Fast Algorithms for Parametric Scheduling Come from Extensions to Parametric Maximum Flow.	S. Thomas McCormick	1996	Fast Algorithms for Parametric Scheduling Come from Extensions to Parametric Maximum Flow.	STOC	theory
4388	STOC	Translational Polygon Containment and Minimal Enclosure using Linear Programming Based Restriction.	Victor Milenkovic	1996	Translational Polygon Containment and Minimal Enclosure using Linear Programming Based Restriction.	STOC	theory
4389	STOC	Embedding Graphs in an Arbitrary Surface in Linear Time.	Bojan Mohar	1996	Embedding Graphs in an Arbitrary Surface in Linear Time.	STOC	theory
4390	STOC	Deterministic (nm) Time Edge-Splitting in Undirected Graphs.	Hiroshi Nagamochi,Toshihide Ibaraki	1996	Deterministic (nm) Time Edge-Splitting in Undirected Graphs.	STOC	theory
4391	STOC	Evaluation May Be Easier Than Generation (Extended Abstract).	Moni Naor	1996	Evaluation May Be Easier Than Generation (Extended Abstract).	STOC	theory
4392	STOC	Public vs. Private Coin Flips in One Round Communication Games (Extended Abstract).	Ilan Newman,Mario Szegedy	1996	Public vs. Private Coin Flips in One Round Communication Games (Extended Abstract).	STOC	theory
4393	STOC	The PL Hierarchy Collapses.	Mitsunori Ogihara	1996	It is shown that the PL hierarchy PLH = PL ,\bigcup\limits\, PLPL ,\bigcup\limits\, PLPLPL ,\bigcup\limits\, \cdots$, defined in terms of the Ruzzo--Simon--Tompa relativization, collapses to PL.	STOC	theory
4394	STOC	On Relationships between Statistical Zero-Knowledge Proofs.	Tatsuaki Okamoto	1996	On Relationships between Statistical Zero-Knowledge Proofs.	STOC	theory
4395	STOC	Distributed Packet Switching in Arbitrary Networks.	Yuval Rabani,Éva Tardos	1996	Distributed Packet Switching in Arbitrary Networks.	STOC	theory
4396	STOC	Efficiently Four-Coloring Planar Graphs.	Neil Robertson,Daniel P. Sanders,Paul D. Seymour,Robin Thomas	1996	Efficiently Four-Coloring Planar Graphs.	STOC	theory
4397	STOC	A Tight Analysis of the Greedy Algorithm for Set Cover.	Petr Slavík	1996	A Tight Analysis of the Greedy Algorithm for Set Cover.	STOC	theory
4398	STOC	Faster Isomorphism Testing of Strongly Regular Graphs.	Daniel A. Spielman	1996	Faster Isomorphism Testing of Strongly Regular Graphs.	STOC	theory
4399	STOC	On Extracting Randomness From Weak Random Sources (Extended Abstract).	Amnon Ta-Shma	1996	On Extracting Randomness From Weak Random Sources (Extended Abstract).	STOC	theory
4400	STOC	Efficient 3-D Range Searching in External Memory.	Darren Erik Vengroff,Jeffrey Scott Vitter	1996	Efficient 3-D Range Searching in External Memory.	STOC	theory
4401	STOC	Randomness-Optimal Sampling, Extractors, and Constructive Leader Election.	David Zuckerman	1996	Randomness-Optimal Sampling, Extractors, and Constructive Leader Election.	STOC	theory
4402	STOC	Generating Random Spanning Trees More Quickly than the Cover Time.	David Bruce Wilson	1996	Generating Random Spanning Trees More Quickly than the Cover Time.	STOC	theory
4403	STOC	Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, Philadelphia, Pennsylvania, USA, May 22-24, 1996	Gary L. Miller	1996	Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, Philadelphia, Pennsylvania, USA, May 22-24, 1996	STOC	theory
4404	CVPR	Pattern Rejection.	Simon Baker,Shree K. Nayar	1996	The efficiency of pattern recognition is particularly crucial in two scenarios; whenever there are a large number of classes to discriminate, and, whenever recognition must be performed a large number of times. We propose a single technique, namely, pattern rejection, that greatly enhances efficiency in both cases. A rejector is a generalization of a classifier, that quickly eliminates a large fraction of the candidate classes or inputs. This allows a recognition algorithm to dedicate its efforts to a much smaller number of possibilities. Importantly, a collection of rejectors may be combined to form a composite rejector, which is shown to be far more effective than any of its individual components. A simple algorithm is proposed for the construction of each of the component rejectors. Its generality is established through close relationships with the Karhunen-Loéve expansion and Fisher's discriminant analysis. Composite rejectors were constructed for two representative applications, namely, appearance matching based object recognition and local feature detection. The results demonstrate substantial efficiency improvements over existing approaches, most notably Fisher's discriminant analysis.	CVPR	visu
4405	CVPR	Extracting Salient Curves from Images: An Analysis of the Saliency Network.	T. D. Alter,Ronen Basri	1996	The Saliency Network proposed by Shashua and Ullman is a well-known approach to the problem of extracting salient curves from images while performing gap completion. This paper analyzes the Saliency Network. The Saliency Network is attractive for several reasons. First, the network generally prefers long and smooth curves over short or wiggly ones. While computing saliencies, the network also fills in gaps with smooth completions and tolerates noise. Finally, the network is locally connected, and its size is proportional to the size of the image. Nevertheless, our analysis reveals certain weaknesses with the method. In particular, we show cases in which the most salient element does not lie on the perceptually most salient curve. Furthermore, in some cases the saliency measure changes its preferences when curves are scaled uniformly. Also, we show that for certain fragmented curves the measure prefers large gaps over a few small gaps of the same total size. In addition, we analyze the time complexity required by the method. We show that the number of steps required for convergence in serial implementations is quadratic in the size of the network, and in parallel implementations is linear in the size of the network. We discuss problems due to coarse sampling of the range of possible orientations. We show that with proper sampling the complexity of the network becomes at least cubic in the size of the network. Finally, we consider the possibility of using the Saliency Network for grouping. We show that the Saliency Network recovers the most salient curve efficiently, but it has problems with identifying any salient curve other than the most salient one.	CVPR	visu
4406	CVPR	Extraction of maximal inscribed disks from discrete Euclidean distance maps.	Yaorong Ge,J. Michael Fitzpatrick	1996	Extraction of maximal inscribed disks from discrete Euclidean distance maps.	CVPR	visu
4407	CVPR	Real-time Extraction of connected Components in 3-D Sonar Range Images.	Per Gunnar Auran,Kjell E. Malvig	1996	This paper describes an efficient algorithm for the segmentation of echo clusters within a dynamic 3-D sonar image. The sensor centered image is an echo management framework grouping sonar returns into spherical cells, and allowing real-time organisation of 3-D range data using inexpensive equipment. Each cell acts as a spatial key to the features related to this location. The spherical representation is effectively exploited for segmentation using an approach motivated from connected components analysis in binary video images. A fast algorithm (linear in time complexity) based on cell connectivity between sonar beams is presented, including methods for coping with sparse data.	CVPR	visu
4408	CVPR	Finding Corresponding Points Based on Bayesian Triangulation.	Anand S. Bedekar,Robert M. Haralick	1996	In this paper, we consider the problems of finding corresponding points from multiple perspective projection images (the correspondence problem), and estimating the 3-D point from which these points have arisen (the triangulation problem). We pose the triangulation problem as that of finding the Bayesian maximum a posteriori estimate of the 3-D point, given its projections in N images, assuming a Gaussian error model for the image point co-ordinates and the camera parameters. We solve this by an iterative steepest descent method. We then consider the correspondence problem as a statistical hypothesis verification problem. Given a set of 2-D points, under the hypothesis that the points are in correspondence, the MAP estimate of the 3-D point is computed. Based on the MAP estimate, we derive a statistical test for verifying this hypothesis. To find sets of corresponding points when multiple points in each of N images are given, we propose a method that does the Bayesian triangulation and hypothesis verification on each N-tuple of points, selecting those that pass the hypothesis test. We characterize the performance of the Bayesian triangulation in terms of the average distance of the triangulated 3-D point from the true 3-D point, and of the point correspondence method in terms of its misdetection and false alarm rates.	CVPR	visu
4409	CVPR	What is the set of images of an object under all possible lighting conditions?	Peter N. Belhumeur,David J. Kriegman	1996	The appearance of a particular object depends on both the viewpoint from which it is observed and the light sources by which it is illuminated. If the appearance of two objects is never identical for any pose or lighting conditions, then-in theory - the objects can always be distinguished or recognized. The question arises: What is the set of images of an object under all lighting conditions and pose? In this paper, we consider only the set of images of an object under variable illumination (including multiple, extended light sources and attached shadows). We prove that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a convex polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals. Furthermore, we show that the cone for a particular object can be constructed from three properly chosen images. Finally, we prove that the set of n-pixel images of an object of any shape and with an arbitrary reflectance function, seen under all possible illumination conditions, still forms a convex cone in IR/sup n/. These results immediately suggest certain approaches to object recognition. Throughout this paper, we offer results demonstrating the empirical validity of the illumination cone representation.	CVPR	visu
4410	CVPR	Interpreting and representing tabular documents.	Juan F. Arias,Atul K. Chhabra,Vishal Misra	1996	This paper describes a methodology to interpret the information from telephone company DSX assignment table drawings. Horizontal lines are found using an efficient algorithm that works over the run-length encoded representation of the image. For vertical lines, the image is transposed using an efficient method we developed, and the algorithm for horizontal lines is applied again. Using the information about the lines, the tabular structures are extracted by finding biconnected components on the graph formed by the lines and their intersections. A methodology has also been developed for the representation of end access to the entries inside the tables.	CVPR	visu
4411	CVPR	Multilinear Constraints in the Infinitesimal-time Cas.	Kalle Åström,Anders Heyden	1996	In this paper we study the infinitesimal-time case of the so called multilinear constraints that exist for each subsequence in a sequence of images. These constraints link the infinitesimal motion of the image points with the infinitesimal viewer motion. The analysis is done both for calibrated and uncalibrated cameras. Two simplifications are also presented for the uncalibrated camera case. One simplification is made using affine reduction and kinetic depth. The second simplification is based upon a projective reduction with respect to the image of a planar patch.	CVPR	visu
4412	CVPR	Shadows and shading flow fields.	Pierre Breton,Steven W. Zucker	1996	Many presume that parsing the shadows out of an image is a high-level task, because of the global nature of the shadow formation process. But shape-from-shading algorithms are low-level, in the sense that they seek solutions (surface normals or depth values) directly from image intensities. A dilemma arises: since shape-from-shading involves an illumination term, shadows must first be identified. We show that a structure intermediate between intensities and surfaces-the shading flow field-provides a solution to this dilemma. Our analysis is based on the observation that the geometric information that can be derived from images supports different inferences than the photometric information, and our specific goal will be to articulate this geometric structure and to show how shading flow fields can be reliably computed.	CVPR	visu
4413	CVPR	Calibration of a Foveated Wide-Angle Lens on an Active Vision Head.	Luc Berthouze,Sebastien Rougeaux,Florent Chavand,Yasuo Kuniyoshi	1996	Inspired by the properties of the humam visual system, a new active vision system called ESCHeR (Etl Stereo Compact Head For Robot Vision) has been recently implemented with foveated wide-angle lenses. The lenses exhibit a wide field of view along with a space-varying resolution for facilitating both detection and close observation. However, to handle such optical properties and achieve basic eye movement functions, new calibration methods are needed. Therefore, two novel and online techniques are presented that in one case perform a global identification of the optical process through artificial neural techniques and in the other case compute the physical parameters by using environmental feature-tracking and controlled rotations of the cameras. Self-alignment of the cameras is also achieved using a similar technique.	CVPR	visu
4414	CVPR	Feature Correspondence by Interleaving Shape and Texture Computations.	David Beymer	1996	The correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image. The representation consists of two image measurements made at the feature points: shape and texture. Feature geometry, or shape, is represented using the (x, y) locations of features relative to the some standard reference shape. Image grey levels, or texture, are represented by mapping image grey levels onto the standard reference shape. Computing this representation is essentially a correspondence task, and in this paper we explore an automatic technique for vectorizing face images. Our face vectorizer alternates back and forth between computation steps for shape and texture, and a key idea is to structure the two computations so that each one uses the output of the other. In addition to describing the vectorizer, an application to the problem of facial feature detection will be presented.	CVPR	visu
4415	CVPR	Ordinal Measures for Visual Correspondence.	Dinkar N. Bhat,Shree K. Nayar	1996	We present ordinal measures for establishing image correspondence. Linear correspondence measures like correlation and the sum of squared differences are known to be fragile. Ordinal measures, which are based on relative ordering of intensity values in windows, have demonstrable robustness to depth discontinuities, occlusion and noise. The relative ordering of intensity values in each window is represented by a rank permutation which is obtained by sorting the corresponding intensity data. By using a novel distance metric between the rank permutations, we arrive at ordinal correlation coefficients. These coefficients are independent of absolute intensity scale, i.e they are normalized measures. Further, since rank permutations are invariant to monotone transformations of the intensity values, the coefficients are unaffected by nonlinear effects like gamma variation between images. We have developed a simple algorithm for their efficient implementation. Experiments suggest the superiority of ordinal measures over existing techniques under non-ideal conditions. Though we present ordinal measures in the context of stereo, they serve as a general tool for image matching that is applicable to other vision problems such as motion estimation and image registration.	CVPR	visu
4416	CVPR	Recognition of Planar Object Classes.	Michael C. Burl,Pietro Perona	1996	We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94\% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes.	CVPR	visu
4417	CVPR	On a spectral attentional mechanism.	Philippe Burlina,Bruce Lin,Rama Chellappa	1996	This paper describes an attentional mechanism based on the interpretation of spectral signatures for detecting regular object configurations in areas of an image delineated using context information. The proposed global operator relies on the spectral analyse's of edge structure and exploits spatial as well as frequency domain constraints derived from known geometrical models of monitored objects. A decision theoretic method for learning decision regions is presented. Applications of this mechanism are demonstrated for several aerial image interpretation tasks. Specific examples are described for detecting vehicle formations (such as convoys), qualifying the geometry of detected formations, or monitoring the occupancy of regions of interest (such as parking areas, roads, or open areas). Experiments and sensitivity analysis results are reported.	CVPR	visu
4418	CVPR	Recognition via consensus of local moments of brightness and orientation.	J. Brian Burns	1996	This study combines two useful methods in recognition: consensus or voting-based approaches and moment-based representations. Matches between image patches are generated using a Gaussian-weighted moment encoding of the patches and a feature indexing process. Each match implies an object 3D position and orientation (pose) and generates a vote for this pose. Recognition is accomplished by detecting significant clusters of votes in pose space. This combined method is an improvement over voting and moment methods in isolation. Using image brightness moments, the idea is successfully demonstrated on examples of human faces undergoing full 3D pose change, as well as changes in features such as talking and blinking. The idea is then extended to moments of local texture orientation and successfully demonstrated under large variations in lighting nature and geometry.	CVPR	visu
4419	CVPR	Autonomous recognition: driven by ambiguit.	Franco Callari,Frank P. Ferrie	1996	Recognition ambiguity, due to noisy measurements and uncertain object models, can be quantified and actively used by an autonomous agent to efficiently gather new data and improve its information about the environment. In this work an information-based utility measure is used to derive from a learned classification of shape models an efficient data collection strategy, specifically aimed at increasing classification confidence when recognizing uncertain shapes. Promising simulation results are presented and discussed.	CVPR	visu
4420	CVPR	Lie groups, Space-Variant Fourier Analysis and the Exponential Chirp Transform.	Giorgio Bonmassar,Eric L. Schwartz	1996	The use of visual representations in which retinal neurons receptive fields are not constant over the visual field is universal in the visual systems of higher vertebrates, and is coming to play an important role in active vision applications. The breaking of translation symmetry that is unavoidably associated with non-uniform sampling presents a major algorithmic complication for image processing. In this paper we use a Lie group approach to derive a kernel which provides a quasi-shift (i.e. approximate shift) invariant template matching capability, under normal convolution in the distorted (range) coor- dinates of the non-uniform mapping. We work out the special case of the log- polar mapping, which is of great interest in vision; in this case, we call the associated linear integral transform the ``exponential chirp transform'' (ECT). The method is, however, general for other forms of mapping, or warp, function.	CVPR	visu
4421	CVPR	A hierarchical approach to high resolution edge contour reconstruction.	Stefano Casadei,Sanjoy K. Mitter	1996	Efficient edge detection algorithms such as Canny's (1986) fail near curve singularities. Moreover, the standard linking algorithms used on top of these detectors often fail because of instabilities in the tracking process (due to multiple responses to the same edge and interference of nearby edges). We propose a hierarchical approach to edge detection based on a graph stabilization method that allows bifurcation resolution in stages. Curve singularities are recovered at the last stage by using top-down feedback to select the best curve connections.	CVPR	visu
4422	CVPR	Multi-Stage Target Recognition Using Modular Vector Quantizers and Multilayer Perceptrons.	LipChen Alex Chan,Nasser M. Nasrabadi,Vincent Mirelli	1996	Multi-Stage Target Recognition Using Modular Vector Quantizers and Multilayer Perceptrons.	CVPR	visu
4423	CVPR	Indexing to 3D Model Aspects using 2D Contour Features.	Jin-Long Chen,George C. Stockman	1996	We present a shape-based method of indexing to model aspects from a single intensity image. Objects are assumed to be rigid. A model aspect is represented by a 2 1/2D edgemap and the parts of the object silhouette. Part decomposition is derived from a codon representation of the object silhouette. Invariant features extracted from each part are then used to index into a hash table to generate model-aspect hypotheses. Knowledge about parts is incorporated in voting schemes to order hypotheses for efficient verification of candidate models. Verification of model-aspect hypotheses is carried out by an alignment algorithm that is robust to partial occlusion. Results of tests using 658 model aspects from 100 objects demonstrate that accurate recognition can be achieved with very few verification attempts.	CVPR	visu
4424	CVPR	Competitive Mixture of Deformable Models for Pattern Classification.	Kwok-Wai Cheung,Dit-Yan Yeung,Roland T. Chin	1996	Following the success of applying deformable models to feature extraction, a natural next step is to apply such models to pattern classification. Recently, we have cast a deformable model under a Bayesian framework for classification, giving promising results. However, deformable model methods are computationally expensive due to the required iterative optimization process. The problem is even more severe when there are a large number of models (e.g., for character recognition), because each of them has to deform and match with the input data before a final classification can be derived. In this paper, we propose to combine the deformable models into a mixture, in which the individual models compete with each other to survive the matching process during classification. Models that do not compete well are eliminated early, thus allowing substantial savings in computation. This process of competition- elimination has been applied to handwritten digit recognition in which significant speedup can be achieved without sacrificing recognition accuracy.	CVPR	visu
4425	CVPR	Global Minimum for Active Contour Models: A Minimal Path Approach.	Laurent D. Cohen,Ron Kimmel	1996	A new boundary detection approach for shape modeling is presented. It detects the global minimum of an active contour model&lsquo;s energy between two end points. Initialization is made easier and the curve is not trapped at a local minimum by spurious edges. We modify the &ldquo;snake&rdquo; energy by including the internal regularization term in the external potential term. Our method is based on finding a path of minimal length in a Riemannian metric. We then make use of a new efficient numerical method to find this shortest path.It is shown that the proposed energy, though based only on a potential integrated along the curve, imposes a regularization effect like snakes. We explore the relation between the maximum curvature along the resulting contour and the potential generated from the image.The method is capable to close contours, given only one point on the objects&lsquo; boundary by using a topology-based saddle search routine.We show examples of our method applied to real aerial and medical images.	CVPR	visu
4426	CVPR	A Space-Sweep Approach to True Multi-Image Matching.	Robert T. Collins	1996	The problem of determining feature correspondences across multiple views is considered. The term true multi-image matching is introduced to describe techniques that make full and efficient use of the geometric relationships between multiple images and the scene. A true multi-image technique must generalize to any number of images, be of linear algorithmic complexity in the number of images, and use all the images in an equal manner. A new space-sweep approach to true multi-image matching is presented that simultaneously determines 2D feature correspondences and the 3D positions of feature points in the scene. The method is based on the premise that areas of space where several viewing rays intersect are the likely locations of observed 3D scene features. It is shown that the intersections of viewing rays with a plane sweeping through space can be determined very efficiently, and a statistical model is developed to tell how likely it is that a given number of viewing rays will pass through an area of the plane by chance. The method is illustrated on a seven-image matching example from the aerial image domain. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player	CVPR	visu
4427	CVPR	Feature-Based Face Recognition Using Mixture-Distance.	Ingemar J. Cox,Joumana Ghosn,Peter N. Yianilos	1996	Feature-Based Face Recognition Using Mixture-Distance.	CVPR	visu
4428	CVPR	Hand segmentation using learning-based prediction and verification for hand sign recognition.	Yuntao Cui,John J. Weng	1996	This paper presents a prediction-and-verification segmentation scheme wing attention images from multiple fixations. A major advantage of this scheme is that it can handle a large number of different deformable objects presented in complex backgrounds. The scheme is also relatively efficient since the segmentation is guided by the past knowledge through a prediction-and-verification scheme. The system has been tested to segment hands in the sequences of intensity images, where each sequence represents a hand sign. The experimental result showed a 95% correct segmentation rate with a 3% false rejection rate.	CVPR	visu
4429	CVPR	Active Intrinsic Calibration Using Vanishing Points.	Konstantinos Daniilidis,Jörg Ernst	1996	We propose a new method for the estimation of the intrinsic parameters of an active camera. During a fixed axis camera rotation every point is moving on a conic section. If the point used is a vanishing point the conic section is invariant to possible translations of the observer. Given the rotation axis and the inter-frame correspondence of a set of parallel lines we are able to compute the intrinsic parameters without knowledge of the rotation angles. We propagate the error covariances and we remove the bias in the computation of the conic. We experimentally study the sensitivity of calibration to the amount of rotation and we compare our performance to the performance of a recent active calibration technique.	CVPR	visu
4430	CVPR	Active Face Tracking and Pose Estimation in an Interactive Room.	Trevor Darrell,Baback Moghaddam,Alex Pentland	1996	We demonstrate real-time face tracking and pose estimation in an unconstrained office environment with an active foveated camera. Using vision routines previously implemented for an interactive environment, we determine the spatial location of a user's head and guide an active camera to obtain foveated images of the face. Faces are analyzed using a set of eigenspaces indexed over both pose and world location. Closed loop feedback from the estimated facial location is used to guide the camera when a face is present in the foveated view. Our system can detect the head pose of an unconstrained user in real-time as he or she moves about an open room.	CVPR	visu
4431	CVPR	Convexity Analysis of Active Contour Problems.	Christos Davatzikos,Jerry L. Prince	1996	Convexity Analysis of Active Contour Problems.	CVPR	visu
4432	CVPR	The Integration of Optical Flow and Deformable Models with Applications to Human Face Shape and Motion Estimation.	Douglas DeCarlo,Dimitris N. Metaxas	1996	We present a formal methodology for the integration of optical flow and deformable models. The optical flow constraint equation provides a non-holonomic constraint on the motion of the deformable model. In this augmented system, forces computed from edges and optical flow are used simultaneously. When this dynamic system is solved, a model-based least-squares solution for the optical flow is obtained and improved estimation results are achieved. The use of a 3-D model reduces or eliminates problems associated with optical flow computation. This approach instantiates a general methodology for treating visual cues as constraints on deformable models. We apply this framework to human face shape and motion estimation. Our 3-D deformable face model uses a small number of parameters to describe a rich variety of face shapes and facial expressions. We present experiments in extracting the shape and motion of a face from image sequences.	CVPR	visu
4433	CVPR	The Integration of Optical Flow and Deformable Models with Applications to Human Face Shape and Motion Estimation.	Douglas DeCarlo,Dimitris N. Metaxas	1996	We present a formal methodology for the integration of optical flow and deformable models. The optical flow constraint equation provides a non-holonomic constraint on the motion of the deformable model. In this augmented system, forces computed from edges and optical flow are used simultaneously. When this dynamic system is solved, a model-based least-squares solution for the optical flow is obtained and improved estimation results are achieved. The use of a 3-D model reduces or eliminates problems associated with optical flow computation. This approach instantiates a general methodology for treating visual cues as constraints on deformable models. We apply this framework to human face shape and motion estimation. Our 3-D deformable face model uses a small number of parameters to describe a rich variety of face shapes and facial expressions. We present experiments in extracting the shape and motion of a face from image sequences.	CVPR	visu
4434	CVPR	From projective to Euclidean reconstruction.	Frederic Devernay,Olivier D. Faugeras	1996	To make a Euclidean reconstruction of the world seen through a stereo rig, we can either use a calibration grid, and the results will rely on the precision Of the grid and the extracted points of interest, or use self-calibration. Past work on self-calibration is focussed on the use of only one camera, and gives sometimes very unstable results. In this paper, we use a stereo rig which is supposed to be weakly calibrated using a method such as the one described in Deriche et al. (1994). Then, by matching two sets of points of the same scene reconstructed from different points of view, we try to find both the homography that maps the projective reconstruction to the Euclidean space and the displacement from the first set of points to the second set of points. We present results of the Euclidean reconstruction of a whole object from uncalibrated cameras using the method proposed here.	CVPR	visu
4435	CVPR	Sparse Representations for Image Decomposition with Occlusions.	Michael J. Donahue,Davi Geiger,Tyng-Luh Liu,Robert A. Hummel	1996	We study the problem of how to detect interesting objects'' appeared in a given image, I. Our approach is to treat it as a function approximation problem based on an over-redundant basis, and also account for occlusions, where the basis superposition principle is no longer valid. Since the basis (a library of image templates) is over-redundant, there are infinitely many ways to decompose I. We are motivated to select a sparse/compact representation of I, and to account for occlusions and noise. We then study a greedy and iterative weighted Lp Matching Pursuit strategy, with 0	CVPR	visu
4436	CVPR	An MIMD Computing Platform for a Hierarchical Foveal Machine Vision System.	Fenglei Du,Andrew Izatt,Cesar Bandera	1996	A Multiple Instruction Multiple Data (MIMD) parallel computing platform built upon a network of TMS320C40/44s (C40/C44) for real-time image processing of a hierarchical foveal machine vision (HFMV) system is described in this paper. The architecture of the system, the parallel algorithm development environment, and strategies to map tasks into the computing platform are described. The platform supports both static and dynamic computing resource allocation. The performance of the computing platform is illustrated by examples.	CVPR	visu
4437	CVPR	Space Scale Localization, Blur, and Contour-Based Image Coding.	James H. Elder,Steven W. Zucker	1996	We have recently proposed a scale-adaptive algorithm for reliable edge detection and blur estimation. The algorithm produces a contour code which consists of estimates of position, brightness, contrast and blur for each edge point in the image. Here we address two questions: 1. Can scale adaptation be used to achieve precise localization of blurred edges? 2. How much of the perceptual content of an image is carried by the 1-D contour code? We report an efficient algorithm for subpixel localization, and show that local scale control allows excellent precision even for highly blurred edges. We further show how local scale control can quantitatively account for human visual acuity of blurred edge stimuli. To address the question of perceptual content, we report an algorithm for inverting the contour code to reconstruct an estimate of the original image. While reconstruction based on edge brightness and contrast alone introduces significant artifact, restitution of the local blur signal is shown to produce perceptually accurate reconstructions.	CVPR	visu
4438	CVPR	A Robust Clustering Algorithm Based on Competitive Agglomeration and Soft Rejection of Outliers.	Hichem Frigui,Raghu Krishnapuram	1996	We present a new clustering algorithm that addresses two major issues associated with conventional partitional clustering: the difficulty in determining the number of clusters, and the sensitivity to noise and outliers. The proposed algorithm determines the number of clusters by a process of competitive agglomeration. Noise immunity is achieved by integrating concepts from robust statistics into the algorithm. The proposed approach can incorporate different distance measures in the objective function to find an unknown number of clusters of various types including lines, planes and surfaces.	CVPR	visu
4439	CVPR	The use of hybrid models to recover cardiac wall motion in tagged MR images.	Gareth Funka-Lea,Alok Gupta	1996	We present a new algorithm for the automatic recovery of tag grid-line intersections in Tagged MR images of the left ventricle of the heart. Our method uses an active spring mesh to capture local properties of the motion and a global motion model to capture the global coherence of the motion. We recover the global component of the motion using robust estimation. Different motion models have been developed for short and long axis views of the heart. The algorithm has been tested on healthy and pathological data.	CVPR	visu
4440	CVPR	3-D model-based tracking of humans in action: a multi-view approach.	Dariu Gavrila,Larry S. Davis	1996	We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-In-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango.	CVPR	visu
4441	CVPR	Visual Organization for Figure/Ground Separation.	Davi Geiger,Krishnan Kumaran,Laxmi Parida	1996	A common factor in all illusory contour figures is the perception of a surface occluding part of a background. In our previous work we have shown that by detecting junctions and assigning a proper set of hypothesis at each junction, we could diffuse this information and obtain surface reconstructions where the surface boundaries represented illusory contours. Amodal completions emerge at the overlapping surfaces. We here address the problem of selecting the best image organization (set of hypothesis). We propose two optimization criteria, one based on a coherence measure between pairs of junctions (correlation between the diffusion of each pair) and another one based on an entropy measure (sharpness of the reconstruction). We show their similarity and a statistical physics approach to select the best organization. The experiments suggest that despite the large number of possible organizations our approach may take a few steps to select the best organization (starting from random organizations).	CVPR	visu
4442	CVPR	Target Detection in Foveal ATR Systems.	Sugata Ghosal,Douglas C. McKee	1996	Automatic target recognition (ATR) applications require simultaneously a wide field of view (FOV) for better detection and situation awareness, high resolution for target recognition and threat assessment, and high frame rate for detecting brief events and disambiguating frame-to-frame correlation. Uniformly sampling the entire FOV at recognition resolution is simply wasteful in ATR scenarios with localized regions of interest (ROIs). Foveal data acquisition with space-variant sampling and context- sensitive sensor articulation is highly optimized for active ATR applications. We propose a multiscale local Zernike filter-based front end target detection technique for a commercially feasible foveal sensor topology with piecewise constant resolution profile. Anisotropic heat diffusion is employed for preprocessing of the foveal data. Expansion template matching is used to derive a detection filter that optimizes the discriminant signal-to-noise ratio (SNR). Results are presented with simulated foveal imagery derived from real uniform acuity FLIR data.	CVPR	visu
4443	CVPR	Real-time tracking of image regions with changes in geometry and illumination.	Gregory D. Hager,Peter N. Belhumeur	1996	Historically, SSD or correlation-based visual tracking algorithms have been sensitive to changes in illumination and shading across the target region. This paper describes methods for implementing SSD tracking that is both insensitive to illumination variations and computationally efficient. We first describe a vector-space formulation of the tracking problem, showing how to recover geometric deformations. We then show that the same vector space formulation can be used to account for changes in illumination. We combine geometry and illumination into an algorithm that tracks large image regions on live video sequences using no more computation than would be required to trade with no accommodation for illumination changes. We present experimental results which compare the performance of SSD tracking with and without illumination compensation.	CVPR	visu
4444	CVPR	/spl lambda//spl tau/-space representation of images and generalized edge detector.	Muhittin Gökmen,Anil K. Jain	1996	An image clad surface representation based on regularization theory is introduced in this paper. This representation is based on a hybrid model derived from the physical membrane and plate models. The representation, called the /spl lambda//spl tau/-representation, has two dimensions; one dimension represents smoothness or scale while the other represents the continuity of the image or surface. It contains images/surfaces sampled both in scale space and the weighted Sobolev space of continuous functions. Thus, this new representation can be viewed as an extension of the well-known scale space representation. We have experimentally shown that the proposed hybrid model results in improved results compared to the two extreme constituent model, i.e., the membrane and the plate models. Based on this hybrid model, a generalized edge detector (GED) which encompasses most of the well-known edge detectors under a common framework is developed. The existing edge detectors can be obtained from the generalized edge detector by simply specifying the valves of two parameters, one of which controls the shape of the filter (/spl tau/) and the other controls the scale of the filter (/spl lambda/). By sweeping the valves of these two parameters continuously, one can generate an edge representation in the /spl lambda//spl tau/ space, which is very useful for developing a goal-directed edge detection scheme for a specific task. The proposed representation and the edge detector have been evaluated qualitatively and quantitatively on several different types of image data such as intensity, range and stereo images.	CVPR	visu
4445	CVPR	Graph matching by graduated assignment.	Steven Gold,Anand Rangarajan	1996	A new algorithm for graph matching, which uses graduated assignment is presented, along with experimental results demonstrating large improvements in speed and accuracy over previous techniques. The softassign, a novel constraint satisfaction technique, is applied to a new graph matching energy function that uses a robust, sparse distance measure between the links of the two graphs. The softassign, which has emerged out of the neural network/statistical physics framework enforces two-way (assignment) constraints without the use of penalty terms. The algorithm's low order computational complexity [0(lm), where l and m are the number of links in the two graphs] compares favorably with most competing approaches. The method, not restricted to any special class of graph, is applied to subgraph isomorphism, weighted graph matching, and attributed relational graph matching. Experiments on graphs generated from images and on randomly generated graphs, including benchmarks against a relation labeling algorithm and an algorithm employing Potts glass dynamics are reported. Over twenty-five thousand experiments were conducted. No comparable results have been reported by any other graph matching algorithm before in the research literature.	CVPR	visu
4446	CVPR	Mirror and Point Symmetry under Perspective Skewing.	Luc J. Van Gool,Theo Moons,Marc Proesmans	1996	Over recent years, symmetry research has shifted from the detection of affinely to perspectively skewed mirror symmetry. Also, links between invariance research and symmetry-specific geometric constraints have been established. The paper aims to contribute to both strands. Several sets of symmetry specific invariants are derived, that can be used in different situations, depending on the a priori assumptions made. It is also argued that all the results directly apply to the case of perspectively skewed point symmetry.	CVPR	visu
4447	CVPR	Inference of segmented, volumetric shape from three intensity images.	Parag Havaldar,Gérard G. Medioni	1996	We present a method to infer segmented and full volumetric descriptions of objects from intensity images. We use three weakly calibrated images from closely spaced viewpoints as input. Deriving full volumetric descriptions requires the development of robust inference rules. The inference rules are based on local properties of generalized cylinders (GCs). We first detect groups in each image based on proximity, parallelism and symmetry. The groups in the three images are matched and their contours are labelled as true and limb edges. We use the information about groups and the label associated with their contours to recover visible surfaces and their surface axes. To extract the complete volume in terms of a GC, we need to infer the GC axis, its cross section and the scaling function. The properties of straight and curved axis generalized cylinders are used locally on the visible surfaces to obtain the GC axis. The cross section is recovered if seen in the images, else it is inferred using the visible surfaces and GC properties. We consider groups with true edges, limb edges or a combination of both. The final descriptions are volumetric and in terms of parts. Sometimes, when not enough information is present to make volumetric inferences, the descriptions remain at the surface level. We demonstrate results on real images of moderately complex objects with texture and shadows.	CVPR	visu
4448	CVPR	Using physics-based invariant representations for the recognition of regions in multispectral satellite images.	Glenn Healey,Amit Jain	1996	We present a set of algorithms and a search strategy for the robust content- based retrieval of multispectral satellite images. Since the property of interest in these images is usually the physical characteristics of ground cover, we use representations and methods that are invariant to illumination and atmospheric conditions. The representations and algorithms are derived for this application from a physical model for the formation of multispectral satellite images. The use of several representations and algorithms is necessary to interpret the diversity of physical and geometric structure in these images. Algorithms are used that exploit multispectral distributions, multispectral spatial structure, and labeled classes. The performance of the system is demonstrated on a large set of multispectral satellite images taken over different areas of the United States under different illumination and atmospheric conditions.	CVPR	visu
4449	CVPR	Comparison of Edge Detectors: A Methodology and Initial Study.	Michael D. Heath,Sudeep Sarkar,Thomas A. Sanocki,Kevin W. Bowyer	1996	Because of the difficulty of obtaining ground truth for real images, the traditional technique for comparing low-level vision algorithms is to present image results, side by side, and to let the reader subjectively judge the quality. This is not a scientifically satisfactory strategy. However, human rating experiments can be done in a more rigorous manner, to provide useful quantitative conclusions. We present a paradigm based on experimental psychology and statistics, in which humans rate the output of low level vision algorithms. We demonstrate the proposed experimental strategy by comparing four well known edge detectors: Canny, Nalwa-Binford, Sarkar-Boyer, and Sobel. We answer the following questions: Is there a statistically significant difference in edge detector outputs as perceived by humans? Do the edge detection results of an operator vary significantly with the choice of its parameters? For each detector, is it possible to choose a single set of optimal parameters for all the images without significantly affecting the edge output quality? Does an edge detector produce edges of the same quality for all images, or does the edge quality vary with the image?	CVPR	visu
4450	CVPR	Canonical Decomposition of Steerable Functions.	Yacov Hel-Or,Patrick C. Teo	1996	This paper describes a general mathematical formulation for the problem of constructing steerable functions. The formulation is based on Lie group theory and is thus applicable to transformations which are Lie groups, such as, rotation, translation, scaling, and affine transformation. For one-parameter and Abelian multi-parameter Lie transformation groups, a canonical decomposition of all possible steerable functions, derived using the Jordan decomposition of matrices, is developed. It is shown that any steerable function under Lie transformation groups can be described using this decomposition. Finally, a catalog of steerable functions for several common multi-parameter image transformation groups is also provided.	CVPR	visu
4451	CVPR	Invariant histograms and deformable template matching for SAR target recognition.	Katsushi Ikeuchi,Takeshi Shakunaga,Mark D. Wheeler,Taku Yamazaki	1996	Recognizing a target in synthetic-aperture radar (SAR) images is an important, yet challenging, application of the model-based vision technique. This paper describes a model-based SAR recognition system based on invariant histograms and deformable template matching techniques. An invariant histogram is a histogram of invariant values defined by geometric features such as points and lines in SAR images. Although a few invariants are sufficient to recognize a target, we use a histogram of all invariant values given by all possible target feature pairs. This redundant histogram enables robust recognition under severe occlusions typical in SAR recognition scenarios. Multi-step deformable template matching examines the existence of an object by superimposing templates over potential energy field generated from images or primitive features. It determines the template configuration which has the minimum deformation and the best alignment of the template with features. The deformability of the template absorbs the instability of SAR features. We have implemented the system and evaluated the system performance using hybrid SAR images, generated from synthesized model signatures and real SAR background signatures.	CVPR	visu
4452	CVPR	Recognizing 3D Objects by Generating Random Actions.	Stéphane Herbin	1996	This paper presents a formal model of an active recognition system that can be programmed by learning. At each time step the system decides between producing an action to generate new data and stopping to issue the name of the object observed. The actions can be directed either towards the external environment or towards the internal perceptual system of the agent. The decision strategy is based on a quantitative evaluation of the system learning experience. The problem studied is the recognition of chess pieces using a moving camera and a multiscale feature detector. The recognition is difficult because the objects are complex -- neither polyhedral nor smooth -- and rather similar between classes, especially in certain view configurations. The system uses the information obtained by observing internal state transitions when the camera is moved or when the feature detector scale is changed. A simulation of the agent and the environment is used for experimental measures of the model performances.	CVPR	visu
4453	CVPR	SiteCity: A Semi-Automated Site Modelling System.	Yuan C. Hsieh	1996	This paper presents SiteCity, a semi-automated building extraction system integrating photogrammetry, geometric constraints and image understanding algorithms. Existing automated building extraction systems produce mixed results and it is clear that human intervention is required to correct mistakes from fully automated systems. SiteCity gives human operators the ability to construct and manipulate three dimensional building objects using multiple images. Image understanding algorithms are integrated into SiteCity to assist users. The automated processes in SiteCity use user-delineated roof boundaries as cues, and attempt to locate the floor of a building and match the building object in other images. In addition, photogrammetric cues are used to assist automated processes. These automated processes are described and their performance is evaluated, illustrating that automated processes in SiteCity produce comparable performance to that of human subjects.	CVPR	visu
4454	CVPR	Recognizing Three-Dimensional Objects by Comparing Two-Dimensional Images.	Daniel P. Huttenlocher,Liana M. Lorigo	1996	In this paper we address the problem of recognizing an object from a novel viewpoint, given a single ``model'' view of that object. As is common in model-based recognition, objects and images are represented as sets of feature points. We present an efficient algorithm for determining whether two sets of image points (in the plane) could be projections of a common object (a three-dimensional point set). The method relies on the fact that two sets of points in the plane are orthographic projections of the same three-dimensional point set exactly when they have a common projection onto a line. This is a form of the well-known epipolar constraint used in stereopsis. Our algorithm can be used to recognize an object by comparing a stored two-dimensional view of the object against an unknown view, without requiring the correspondence between points in the views to be known a priori. We provide some examples illustrating the approach.	CVPR	visu
4455	CVPR	Skin and Bones: Multi-layer, Locally Affine, Optical Flow and Regularization with Transparency.	Shanon X. Ju,Michael J. Black,Allan D. Jepson	1996	This paper describes a new method for estimating optical flow that strikes a balance between the flexibility of local dense computations and the robustness and accuracy of global parameterized flow models. An affine model of image motion is used within local image patches while a spatial smoothness constraint on the affine flow parameters of neighboring patches enforces continuity of the motion. We refer to this as a ``Skin and Bones'' model in which the affine patches can be thought of as rigid ``bones'' connected by a flexible ``skin''. Since local image patches may contain multiple motions we use a layered representation for the affine bones. To regularize this layered motion representation we develop a new framework for regularization with transparency.	CVPR	visu
4456	CVPR	Gesture recognition using the Perseus architecture.	Roger E. Kahn,Michael J. Swain,Peter N. Prokopowicz,R. James Firby	1996	Interpersonal communication involves more than simply spoken information. Gestures are commonly used to more efficiently and precisely communicate. An important gesture because of its descriptive power and frequency of use is pointing. To produce a more natural and powerful human-robot interface, we have developed a purposive visual architecture called Perseus and have used it to locate objects a person is pointing to. With Perseus, in real-time, we are able to determine when a person enters the scene, track the relevant parts of the person including the hands and head, and recognize when she is pointing. Once the person points, the object pointed to is located. The Perseus architecture allows knowledge about the task and context to be used at all levels of visual analysis for improved performance. This knowledge is explicitly represented in the Perseus system to facilitate the extension of Perseus to other tasks and environments. In this paper we describe Perseus and how it is used to solve this task. Previous work on Perseus is extended by describing a more sophisticated representation of the person and superior segmenting and tracking methods. Experiments showing the success of the Perseus system with numerous naive users in varied environments is presented.	CVPR	visu
4457	CVPR	Model-based estimation of 3D human motion with occlusion based on active multi-viewpoint selection.	Ioannis A. Kakadiaris,Dimitris N. Metaxas	1996	Dept. of Comput. & Inf. Sci., Pennsylvania Univ., Philadelphia, PA, USA Abstract: We present a new method for the 3D model-based tracking of human body parts. To mitigate the difficulties arising due to occlusion among body parts, we employ multiple calibrated cameras in a mutually orthogonal configuration. In addition, we develop criteria for a time varying active selection of a set of cameras to track the motion of a particular human part. In particular, at every frame, each camera tracks a number of parts depending on the visibility of these parts and the observability of their predicted motion from the specific camera. To relate points on the occluding contours of the parts to points on their models we apply concepts from projective geometry. Then, within the physics-based framework we compute the generalized forces applied from the parts' occluding contours to model points of the body parts. These forces update the translational and rotational degrees of freedom of the model, such as to minimize the discrepancy between the sensory data and the estimated model state. We present initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion.	CVPR	visu
4458	CVPR	A Stereo Machine for Video-Rate Dense Depth Mapping and Its New Applications.	Takeo Kanade,Atsushi Yoshida,Kazuo Oda,Hiroshi Kano,Masaya Tanaka	1996	We have developed a video-rate stereo machine that has the capability of generating a dense depth map at the video rate. The performance bench marks of the CMU video-rate stereo machine are: 1) multi image input of up to 6 cameras; 2) throughput of 30 million point-disparity measurements per second; 3) frame rate of 30 frame/sec; 4) a dense depth map of up to 256 x 240 pixels; 5) disparity search range of up to 60 pixels; 6) high precision of depth output up to 8 bi ts (with interpolation). The capability of passively producing such a dense depth map (3D representation) of a scene at the video rate can open up a new class of applications of 3D vision:merging real and virtual worlds in real time.	CVPR	visu
4459	CVPR	3-D Scene Data Recovery using Omnidirectional Multibaseline Stereo.	Sing Bing Kang,Richard Szeliski	1996	A traditional approach to extracting geometric information from a large scene is to compute multiple 3-D depth maps from stereo pairs or direct range finders, and then to merge the 3-D data. However, the resulting merged depth maps may be subject to merging errors if the relative poses between depth maps are not known exactly. In addition, the 3-D data may also have to be resampled before merging, which adds additional complexity and potential sources of errors.This paper provides a means of directly extracting 3-D data covering a very wide field of view, thus by-passing the need for numerous depth map merging. In our work, cylindrical images are first composited from sequences of images taken while the camera is rotated 360&deg; about a vertical axis. By taking such image panoramas at different camera locations, we can recover 3-D data of the scene using a set of simple techniques: feature tracking, an 8-point structure from motion algorithm, and multibaseline stereo. We also investigate the effect of median filtering on the recovered 3-D point distributions, and show the results of our approach applied to both synthetic and real scenes.	CVPR	visu
4460	CVPR	Recognition of Handwritten Phrases as Applied to Street Name Images.	Gyeonghwan Kim,Venu Govindaraju	1996	A method for recognition of street name phrases collected from mail pieces is presented in this paper. Some of the challenges posed by the problem are: (i) patron errors, (ii) non-standardized way of abbreviating names, and (iii) variable number of words in a street name image. A neural network has been designed to segment words in a phrase, a street name in this case, using distances between components and style of writing. The network learns the type of spacing (including size) that one should expect between different pairs of characters in handwritten text. Experiments show perfect word segmentation performance at about 85% of cases. Unlike conventional methods, where lexicon entries are expanded to take care of all variations of prefixes and suffixes, substring matching is attempted only between the main body of a lexicon entry and the word segments of an image. Efforts to reduce computational complexity are successfully made by the sharing of character segmentation results between the segmentation and recognition phases. 83% phrase recognition accuracy is achieved on a test set.	CVPR	visu
4461	CVPR	Panoramic Image Acquisition.	Arun Krishnan,Narendra Ahuja	1996	This paper is concerned with acquiring panoramic focused images using a small field of view video camera. When scene points are distributed over a range of distances from the sensor, obtaining a focused composite image involves focus computations and mechanically changing some sensor parameters (translation of sensor plane, panning of camera etc.) which can be time intensive. In this paper we present methods to optimize the image acquisition strategy in order to reduce redundancy. We show that panning a camera about a point f (focal length) in front of the camera eliminates redundancy. The Non-frontal imaging camera (NICAM) with tilted sensor plane has been previously introduced as a sensor that can acquire focused panoramic images. In this paper we also describe strategies for optimal selection of panning angle increments and sensor plane tilt for NICAM. Experimental results are presented for panoramic image acquisition using a regular camera as well as using NICAM.	CVPR	visu
4462	CVPR	Eigenfeatures for planar pose measurement of partially occluded objects.	John Krumm	1996	Planar pose measurement from images is an important problem for automated assembly and inspection. In addition to accuracy and robustness, ease of use is very important for real world applications. Recently, Murase and Nayar have presented the parametric eigenspace  for object recognition and pose measurement based on training images. Although their system is easy to use, it has potential problems with background clutter and partial occlusions. We present an algorithm that is robust in these terms. It uses several small features on the object rather than a monolithic template. These eigenfeatures are matched using a median statistic, giving the system robustness in the face of background clutter and partial occlusions. We demonstrate our algorithm's pose measurement accuracy with a controlled test, and we demonstrate its detection robustness on cluttered images with the objects of interest partially occluded.	CVPR	visu
4463	CVPR	Recovery of Global Nonrigid Motion - Based Approach Without Point Correspondences.	Senthil Kumar,Dmitry B. Goldgof	1996	Recovery of Global Nonrigid Motion - Based Approach Without Point Correspondences.	CVPR	visu
4464	CVPR	Novel active-vision-based visual-threat-cue for autonomous navigation tasks.	Sridhar R. Kundur,Daniel Raviv	1996	This paper presents a new visual motion cue, we call the Visual Threat Cue (VTC) that provides some measure for a relative change in range as well as clearance between a 3D surface and a fixing observer in motion. The VTC corresponds to visual fields surrounding a moving observer. The fields are time-based imaginary 3-D surfaces that move with the observer. They are analogous to equi-potential fields of an electric dipole. A practical method to extract the VTC is presented. The approach is independent of the 3D surface texture and needs no optical flow information, 3D reconstruction, segmentation, feature tracking or pre-processing. This algorithm to extract the VTC was applied to several indoor as well as outdoor real images of textures, where we observed a similar behavior for most of the textures employed.	CVPR	visu
4465	CVPR	Recovering the viewing parameters of random, translated and noisy projections of asymmetric objects.	Peter D. Lauren,N. Nandhakumar	1996	A method is described for the determination of the viewing parameters of randomly acquired projections of asymmetric objects. It extends upon the common lines algorithm by determining the relative orientation of projections from the location of lines of intersection among the Fourier transforms of the projections in three-dimensional Fourier space. A new technique for finding the lines of intersection in the presence of translational displacement, and for subsequently finding the translational displacement, is presented. A new technique for dealing with noise is also presented. The complete algorithm is described and its efficacy is demonstrated using real data. This technique may be applied to the three-dimensional reconstruction of viruses, molecules, and cells from in vivo images. It also has many other applications including the reconstruction of underwater scenes, radioastronomy, geoseismic analysis, and portable radiography for medical diagnosis and industrial inspection.	CVPR	visu
4466	CVPR	Convolutional Neural Networks for Face Recognition.	Steve Lawrence,C. Lee Giles,Ah Chung Tsoi	1996	Convolutional Neural Networks for Face Recognition.	CVPR	visu
4467	CVPR	New, faster, more controlled fitting of implicit polynomial 2D curves and 3D surfaces to data .	Zhibin Lei,David B. Cooper	1996	Denote a point in the plane by z=(z,y) and a polynomial of nth degree in z by f(z) /spl Sigma//sub i,j//spl ges/o/sub 1/i+j/spl les/n(a/sub ij/x/sup i/y/sup j/). Denote by Z(f) the set of points for which f(z)=0. Z(f) is the 2D curve represented by f(z). In this paper, we present a new approach to fitting 2D curves to data in the plane (or 3D surfaces to range data) which has significant advantages over presently known methods. It requires considerably less computation and the resulting curve can be forced to lie close to the data set at prescribed points provided that there is an nth degree polynomial that can reasonably approximate the data. Linear programming is used to do the fitting. The approach can incorporate a variety of distance measures and global geometric constraints.	CVPR	visu
4468	CVPR	Dealing with occlusions in the eigenspace approach.	Ales Leonardis,Horst Bischof	1996	The basic limitations of the current appearance-based matching methods using eigenimages are non-robust estimation of coefficients and inability to cope with problems related to occlusions and segmentation. In this paper we present a new approach which successfully solves these problems. The major novelty of our approach lies in the way how the coefficients of the eigenimages are determined. Instead of computing the coefficients by a projection of the data onto the eigenimages, we extract them by a hypothesize-and-test paradigm using subsets of image points. Competing hypotheses are then subject to a selection procedure based on the Minimum Description Length principle. The approach enables us not only to reject outliers and to deal with occlusions but also to simultaneously use multiple classes of eigenimages.	CVPR	visu
4469	CVPR	Bayesian image restoration and segmentation by constrained optimizatio.	Stan Z. Li,Kap Luk Chan,Han Wang	1996	Abstract: A constrained optimization method, called the Lagrange-Hopfield (LH) method, is presented for solving Markov random field (MRF) based Bayesian image estimation problems for restoration and segmentation. The method combines the augmented Lagrangian multiplier technique with the Hopfield network to solve a constrained optimization problem into which the original Bayesian estimation problem is reformulated. The LH method effectively overcomes instabilities that are inherent in the penalty method (e.g. Hopfield network) or the Lagrange multiplier method in constrained optimization. An additional advantage of the LH method is its suitability for neural-like analog implementation. Experimental results are presented which show that LH yields good quality solutions at reasonable computational costs.	CVPR	visu
4470	CVPR	Geometric and Photometric Constraints for Surface Recovery.	Jiping Lu,James J. Little	1996	In this paper we present a novel approach to surface recovery from an image sequence of a rotating object. In this approach, the object is illuminated under a collinear light source (where the light source lies on or near the optical axis) and rotated on a controlled turntable. A wire-frame of 3D curves on the object surface is extracted by using shading and occluding contours in the image sequence. Then the whole object surface is recovered by interpolating the surface between curves on the wire-frame. The interpolation can be done by using geometric or photometric methods. The photometric method uses shading information and is more powerful than geometric methods. The experimental results on real image sequence of matte and specular surfaces show that the technique is feasible and promising.	CVPR	visu
4471	CVPR	Texture Features and Learning Similarity.	Wei-Ying Ma,B. S. Manjunath	1996	This paper addresses two important issues related to texture pattern retrieval: feature extraction and similarity search. A Gabor feature representation for textured images is proposed, and its performance in pattern retrieval is evaluated on a large texture image database. These features compare favorably with other existing texture representations. A simple hybrid neural network algorithm is used to learn the similarity by simple clustering in the texture feature space. With learning similarity, the performance of similar pattern retrieval improves significantly. An important aspect of this work is its application to real image data. Texture feature extraction with similarity learning is used to search through large aerial photographs. Feature clustering enables efficient search of the database as our experimental results indicate.	CVPR	visu
4472	CVPR	Edge Detection and Ridge Detection with Automatic Scale Selection.	Tony Lindeberg	1996	When computing descriptors of image data, the type of information that can be extracted may be strongly dependent on the scales at which the image operators are applied. This article presents a systematic methodology for addressing this problem. A mechanism is presented for automatic selection of scale levels when detecting one-dimensional image features, such as edges and ridges.A novel concept of a scale-space edge is introduced, defined as a connected set of points in scale-space at which: (i) the gradient magnitude assumes a local maximum in the gradient direction, and (ii) a normalized measure of the strength of the edge response is locally maximal over scales. An important consequence of this definition is that it allows the scale levels to vary along the edge. Two specific measures of edge strength are analyzed in detail, the gradient magnitude and a differential expression derived from the third-order derivative in the gradient direction. For a certain way of normalizing these differential descriptors, by expressing them in terms of so-called &gamma;-normalized derivatives, an immediate consequence of this definition is that the edge detector will adapt its scale levels to the local image structure. Specifically, sharp edges will be detected at fine scales so as to reduce the shape distortions due to scale-space smoothing, whereas sufficiently coarse scales will be selected at diffuse edges, such that an edge model is a valid abstraction of the intensity profile across the edge.Since the scale-space edge is defined from the intersection of two zero-crossing surfaces in scale-space, the edges will by definition form closed curves. This simplifies selection of salient edges, and a novel significance measure is proposed, by integrating the edge strength along the edge. Moreover, the scale information associated with each edge provides useful clues to the physical nature of the edge.With just slight modifications, similar ideas can be used for formulating ridge detectors with automatic selection, having the characteristic property that the selected scales on a scale-space ridge instead reflect the width of the ridge.It is shown how the methodology can be implemented in terms of straightforward visual front-end operations, and the validity of the approach is supported by theoretical analysis as well as experiments on real-world and synthetic data.	CVPR	visu
4473	CVPR	Viewpoint Variation in the Noise Sensitivity of Pose Estimation.	Claus B. Madsen	1996	The paper presents an analysis of the stability of pose estimation. The investigated pose estimation technique is based on orientations of three edge segments and provides the rotation part of object pose.The specific emphasis of the analysis is on determining how the stability varies with view point relative to an object. The stability investigation propagates the uncertainty in edge segment orientations to the resulting effect on the pose parameters. It is shown that there is a very strong variation in noise sensitivity over the range of viewpoints and that exactly what viewpoints offer highest robustness towards noise can be determined in advance. Experiments on real images verify the theoretical results and show that, dependent on viewpoint, pose parameter variance varies from 0.05 to 20 (degrees squared).	CVPR	visu
4474	CVPR	Word Spotting: A New Approach to Indexing Handwriting.	R. Manmatha,Chengfeng Han,Edward M. Riseman	1996	There are many historical manuscripts written in a single hand which it would be useful to index. Examples include the early Presidential papers at the Library of Congress and the collected works of W. B. DuBois at the library of the University of Massachusetts. The standard technique for indexing documents is to scan them in, convert them to machine readable form (ASCII) using Optical Character Recognition (OCR) and then index them using a text retrieval engine. However, OCR does not work well on handwriting. Here an alternative scheme is proposed for indexing such texts. Each page of the document is segmented into words. The images of the words are then matched against each other to create equivalence classes (each equivalence classes contains multiple instances of the same word). The user then provides ASCII equivalents for say the top 2000 equivalence classes. The current paper deals with the matching aspects of this process. Due to variations in even a single person''s handwriting, it is expected that the matching will be the most difficult step in the whole process. Two different techniques for matching words are discussed. The first method, based on Euclidean distance mapping, matches words assuming that the transformation between the words may be modelled by a translation (shift). The second method, based on an algorithm developed by Scott and Longuet Higgins, matches words assuming that the transformation between the words may be modelled by an affine transform. Experiments are shown demonstrating the feasibility of the approach for indexing handwriting.	CVPR	visu
4475	CVPR	Controlled camera motions for scene reconstruction and exploration.	Éric Marchand,François Chaumette	1996	This paper deals with the 3D structure estimation and exploration of a scene using active vision. Our method is based on the structure from controlled motion approach which consists in constraining the camera motion in order to obtain a precise and robust estimation of the 3D structure of a geometrical primitive. Since this approach involves to gaze on the considered primitive, we present a method for connecting up many estimations in order to recover the complete spatial structure of scenes composed of cylinders and segments. We have developed perceptual strategies able to perform a succession of robust estimations without any assumption on the number and on the localization of the different objects. Furthermore, the proposed strategy ensures the completeness of the reconstruction. An exploration process centered on current visual features and on the structure of the previously studied primitives is presented. This leads to a gaze planning strategy that mainly uses a representation of known and unknown areas as a basis for selecting viewpoints. Finally, experiments carried out on a robotic cell have proved the validity of our approach.	CVPR	visu
4476	CVPR	Physics-Based Segmentation: Moving Beyond Color.	Bruce A. Maxwell,Steven A. Shafer	1996	We previously presented a framework for segmentation of complex scenes using multiple physical hypotheses for simple image regions. A consequence of that framework was a proposal for a new approach to the segmentation of complex scenes into regions corresponding to coherent surfaces rather than merely regions of similar color. Herein we present an implementation of this new approach and show example segmentations for scenes containing multi-colored piece-wise uniform objects. Using our approach we are able to intelligently segment scenes with objects of greater complexity than previous physics-based segmentation algorithms. The results show that by using general physical models we obtain segmentations that correspond more closely to coherent surfaces in the scene than segmentations found using only color.	CVPR	visu
4477	CVPR	Isotropic Gradient Estimatio.	Jason Merron,Michael Brady	1996	The vast majority of corner and edge detectors measure image intensity gradients in order to estimate the positions and strengths of features. However, many of the most popular intensity gradient estimators are inherently and significantly anisotropic. In spite of this, few algorithms take the anisotropy into account, and so the set of features uncovered is typically sensitive to rotations of the image, compromising recognition, matching (e.g. stereo), and tracking. We introduce an effective technique for removing unwanted anisotropies from analytical gradient estimates, by measuring local intensity gradients in four directions rather than the more traditional two. In experiments using real image data, our algorithm reduces the gradient anisotropy associated with conventional analytical gradient estimates by up to 85%, yeilding more consistent feature topologies.	CVPR	visu
4478	CVPR	Dense Nonrigid Motion Tracking from a Sequence of Velocity Fields.	François G. Meyer,R. Todd Constable,Albert J. Sinusas,James S. Duncan	1996	We have addressed the problem of tracking the nonrigid motion of the heart using a sequence of velocity fields and a sequence of contours. The information from both the contours and the dense velocity fields is integrated into a deforming mesh that is placed over the myocardium at one time frame and then tracked over the entire cardiac cycle. The deformation is guided by a smoothing filter that provides a compromise between (i) believing the dense field velocity and the contour data when it is crisp and coherent in a local spatial and temporal sense and (ii) employing a temporally smooth cyclic model of cardiac motion when contour and velocity data are not trustworthy. The method has been carefully evaluated with simulated data and phantom data. Experiments with in vivo data have also been conducted.	CVPR	visu
4479	CVPR	MUSE: Robust Surface Fitting using Unbiased Scale Estimates.	James V. Miller,Charles V. Stewart	1996	Despite many successful applications of robust statistics, they have yet to be completely adapted to many computer vision problems. Range reconstruction, particularly in unstructured environments, requires a robust estimator that not only tolerates a large outlier percentage but also tolerates several discontinuities, extracting multiple surfaces in an image region. Observing that random outliers and/or points from across discontinuities increase a hypothesized fit's scale estimate (standard deviation of the noise), our new operator, called MUSE (Minimum Unbiased Scale Estimator), evaluates a hypothesized fit over potential inlier sets via an objective function of unbiased scale estimates. MUSE extracts the single best fit from the data by minimizing its objective function over a set of hypothesized fits and can sequentially extract multiple surfaces from an image region. We show MUSE to be effective on synthetic data modelling small scale discontinuities and in preliminary experiments on complicated range data.	CVPR	visu
4480	CVPR	Interactive Learning with a Society of Models .	Thomas P. Minka,Rosalind W. Picard	1996	Digital library access is driven by features, but the relevance of a feature for a query is not always obvious. This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool. Instead of requiring universal similarity measures or manual selection of relevant features, the approach provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features. The selection process is guided by positive and negative examples from the user. The inherent combinatorics of using multiple features is reduced by a multistage grouping generation, weighting, and collection process. The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages. The weighting stage adapts the collection stage's search space across uses, so that, in later interactions, good groupings are found given few examples from the user.	CVPR	visu
4481	CVPR	Bayesian face recognition using deformable intensity surfaces.	Baback Moghaddam,Chahab Nastar,Alex Pentland	1996	We describe a novel technique for face recognition based on deformable intensity surfaces which incorporates both the shape and texture components of the 2D image. The intensity surface of the facial image is modeled as a deformable 3D mesh in (z, y, I(x, y)) space. Using an efficient technique for matching two surfaces (in terms of the analytic modes of vibration), we obtain a dense correspondence field (or 3D warp) between two images. The probability distributions of two classes of warps are then estimated from training data: interpersonal and extrapersonal variations. These densities are then used in a Bayesian framework for image matching and recognition. Experimental results with facial data from the US Army FERET database demonstrate an increased recognition rate over the previous best methods.	CVPR	visu
4482	CVPR	Closest Point Search in High Dimensions.	Sameer A. Nene,Shree K. Nayar	1996	The problem of finding the closest point in high-dimensional spaces is common in computational vision. Unfortunately, the complexity of most existing search algorithms, such as k-d tree and R-tree, grows exponentially with dimension, making them impractical for dimensionality above 15. In nearly all applications, the closest point is of interest only if it lies within a user specified distance \epsilon. We present a simple and practical algorithm to efficiently search for the nearest neighbor within Euclidean distance \epsilon. Our algorithm uses a projection search technique along with a novel data structure to dramatically improve performance in high dimensions. A complexity analysis is presented which can help determine \epsilon in structured problems. Benchmarks clearly show the superiority of the proposed algorithm for high dimensional search problems frequently encountered in machine vision, such as real-time object recognition.	CVPR	visu
4483	CVPR	Parametric Feature Detection.	Shree K. Nayar,Simon Baker,Hiroshi Murase	1996	We propose an algorithm to automatically construct feature detectors for arbitrary parametric features. To obtain a high level of robustness we advocate the use of realistic multi-parameter feature models and incorporate optical and sensing effects. Each feature is represented as a densely sampled parametric manifold in a low dimensional subspace of a Hilbert space. During detection, the brightness distribution around each image pixel is projected into the subspace. If the projection lies sufficiently close to the feature manifold, the feature is detected and the location of the closest manifold point yields the feature parameters. The concepts of parameter reduction by normalization, dimension reduction, pattern rejection, and heuristic search are all employed to achieve the required efficiency. By applying the algorithm to appropriate parametric feature models, detectors have been constructed for five features, namely, step edge, roof edge, line, corner, and circular disc. Detailed experiments are reported on the robustness of detection and the accuracy of parameter estimation.	CVPR	visu
4484	CVPR	3-D Object Pose Estimation by Shading and Edge Data Fusion ----Simulating virtual manipulation on mental images.	Yoshihiko Nomura,Dili Zhang,Yuko Sakaida,Seizo Fujii	1996	Human beings seem to recognize objects based on a kind of model-matching, i.e., a virtual manipulation on mental images. This paper presents a 3-D object pose estimation method simulating the human recognition scheme. Computer synthesizes not only an edge image but also a shading image from an object model. Then, it matches the two kinds of synthesized images with the inputted images individually by using a non-linear least-squares method, and estimates the pose parameter values. Finally, it chooses the better of the individually estimated poses. Thus, the fusion of the shading and the edge information is achieved. Since the two pieces of information complement each other, this method has the advantage of much higher robustness and accuracy of pose estimation than ordinary model-matching techniques which rely only on geometrical features such as vertices or edges.	CVPR	visu
4485	CVPR	Recovering Affine Motion and Defocus Blur Simultaneously.	Zarina Myles,Niels da Vitoria Lobo	1996	Motion in depth and/or zooming cause defocus blur. We show how the defocus blur in an image can be recovered simultaneously with affine motion. We introduce the theory, develop a solution method and demonstrate the validity of the theory and the solution by conducting experiments with real scenery.	CVPR	visu
4486	CVPR	Global Models with Parametric Offsets as Applied to Cardiac Motion Recovery.	Thomas O'Donnell,Terrance E. Boult,Alok Gupta	1996	We introduce a new solid shape model formulation that includes built-in offsets from a base global component (e.g. an ellipsoid) which are functions of the global component's parameters. The offsets provide two features. First, they help to form an expected model shape which facilitates appropriate model data correspondences. Second, they scale with the base global model to maintain the expected shape even in the presence of large global deformations. We apply this model formulation to the recovery of 3-D cardiac motion from a volunteer dataset of tagged-MR images. The model instance is a variation of the Hybrid Volumetric Ventriculoid (HVV), a deformable thick-walled ellipsoid model resembling the left ventricle (LV) of the heart. A unique aspect of our implementation is the employment of constant volume constraints when recovering the cardiac motion. In addition, we present a novel geodesic-like prismoidal tessellation of the model which provides for more stable fits.	CVPR	visu
4487	CVPR	Occlusion Detectable Stereo -- Occlusion Patterns in Camera Matrix.	Yuichi Nakamura,Tomohiko Matsuura,Kiyohide Satoh,Yuichi Ohta	1996	In stereo algorithms with more than two cameras, the improvement of accuracy is often reported since they are robust against noise. However, another important aspect of the polynocular stereo, that is the ability of occlusion detection, has been paid less attention. We intensively analyzed the occlusion in the camera matrix stereo (SEA) and developed a simple but effective method to detect the presence of occlusion and to eliminate its effect in the correspondence search. By considering several statistics on the occlusion and the accuracy in the SEA, we derived a few base masks which represent occlusion patterns and are effective for the detection of occlusion. Several experiments using typical indoor scenes showed quite good performance to obtain dense and accurate depth maps even at the occluding boundaries of objects.	CVPR	visu
4488	CVPR	Structure from Linear or Planar Motions.	John Oliensis	1996	We recently demonstrated a new approach to multiframe structure from motion from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. The algorithm works for general motion and large perspective effects. In this paper, we describe how to adapt our approach to translational motion lying along a line or in a plane, with arbitrary rotations. An analysis of the bas--relief effect for multiple--motion sequences is also presented.	CVPR	visu
4489	CVPR	Connectionist networks for feature indexing and object recognition.	Clark F. Olson	1996	Feature indexing techniques are promising for object recognition because of their ability to eliminate many feature set matches from consideration without much computation. This work exploits another property of such techniques. They have inherently parallel structure and connectionist network formulations are easy to develop. Once indexing has been performed, a voting scheme such as geometric hashing [Lamdan et al. 1990] can be used to generate object hypotheses in parallel. We give a framework for the connectionist implementation for such indexing and recognition techniques. With sufficient processing elements, recognition can be performed in a small number of time steps. The number of processing elements necessary to achieve peak performance and the fan-in/fan-out required for the processing elements is determined. These techniques have been simulated on a conventional architecture with good results.	CVPR	visu
4490	CVPR	Affine Invariant Detection: Edges, Active Contours, and Segments.	Peter J. Olver,Guillermo Sapiro,Allen Tannenbaum	1996	In this paper we undertake a systematic investigation of affine invariant object detection. Edge detection is first presented from the point of view of the affine invariant scale-space obtained by curvature based motion of the image level-sets. In this case, affine invariant edges are obtained as a weighted difference of images at different scales. We then introduce the affine gradient as the simplest possible affine invariant differential function which has the same qualitative behavior as the Euclidean gradient magnitude. These edge detectors are the basis both to extend the affine invariant scale-space to a complete affine flow for image denoising and simplification, and to define affine invariant active contours for object detection and edge integration. The active contours are obtained as a gradient flow in a conformally Euclidean space defined by the image on which the object is to be detected. That is, we show that objects can be segmented in an affine invariant manner by computing a path of minimal weighted affine distance,the weight being given by functions of the affine edge detectors. The geodesic path is computed via an algorithm which allows to simultaneously detect any number of objects independently of the initial curve topology.	CVPR	visu
4491	CVPR	A fast and flexible statistical method for text extraction in document pages.	Pietro Parodi,Giulia Piccioli	1996	This paper describes a fast and flexible method for extracting text regions from a document page containing text, graphics, and pictures. Such regions can be given as an input to an OCR system. The user fixes two parameters, the minimum width w of the text to be detected, and the precision \epsilon needed (both expressed as a percentage of the image width), according to the implementation needs. The method works by subdividing the page into overlapping columns whose width and inter-shift depend on w and \epsilon, and by performing text lines extraction on each column separately. Successively, a statistical analysis of the text line elements found in each column is performed, and they are connected to form complete text lines. Finally, related pieces of text are merged into blocks so that a sensible reading order is provided for the OCR system. The algorithm is very fast, is able to work on low-resolution document pages and is robust against skew. The algorithm is also very flexible: no assumptions are made on the layout of the document, the shape of the text regions, and the font size and style; the main assumption is that the background is uniform and the text approximately horizontal. Despite the statistical nature of the method, a single line of text of a certain font size is generally sufficient to warrant detection. Experimental results are shown which demonstrate the effectiveness of the method on several different kinds of documents.	CVPR	visu
4492	CVPR	A Factorization Method for Affine Structure from Line Correspondences.	Long Quan,Takeo Kanade	1996	A family of structure from motion algorithms called the factorization method has been recently developed from the orthographic projection model to the affine camera model. All these algorithms are limited to handling only point features of the image stream. We propose in this paper an algorithm for the recovery of shape and motion from line correspondences by the factorization method with the affine camera. Instead of one step factorization for points, a multi-step factorization method is developed for lines based on the decomposition of the whole shape and motion into three separate substructures. Each of these substructures can then be linearly solved by factorizing the appropriate measurement matrices. It is also established that affine shape and motion with uncalibrated affine cameras can be achieved with at least seven lines over three views, which extends the previous results of Koenderink and Van Doorn for points to lines.	CVPR	visu
4493	CVPR	Closed-Loop Object Recognition Using Reinforcement Learning.	Jing Peng,Bir Bhanu	1996	Current computer vision systems whose basic methodology is open-loop or filter type typically use image segmentation followed by object recognition algorithms. These systems are not robust for most real-world applications. In contrast, the system presented here achieves robust performance by using reinforcement learning to induce a mapping from input images to corresponding segmentation parameters. This is accomplished by using the confidence level of model matching as a reinforcement signal for a team of learning automata to search for segmentation parameters during training. The use of the recognition algorithm as part of the evaluation function for image segmentation gives rise to significant improvement of the system performance by automatic generation of recognition strategies. The system is verified through experiments on sequences of indoor and outdoor color images with varying external conditions.	CVPR	visu
4494	CVPR	Randomness and Geometric Features in Computer Vision.	Xavier Pennec,Nicholas Ayache	1996	It is often necessary to handle randomness and geometry in computer vision, for instance to match and fuse together noisy geometric features such as points, lines or 3D frames, or to estimate a geometric transformation from a set of matched features. However, the proper handling of these geometric features is far more difficult than for points, and a number of paradoxes can arise. We analyse in this article three basic problems: (1) what is a uniform random distribution of features, (2) how to define a distance between features, and (3) what is the ``mean feature'' of a number of feature measurements, and we propose generic methods to solve them.	CVPR	visu
4495	CVPR	Epipolar Geometry and Linear Subspace Methods: A New Approach to Weak Calibration.	Jean Ponce,Yakup Genc	1996	This paper addresses the problem of estimating the epipolar geometry from point correspondences between two images taken by uncalibrated perspective cameras. It is shown that Jepson&lsquo;s and Heeger&lsquo;s linear subspace technique for infinitesimal motion estimation can be generalized to the finite motion case by choosing an appropriate basis for projective space. This yields a linear method for weak calibration. The proposed algorithm has been implemented and tested on both real and synthetic images, and it is compared to other linear and non-linear approaches to weak calibration.	CVPR	visu
4496	CVPR	Constrained Phase Congruency: Simultaneous Detection of Interest Points and of their Scales.	Daniel Reisfeld	1996	A novel feature detector -- the Constrained Phase Congruency Transform (CPCT) is introduced. It simultaneously detects interest points as well as their scale in various orientations. The CPCT is especially important in registration applications: the local transformation between interest points can be determined based on their orientational scales. The CPCT detects the features in Mach bands and in sinusoidal waves. This cannot be done simply by looking for local maxima in intensity gradient nor by looking for local energy maxima. I conjecture that constraining the general phase congruency is sufficient for feature detection. The correct detection of features' location and of their scale is demonstrated. The robustness of the CPCT is achieved by constraining the local phase. Only four easy-to-detect phases are used in the computations. They correspond to symmetry and anti-symmetry in their neighborhood. The scale at any location and orientation is determined by the scale of the channel that conforms to the constraints and maximizes energy.	CVPR	visu
4497	CVPR	Modeling Clutter and Context for Target Detection in Infrared Images.	Songnian Rong,Bir Bhanu	1996	In order to reduce false alarms and to improve the target detection performance of an automatic target detection and recognition system operating in a cluttered environment, it is important to develop the models not only for man-made targets but also of natural background clutters. Because of the high complexity of natural clutters, this clutter model can only be reliably built through learning from real examples. If available, contextual information that characterizes each training example can be used to further improve the learned clutter model. In this paper, we present such a clutter model aided target detection system. Emphases are placed on two topics: (1) learning the background clutter model from sensory data through a self-organizing process, (2) reinforcing the learned clutter model using contextual information.	CVPR	visu
4498	CVPR	Affine Structure and Photometry.	Ruth Rosenholtz,Jan J. Koenderink	1996	Motion of an observer relative to objects in a scene provides information about the structure of the scene. Changing patterns of shading due to motion relative to the light source provide information about surface structure, albedos, and light sources. One can stratify this photometric information into affine, unitary, and metric structure, much like the stratification of structure from motion. For Lambertian surfaces, if either motion or photometry give us more than affine structure, the two cues can be combined to yield full metric information. Edge constraints plus unitary photometry also give us full metric photometry. Affine structure alone contains much of the quantitative structure information, allowing us to judge such things as the ordinal relationships between the albedos.	CVPR	visu
4499	CVPR	Optimal servoing for active foveated vision.	Héctor Rotstein,Ehud Rivlin	1996	Foveated vision and two-mode tracking, as inspired by the human oculomotor system, are often used in active vision system. The purpose of this paper is to provide answers to the following basic questions which arise from implementations. First, is it beneficial to have foveated vision and what is the optimal size of the foveal window? Second, is there a need for two control mechanisms (smooth pursuit and saccade) for improved performance and how can one efficiently switch between them? In order to do so, a setup is proposed in which these strategies can be evaluated in a systematic manner. It is shown that the fovea appears as a compromise between the tightness of the tracking specifications and computational constraints. Introducing a model for the later and postulating some a priori knowledge of the target behavior, it is possible to compute the size of the fovea in an optimal way. As a by-product, smooth-pursuit can be defined in a natural way, and the use of a two-mode tracking scheme is justified. The second mode, i.e. saccadic control, aims at re-centering the target on the fovea so that the smooth pursuit controller can continue to operate. It is shown that a control strategy can indeed be defined so that this objective can be met under appropriate operating conditions.	CVPR	visu
4500	CVPR	Robust Recovery of Camera Rotation from Three Frames.	Benny Rousso,Shai Avidan,Amnon Shashua,Shmuel Peleg	1996	Computing camera rotation from image sequences can be used for image stabilization, and when the camera rotation is known the computation of translation and scene structure are much simplified as well. A robust approach for recovering camera rotation is presented, which does not assume any specific scene structure (e.g. no planar surface is required), and which avoids prior computation of the epipole. Given two images taken from two different viewing positions, the rotation matrix between the images can be computed from any three homgraphy matrices. The homographies are computed using the trilinear tensor which describes the relations between the projections of a 3D point into three images. The entire computation is linear for small angles, and is therefore fast and stable. Iterating the linear computation can then be used to recover larger rotations as well.	CVPR	visu
4501	CVPR	Neural Network-Based Face Detection.	Henry A. Rowley,Shumeet Baluja,Takeo Kanade	1996	We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.	CVPR	visu
4502	CVPR	Similarity Queries in Image Database.	Simone Santini,Ramesh Jain	1996	Query-by-content image database will be based on similarity, rater than on matching, where similarity is a measure that is defined and meaningful for every pair of images in the image space. Since it is the human user that, in the end, has to be satisfied with the results of the query, it is natural to base the similarity measure that we will use on the characteristics of human similarity assessment. In the first part of this paper, we review some of these characteristics and define a similarity measure based on them. Another problem that similarity-based databases will have to face is how to combine different queries into a single complex query. We present a solution based on three operators that are the analogous of the and, or, and not operators one uses in traditional databases. These operators are powerful enough to express queries of unlimited complexity, yet have a very intuitive behavior, making easy for the user to specify a query tailored to a particular need.	CVPR	visu
4503	CVPR	Vector-Valued Active Contours.	Guillermo Sapiro	1996	A framework for object segmentation in vector-valued images is presented in this paper. The first scheme proposed is based on geometric active contours moving towards the objects to be detected in the vector-valued image. Objects boundaries are obtained as geodesics or minimal weighted distance curves in a Riemannian space. The metric in this space is given by a definition of edges in vector-valued images. The curve flow corresponding to the proposed active contours holds formal existence, uniqueness, stability, and correctness results. The techniques is applicable for example to color and texture images. The scheme automatically handles changes in the deforming curve topology. We conclude the paper presenting an extension of the color active contours which leads to a possible image flow for vector-valued image segmentation. The algorithm is based on moving each one of the image level-sets according to the proposed color active contours. This extension also shows the relation of the color geodesic active contours with a number of partial-differential-equations based image processing algorithms as anisotropic diffusion and shock filters.	CVPR	visu
4504	CVPR	Complexity analysis of RBF networks for Pattern Recognition.	Lucia Sardo,Josef Kittler	1996	The problem of non-parametric probability density function (PDF) estimation using Radial Basis Function (RBF) Neural Networks is addressed here. We investigate two criteria, based on a modified Kullback-Leibler distance, that lead to an appropriate choice of the network architecture complexity. In the first criterion the modification consists in the addition of a term that penalizes complex architectures (MPL criterion). The second strategy involves the regularization of the network through the imposition of lower bounds on the standard deviation derived from conditions of existence of rejection tests (LBSD criterion). Experimental results indicate that the MPL criterion outperforms the LBSD method.	CVPR	visu
4505	CVPR	Quantitative Measures of Change based on Feature Organization: Eigenvalues and Eigenvectors.	Sudeep Sarkar,Kim L. Boyer	1996	One important task of site monitoring is change detection from aerial images. Change, in general, can be of various types. In this paper we address the problem of detecting change due to construction activity. Specifically, we would like to know about new construction at a previously undeveloped site and possibly monitor its progress. Model based approaches are not suited for this kind of change as it usually happens in unmodelled areas. Since it is difficult to infer construction activity by predicting and verifying specific local features, we rely on more global statistical indicators. The thesis of this paper is that the change induced by human activity can be inferred from changes in the organization among the visual features. Not only will the attributes of the individual image features change but also the relationships among these features will evolve. With the progress of construction we expect to see increased structure among the image features. We exploit this emerging structure, or organization, to infer change. In this paper, we propose four measures to quantify the global statistical properties of the individual features and the relationships among them. We base these measures on the theory of graph spectra. We provide extensive analysis of the robustness of these measures under various imaging conditions. We also demonstrate the ability of these organization based measures to discriminate between no development, onset of construction, and full development.	CVPR	visu
4506	CVPR	Stereo Vision for View Synthesis.	Daniel Scharstein	1996	We propose a new method for view synthesis from real images using stereo vision. The method does not explicitly model scene geometry, and enables fast and exact generation of synthetic views. We also re-evaluate the requirements on stereo algorithms for the application of view synthesis and discuss ways of dealing with partially occluded regions of unknown depth and with completely occluded regions of unknown texture. Our experiments demonstrate that it is possible to efficiently synthesize realistic new views even from inaccurate and incomplete depth information.	CVPR	visu
4507	CVPR	Stereo Matching with Non-Linear Diffusion.	Daniel Scharstein,Richard Szeliski	1996	One of the central problems in stereo matching (and other image registration tasks) is the selection of optimal window sizes for comparing image regions. This paper addresses this problem with some novel algorithms based on iteratively diffusing support at different disparity hypotheses, and locally controlling the amount of diffusion based on the current quality of the disparity estimate. It also develops a novel Bayesian estimation technique which significantly outperforms techniques based on area-based matching (SSD) and regular diffusion. We provide experimental results on both synthetic and real stereo image pairs.	CVPR	visu
4508	CVPR	Combining greyvalue invariants with local constraints for object recognition.	Cordelia Schmid,Roger Mohr	1996	This paper addresses the problem of recognizing objects in large image databases. The method is based on local characteristics which are invariant to similarity transformations in the image. These characteristics are computed at automatically detected keypoints using the greyvalue signal. The method therefore works on images such as paintings for which geometry based recognition fails.Due to the locality of the method, images can be recognized being given part of an image and in the presence of occlusions. Applying a voting algorithm and semi-local constraints makes the method robust to noise, scene clutter and small perspective deformations. Experiments show an efficient recognition for different types of images. The approach has been validated on an image database containing 1020 images, some of them being very similar by structure, texture or shape.	CVPR	visu
4509	CVPR	Structure from Multiple 2D Affine Correspondences without Camera Calibration.	Haim Schweitzer,Radha Krishnan	1996	Image motion induced by camera or object motion can be approximated locally by an affine coordinate transformation. We extract 3D information directly from the affine parameters, without camera calibration. The derivation relies on the following assumptions: the object is rigid, locally planar, and its local 3D motion is translation. These assumptions enable complete recovery of 3D structure, whereas it is impossible to compute the direction (and magnitude) of the motion. Still, it is possible to distinguish between objects moving differently. Explicit expressions for the structure and the motion indicators are given in terms of the 6 affine parameters, computed for each image patch. Results of experiments on data with known ground truth are described.	CVPR	visu
4510	CVPR	Coregistration of Range and Optical Images Using Coplanarity and Orientation Constraints.	Anthony N. A. Schwickerath,J. Ross Beveridge	1996	A least-squares method simultaneously solves for the model-to-sensor-suite pose and sensor-to-sensor registration. The development is for a sensor-suite containing separate range and optical sensors. To address outliers and, more generally, match finding, a statistical method (median filtering) and a search method (local search) are developed. Sensitivity to Gaussian noise and the choice of initial pose estimates is investigated on synthetic data. Both of the matching methods are demonstrated on real data.	CVPR	visu
4511	CVPR	A Common Framework for Curve Evolution, Segmentation and Anisotropic Diffusio.	Jayant Shah	1996	In recent years, curve evolution has developed into an important tool in Computer Vision and has been applied to a wide variety of problems such as smoothing of shapes, shape analysis and shape recovery. The underlying principle is the evolution of a simple closed curve whose points move in the direction of the normal with prescribed velocity. A fundamental limitation of the method as it stands is that it cannot deal with important image features such as triple points. The method also requires a choice of an edge-strength function, defined over the image domain, indicating the likelihood of an object boundary being present at any point in the image domain. This implies a separate preprocessing step, in essence precomputing approximate boundaries in the presence of noise. One also has to choose the initial curve. It is shown here that the different versions of curve evolution used in Computer Vision together with the preprocessing step can be integrated in the form of a new segmentation functional which overcomes these limitations and extends curve evolution models. Moreover, the numerical solutions obtained retain sharp discontinuities or shocks, thus providing sharp demarcation of object boundaries.	CVPR	visu
4512	CVPR	Subpixel Image Registration by Estimating the Polyphase Decomposition of Cross Power Spectrum.	Hassan Shekarforoush,Marc Berthod,Josiane Zerubia	1996	A method of registering images at subpixel accuracy has been proposed, which does not resort to interpolation. The method is based on the phase correlation method and is remarkably robust to correlated noise and uniform variations of luminance. We have shown that the cross power spectrum of two images, containing subpixel shifts, is a polyphase decomposition of a Dirac delta function. By estimating the sum of polyphase components one can then determine subpixel shifts along each axis.	CVPR	visu
4513	CVPR	On 3D Shape Similarity.	Heung-Yeung Shum,Martial Hebert,Katsushi Ikeuchi	1996	On 3D Shape Similarity.	CVPR	visu
4514	CVPR	A shock grammar for recognition.	Kaleem Siddiqi,Benjamin B. Kimia	1996	We confront the theoretical and practical difficulties of computing a representation for two-dimensional shape, based on shocks or singularities that arise as the shape's boundary is deformed. First, we develop subpixel local detectors for finding and classifying shocks. Second, to show that shock patterns are not arbitrary but obey the rules of a grammar, and in addition satisfy specific topological and geometric constraints. Shock hypotheses that violate the grammar or are topologically or geometrically invalid are pruned to enforce global consistency. Survivors are organized into a hierarchical graph of shock groups computed in the reaction-diffusion space, where diffusion plays a role of regularization to determine the significance of each shock group. The shock groups can be functionally related to the object's parts, protrusions and bends, and the representation is suited to recognition: several examples illustrate its stability with rotations, scale changes, occlusion and movement of parts, even at very low resolutions.	CVPR	visu
4515	CVPR	Further constraints on visual articulated motions.	David Sinclair,K. Zesar	1996	This paper derives what we term the Euclidean hinge constraint for projective reconstruction of objects displaying articulated motion. A Euclidean hinge is defined here to be an articulation axis with the proviso that any plane perpendicular to the articulation axis in link 1 has a coincident plane which is perpendicular to the articulation ads in link 2 and that these planes remain coincident under articulated motion. This constraint permits the independent projective reconstructions of two adjacent articulated links to be placed in a common frame. The constraint may be expressed mathematically by considering what we define as circular parallax. Additionally the existence of a Euclidean hinge permits the permits the projective frame to be brought nearer to a Euclidean frame for the reconstructed object. A brief reprise of the method of articulation axis estimation is given together with a more extensive series of experimental results.	CVPR	visu
4516	CVPR	Using a spectral reflectance model for the illumination-invariant recognition of local image structure.	David Slater,Glenn Healey	1996	We represent local spatial structure in a color image using feature matrices that are computed from an image region. Feature matrices contain significantly more information about local image structure than previous representations. Although feature matrices are useful for surface recognition, this representation depends on the spectral properties of the scene illumination. Using a finite dimensional linear model for surface spectral reflectance with the same number of parameters as the number of color bands, we show that illumination changes correspond to linear transformations of the feature matrices and that surface rotations correspond to circular shifts of the matrices. From these relationships we derive an algorithm for illumination and geometry invariant recognition of local surface structure. We demonstrate the algorithm with a series of experiments on images of real objects.	CVPR	visu
4517	CVPR	Motion from fixation.	Stefano Soatto,Pietro Perona	1996	We study the problem of estimating rigid motion from a sequence of monocular perspective images obtained by navigating around an object while fixating a particular feature point. We cast the problem in the framework of epipolar geometry, and propose a filter based upon implicit dynamical model for recursively estimating motion under the fixation constraint. This allows us to compare the quality of the estimates directly against the ones obtained assuming a general rigid motion simply by changing the geometry of the parameter space, while maintaining the same structure of the recursive estimator. We also present a closed-form static solution from two views, and a recursive estimator of the relative pose between the viewer and the scene.	CVPR	visu
4518	CVPR	Reducing structure from motion.	Stefano Soatto,Pietro Perona	1996	The literature on recursive estimation of structure and motion from monocular image sequences comprises a large number of different models and estimation techniques. We propose a framework that allows us to derive and compare all models by following the idea of dynamical system reduction. The natural dynamic model, derived by the rigidity constraint and the perspective projection, is first reduced by explicitly decoupling structure (depth) from motion. Then implicit decoupling techniques are explored, which consist of imposing that some function of the unknown parameters is held constant. By appropriately choosing such a function, not only can we account for all models seen so far in the literature, but we can also derive novel ones. Casting all the different models in a common framework allows us to compare their geometric properties on common experimental grounds.	CVPR	visu
4519	CVPR	Towards Accurate Recovery of Shape from Shading under Diffuse Lighting.	A. James Stewart,Michael S. Langer	1996	A new surface radiance model for diffuse lighting is presented which incorporates shadows, interreflections, and surface orientation. An algorithm is presented that uses this model to compute shape-from-shading under diffuse lighting. The algorithm is tested on both synthetic and real images, and is found to perform more accurately than the only previous algorithm for this problem.	CVPR	visu
4520	CVPR	Runway Obstacle Detection by Controlled Spatiotemporal Image Flow Disparity.	Sanghoon Sull,Banavar Sridhar	1996	This paper proposes a method for detecting obstacles on a runway by controlling their expected disparities. By approximating the runway by a planar surface, the initial model flow field (MFF) corresponding to an obstacle-free runway is described by the data from on-board sensors (OBS). The error variance of the initial MFF is computed and used to estimate the MFF. Obstacles are detected by comparing the expected residual flow disparities with the residual flow field (RFF) estimated after warping (or stabilizing) an image using the MFF. Expected temporal and spatial disparities are obtained from the use of the OBS. This allows us to control the residual disparities by increasing the temporal baseline and/or by utilizing the spatial baseline if distant objects cannot be detected for a given temporal baseline. Experimental results for two real flight image sequences are presented.	CVPR	visu
4521	CVPR	Efficient Image Gradient-Based Object Localisation and Recognitio.	T. N. Tan,Geoffrey D. Sullivan,Keith D. Baker	1996	This paper reports novel algorithms for the efficient localization and recognition of vehicles in traffic scenes, which eliminate the need for explicit symbolic feature extraction and matching. The algorithms make use of two a priori sources of knowledge about the scene and the objects: (i) the ground-plane constraint, and (ii) the fact that road vehicles are strongly rectilinear. The algorithms are demonstrated and tested using routine outdoor traffic images. Success with a variety of vehicles demonstrates the efficiency and robustness of context-based computer vision in road traffic scenes. The limitations of the algorithms are also addressed in the paper.	CVPR	visu
4522	CVPR	Non-Rigid Matching Using Demons.	Jean-Philippe Thirion	1996	We present the concept of non-rigid matching based on demons, by reference to Maxwell's demons. We contrast this concept with the more conventional viewpoint of attraction. We show that demons and attractive points are clearly distinct for large deformations, but also that they become similar for small displacements, encompassing techniques close to optical flow. We describe a general iterative matching method based on demons, and derive from it three different non-rigid matching algorithms, one using all the image intensities, one using only contours, and one for already segmented images. At last, we present results with synthesized and real deformations, with applications to Computer Vision and Medical Image Processing.	CVPR	visu
4523	CVPR	Comparison of Approaches to Egomotion Computation.	Tina Yu Tian,Carlo Tomasi,David J. Heeger	1996	We evaluated six algorithms for computing egomotion from image velocities. We established benchmarks for quantifying bias and sensitivity to noise, and for quantifying the convergence properties of those algorithms that require numerical search. Our simulation results reveal some interesting and surprising results. First, it is often written in the literature that the egomotion problem is difficult because translation (e.g., along the X-axis) and rotation (e.g., about the Y-axis) produce similar image velocities. We found, to the contrary, that the bias and sensitivity of our six algorithms are totally invariant with respect to the axis of rotation. Second, it is also believed by some that fixating helps to make the egomotion problem easier. We found, to the contrary, that fixating does not help when the noise is independent of the image velocities. Fixation does help if the noise is proportional to speed, but this is only for the trivial reason that the speeds are slower under fixation. Third, it is widely believed that increasing the field of view will yield better performance. We found, to the contrary, that this is not necessarily true.	CVPR	visu
4524	CVPR	Factorization Methods for Projective Structure and Motion.	Bill Triggs	1996	This paper describes a family of factorization-based algorithms that recover 3D projective structure and motion from multiple uncalibrated perspective images of 3D points and lines. They can be viewed as generalizations of the Tomasi-Kanade algorithm from affine to fully perspective cameras, and from points to lines. They make no restrictive assumptions about scene or camera geometry, and unlike most existing reconstruction methods they do not rely on `privileged' points or images. All of the available image data is used, and each feature in each image is treated uniformly. The key to projective factorization is the recovery of a consistent set of projective depths (scale factors) for the image points: this is done using fundamental matrices and epipoles estimated from the image data. We compare the performance of the new techniques with several existing ones, and also describe an approximate factorization method that gives similar results to SVD-based factorization, but runs much more quickly for large problems.	CVPR	visu
4525	CVPR	A Framework for Recognizing a Facial Image from a Police Sketch.	Robert G. Uhl Jr.,Niels da Vitoria Lobo	1996	We present a theory and practical computations for automatically matching a police artist sketch to a set of true photographs. We locate facial features in both the sketch as well as the set of photograph images. Then, the sketch is photometrically standardized to facilitate comparison with a photo and then both the sketch and the photos are geometrically standardized. Finally, for matching, eigenanalysis is employed. Results using real police sketches and arrest photos are presented.	CVPR	visu
4526	CVPR	Structure and motion of curved 3D objects from monocular silhouettes.	B. Vijayakumar,David J. Kriegman,Jean Ponce	1996	The silhouette of a smooth 3D object observed by a moving camera changes over time. Past work has shown how surface geometry can be recovered using the deformation of the silhouette when the camera motion is known. This paper addresses the problem of estimating both the full Euclidean surface structure and the camera motion from a dense set of silhouettes captured under orthographic or scaled orthographic projection. The approach relies on a viewpoint-invariant representation of curves swept by viewpoint-dependent features such as bitangents, inflections and contour points with parallel tangents. Feature points, which form stereo frontier points between non-consecutive images, are matched using this representation. The camera's angular velocity is computed from constraints derived from this correspondence along with the image velocity of these features. From the angular velocity, the epipolar geometry is ascertained, and infinitesimal motion frontier points can be detected. In turn, the motion of these frontier points constrains the translation component of camera motion. Finally, the surface is reconstructed using established techniques once the camera motion has been estimated.	CVPR	visu
4527	CVPR	Blurring Strategies for Image Segmentation Using a Multiscale Linking Model.	Koen L. Vincken,Wiro J. Niessen,Max A. Viergever	1996	Multiscale approaches are an invaluable tool for image segmentation. A vast amount of research has been devoted to the construction of different multiscale representations of an image. In this paper we use the `hyperstack'--a multiscale linking model for image segmentation--for an in-depth comparison of four different scale space generators with respect to segmentation results. We consider the linear (Gaussian) scale space both in the spatial and the Fourier domain, the variable conductance diffusion according to the Perona & Malik equation, and the Euclidean shortening flow. We have done experiments on MR images of the brain, for which a gold standard is available. The hyperstack proofs to be rather insensitive to the underlying scale space generator.	CVPR	visu
4528	CVPR	Determining Correspondences and Rigid Motion of 3-D Point Sets with Missing Data.	Xiaoguang Wang,Yong-Qing Cheng,Robert T. Collins,Allen R. Hanson	1996	This paper addresses the general 3-D rigid motion problem, where the point correspondences and the motion parameters between two sets of 3-D points are to be recovered. The existence of missing points in the two sets is the most difficult problem. We first show a mathematical symmetry in the solutions of rotation parameters and point correspondences. A closed-form solution based on the correlation matrix eigenstructure decomposition is proposed for correspondence recovery with no missing points. Using a heuristic measure of point pair affinity derived from the eigenstructure, a weighted bipartite matching algorithm is developed to determine the correspondences in general cases where missing points occur. The use of the affinity heuristic also leads to a fast outlier removal algorithm, which can be run iteratively to refine the correspondence recovery. Simulation results and experiments on real images are shown in both ideal and general cases.	CVPR	visu
4529	CVPR	Illumination and geometry invariant recognition of texture in color images.	Lizhi Wang,Glenn Healey	1996	We develop a method for recognizing color texture independent of rotation, scale, and illumination. Color texture is modeled using spatial correlation functions defined within and between sensor bands. Using a linear model for surface spectral reflectance with the same number of parameters as the number of sensor classes, we show that illumination and geometry changes in the scene correspond to a linear transformation of the correlation functions and a linear transformation of their coordinates. A several step algorithm which includes scale estimation and correlation moment computation is used to achieve the invariance. The key to the method is the new result that illumination and geometry changes in the scene correspond to a specific transformation of correlation function Zernike moment matrices. These matrices can be estimated from a color image. This relationship is used to derive an efficient algorithm for recognition. The algorithm is substantiated using classification results on over 200 images of color textures obtained under various illumination conditions and geometric configurations.	CVPR	visu
4530	CVPR	Minimal operator set for passive depth from defocus.	Masahiro Watanabe,Shree K. Nayar	1996	A fundamental problem in depth from defocus is the measurement of relative defocus between images. We propose a class of broadband operators that, when used together, provide invariance to scene texture and produce accurate and dense depth maps. Since the operators are broadband, a small number of them are sufficient for depth estimation of scenes with complex textural properties. Experiments are conducted on both synthetic and real scenes to evaluate the performance of the proposed operators. The depth detection gain error is less than 1%, irrespective of texture frequency. Depth accuracy is found to be 0.5/spl sim/1.2% of the distance of the object from the imaging optics.	CVPR	visu
4531	CVPR	A Unified Mixture Framework for Motion Segmentation: Incorporating Spatial Coherence and Estimating the Number of Models.	Yair Weiss,Edward H. Adelson	1996	Describing a video sequence in terms of a small number of coherently moving segments is useful for tasks ranging from video compression to event perception. promising approach is to view the motion segmentation problem in a mixture estimation framework. However, existing formulations generally use only the motion data and thus fail to make use of static cues when segmenting the sequence. Furthermore, the number of models is either specified in advance or estimated outside the mixture model framework. In this work we address both of these issues. We show how to add spatial constraints to the mixture formulations and present a variant of the EM algorithm that makes use of both the form and the motion constraints. Moreover this algorithm estimates the number of segments given knowledge about the level of model failure expected in the sequence. The algorithm's performance is illustrated on synthetic and real image sequences.	CVPR	visu
4532	CVPR	Nonlinear Shape Restoration For Document Images.	Yun Weng,Qiuming Zhu	1996	Previous researches on nonlinear shape restoration are based on the assumptions that the original shapes and distortions of the images have known formulations under certain conditions. The main contribution of this research is the development of a new restoration algorithm, called Multi-Steps Restoration. The algorithm is based on a liner interpolation theory that is able to detect and restore nonlinear shape distortions in any irregular quadrilateral-shaped patterns. The main idea of the algorithm is the use of two-dimensional spline functions in bicubic, biquadratic, and/or bilinear models to approximate the three-dimensional nonlinear distortion curves. The performance of the approach shown by experiment is promising.	CVPR	visu
4533	CVPR	Attention Control for Robot Vision.	Carl-Fredrik Westin,Carl-Johan Westelius,Hans Knutsson,Gösta H. Granlund	1996	Focus of attention mechanisms for robot vision are discussed. A new method for neglecting low level filter responses from already modelled structures is presented. The method is based on a filtering technique termed normalized convolution. In one experiment, the robot is continuously moving its arm in the scene while tracking other objects. It is shown how the arm can be made ``invisible'' so that only the moving object of interest is detected. This makes tracking of objects much simpler. In another experiment, the attention of the system is shifted between objects by simply cancelling the mask of the object to be attended to. With this strategy the low level processes do not need to know the difference between a new object entering the scene and a mask being cancelled, and thus a complex communication structure between high and low levels is avoided.	CVPR	visu
4534	CVPR	Local Parallel Computation of Stochastic Completion Fields.	Lance R. Williams,David W. Jacobs	1996	We describe a local parallel method for computing the stochastic completion field introduced in an earlier paper\cite{williams}. The stochastic completion field represents the likelihood that a completion joining two contour fragments passes through any given position and orientation in the image plane. It is based upon the assumption that the prior probability distribution of completion shape can be modeled as a random walk in a lattice of discrete positions and orientations. The local parallel method can be interpreted as a stable finite difference scheme for solving the underlying Fokker-Planck equation identified by Mumford\cite{mumford}. The resulting algorithm is significantly faster than the previously employed method which relied on convolution with large-kernel filters computed by Monte Carlo simulation. The complexity of the new method is O(n3m) while that of the previous algorithm was O(n4m2) (for an n X n image with m discrete orientations). Perhaps most significantly, the use of a local method allows us to model the probability distribution of completion shape using stochastic processes which are neither homogenous nor isotropic. For example, it is possible to modulate particle decay rate by a directional function of local image brightnesses (i.e., anisotropic decay). The effect is that illusory contours can be made to respect the local image brightness structure. Finally, we note that the new method is more plausible as a neural model since 1) unlike the previous method, it can be computed in a sparse, locally connected network; and 2) the network dynamics are consistent with psychophysical measurements of the time course of illusory contour formation.	CVPR	visu
4535	CVPR	Gauging Relational Consistency and Correcting Structural Errors.	Richard C. Wilson,Edwin R. Hancock	1996	The aim of this paper is to provide a comparative evaluation of a number of contrasting approaches to relational matching. Unique to this study is the way in which we show how a diverse family of algorithms relate to one-another using a common Bayesian framework. Broadly speaking there are two main aspects to this study. Firstly we focus on the issue of how relational inexactness may be quantified. We illustrate that several popular relational distance measures can be recovered as specific limiting cases of the same Bayesian consistency measure. The second aspect of our comparison concerns the way in which structural inexactness is controlled. We investigate three different realisations of the matching process which draw on contrasting control models. The main conclusion of our study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter.	CVPR	visu
4536	CVPR	Polarization Phase-Based Method for Material Classification and Object Recognition in Computer Vision.	Larry Wolff	1996	A robust and accurate polarization phase-based technique for material classification is presented. The novelty of this technique is three-fold in (i) its theoretical development, (ii) its application, and, (iii) its experimental implementation. The concept of phase of polarization of a light wave is introduced to computer vision for discrimination between materials according to their intrinsic electrical conductivity, such as distinguishing conducting metals, and poorly-conducting dielectrics. Previous work has used intensity, color and polarization component ratios. This new method is based on the physical principle that metals retard orthogonal components of light upon reflection while dielectrics do not. This method has significant complementary advantages with respect to existing techniques, is computationally efficient, and can be easily implemented with existing imaging technology. Experiments for real circuit board inspection, non-conductive and conductive glass, and, outdoor object recognition have been performed to demonstrate its accuracy and potential capabilities.	CVPR	visu
4537	CVPR	Combination of Multiple Classifiers Using Local Accuracy Estimates.	Kevin Woods,Kevin W. Bowyer,W. Philip Kegelmeyer	1996	Combination of Multiple Classifiers Using Local Accuracy Estimates.	CVPR	visu
4538	CVPR	Video Browsing Using Edges and Motion.	Ramin Zabih,Justin Miller,Kevin Mai	1996	Video Browsing Using Edges and Motion.	CVPR	visu
4539	CVPR	FRAME: Filters, Random fields, and Minimax Entropy-- Towards a Unified Theory for Texture Modeling.	Song Chun Zhu,Ying Nian Wu,David Mumford	1996	In this paper, a minimax entropy principle is studied, based on which a novel theory, called FRAME (Filters, Random fields And Minimax Entropy) is proposed for texture modeling. FRAME combines attractive aspects of two important themes in texture modeling: multi-channel filtering and Markov random field (MRF) modeling. It incorporates the responses of a set of well selected filters into the distribution over a random field, and hence has a much stronger descriptive ability than the traditional MRF models. Furthermore, it interprets and clarifies many previous concepts and methods for texture analysis and synthesis from a unified point of view. Algorithms are proposed for probability inference, stochastic simulation and filter selection. Experiments on a variety of textures are described to illustrate our theory and to show the performance of our algorithms. These experiments demonstrate that many textures previously considered as different categories can be modeled and synthesized in a common framework.	CVPR	visu
4540	CVPR	Isotropic Processing for Gradient Estimation.	Djemel Ziou,Shengrui Wang	1996	This paper concerns the influence of edge direction on the estimation of edge contrast and orientation. We show that the gradient estimated using radial filters is not affected by edge orientation. For non-radial filters the gradient can be affected by edge orientation. For instance, we find that the estimated edge orientation using a non-radial filter may be biased, even if the signal is noise-free. However, there are non-radial filters for which gradient is unaffected by edge orientation as in the case of radial filters. The properties of these functions are given in this paper. The results are illustrated by the study of the Canny, Deriche, and Shen & Castan detectors. We take into account discretization errors. These results give a clear indication of the effect of the rotation invariance property of an edge detector on its response, thus providing a more precise meaning for this property in edge detection.	CVPR	visu
4541	CVPR	1996 Conference on Computer Vision and Pattern Recognition (CVPR '96), June 18-20, 1996 San Francisco, CA, USA		1996	1996 Conference on Computer Vision and Pattern Recognition (CVPR '96), June 18-20, 1996 San Francisco, CA, USA	CVPR	visu
4542	CVPR	Incremental Focus of Attention for Robust Visual Tracking.	Kentaro Toyama,Gregory D. Hager	1996	Incremental Focus of Attention for Robust Visual Tracking.	CVPR	visu
4543	IEEE Visualization	A Linear Iteration Time Layout Algorithm for Visualising High-Dimensional Data.	Matthew Chalmers	1996	A Linear Iteration Time Layout Algorithm for Visualising High-Dimensional Data.	IEEE Visualizat	visu
4544	IEEE Visualization	Cheops: A Compact Explorer for Complex Hierarchies.	Luc Beaudoin,Marc-Antoine Parent,Louis C. Vroomen	1996	Cheops: A Compact Explorer for Complex Hierarchies.	IEEE Visualizat	visu
4545	IEEE Visualization	BLaC-Wavelets: A Multiresolution Analysis With Non-Nested Spaces.	Georges-Pierre Bonneau,Stefanie Hahmann,Gregory M. Nielson	1996	BLaC-Wavelets: A Multiresolution Analysis With Non-Nested Spaces.	IEEE Visualizat	visu
4546	IEEE Visualization	Visualization of Complex Models Using Dynamic Texture-based Simplification.	Daniel G. Aliaga	1996	Visualization of Complex Models Using Dynamic Texture-based Simplification.	IEEE Visualizat	visu
4547	IEEE Visualization	Directional Flow Visualization of Vector Fields.	Ed Boring,Alex Pang	1996	Directional Flow Visualization of Vector Fields.	IEEE Visualizat	visu
4548	IEEE Visualization	Breaking the Myth: a Picture is NOT (always) Worth a 1, 000 Words.	Robert Braham,F. David Fracchia,Andrew S. Glassner,Barbara Mones-Hattal,Russ Rose,Nahum D. Gershon	1996	Breaking the Myth: a Picture is NOT (always) Worth a 1, 000 Words.	IEEE Visualizat	visu
4549	IEEE Visualization	A Haptic Interaction Method for Volume Visualization.	Ricardo S. Avila,Lisa M. Sobierajski	1996	A Haptic Interaction Method for Volume Visualization.	IEEE Visualizat	visu
4550	IEEE Visualization	Time Management, Simultaneity and Time-Critical Computation in Interactive Unsteady Visualization Environments.	Steve Bryson,Sandy Johan	1996	Time Management, Simultaneity and Time-Critical Computation in Interactive Unsteady Visualization Environments.	IEEE Visualizat	visu
4551	IEEE Visualization	FEL: The Field Encapsulation Library.	Steve Bryson,David N. Kenwright,Michael J. Gerald-Yamasaki	1996	FEL: The Field Encapsulation Library.	IEEE Visualizat	visu
4552	IEEE Visualization	Mathematical Visualization: Standing at the Crossroads.	David Banks,George Francis,Andrew J. Hanson,Loki Jorgenson	1996	Mathematical Visualization: Standing at the Crossroads.	IEEE Visualizat	visu
4553	IEEE Visualization	Data Reduction and Interpolation for Visualizing 3D Soil-Quality Data.	David C. Banks,Bernd Hamann,Po-Yu Tsai,Robert J. Moorhead,Jonathan Barlow	1996	Data Reduction and Interpolation for Visualizing 3D Soil-Quality Data.	IEEE Visualizat	visu
4554	IEEE Visualization	History Consideration in Reconstructuring Polythedral Surfaces from Parallel Slices.	Gill Barequet,Daniel Shapiro,Ayellet Tal	1996	History Consideration in Reconstructuring Polythedral Surfaces from Parallel Slices.	IEEE Visualizat	visu
4555	IEEE Visualization	Case Study: Visual Access for Landscape Event Based Temporal Data.	M. Sheelagh T. Carpendale,Andrew Fall,David J. Cowperthwaite,Joseph Fall,F. David Fracchia	1996	Case Study: Visual Access for Landscape Event Based Temporal Data.	IEEE Visualizat	visu
4556	IEEE Visualization	Flexible Information Visualization of Multivariate Data from Biological Sequence Similarity Searches.	Ed Huai-hsin Chi,John Riedl,Elizabeth Shoop,John V. Carlis,Ernest Retzel,Phillip Barry	1996	Flexible Information Visualization of Multivariate Data from Biological Sequence Similarity Searches.	IEEE Visualizat	visu
4557	IEEE Visualization	Temporal Continuity of Levels of Detail in Delaunay Triangualted Terrain.	Daniel Cohen-Or,Yishay Levanoni	1996	Temporal Continuity of Levels of Detail in Delaunay Triangualted Terrain.	IEEE Visualizat	visu
4558	IEEE Visualization	Contour Blending Using Warp-Guided Distance Field Interpolation.	Daniel Cohen-Or,David Levin,Amira Solomovici	1996	Contour Blending Using Warp-Guided Distance Field Interpolation.	IEEE Visualizat	visu
4559	IEEE Visualization	Real-time Slicing of Data Space.	Roger Crawfis	1996	Real-time Slicing of Data Space.	IEEE Visualizat	visu
4560	IEEE Visualization	Optimizing Triangle Strips for Fast Rendering.	Francine Evans,Steven Skiena,Amitabh Varshney	1996	Optimizing Triangle Strips for Fast Rendering.	IEEE Visualizat	visu
4561	IEEE Visualization	Deformable Volume Rendering by 3D Texture Mapping and Octree Encoding.	Shiaofen Fang,Rajagopalan Srinivasan,Su Huang,Raghu Raghavan	1996	Deformable Volume Rendering by 3D Texture Mapping and Octree Encoding.	IEEE Visualizat	visu
4562	IEEE Visualization	Fast Stereo Volume Rendering.	Taosong He,Arie E. Kaufman	1996	Fast Stereo Volume Rendering.	IEEE Visualizat	visu
4563	IEEE Visualization	Visualization of Water Quality Data for the Chesapeake Bay.	Adam B. Forgang,Bernd Hamann,Carl F. Cerco	1996	Visualization of Water Quality Data for the Chesapeake Bay.	IEEE Visualizat	visu
4564	IEEE Visualization	Raycasting Vector Fields.	Thomas Frühauf	1996	Raycasting Vector Fields.	IEEE Visualizat	visu
4565	IEEE Visualization	Two-handed Interactive Stereoscopic Visualization.	David S. Ebert,Christopher D. Shaw,Amen Zwa,Cindy Starr	1996	Two-handed Interactive Stereoscopic Visualization.	IEEE Visualizat	visu
4566	IEEE Visualization	Real-Time Incremental Visualization of Dynamic Ultrasound Volumes Using Parallel BSP Trees.	William F. Garrett,Henry Fuchs,Mary C. Whitton,Andrei State	1996	Real-Time Incremental Visualization of Dynamic Ultrasound Volumes Using Parallel BSP Trees.	IEEE Visualizat	visu
4567	IEEE Visualization	A System for Measuring Surface Facet Orientation from Atomic Force Microscope Data.	John G. Hagedorn,Holly E. Rushmeier,John Blendell,Mark Vaudin	1996	A System for Measuring Surface Facet Orientation from Atomic Force Microscope Data.	IEEE Visualizat	visu
4568	IEEE Visualization	Triangular NURBS Surface Modeling of Scattered Data.	Song Han,Gérard G. Medioni	1996	Triangular NURBS Surface Modeling of Scattered Data.	IEEE Visualizat	visu
4569	IEEE Visualization	Generation of Transfer Functions with Stochastic Search Techniques.	Taosong He,Lichan Hong,Arie E. Kaufman,Hanspeter Pfister	1996	Generation of Transfer Functions with Stochastic Search Techniques.	IEEE Visualizat	visu
4570	IEEE Visualization	Choosing Effective Colours for Data Visualization.	Christopher G. Healey	1996	Choosing Effective Colours for Data Visualization Christopher G. Healey In this paper we describe a technique for choosing multiple colours for use during data visualization. Our goal is a systematic method for maximizing the total number of colours available for use, while still allowing an observer to rapidly and accurately search a display for any one of the given colours. Previous research suggests that we need to consider three separate effects during colour selection: colour distance, linear separation, and colour category. We describe a simple method for measuring and controlling all of these effects. Our method was tested by performing a set of target identification studies; we analysed the ability of thirty-eight observers to find a colour target in displays that contained differently coloured background elements. Results showed that our method can be used to select a group of colours that will provide good differentiation between data elements during visualization.	IEEE Visualizat	visu
4571	IEEE Visualization	Untangling Knots by Stochastic Energy Optimization.	Milana Huang,Robert P. Grzeszczuk,Louis H. Kauffman	1996	Untangling Knots by Stochastic Energy Optimization.	IEEE Visualizat	visu
4572	IEEE Visualization	Perceptualisation using a Tactile Mouse.	Robert G. Hughes,A. Robin Forrest	1996	Perceptualisation using a Tactile Mouse.	IEEE Visualizat	visu
4573	IEEE Visualization	Illustrating Transparent Surfaces with Curvature-Directed Strokes.	Victoria Interrante,Henry Fuchs,Stephen M. Pizer	1996	Illustrating Transparent Surfaces with Curvature-Directed Strokes.	IEEE Visualizat	visu
4574	IEEE Visualization	Volume Thinning for Automatic Isosurface Propagation.	Takayuki Itoh,Yasushi Yamaguchi,Koji Koyamada	1996	Volume Thinning for Automatic Isosurface Propagation.	IEEE Visualizat	visu
4575	IEEE Visualization	Using Visualization in the Archaeological Excavations of Pre-Inca Temple in Peru.	Alan D. Kalvin,Alfredo Remy,Orlando Ardito,Kim Morla,Eduardo Nolasco,Jorge Prado,Regulo Franco,Antonio Murga,Guillermo Wiese	1996	Using Visualization in the Archaeological Excavations of Pre-Inca Temple in Peru.	IEEE Visualizat	visu
4576	IEEE Visualization	Anatomy-Based Facial Tissue Modeling Using the Finite Element Method.	Erwin Keeve,Sabine Girod,Paula Pfeifle,Bernd Girod	1996	Anatomy-Based Facial Tissue Modeling Using the Finite Element Method.	IEEE Visualizat	visu
4577	IEEE Visualization	Multi-Frequency Noise for LIC.	Ming-Hoe Kiu,David C. Banks	1996	Multi-Frequency Noise for LIC.	IEEE Visualizat	visu
4578	IEEE Visualization	Mesh Reduction with Error Control.	Reinhard Klein,Gunther Liebich,Wolfgang Straßer	1996	Mesh Reduction with Error Control.	IEEE Visualizat	visu
4579	IEEE Visualization	UFLOW: Visualizing Uncertainty in Fluid Flow.	Suresh K. Lodha,Alex Pang,Robert E. Sheehan,Craig M. Wittenbrink	1996	UFLOW: Visualizing Uncertainty in Fluid Flow.	IEEE Visualizat	visu
4580	IEEE Visualization	LISTEN: Sounding Uncertainty Visualization.	Suresh K. Lodha,Catherine M. Wilson,Robert E. Sheehan	1996	LISTEN: Sounding Uncertainty Visualization.	IEEE Visualizat	visu
4581	IEEE Visualization	Surface Rendering versus Volume Rendering in Medical Imaging.	William E. Lorensen,Ron Kikinis,Sandy Napel,Arie E. Kaufman,John Flynn	1996	Surface Rendering versus Volume Rendering in Medical Imaging.	IEEE Visualizat	visu
4582	IEEE Visualization	A Visualization Tool for Mechanical Design.	Shao-Chiung Lu,Alec B. Rebello,D. H. Cui,Roni Yagel,R. A. Miller,G. L. Kinzel	1996	A Visualization Tool for Mechanical Design.	IEEE Visualizat	visu
4583	IEEE Visualization	A 3D Contextual Shading Method for Visualization of Diecasting Defects.	Shao-Chiung Lu,Alec B. Rebello,D. H. Cui,Roni Yagel,R. A. Miller,G. L. Kinzel	1996	A 3D Contextual Shading Method for Visualization of Diecasting Defects.	IEEE Visualizat	visu
4584	IEEE Visualization	Fast Perspective Volume Rendering with Splatting by Utilizing a Ray-Driven Approach.	Klaus Mueller,Roni Yagel	1996	Fast Perspective Volume Rendering with Splatting by Utilizing a Ray-Driven Approach.	IEEE Visualizat	visu
4585	IEEE Visualization	Three Dimensional Visualization of Proteins in Cellular Interactions.	Colin R. F. Monks,Patricia Crossno,George S. Davidson,Constantine J. Pavlakos,Abraham Kupfer,Cláudio T. Silva,Brian N. Wylie	1996	Three Dimensional Visualization of Proteins in Cellular Interactions.	IEEE Visualizat	visu
4586	IEEE Visualization	Interactive Visulization of Ocean Circulation Models.	Scott Nations,Robert J. Moorhead,Kelly P. Gaither,Steve Aukstakalnis,Rhonda Vickery,Warren Carl Couvillion Jr.,Daniel N. Fox,Peter Flynn,Alan J. Wallcraft,Patrick Hogan,Ole Martin Smedstad	1996	Interactive Visulization of Ocean Circulation Models.	IEEE Visualizat	visu
4587	IEEE Visualization	Virtual Workbench - A Non-Immersive Virtual Environment for Visualizing and Interacting with 3D Objects for Scientific Visualization.	Upul Obeysekare,Chas Williams,Jim Durbin,Lawrence J. Rosenblum,Robert Rosenberg,Fernando Grinstein,Ravi Ramamurthi,Alexandra Landsberg,William Sandberg	1996	Virtual Workbench - A Non-Immersive Virtual Environment for Visualizing and Interacting with 3D Objects for Scientific Visualization.	IEEE Visualizat	visu
4588	IEEE Visualization	Dynamic View-Dependent Simplification for Polygonal Models.	Julie C. Xia,Amitabh Varshney	1996	Dynamic View-Dependent Simplification for Polygonal Models.	IEEE Visualizat	visu
4589	IEEE Visualization	Mantle Convection Visualization on the Cray T3D.	James S. Painter,Hans-Peter Bunge,Yarden Livnat	1996	Mantle Convection Visualization on the Cray T3D.	IEEE Visualizat	visu
4590	IEEE Visualization	Electrical Energy Absorption in the Human Head from a Cellular Telephone.	Vishram Pandit,Robert McDermott,Gianluca Lazzi,Cynthia Furse,Om Gandhi	1996	Electrical Energy Absorption in the Human Head from a Cellular Telephone.	IEEE Visualizat	visu
4591	IEEE Visualization	Real-Time Accelerators for Volume Rendering.	Hanspeter Pfister,Günter Knittel,Jürgen Hesser,John C. Goble	1996	Real-Time Accelerators for Volume Rendering.	IEEE Visualizat	visu
4592	IEEE Visualization	Information Exploration Shootout.	Gregory Piatetsky-Shapiro,Graham J. Wills	1996	Information Exploration Shootout.	IEEE Visualizat	visu
4593	IEEE Visualization	Opacity-modulating Triangular Textures for Irregular Surfaces.	Penny Rheingans	1996	Opacity-modulating Triangular Textures for Irregular Surfaces.	IEEE Visualizat	visu
4594	IEEE Visualization	A System for the Complementary Visualization of 3D Volume Images Using 2D and 3D Binaurally Processed Sonification Representations.	David Rossiter,Wai-Yin Ng	1996	A System for the Complementary Visualization of 3D Volume Images Using 2D and 3D Binaurally Processed Sonification Representations.	IEEE Visualizat	visu
4595	IEEE Visualization	Flow Visualization for Turbomachinery Design.	Martin Roth,Ronald Peikert	1996	Flow Visualization for Turbomachinery Design.	IEEE Visualizat	visu
4596	IEEE Visualization	Visualization of Laser Confocal Microscopy Datasets.	Georgios Sakas,Michael G. Vicker,Peter Jörg Plath	1996	Visualization of Laser Confocal Microscopy Datasets.	IEEE Visualizat	visu
4597	IEEE Visualization	The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization.	William J. Schroeder,Ken Martin,William E. Lorensen	1996	The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization.	IEEE Visualizat	visu
4598	IEEE Visualization	Octree-Based Decimation of Marching Cubes Surfaces.	Raj Shekhar,Elias Fayyad,Roni Yagel,J. Fredrick Cornhill	1996	Octree-Based Decimation of Marching Cubes Surfaces.	IEEE Visualizat	visu
4599	IEEE Visualization	Isosurfacing in Span Space with Utmost Efficiency (ISSUE).	Han-Wei Shen,Charles D. Hansen,Yarden Livnat,Christopher R. Johnson	1996	Isosurfacing in Span Space with Utmost Efficiency (ISSUE).	IEEE Visualizat	visu
4600	IEEE Visualization	Volume Tracking.	Deborah Silver,Xin Wang	1996	Volume Tracking.	IEEE Visualizat	visu
4601	IEEE Visualization	Keynote Address: Bringing Visualization to the User (Abstract).	Alvy Ray Smith	1996	Keynote Address: Bringing Visualization to the User (Abstract).	IEEE Visualizat	visu
4602	IEEE Visualization	Visualization of Roughness in Musical Consonance.	Florian Sobieczky	1996	Visualization of Roughness in Musical Consonance.	IEEE Visualizat	visu
4603	IEEE Visualization	Data Level Comparative Visualization in Aircraft Design.	Jens C. Trapp,Hans-Georg Pagendarm	1996	Data Level Comparative Visualization in Aircraft Design.	IEEE Visualizat	visu
4604	IEEE Visualization	Wavelets Applied to Lossless Compression and Progressive Transmission of Floating Point Data in 3-D Curvilinear Grids.	Aaron Trott,Robert J. Moorhead,John McGinley	1996	Wavelets Applied to Lossless Compression and Progressive Transmission of Floating Point Data in 3-D Curvilinear Grids.	IEEE Visualizat	visu
4605	IEEE Visualization	A Fast Gibbs Sampler for Synthesizing Constrained Fractals.	Baba C. Vemuri,Chhandomay Mandal	1996	A Fast Gibbs Sampler for Synthesizing Constrained Fractals.	IEEE Visualizat	visu
4606	IEEE Visualization	Capstone Address: Color, Pattern, and the Human Visual System (Abstract).	Brian A. Wandell	1996	Capstone Address: Color, Pattern, and the Human Visual System (Abstract).	IEEE Visualizat	visu
4607	IEEE Visualization	Complex-Valued Contour Meshing.	Chris Weigle,David C. Banks	1996	Complex-Valued Contour Meshing.	IEEE Visualizat	visu
4608	IEEE Visualization	Interactive Exploration and Modeling of Large Data Sets: A Case Study with Venus Light Scattering Data.	Jarke J. van Wijk,Hans J. W. Spoelder,Willem-Jan Knibbe,Kamran Eftekhari Shahroudi	1996	We present a system where visualization and the control of the simulation are integrated to facilitate interactive exploration and modeling of large data sets. The system was developed to estimate properties of the atmosphere of Venus from comparison between measured and simulated data. Reuse of results, distributed computing, and multiple views on the data were the major ingredients to create an effective environment.	IEEE Visualizat	visu
4609	IEEE Visualization	Hierarchical and Parallelizable Direct Volume Rendering for Irregular and Multiple Grids.	Jane Wilhelms,Allen Van Gelder,Paul Tarantino,Jonathan Gibbs	1996	Hierarchical and Parallelizable Direct Volume Rendering for Irregular and Multiple Grids.	IEEE Visualizat	visu
4610	IEEE Visualization	Multiresolution Multidimensional Wavelet Brushing.	Pak Chung Wong,R. Daniel Bergeron	1996	Multiresolution Multidimensional Wavelet Brushing.	IEEE Visualizat	visu
4611	IEEE Visualization	Visualization Over the World Wide Web and its Application to Environmental Data.	Jason Wood,Ken Brodlie,Helen Wright	1996	Visualization Over the World Wide Web and its Application to Environmental Data.	IEEE Visualizat	visu
4612	IEEE Visualization	The Challenges of Visualizing and Modeling Environmental Data.	Yingcai Xiao,John P. Ziebarth,Chuck Woodbury,Eric Bayer,Bruce Rundell,Jeroen van der Zijp	1996	The Challenges of Visualizing and Modeling Environmental Data.	IEEE Visualizat	visu
4613	IEEE Visualization	Clinical Evaluation of Interactive Volume Visualization.	Karel J. Zuiderveld,Peter M. A. van Ooijen,John W. C. Chin-A-Woeng,Pieter C. Buijs,Marco Olree,Frits H. Post	1996	Clinical Evaluation of Interactive Volume Visualization.	IEEE Visualizat	visu
4614	IEEE Visualization	Interactive Visualiztion of 3D-Vector Fields using Illuminated Streamlines.	Malte Zöckler,Detlev Stalling,Hans-Christian Hege	1996	Interactive Visualiztion of 3D-Vector Fields using Illuminated Streamlines.	IEEE Visualizat	visu
4615	IEEE Visualization	Visualization '96, Proceedings, San Francisco, CA, USA, October 27 - November 1, 1996.	Roni Yagel,Gregory M. Nielson	1996	Visualization '96, Proceedings, San Francisco, CA, USA, October 27 - November 1, 1996.	IEEE Visualizat	visu
4616	IEEE Trans. Vis. Comput. Graph.	Structured Penumbral Irradiance Computation.	George Drettakis,Eugene Fiume	1996	A definitive understanding of irradiance behavior in penumbral regions has been hard to come by, mainly due to the computational expense of determining the visible parts of an area light source. Consequently, sampling strategies have been mostly ad hoc, and evaluation of the resulting approximations has been difficult. In this paper, the structure of penumbral irradiance is investigated empirically and numerically. This study has been made feasible by the use of the discontinuity mesh and the backprojection, an efficient data structure representing visibility in regions of partial occlusion. Regions of penumbrae in which irradiance varies nonmonotonically are characterized empirically, and numerical tests are performed to determine the frequency of their occurrence. This study inspired the development of two algorithms for the construction of interpolating approximations to irradiance: One algorithm reduces the number of edges in the mesh defining the interpolant domain, and the other algorithm chooses among linear, quadratic, and mixed interpolants based on irradiance monotonicity. Results from numerical tests and images are presented that demonstrate good performance of the new algorithms for various realistic test configurations.	IEEE Trans. Vis	visu
4617	IEEE Trans. Vis. Comput. Graph.	Frequency Analysis of Gradient Estimators in Volume Rendering.	Mark J. Bentum,Barthold B. A. Lichtenbelt,Thomas Malzbender	1996	Gradient information is used in volume rendering to classify and color samples along a ray. In this paper, we present an analysis of the theoretically ideal gradient estimator and compare it to some commonly used gradient estimators. A new method is presented to calculate the gradient at arbitrary sample positions, using the derivative of the interpolation filter as the basis for the new gradient filter. As an example, we will discuss the use of the derivative of the cubic spline. Comparisons with several other methods are demonstrated. Computational efficiency can be realized since parts of the interpolation computation can be leveraged in the gradient estimation.	IEEE Trans. Vis	visu
4618	IEEE Trans. Vis. Comput. Graph.	Splatting of Non Rectilinear Volumes Through Stochastic Resampling.	Xiaoyang Mao	1996	This paper extends the conventional splatting algorithm for volume rendering non rectilinear grids. A stochastic sampling technique called Poisson sphere/ellipsoid is employed to adaptively resample a non rectilinear grid with a set of randomly distributed points whose energy support extents are well approximated by spheres or ellipsoids. Then volume rendered images can be generated by splatting the scalar values at the new sample points with filter kernels corresponding to these spheres and ellipsoids. Experiments have been carried out to investigate the image quality as well as the time/space efficiency of the new approach, and the results suggest that our approach can be regarded as an alternative for existing fast volume rendering techniques of non rectilinear grids.	IEEE Trans. Vis	visu
4619	IEEE Trans. Vis. Comput. Graph.	Volumetric Data Exploration Using Interval Volume.	Issei Fujishiro,Yuji Maeda,Hiroshi Sato,Yuriko Takeshima	1996	A new type of geometric model called Interval volume for volumetric data exploration is presented. An interval volume represents a three-dimensional subvolume for which the associate scalar values lie within a user-specified interval, and provides one of the promising approaches to solid fitting, which is an extended concept of traditional surface fitting. A well known isosurfacing algorithm called Marching Cubes is extended to obtain a solid fitting algorithm, which extracts from a given volumetric data set a high resolution, polyhedral solid data structure of an interval volume. Branch-on-Need Octree is used as an auxiliary data structure to accelerate the extraction process. A variety of interval volume rendering methods and principal related operations, including measurements and focusing, are also presented. The effectiveness of measurement-coupled visualization capabilities of the presented approach is demonstrated by application to visualizing a four-dimensional simulated data from atomic collision research.	IEEE Trans. Vis	visu
4620	IEEE Trans. Vis. Comput. Graph.	Efficient Triangular Surface Approximations Using Wavelets and Quadtree Data Structures.	Markus H. Gross,Oliver G. Staadt,Roger Gatti	1996	We present a new method for adaptive surface meshing and triangulation which controls the local level-of-detail of the surface approximation by local spectral estimates. These estimates are determined by a wavelet representation of the surface data. The basic idea is to decompose the initial data set by means of an orthogonal or semi-orthogonal tensor product wavelet transform (WT) and to analyze the resulting coefficients. In surface regions, where the partial energy of the resulting coefficients is low, the polygonal approximation of the surface can be performed with larger triangles without loosing too much fine grain details. However, since the localization of the WT is bound by the Heisenberg principle the meshing method has to be controlled by the detail signals rather than directly by the coefficients. The dyadic scaling of the WT stimulated us to build an hierarchical meshing algorithm which transforms the initially regular data grid into a quadtree representation by rejection of unimportant mesh vertices. The optimum triangulation of the resulting quadtree cells is carried out by selection from a look-up table. The tree grows recursively as controlled by detail signals which are computed from a modified inverse WT.In order to control the local level-of-detail, we introduce a new class of wavelet space filters acting as magnifying glasses on the data.We show that our algorithm performs a low algorithmic complexity, so that surface meshing can be achieved at interactive rates, such as required by flight simulators. However, other applications are possible as well, such as mesh reduction in complex data, FEM or radiosity meshing.The method is applied on different types of data comprising both digital terrain models and laser range scans. In addition, quantitative investigations on error analysis are carried out.	IEEE Trans. Vis	visu
4621	IEEE Trans. Vis. Comput. Graph.	Fractal Volume Compression.	Wayne O. Cochran,John C. Hart,Patrick J. Flynn	1996	This research explores the principles, implementation, and optimization of a competitive volume compression system based on fractal image compression. The extension of fractal image compression to volumetric data is trivial in theory. However, the simple addition of a dimension to existing fractal image compression algorithms results in infeasible compression times and noncompetitive volume compression results. This paper extends several fractal image compression enhancements to perform properly and efficiently on volumetric data, and introduces a new 3D edge classification scheme based on principal component analysis. Numerous experiments over the many parameters of fractal volume compression suggest aggressive settings of its system parameters. At this peak efficiency, fractal volume compression surpasses vector quantization and approaches within 1 dB PSNR of the discrete cosine transform. When compared to the DCT, fractal volume compression represents surfaces in volumes exceptionally well at high compression rates, and the artifacts of its compression error appear as noise instead of deceptive smoothing or distracting ringing.	IEEE Trans. Vis	visu
4622	IEEE Trans. Vis. Comput. Graph.	A Real-Time Photo-Realistic Visual Flythrough.	Daniel Cohen-Or,Eran Rich,Uri Lerner,Victor Shenkar	1996	In this paper we present a comprehensive flythrough system which generates photo-realistic images in true real-time. The high performance is due to an innovative rendering algorithm based on a discrete ray casting approach, accelerated by ray coherence and multiresolution traversal. The terrain as well as the 3D objects are represented by a textured mapped voxel-based model. The system is based on a pure software algorithm and is thus portable. It was first implemented on a workstation and then ported to a general-purpose parallel architecture to achieve real-time performance.	IEEE Trans. Vis	visu
4623	IEEE Trans. Vis. Comput. Graph.	Editorial.		1996	Editorial.	IEEE Trans. Vis	visu
4624	IEEE Trans. Vis. Comput. Graph.	Visualizing Unstructured Flow Data Using Dual Stream Functions.	David Knight,Gordon Mallinson	1996	One of the most important ways of visualizing fluid flow is the construction of streamlines, which are lines that are everywhere tangential to the local fluid velocity. Stream surfaces are defined as surfaces through which no fluid penetrates. Streamlines can therefore be computed from the intersection of two nonparallel stream surfaces. This paper presents new algorithms for the computation of dual stream functions from Computational Fluid Dynamics data that is defined on an unstructured tetrahedral mesh. These algorithms are compared with standard numerical routines for computing streamlines, and are shown to be quicker and more accurate than techniques involving numerical integration along the streamline.	IEEE Trans. Vis	visu
4625	IEEE Trans. Vis. Comput. Graph.	Interactive Display of Large NURBS Models.	Subodh Kumar,Dinesh Manocha,Anselmo Lastra	1996	We present algorithms for interactive rendering of large-scale NURBS models. The algorithms convert the NURBS surfaces to Bézier surfaces, tessellate each Bézier surface into triangles, and render them using the triangle-rendering capabilities common to current graphics systems. This paper presents algorithms for computing tight bounds on surface properties in order to generate high quality tessellation of Bézier surfaces. We introduce enhanced visibility determination techniques and present methods to make efficient use of coherence between successive frames. In addition, we also discuss issues in parallelization of these techniques. The algorithm also avoids polygonization anomalies like cracks. Our algorithms work well in practice and, on high-end graphics systems, are able to display models described using thousands of Bézier surfaces at interactive frame rates.	IEEE Trans. Vis	visu
4626	IEEE Trans. Vis. Comput. Graph.	Analysis of a Parallel Volume Rendering System Based on the Shear-Warp Factorization.	Philippe Lacroute	1996	This paper presents a parallel volume rendering algorithm that can render a 256 × 256 × 225 voxel medical data set at over 15 Hz and a 512 × 512 × 334 voxel data set at over 7 Hz on a 32-processor Silicon Graphics Challenge. The algorithm achieves these results by minimizing each of the three components of execution time: computation time, synchronization time, and data communication time. Computation time is low because the parallel algorithm is based on the recently-reported shear-warp serial volume rendering algorithm which is over five times faster than previous serial algorithms. The algorithm uses run-length encoding to exploit coherence and an efficient volume traversal to reduce overhead. Synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events. Data communication costs are low because the algorithm is implemented for shared-memory multiprocessors, a class of machines with hardware support for low-latency fine-grain communication and hardware caching to hide latency.We draw two conclusions from our implementation. First, we find that on shared-memory architectures data redistribution and communication costs do not dominate rendering time. Second, we find that cache locality requirements impose a limit on parallelism in volume rendering algorithms. Specifically, our results indicate that shared-memory machines with hundreds of processors would be useful only for rendering very large data sets.	IEEE Trans. Vis	visu
4627	IEEE Trans. Vis. Comput. Graph.	Controlled Topology Simplification.	Taosong He,Lichan Hong,Amitabh Varshney,Sidney W. Wang	1996	We present a simple, robust, and practical method for object simplification for applications where gradual elimination of high frequency details is desired. This is accomplished by converting an object into multi-resolution volume rasters using a controlled filtering and sampling technique. A multiresolution triangle-mesh hierarchy can then be generated by applying the Marching Cubes algorithm. We further propose an adaptive surface generation algorithm to reduce the number of triangles generated by the standard Marching Cubes. Our method simplifies the topology of objects in a controlled fashion. In addition, at each level of detail, multilayered meshes can be used for an efficient antialiased rendering.	IEEE Trans. Vis	visu
4628	IEEE Trans. Vis. Comput. Graph.	Solving Geometric Constraints By Homotopy.	Hervé Lamure,Dominique Michelucci	1996	Solving Geometric Constraints By Homotopy.	IEEE Trans. Vis	visu
4629	IEEE Trans. Vis. Comput. Graph.	Image Composition Schemes for Sort-Last Polygon Rendering on 2D Mesh Multicomputers.	Tong-Yee Lee,C. S. Raghavendra,John B. Nicholas	1996	In a sort-last polygon rendering system, the efficiency of image composition is very important for achieving fast rendering. In this paper, the implementation of a sort-last rendering system on a general purpose multicomputer system is described. A two-phase sort-last-full image composition scheme is described first, and then many variants of it are presented for 2D mesh message-passing multicomputers, such as the Intel Delta and Paragon. All the proposed schemes are analyzed and experimentally evaluated on Caltech's Intel Delta machine for our sort-last parallel polygon renderer. Experimental results show that sort-last-sparse strategies are better suited than sort-last-full schemes for software implementation on a general purpose multicomputer system. Further, interleaved composition regions perform better than coherent regions. In a large multicomputer system, performance can be improved by carefully scheduling the tasks of rendering and communication. Using 512 processors to render our test scenes, the peak rendering rate achieved on a 262, 144 triangle dataset is close to 4.6 million triangles per second which is comparable to the speed of current state-of-the-art graphics workstations.	IEEE Trans. Vis	visu
4630	IEEE Trans. Vis. Comput. Graph.	A Road Map To Solid Modeling.	Christoph M. Hoffmann,Jarek Rossignac	1996	The objective of solid modeling is to represent, manipulate, and reason about, the three-dimensional shape of solid physical objects, by computer. Such representations should be unambiguous.Solid modeling is an application-oriented field that began in earnest in the early 1970s. [46]. Major application areas include design, manufacturing, computer vision, graphics, and virtual reality. Technically, the field draws on diverse sources including numerical analysis, symbolic algebraic computation, approximation theory, applied mathematics, point set topology, algebraic geometry, computational geometry, and data bases. Monographs and major surveys of solid modeling include [13], [19], [27], [37], [44], [45], [46].In this road map article, we begin with some mathematical foundations of the field. We review next the major representation schemata of solids. Then, major layers of abstraction in a typical solid modeling system are characterized: The lowest level of abstraction comprises a substratum of basic service algorithms. At an intermediate level of abstraction there are algorithms for larger, more conceptual operations. Finally, a yet higher level of abstraction presents to the user a functional view that is typically targeted towards solid design. Here, we will look at some applications and at user interaction concepts.The classical design paradigms of Solid Modeling concentrated on obtaining one specific final shape. Those paradigms are becoming supplanted by feature-based, constraint-based design paradigms that are oriented more toward the design process and define classes of shape instances. These new paradigms venture into territory that has yet to be explored systematically. Concurrent with this paradigm shift, there is also a shift in the system architecture towards modularized confederations of plug-compatible functional components. We explore these trends lightly in the last section.	IEEE Trans. Vis	visu
4631	IEEE Trans. Vis. Comput. Graph.	Image Metamorphosis with Scattered Feature Constraints.	Seungyong Lee,George Wolberg,Kyung-Yong Chwa,Sung Yong Shin	1996	This paper describes an image metamorphosis technique to handle scattered feature constraints specified with points, polylines, and splines. Solutions to the following three problems are presented: feature specification, warp generation, and transition control. We demonstrate the use of snakes to reduce the burden of feature specification. Next, we propose the use of multilevel free-form deformations (MFFD) to compute C2-continuous and one-to-one mapping functions among the specified features. The resulting technique, based on B-spline approximation, is simpler and faster than previous warp generation methods. Furthermore, it produces smooth image transformations without undesirable ripples and foldovers. Finally, we simplify the MFFD algorithm to derive transition functions to control geometry and color blending. Implementation details are furnished and comparisons among various metamorphosis techniques are presented.	IEEE Trans. Vis	visu
4632	IEEE Trans. Vis. Comput. Graph.	RIVA: A Versatile Parallel Rendering System for Interactive Scientific Visualization.	Peggy Li,William H. Duquette,David W. Curkendall	1996	JPL's Remote Interactive Visualization and Analysis System (RIVA) is described in detail. The RIVA system integrates workstation graphics, massively parallel computing technology, and gigabit communication networks to provide a flexible interactive environment for scientific data perusal, analysis, and visualization. RIVA's kernel is a highly scalable parallel perspective renderer tailored especially for the demands of large datasets beyond the sensible reach of workstations. Early experience with using RIVA to interactively explore and process multivariate, multiresolution datasets is reported; several examples using data from a variety of remote sensing instruments are discussed in detail and the results shown. Particular attention is placed on describing the algorithmic details of RIVA's parallel renderer kernel, with emphasis on the key aspects of achieving the algorithm's overall scalability. The paper summarizes the performance achieved for machine sizes up to more than 500 nodes and for initial input image/terrain bases in the 2 Gbyte range.	IEEE Trans. Vis	visu
4633	IEEE Trans. Vis. Comput. Graph.	Editorial.		1996	Editorial.	IEEE Trans. Vis	visu
4634	IEEE Trans. Vis. Comput. Graph.	A Near Optimal Isosurface Extraction Algorithm Using the Span Space.	Yarden Livnat,Han-Wei Shen,Christopher R. Johnson	1996	We present the Near Optimal IsoSurface Extraction (NOISE) algorithm for rapidly extracting isosurfaces from structured and unstructured grids. Using the span space, a new representation of the underlying domain, we develop n isosurface extraction algorithm with a worst case complexity of $O\left ({\sqrt n} + k\right )$ for the search phase, where n is the size of the data set and k is the number of cells intersected by the isosurface. The memory requirement is kept at O(n) while the preprocessing step is O(n log n). We utilize the span space representation as a tool for comparing isosurface extraction methods on structured and unstructured grids. We also present a fast triangulation scheme for generating and displaying unstructured tetrahedral grids.	IEEE Trans. Vis	visu
4635	IEEE Trans. Vis. Comput. Graph.	Correction: A Near Optimal Isosurface Extraction Algorithm Using the Span Space.	Yarden Livnat,Han-Wei Shen,Christopher R. Johnson	1996	Correction: A Near Optimal Isosurface Extraction Algorithm Using the Span Space.	IEEE Trans. Vis	visu
4636	IEEE Trans. Vis. Comput. Graph.	Editorial.	Arie E. Kaufman	1996	Editorial.	IEEE Trans. Vis	visu
4637	IEEE Trans. Vis. Comput. Graph.	Reconstruction Error Characterization and Control: A Sampling Theory Approach.	Raghu Machiraju,Roni Yagel	1996	Reconstruction is prerequisite whenever a discrete signal needs to be resampled as a result of transformation such as texture mapping, image manipulation, volume slicing, and rendering. We present a new method for the characterization and measurement of reconstruction error in spatial domain. Our method uses the Classical Shannon's Sampling Theorem as a basis to develop error bounds. We use this formulation to provide, for the first time, an efficient way to guarantee an error bound at every point by varying the size of the reconstruction filter. We go further to support position-adaptive reconstruction and data-adaptive reconstruction which adjust filter size to the location of reconstruction point and to the data values in its vicinity. We demonstrate the effectiveness of our methods with 1D signals, 2D signals (images), and 3D signals (volumes).	IEEE Trans. Vis	visu
4638	IEEE Trans. Vis. Comput. Graph.	Interactive Time-Dependent Particle Tracing Using Tetrahedral Decomposition.	David N. Kenwright,David A. Lane	1996	Streak lines and particle traces are effective visualization techniques for studying unsteady fluid flows. For real-time applications, accuracy is often sacrificed to achieve interactive frame rates. Physical space particle tracing algorithms produce the most accurate results although they are usually too expensive for interactive applications. An efficient physical space algorithm is presented in this paper which was developed for interactive investigation and visualization of large, unsteady, aeronautical simulations. Performance has been increased by applying tetrahedral decomposition to speed up point location and velocity interpolation in curvilinear grids. Preliminary results from batch computations [1] showed that this approach was up to six times faster than the most common algorithm which uses the Newton-Raphson method and trilinear interpolation. Results presented here show that the tetrahedral approach also permits interactive computation and visualization of unsteady particle traces. Statistics are given for frame rates and computation times on single and multiprocessors. The benefits of interactive feature detection in unsteady flows are also demonstrated.	IEEE Trans. Vis	visu
4639	IEEE Trans. Vis. Comput. Graph.	A Digital Brain Atlas for Surgical Planning, Model-Driven Segmentation, and Teaching.	Ron Kikinis,Martha Elizabeth Shenton,Dan V. Iosifescu,Robert W. McCarley,Pairash Saiviroonporn,Hiroto H. Hokama,Andre Robatino,David Metcalf,Cindy Wible,Chiara M. Portas,Robert M. Donnino,Ferenc A. Jolesz	1996	We developed a three-dimensional (3D) digitized atlas of the human brain to visualize spatially complex structures. It was designed for use with magnetic resonance (MR) imaging data sets. Thus far, we have used this atlas for surgical planning, model-driven segmentation, and teaching. We used a combination of automated and supervised segmentation methods to define regions of interest based on neuroanatomical knowledge. We also used 3D surface rendering techniques to create a brain atlas that would allow us to visualize complex 3D brain structures. We further linked this information to script files in order to preserve both spatial information and neuroanatomical knowledge. We present here the application of the atlas for visualization in surgical planning for model-driven segmentation and for the teaching of neuroanatomy. This digitized human brain has the potential to provide important reference information for the planning of surgical procedures. It can also serve as a powerful teaching tool, since spatial relationships among neuroanatomical structures can be more readily envisioned when the user is able to view and rotate the structures in 3D space. Moreover, each element of the brain atlas is associated with a name tag, displayed by a user-controlled pointer. The atlas holds a major promise as a template for model-driven segmentation. Using this technique, many regions of interest can be characterized simultaneously on new brain images.	IEEE Trans. Vis	visu
4640	IEEE Trans. Vis. Comput. Graph.	Theme Issue Introduction: Challenges in Visualization Research.	Gregory M. Nielson	1996	Theme Issue Introduction: Challenges in Visualization Research.	IEEE Trans. Vis	visu
4641	IEEE Trans. Vis. Comput. Graph.	Implementation and Analysis of an Image-Based Global Illumination Framework for Animated Environments.	Jeffry Nimeroff,Julie Dorsey,Holly E. Rushmeier	1996	We describe a new framework for efficiently computing and storing global illumination effects for complex, animated environments. The new framework allows the rapid generation of sequences representing any arbitrary path in a view space within an environment in which both the viewer and objects move. The global illumination is stored as time sequences of range-images at base locations that span the view space. We present algorithms for determining locations for these base images, and the time steps required to adequately capture the effects of object motion. We also present algorithms for computing the global illumination in the base images that exploit spatial and temporal coherence by considering direct and indirect illumination separately. We discuss an initial implementation using the new framework. Results and analysis of our implementation demonstrate the effectiveness of the individual phases of the approach; we conclude with an application of the complete framework to a complex environment that includes object motion.	IEEE Trans. Vis	visu
4642	IEEE Trans. Vis. Comput. Graph.	D-NURBS: A Physics-Based Framework for Geometric Design.	Hong Qin,Demetri Terzopoulos	1996	This paper presents dynamic NURBS, or D-NURBS, a physics-based generalization of Non-Uniform Rational B-Splines. NURBS have become a de facto standard in commercial modeling systems because of their power to represent both free-form shapes and common analytic shapes. Traditionally, however, NURBS have been viewed as purely geometric primitives, which require the designer to interactively adjust many degrees of freedom (DOFs)¿control points and associated weights¿to achieve desired shapes. The conventional shape modification process can often be clumsy and laborious. D-NURBS are physics-based models that incorporate mass distributions, internal deformation energies, forces, and other physical quantities into the NURBS geometric substrate. Their dynamic behavior, resulting from the numerical integration of a set of nonlinear differential equations, produces physically meaningful, hence intuitive shape variation. Consequently, a modeler can interactively sculpt complex shapes to required specifications not only in the traditional indirect fashion, by adjusting control points and setting weights, but also through direct physical manipulation, by applying simulated forces and local and global shape constraints. We use Lagrangian mechanics to formulate the equations of motion for D-NURBS curves, tensor-product D-NURBS surfaces, swung D-NURBS surfaces, and triangular D-NURBS surfaces. We apply finite element analysis to reduce these equations to efficient numerical algorithms computable at interactive rates on common graphics workstations. We implement a prototype modeling environment based on D-NURBS and demonstrate that D-NURBS can be effective tools in a wide range of CAGD applications such as shape blending, scattered data fitting, and interactive sculpting.	IEEE Trans. Vis	visu
4643	IEEE Trans. Vis. Comput. Graph.	Volume-Preserving Free-Form Solids.	Ari Rappoport,Alla Sheffer,Michel Bercovier	1996	Volume-Preserving Free-Form Solids.	IEEE Trans. Vis	visu
4644	IEEE Trans. Vis. Comput. Graph.	Shape Description By Medial Surface Construction.	Damian J. Sheehy,Cecil G. Armstrong,Desmond J. Robinson	1996	The medial surface is a skeletal abstraction of a solid that provides useful shape information, which compliments existing model representation schemes. The medial surface and its associated topological entities are defined, and an algorithm for computing the medial surface of a large class of B-rep solids is then presented. The algorithm is based on the domain Delaunay triangulation of a relatively sparse distribution of points, which are generated on the boundary of the object. This strategy is adaptive in that the boundary point set is refined to guarantee a correct topological representation of the medial surface.	IEEE Trans. Vis	visu
4645	IEEE Trans. Vis. Comput. Graph.	An Algorithm for the Medial Axis Transform of 3D Polyhedral Solids.	Evan C. Sherbrooke,Nicholas M. Patrikalakis,Erik Brisson	1996	The medial axis transform (MAT) is a representation of an object which has been shown to be useful in design, interrogation, animation, finite element mesh generation, performance analysis, manufacturing simulation, path planning, and tolerance specification. In this paper, an algorithm for determining the MAT is developed for general 3D polyhedral solids of arbitrary genus without cavities, with nonconvex vertices and edges. The algorithm is based on a classification scheme which relates different pieces of the medial axis (MA) to one another even in the presence of degenerate MA points. Vertices of the MA are connected to one another by tracing along adjacent edges, and finally the faces of the axis are found by traversing closed loops of vertices and edges. Representation of the MA and associated radius function is addressed, and pseudocode for the algorithm is given along with recommended optimizations. A connectivity theorem is proven to show the completeness of the algorithm. Complexity estimates and stability analysis for the algorithms are presented. Finally, examples illustrate the computational properties of the algorithm for convex and nonconvex 3D polyhedral solids with polyhedral holes.	IEEE Trans. Vis	visu
4646	IEEE Trans. Vis. Comput. Graph.	Function Representation for Sweeping by a Moving Solid.	Alexei Sourin,Alexander A. Pasko	1996	Function Representation for Sweeping by a Moving Solid.	IEEE Trans. Vis	visu
4647	IEEE Trans. Vis. Comput. Graph.	Efficient Streamline, Streamribbon, and Streamtube Constructions on Unstructured Grids.	Shyh-Kuang Ueng,Christopher A. Sikorski,Kwan-Liu Ma	1996	Streamline construction is one of the most fundamental techniques for visualizing steady flow fields. Streamribbons and streamtubes are extensions for visualizing the rotation and the expansion of the flow. This paper presents efficient algorithms for constructing streamlines, streamribbons, and streamtubes on unstructured grids. A specialized Runge-Kutta method is developed to speed up the tracing of streamlines. Explicit solutions are derived for calculating the angular rotation rates of streamribbons and the radii of streamtubes. In order to simplify mathematical formulations and reduce computational costs, all calculations are carried out in the canonical coordinate system instead of the physical coordinate system. The resulting speed-up in overall performance helps explore large flow fields.	IEEE Trans. Vis	visu
4648	IEEE Trans. Vis. Comput. Graph.	Feature Extraction and Iconic Visualization.	Theo van Walsum,Frits H. Post,Deborah Silver,Frank J. Post	1996	We present a conceptual framework and a process model for feature extraction and iconic visualization. The features are regions of interest extracted from a dataset. They are represented by attribute sets, which play a key role in the visualization process. These attribute sets are mapped to icons, or symbolic parametric objects, for visualization. The features provide a compact abstraction of the original data, and the icons are a natural way to visualize them. We present generic techniques to extract features and to calculate attribute sets, and describe a simple but powerful modeling language which was developed to create icons and to link the attributes to the icon parameters. We present illustrative examples of iconic visualization created with the techniques described, showing the effectiveness of this approach.	IEEE Trans. Vis	visu
4649	IEEE Trans. Vis. Comput. Graph.	Glyphs for Visualizing Uncertainty in Vector Fields.	Craig M. Wittenbrink,Alex Pang,Suresh K. Lodha	1996	Environmental data have inherent uncertainty which is often ignored in visualization. Meteorological stations and doppler radars, including their time series averages, have a wealth of uncertainty information that traditional vector visualization methods such as meteorological wind barbs and arrow glyphs simply ignore. We have developed a new vector glyph to visualize uncertainty in winds and ocean currents. Our approach is to include uncertainty in direction and magnitude, as well as the mean direction and length, in vector glyph plots. Our glyph shows the variation in uncertainty, and provides fair comparisons of data from instruments, models, and time averages of varying certainty. We also define visualizations that incorporate uncertainty in an unambiguous manner as verify visualization. We use both quantitative and qualitative methods to compare our glyphs to traditional ones. Subjective comparison tests with experts are provided, as well as objective tests, where the information density of our new glyphs and traditional glyphs are compared. The design of the glyph and numerous examples using environmental data are given. We show enhanced visualization, data together with their uncertainty information, that may improve understanding of environmental vector field data quality.	IEEE Trans. Vis	visu
4650	IEEE Trans. Vis. Comput. Graph.	A Fast Method for Estimating Discrete Field Values in Early Engineering Design.	Jovan Zagajac	1996	A Fast Method for Estimating Discrete Field Values in Early Engineering Design.	IEEE Trans. Vis	visu
4651	KDD	Discovery of Actionable Patterns in Databases: The Action Hierarchy Approach.	Gediminas Adomavicius,Alexander Tuzhilin	1997	Discovery of Actionable Patterns in Databases: The Action Hierarchy Approach.	KDD	datamining
4652	KDD	Brute-Force Mining of High-Confidence Classification Rules.	Roberto J. Bayardo Jr.	1997	Brute-Force Mining of High-Confidence Classification Rules.	KDD	datamining
4653	KDD	Applying Data Mining and Machine Learning Techniques to Submarine Intelligence Analysis.	Ulla Bergsten,Johan Schubert,Per Svensson	1997	Applying Data Mining and Machine Learning Techniques to Submarine Intelligence Analysis.	KDD	datamining
4654	KDD	Partial Classification Using Association Rules.	Kamal Ali,Stefanos Manganaris,Ramakrishnan Srikant	1997	Partial Classification Using Association Rules.	KDD	datamining
4655	KDD	Increasing the Efficiency of Data Mining Algorithms with Breadth-First Marker Propagation.	John M. Aronis,Foster J. Provost	1997	Increasing the Efficiency of Data Mining Algorithms with Breadth-First Marker Propagation.	KDD	datamining
4656	KDD	Process-Based Database Support for the Early Indicator Method.	Christoph Breitner,Jörg Schlösser,Rüdiger Wirth	1997	Process-Based Database Support for the Early Indicator Method.	KDD	datamining
4657	KDD	MineSet: An Integrated System for Data Mining.	Clifford Brunk,James Kelly,Ron Kohavi	1997	MineSet: An Integrated System for Data Mining.	KDD	datamining
4658	KDD	Zeta: A Global Method for Discretization of Continuous Variables.	K. M. Ho,Paul D. Scott	1997	Zeta: A Global Method for Discretization of Continuous Variables.	KDD	datamining
4659	KDD	Proposal and Empirical Comparison of a Parallelizable Distance-Based Discretization Method.	Jesús Cerquides,Ramon López de Mántaras	1997	Proposal and Empirical Comparison of a Parallelizable Distance-Based Discretization Method.	KDD	datamining
4660	KDD	Mining Multivariate Time-Series Sensor Data to Discover Behavior Envelopes.	Dennis DeCoste	1997	Mining Multivariate Time-Series Sensor Data to Discover Behavior Envelopes.	KDD	datamining
4661	KDD	Large Scale Data Mining: Challenges and Responses.	Jaturon Chattratichat,John Darlington,Moustafa Ghanem,Yike Guo,Harald Hüning,Martin Köhler,Janjao Sutiwaraphun,Hing Wing To,Dan Yang	1997	Large Scale Data Mining: Challenges and Responses.	KDD	datamining
4662	KDD	An Interactive Visualization Environment for Data Exploration.	Mark Derthick,John Kolojejchick,Steven F. Roth	1997	An Interactive Visualization Environment for Data Exploration.	KDD	datamining
4663	KDD	Why Does Bagging Work? A Bayesian Account and its Implications.	Pedro Domingos	1997	Why Does Bagging Work? A Bayesian Account and its Implications.	KDD	datamining
4664	KDD	Using Artificial Intelligence Planning to Automate Science Data Analysis for Large Image Databases.	Steve A. Chien,Forest Fisher,Helen Mortensen,Edisanter Lo,Ronald Greeley	1997	Using Artificial Intelligence Planning to Automate Science Data Analysis for Large Image Databases.	KDD	datamining
4665	KDD	Fast Committee Machines for Regression and Classification.	Harris Drucker	1997	Fast Committee Machines for Regression and Classification.	KDD	datamining
4666	KDD	Improving Scalability in a Scientific Discovery System by Exploiting Parallelism.	Gehad Galal,Diane J. Cook,Lawrence B. Holder	1997	Improving Scalability in a Scientific Discovery System by Exploiting Parallelism.	KDD	datamining
4667	KDD	A Guided Tour through the Data Mining Jungle.	Robert Engels,Guido Lindner,Rudi Studer	1997	A Guided Tour through the Data Mining Jungle.	KDD	datamining
4668	KDD	Density-Connected Sets and their Application for Trend Detection in Spatial Databases.	Martin Ester,Hans-Peter Kriegel,Jörg Sander,Xiaowei Xu	1997	Density-Connected Sets and their Application for Trend Detection in Spatial Databases.	KDD	datamining
4669	KDD	Maximal Association Rules: A New Tool for Mining for Keyword Co-Occurrences in Document Collections.	Ronen Feldman,Yonatan Aumann,Amihood Amir,Amir Zilberstein,Willi Klösgen	1997	Maximal Association Rules: A New Tool for Mining for Keyword Co-Occurrences in Document Collections.	KDD	datamining
4670	KDD	Visualization Techniques to Explore Data Mining Results for Document Collections.	Ronen Feldman,Willi Klösgen,Amir Zilberstein	1997	Visualization Techniques to Explore Data Mining Results for Document Collections.	KDD	datamining
4671	KDD	Deep Knowledge Discovery from Natural Language Texts.	Udo Hahn,Klemens Schnattinger	1997	Deep Knowledge Discovery from Natural Language Texts.	KDD	datamining
4672	KDD	Integrating and Mining Distributed Customer Databases.	Ira J. Haimowitz,Özden Gür-Ali,Henry Schwarz	1997	Integrating and Mining Distributed Customer Databases.	KDD	datamining
4673	KDD	GA-Based Rule Enhancement in Concept Learning.	Jukka Hekanaho	1997	We describe an application of DOGMA, a GA-based theory revision system, to MDL-based rule enhancement in supervised concept learning. The system takes as input classification data and a rule-based classification theory, produced by some rule-based learner, and builds a second, hopefully more accurate, model of the data. Unlike most theory revision systems DOGMA doesn''t revise the initial rules, but builds instead a completely new theory, using stochastic sampling and adaptation of the initial rules. The search for the new model is guided by a MDL-based complexity measure. The proposed methodology offers a partial solution both to the local mimima trap of fast greedy rule-based concept learners, and to the time complexity problem of GA-based concept learners. As an example we show how the system improves rules produced by C4.5Rules.	KDD	datamining
4674	KDD	Target-Independent Mining for Scientific Data: Capturing Transients and Trends for Phenomena Mining.	Thomas H. Hinke,John A. Rushing,Heggere S. Ranganath,Sara J. Graves	1997	Target-Independent Mining for Scientific Data: Capturing Transients and Trends for Phenomena Mining.	KDD	datamining
4675	KDD	From Large to Huge: A Statistician's Reactions to KDD & DM.	Peter J. Huber	1997	From Large to Huge: A Statistician's Reactions to KDD & DM.	KDD	datamining
4676	KDD	Adjusting for Multiple Comparisons in Decision Tree Pruning.	David Jensen,Matthew D. Schmill	1997	Adjusting for Multiple Comparisons in Decision Tree Pruning.	KDD	datamining
4677	KDD	SIPping from the Data Firehose.	George H. John,Brian Lent	1997	SIPping from the Data Firehose.	KDD	datamining
4678	KDD	Mining Generalized Term Associations: Count Propagation Algorithm.	Jonghyun Kahng,Wen-Hsiang Kevin Liao,Dennis McLeod	1997	Mining Generalized Term Associations: Count Propagation Algorithm.	KDD	datamining
4679	KDD	Metarule-Guided Mining of Multi-Dimensional Association Rules Using Data Cubes.	Micheline Kamber,Jiawei Han,Jenny Chiang	1997	Metarule-Guided Mining of Multi-Dimensional Association Rules Using Data Cubes.	KDD	datamining
4680	KDD	Scalable, Distributed Data Mining - An Agent Architecture.	Hillol Kargupta,Ilker Hamzaoglu,Brian Stafford	1997	Scalable, Distributed Data Mining - An Agent Architecture.	KDD	datamining
4681	KDD	A Probabilistic Approach to Fast Pattern Matching in Time Series Databases.	Eamonn J. Keogh,Padhraic Smyth	1997	A Probabilistic Approach to Fast Pattern Matching in Time Series Databases.	KDD	datamining
4682	KDD	Clustering Sequences of Complex Objects.	A. Ketterlin	1997	Clustering Sequences of Complex Objects.	KDD	datamining
4683	KDD	A Unified Notion of Outliers: Properties and Computation.	Edwin M. Knorr,Raymond T. Ng	1997	A Unified Notion of Outliers: Properties and Computation.	KDD	datamining
4684	KDD	Mining for Causes of Cancer: Machine Learning Experiments at Various Levels of Detail.	Stefan Kramer,Bernhard Pfahringer,Christoph Helma	1997	Mining for Causes of Cancer: Machine Learning Experiments at Various Levels of Detail.	KDD	datamining
4685	KDD	Discovering Trends in Text Databases.	Brian Lent,Rakesh Agrawal,Ramakrishnan Srikant	1997	Discovering Trends in Text Databases.	KDD	datamining
4686	KDD	Using General Impressions to Analyze Discovered Classification Rules.	Bing Liu,Wynne Hsu,Shu Chen	1997	Using General Impressions to Analyze Discovered Classification Rules.	KDD	datamining
4687	KDD	Fast Robust Visual Data Mining.	Ted Mihalisin,John Timlin	1997	Fast Robust Visual Data Mining.	KDD	datamining
4688	KDD	Development of Multi-Criteria Metrics for Evaluation of Data Mining Algorithms.	Gholamreza Nakhaeizadeh,Alexander Schnabl	1997	Development of Multi-Criteria Metrics for Evaluation of Data Mining Algorithms.	KDD	datamining
4689	KDD	Beyond Concise and Colorful: Learning Intelligible Rules.	Michael J. Pazzani,Subramani Mani,William Rodman Shankle	1997	Beyond Concise and Colorful: Learning Intelligible Rules.	KDD	datamining
4690	KDD	Discriminative vs Informative Learning.	Y. Dan Rubinstein,Trevor Hastie	1997	Discriminative vs Informative Learning.	KDD	datamining
4691	KDD	Analysis and Visualization of Classifier Performance: Comparison under Imprecise Class and Cost Distributions.	Foster J. Provost,Tom Fawcett	1997	Analysis and Visualization of Classifier Performance: Comparison under Imprecise Class and Cost Distributions.	KDD	datamining
4692	KDD	Scaling Up Inductive Algorithms: An Overview.	Foster J. Provost,Venkateswarlu Kolluri	1997	Scaling Up Inductive Algorithms: An Overview.	KDD	datamining
4693	KDD	Knowledge Discovery in Integrated Call Centers: A Framework for Effective Customer-Driven Marketing.	Paul Xia	1997	Knowledge Discovery in Integrated Call Centers: A Framework for Effective Customer-Driven Marketing.	KDD	datamining
4694	KDD	Visualizing Bagged Decision Trees.	J. Sunil Rao,William J. E. Potts	1997	Visualizing Bagged Decision Trees.	KDD	datamining
4695	KDD	KESO: Minimizing Database Interaction.	Arno Siebes,Martin L. Kersten	1997	KESO: Minimizing Database Interaction.	KDD	datamining
4696	KDD	Detecting Atmospheric Regimes Using Cross-Validated Clustering.	Padhraic Smyth,Michael Ghil,Kayo Ide,Joseph Roden,Andrew Fraser	1997	Detecting Atmospheric Regimes Using Cross-Validated Clustering.	KDD	datamining
4697	KDD	Anytime Exploratory Data Analysis for Massive Data Sets.	Padhraic Smyth,David Wolpert	1997	Anytime Exploratory Data Analysis for Massive Data Sets.	KDD	datamining
4698	KDD	Learning to Extract Text-Based Information from the World Wide Web.	Stephen Soderland	1997	Learning to Extract Text-Based Information from the World Wide Web.	KDD	datamining
4699	KDD	Mining Association Rules with Item Constraints.	Ramakrishnan Srikant,Quoc Vu,Rakesh Agrawal	1997	Mining Association Rules with Item Constraints.	KDD	datamining
4700	KDD	JAM: Java Agents for Meta-Learning over Distributed Databases.	Salvatore J. Stolfo,Andreas L. Prodromidis,Shelley Tselepis,Wenke Lee,Dave W. Fan,Philip K. Chan	1997	JAM: Java Agents for Meta-Learning over Distributed Databases.	KDD	datamining
4701	KDD	Image Feature Reduction through Spoiling: Its Application to Multiple Matched Filters for Focus of Attention.	Timothy M. Stough,Carla E. Brodley	1997	Image Feature Reduction through Spoiling: Its Application to Multiple Matched Filters for Focus of Attention.	KDD	datamining
4702	KDD	A Visual Interactive Framework for Attribute Discretization.	Ramesh Subramonian,Ramana Venkata,Joyce Chen	1997	A Visual Interactive Framework for Attribute Discretization.	KDD	datamining
4703	KDD	Autonomous Discovery of Reliable Exception Rules.	Einoshin Suzuki	1997	Autonomous Discovery of Reliable Exception Rules.	KDD	datamining
4704	KDD	An Efficient Algorithm for the Incremental Updation of Association Rules in Large Databases.	Shiby Thomas,Sreenath Bodagala,Khaled Alsabti,Sanjay Ranka	1997	An Efficient Algorithm for the Incremental Updation of Association Rules in Large Databases.	KDD	datamining
4705	KDD	Bayesian Inference for Identifying Solar Active Regions.	Michael J. Turmon,Saleem Mukhtar,Judit Pap	1997	Bayesian Inference for Identifying Solar Active Regions.	KDD	datamining
4706	KDD	Schema Discovery for Semistructured Data.	Ke Wang,Huiqing Liu	1997	Schema Discovery for Semistructured Data.	KDD	datamining
4707	KDD	Selecting Features by Vertical Compactness of Data.	Ke Wang,Suman Sundaresh	1997	Selecting Features by Vertical Compactness of Data.	KDD	datamining
4708	KDD	Automated Discovery of Active Motifs in Three Dimensional Molecules.	Xiong Wang,Jason Tsong-Li Wang,Dennis Shasha,Bruce A. Shapiro,Sitaram Dikshitulu,Isidore Rigoutsos,Kaizhong Zhang	1997	Automated Discovery of Active Motifs in Three Dimensional Molecules.	KDD	datamining
4709	KDD	Fast and Intuitive Clustering of Web Documents.	Oren Zamir,Oren Etzioni,Omid Madani,Richard M. Karp	1997	Fast and Intuitive Clustering of Web Documents.	KDD	datamining
4710	KDD	KDD Process Planning.	Ning Zhong,Chunnian Liu,Yoshitsugu Kakemoto,Setsuo Ohsuga	1997	KDD Process Planning.	KDD	datamining
4711	KDD	Optimal Multiple Intervals Discretization of Continuous Attributes for Supervised Learning.	Djamel A. Zighed,Ricco Rakotomalala,Fabien Feschet	1997	Optimal Multiple Intervals Discretization of Continuous Attributes for Supervised Learning.	KDD	datamining
4712	KDD	A Dataset Decomposition Approach to Data Mining and Machine Discovery.	Blaz Zupan,Marko Bohanec,Ivan Bratko,Bojan Cestnik	1997	A Dataset Decomposition Approach to Data Mining and Machine Discovery.	KDD	datamining
4713	KDD	Knowledge = Concepts: A Harmful Equation.	Jan M. Zytkow	1997	Knowledge = Concepts: A Harmful Equation.	KDD	datamining
4714	KDD	Computing Optimized Rectilinear Regions for Association Rules.	Kunikazu Yoda,Takeshi Fukuda,Yasuhiko Morimoto,Shinichi Morishita,Takeshi Tokuyama	1997	Computing Optimized Rectilinear Regions for Association Rules.	KDD	datamining
4715	KDD	New Algorithms for Fast Discovery of Association Rules.	Mohammed Javeed Zaki,Srinivasan Parthasarathy,Mitsunori Ogihara,Wei Li	1997	Association rule discovery has emerged as an important problem in knowledge discovery and data mining. The association mining task consists of identifying the frequent itemsets, and then forming conditional implication rules among them. In this paper we present efficient algorithms for the discovery of frequent itemsets, which forms the compute intensive phase of the task. The algorithms utilize the structural properties of frequent itemsets to facilitate fast discovery. The related database items are grouped together into clusters representing the potential maximal frequent itemsets in the database. Each cluster induces a sub-lattice of the itemset lattice. Efficient lattice traversal techniques are presented, which quickly identify all the true maximal frequent itemsets, and all their subsets if desired. We also present the effect of using different database layout schemes combined with the proposed clustering and traversal techniques. The proposed algorithms scan a (pre-processed) database only once, addressing the open question in association mining, whether all the rules can be efficiently extracted in a single database pass. We experimentally compare the new algorithms against the previous approaches, obtaining improvements of more than an order of magnitude for our test databases.	KDD	datamining
4716	KDD	Proceedings of the Third International Conference on Knowledge Discovery and Data Mining (KDD-97), Newport Beach, California, USA, August 14-17, 1997	David Heckerman,Heikki Mannila,Daryl Pregibon	1997	Proceedings of the Third International Conference on Knowledge Discovery and Data Mining (KDD-97), Newport Beach, California, USA, August 14-17, 1997	KDD	datamining
4717	PKDD	Discovery of Health Risks and Case-Based Forecasting of Epidemics in a Health Surveillance System.	Mathias Bull,Günther Kundt,Lothar Gierl	1997	Discovery of Health Risks and Case-Based Forecasting of Epidemics in a Health Surveillance System.	PKDD	datamining
4718	PKDD	Data Mining in the Telecommunications Industry (Abstract).	Leo Carbonara,Huw Roberts,Blaise Egan	1997	Data Mining in the Telecommunications Industry (Abstract).	PKDD	datamining
4719	PKDD	Mining in the Phrasal Frontier.	Helena Ahonen,Oskari Heinonen,Mika Klemettinen,A. Inkeri Verkamo	1997	Mining in the Phrasal Frontier.	PKDD	datamining
4720	PKDD	Share Based Measures for Itemsets.	Colin L. Carter,Howard J. Hamilton,Nick Cercone	1997	Share Based Measures for Itemsets.	PKDD	datamining
4721	PKDD	A New and Versatile Method for Association Generation.	Amihood Amir,Ronen Feldman,Reuven Kashi	1997	A New and Versatile Method for Association Generation.	PKDD	datamining
4722	PKDD	Using Signature Files for Querying Time-Series Data.	Henrik André-Jönsson,Dushan Z. Badal	1997	Using Signature Files for Querying Time-Series Data.	PKDD	datamining
4723	PKDD	Interactive Interpretation of Hierarchical Clustering.	Eric Boudaillier,Georges Hébrail	1997	Interactive Interpretation of Hierarchical Clustering.	PKDD	datamining
4724	PKDD	Recognizing Reliability of Discovered Knowledge.	Petr Berka	1997	Recognizing Reliability of Discovered Knowledge.	PKDD	datamining
4725	PKDD	Bivariate Decision Trees.	Jan C. Bioch,Onno van der Meer,Rob Potharst	1997	Bivariate Decision Trees.	PKDD	datamining
4726	PKDD	Mining Time Series Using Rough Sets - A Case Study.	Anders Torvill Bjorvand	1997	Mining Time Series Using Rough Sets - A Case Study.	PKDD	datamining
4727	PKDD	Finding Similar Time Series.	Gautam Das,Dimitrios Gunopulos,Heikki Mannila	1997	Finding Similar Time Series.	PKDD	datamining
4728	PKDD	Efficient Multisplitting on Numerical Data.	Tapio Elomaa,Juho Rousu	1997	Efficient Multisplitting on Numerical Data.	PKDD	datamining
4729	PKDD	Pattern Based Browsing in Document Collections.	Ronen Feldman,Willi Klösgen,Yaniv Ben-Yehuda,Gil Kedar,Vladimir Reznikov	1997	Pattern Based Browsing in Document Collections.	PKDD	datamining
4730	PKDD	Knowledge Discovery - A Control Theory Perspective.	Bjarne A. Foss	1997	Knowledge Discovery - A Control Theory Perspective.	PKDD	datamining
4731	PKDD	The Pronciple of Transformation between Efficiency and Effectiveness: Towards a Fair Evaluation of the Cost-Effectiveness of KDD Techniques.	Alex Alves Freitas	1997	The Pronciple of Transformation between Efficiency and Effectiveness: Towards a Fair Evaluation of the Cost-Effectiveness of KDD Techniques.	PKDD	datamining
4732	PKDD	Parallel Knowledge Discovery Using Domain Generalization Graphs.	Robert J. Hilderman,Howard J. Hamilton,Robert J. Kowalchuk,Nick Cercone	1997	Parallel Knowledge Discovery Using Domain Generalization Graphs.	PKDD	datamining
4733	PKDD	Finding Spatial Clusters.	Friedrich Gebhardt	1997	Finding Spatial Clusters.	PKDD	datamining
4734	PKDD	A Tutorial Introduction to High Performance Data Mining (Abstract).	Robert L. Grossman	1997	A Tutorial Introduction to High Performance Data Mining (Abstract).	PKDD	datamining
4735	PKDD	Regression-Based Classification Methods and Their Comparisons with Desision Tree Algorithms.	Mikhail V. Kiselev,Sergei M. Ananyan,Sergei B. Arseniev	1997	Regression-Based Classification Methods and Their Comparisons with Desision Tree Algorithms.	PKDD	datamining
4736	PKDD	techniques and Applications of KDD (Abstract).	Willi Klösgen,Jan M. Zytkow	1997	techniques and Applications of KDD (Abstract).	PKDD	datamining
4737	PKDD	Exploration of Document Collections with Self-Organizing Maps: A Novel Approach to Similarity Representation.	Dieter Merkl	1997	Exploration of Document Collections with Self-Organizing Maps: A Novel Approach to Similarity Representation.	PKDD	datamining
4738	PKDD	Rough Sets for Data Mining and Knowledge Discovery (Abstract).	Henryk Jan Komorowski,Lech Polkowski,Andrzej Skowron	1997	Rough Sets for Data Mining and Knowledge Discovery (Abstract).	PKDD	datamining
4739	PKDD	Modelling Customer Retention with Rough Data Models.	Wojciech Kowalczyk,Frank Slisser	1997	Modelling Customer Retention with Rough Data Models.	PKDD	datamining
4740	PKDD	Algorithms for Constructing of Decision Trees.	Mikhail Moshkov	1997	Algorithms for Constructing of Decision Trees.	PKDD	datamining
4741	PKDD	Clustering Techniques in Biological Sequence Analysis.	Anna M. Manning,Andy Brass,Carole A. Goble,John A. Keane	1997	Clustering Techniques in Biological Sequence Analysis.	PKDD	datamining
4742	PKDD	Generation of Rules from Incomplete Information Systems.	Marzena Kryszkiewicz	1997	Generation of Rules from Incomplete Information Systems.	PKDD	datamining
4743	PKDD	Searching for Relational Patterns in Data.	Sinh Hoa Nguyen,Andrzej Skowron	1997	Searching for Relational Patterns in Data.	PKDD	datamining
4744	PKDD	Rough Set Theory and Rule Induction Techniques for Discovery of Attribute Dependencies in Medical Information Systems.	Jerzy Stefanowski,Krzysztof Slowinski	1997	Rough Set Theory and Rule Induction Techniques for Discovery of Attribute Dependencies in Medical Information Systems.	PKDD	datamining
4745	PKDD	Induction of Strong Feature Subsets.	Mohamed Quafafou,Moussa Boussouf	1997	Induction of Strong Feature Subsets.	PKDD	datamining
4746	PKDD	Induction of Fuzzy Characteristic Rules.	Dan Rasmussen,Ronald R. Yager	1997	Induction of Fuzzy Characteristic Rules.	PKDD	datamining
4747	PKDD	Logical Calculi for Knowledge Discovery in Databases.	Jan Rauch	1997	Logical Calculi for Knowledge Discovery in Databases.	PKDD	datamining
4748	PKDD	Knowledge Discovery from Software Engineering Data: Rough Set Analysis and Its Interaction with Goal-Oriented Measurement.	Günther Ruhe	1997	Knowledge Discovery from Software Engineering Data: Rough Set Analysis and Its Interaction with Goal-Oriented Measurement.	PKDD	datamining
4749	PKDD	Extraction of Experts' Decision Process from Clinical Databases Using Rough Set Model.	Shusaku Tsumoto	1997	Extraction of Experts' Decision Process from Clinical Databases Using Rough Set Model.	PKDD	datamining
4750	PKDD	A Connectionist Approach to Structural Simiarity Determination as a Basis of Clustering, Classification and Feature Detection.	Kristina Schädler,Fritz Wysotzki	1997	A Connectionist Approach to Structural Simiarity Determination as a Basis of Clustering, Classification and Feature Detection.	PKDD	datamining
4751	PKDD	Neural Networks Design: Rough Set Approach to Continuous Data.	Hung Son Nguyen,Marcin S. Szczuka,Dominik Slezak	1997	Neural Networks Design: Rough Set Approach to Continuous Data.	PKDD	datamining
4752	PKDD	SNOUT: An Intelligent Assistant for Exploratory Data Anaylsis.	Paul D. Scott,A. P. M. Coxon,M. H. Hobbs,R. J. Williams	1997	SNOUT: An Intelligent Assistant for Exploratory Data Anaylsis.	PKDD	datamining
4753	PKDD	Exploratory Analysis of Biochemical Processes Using Hybrid Modeling Methods.	Rimvydas Simutis	1997	Exploratory Analysis of Biochemical Processes Using Hybrid Modeling Methods.	PKDD	datamining
4754	PKDD	TOAS Intelligence Mining; Analysis of Natural Language Processing and Computational Linguistics.	Robert J. Watts,Alan L. Porter,Scott Cunningham,Donghua Zhu	1997	TOAS Intelligence Mining; Analysis of Natural Language Processing and Computational Linguistics.	PKDD	datamining
4755	PKDD	Attribute Discovery and Rough Sets.	Jaroslaw Stepaniuk	1997	Attribute Discovery and Rough Sets.	PKDD	datamining
4756	PKDD	Towards Process-Oriented Tool Support for Knowledge Discovery in Databases.	Rüdiger Wirth,Colin Shearer,Udo Grimmer,Thomas P. Reinartz,Jörg Schlösser,Christoph Breitner,Robert Engels,Guido Lindner	1997	Towards Process-Oriented Tool Support for Knowledge Discovery in Databases.	PKDD	datamining
4757	PKDD	An Algorithm for Multi-relational Discovery of Subgroups.	Stefan Wrobel	1997	An Algorithm for Multi-relational Discovery of Subgroups.	PKDD	datamining
4758	PKDD	On Meta Levels of an Organized Society of KDD Agents.	Ning Zhong,Setsuo Ohsuga,Chunnian Liu,Yoshitsugu Kakemoto,Xiaosong Zhang	1997	On Meta Levels of an Organized Society of KDD Agents.	PKDD	datamining
4759	PKDD	Using Neural Network to Extract Knowledge from Database.	Yuanhui Zhou,Yuchang Lu,Chunyi Shi	1997	Using Neural Network to Extract Knowledge from Database.	PKDD	datamining
4760	PKDD	Principles of Data Mining and Knowledge Discovery, First European Symposium, PKDD '97, Trondheim, Norway, June 24-27, 1997, Proceedings	Henryk Jan Komorowski,Jan M. Zytkow	1997	Principles of Data Mining and Knowledge Discovery, First European Symposium, PKDD '97, Trondheim, Norway, June 24-27, 1997, Proceedings	PKDD	datamining
4761	ICDE	ULIXES: Building Relational Views over the Web.	Paolo Atzeni,Alessandro Masci,Giansalvatore Mecca,Paolo Merialdo,Elena Tabet	1997	The authors consider structured Web sites, those sites in which structures are so tight and regular that one can assimilate the site, from the logical viewpoint, to a conventional database. They have argued that, with respect to structured Web servers, it is possible to apply ideas from traditional database techniques, specifically with respect to design, query, and update. They focus on the querying process, which consists of associating a scheme with a server and then using this scheme to pose queries in a high level query language. To describe the scheme, they use a specific data model, called the ARANEUS Data Model (ADM). They call ADM a page oriented model, in the sense that the main construct of the model is that of a page scheme, used to describe the structure of sets of homogeneous pages in the server. ADM schemes are then offered to the user, who can query them using the ULIXES language, whose expressions produce relations as results. These are essentially relational views over Web data and can therefore be queried using any relational query language. It should be noted that the approach inherited some ideas from other proposals for query languages for the Web. However, these approaches are mainly based on a loose notion of structure, and tend to view the Web as a huge collection of unstructured objects, organized as a graph. In contrast, the approach explicitly considers structure, both in the information source (the Web) and in the derived information (the relational views).	ICDE	database
4762	ICDE	Universal Access versus Universal Storage.	William Baker	1997	Universal Access versus Universal Storage.	ICDE	database
4763	ICDE	SEOF: An Adaptable Object Prefetch Policy for Object-Oriented Database Systems.	Jung-Ho Ahn,Hyoung-Joo Kim	1997	The performance of object access can be drastically improved by efficient object prefetch. In this paper we present a new object prefetch policy, Selective Eager Object Fetch(SEOF) which prefetches objects only from selected candidate pages without using any high level object semantics. Our policy considers both the correlations and the frequencies of fetching objects. Unlike existing prefetch policies, this policy utilizes the memory and the swap space of clients efficiently without resource exhaustion. Furthermore, the proposed policy has good adaptability to both the effectiveness of clustering and database size. We show the performance of the proposed policy through experiments over various multi-client system configurations.	ICDE	database
4764	ICDE	The Constraint-Based Knowledge Broker System.	Jean-Marc Andreoli,Uwe M. Borghoff,Pierre-Yves Chevalier,Boris Chidlovskii,Remo Pareschi,Jutta Willamowski	1997	The amount of information available from electronic sources on the World Wide Web and other on-line information repositories is highly heterogeneous and increases dramatically. Tools are needed to extract relevant information from these repositories. The Constraint-Based Knowledge Brokers project (CBKB) at RXRC Grenoble realizes sophisticated facilities for efficient information retrieval, schema integration, and knowledge fusion. The current implementation of the CBKB research prototype involves three kinds of agents: a) users, who input queries and process answers (i.e., ranking, fusion) through a GUI; b) wrappers, capable of interrogating heterogeneous information sources, which can provide answers to elementary queries (essentially various public bibliographic catalogues available on the Web, as well as preprint archives and opera information repositories); c) brokers, which can manage complex queries (i.e., decompose a complex query, recompose the partial answers, synthesize a full answer) and which mediate between the GUI and the different wrappers.	ICDE	database
4765	ICDE	Modeling Multidimensional Databases.	Rakesh Agrawal,Ashish Gupta,Sunita Sarawagi	1997	We propose a data model and a few algebraic operations that provide semantic foundation to multidimensional databases. The distinguishing feature of the proposed model is the symmetric treatment not only of all dimensions but also measures. The model provides support for multiple hierarchies along each dimension and support for adhoc aggregates. The proposed operators are composable, reorderable, and closed in application. These operators are also minimal in the sense that none can be expressed in terms of others nor can any one be dropped without sacrificing functionality. They make possible the declarative specification and optimization of multidimensional database queries that are currently specified operationally. The operators have been designed to be translated to SQL and can be implemented either on top of a relational database system or within a special purpose multidimensional database engine. In effect, they provide an algebraic application programming interface (API) that allows the separation of the frontend from the backend. Finally, the proposed model provides a framework in which to study multidimensional databases and opens several new research problems.	ICDE	database
4766	ICDE	Data Warehousing: Dealing with the Growing Pains.	Robert Armstrong	1997	A data warehouse provides a customer with information to run and plan their business. It is true that if the data warehouse can not quickly adapt to changes in the environment then the company will lose the advantage that information provides. A warehouse must be built with a solid foundation that is flexible and responsive to business changes. The purpose of this paper is to share experiences in the area of managing the growth within the data warehouse. There are many technical issues that need to be addressed as the data warehouse grows in multiple dimensions. The ideas in this paper should enable you to provide the correct foundation for a long term warehouse. Very few companies are discussing these issues and the lack of discussion leads to a lack of knowledge that will further lead to poor architectural choices. This paper will articulate not only the benefits that are derived from data warehousing today but how to prepare to reap benefits for many tomorrow s. It will also explore the questions to ask, the points to make, and the issues to be addressed to have a long term successful data warehouse project.	ICDE	database
4767	ICDE	An Argument in Favour of Presumed Commit Protocol.	Yousef J. Al-Houmaily,Panos K. Chrysanthis,Steven P. Levitan	1997	We argue in favor of the presumed commit protocol by proposing two new presumed commit variants that significantly reduce the cost of logging activities associated with the original presumed commit protocol. Furthermore, for read-only transactions, we apply our unsolicited update-vote optimization and show that the cost associated with this type of transactions is the same in both presumed commit and presumed abort protocols, thus, nullifying the basis for the argument that favors the presumed abort protocol. This is especially important for modern distributed environments which are characterized by high reliability and high probability of transactions being committed rather than aborted.	ICDE	database
4768	ICDE	Performance Evaluation of Rule Semantics in Active Databases.	Elena Baralis,Andrea Bianco	1997	Different rule execution semantics may be available in the same active database system. We performe several simulation experiments to evaluate the performance trade-offs yielded by different execution semantics in various operating conditions. In particular, we evaluate the effect of executing transaction and rule statements that affect a varying number of data instances, and applications with different rule triggering breadth and depth. Since references to data changed by the database operation triggering the rules are commonly used in active rule programming, we also analyze the impact of its management on overall performance.	ICDE	database
4769	ICDE	Pinwheel Scheduling for Fault-Tolerant Broadcast Disks in Real-time Database Systems.	Sanjoy K. Baruah,Azer Bestavros	1997	Abstract The design of programs for broadcast disks which incorporate real-time and fault-tolerance requirements is considered. A generalized model for real-time fault-tolerant broadcast disks is defined. It is shown that designing programs for broadcast disks specified in this model is closely related to the scheduling of pinwheel task systems. Some new results in pinwheel scheduling theory are derived, which facilitate the efficient generation of real-time fault-tolerant broadcast disk programs.	ICDE	database
4770	ICDE	Tools to Enable Interoperation of Heterogeneous Databases.	Wernher Behrendt,N. J. Fiddian,Ajith P. Madurapperuma	1997	We demonstrate a prototype toolkit called ITSE (Integrated Translation Support Environment), for interoperation and migration of heterogeneous database systems. The main objective of ITSE is to enable transparency in heterogeneous database environments. Therefore, tools have been developed to support flexible configuration of databases and the wrapping or migrating of legacy systems in intranets. The tools themselves are aimed at MDBMS administrators and MIS analysts. These users can tailor the toolkit's operation so that end users are shielded from the underlying heterogeneity of their information system.	ICDE	database
4771	ICDE	ODB-QOPTIMIZER: A Tool for Semantic Query Optimization in OODB.	Sonia Bergamaschi,Domenico Beneventano,Claudio Sartori,Maurizio Vincini	1997	ODB-QOptimizer is a ODMG 93 compliant tool for the schema validation and semantic query optimization. The approach is based on two fundamental ingredients. The first one is the OCDL description logics (DLs) proposed as a common formalism to express class descriptions, a relevant set of integrity constraints rules (IC rules) and queries. The second one are DLs inference techniques, exploited to evaluate the logical implications expressed by IC rules and thus to produce the semantic expansion of a given query.	ICDE	database
4772	ICDE	Title, General Chairs' Message, Program Chairs' Message, Committees, Reviewers, Author Index.		1997	Title, General Chairs' Message, Program Chairs' Message, Committees, Reviewers, Author Index.	ICDE	database
4773	ICDE	Titan: A High-Performance Remote Sensing Database.	Chialin Chang,Bongki Moon,Anurag Acharya,Carter Shock,Alan Sussman,Joel H. Saltz	1997	There are two major challenges for a high performance remote sensing database. First, it must provide low latency retrieval of very large volumes of spatio temporal data. This requires effective declustering and placement of a multidimensional dataset onto a large disk farm. Second, the order of magnitude reduction in data size due to post processing makes it imperative, from a performance perspective, that the post processing be done on the machine that holds the data. This requires careful coordination of computation and data retrieval. The paper describes the design, implementation and evaluation of Titan, a parallel shared nothing database designed for handling remote sensing data. The computational platform for Titan is a 16 processor IBM SP-2 with four fast disks attached to each processor. Titan is currently operational and contains about 24 GB of AVHRR data from the NOAA-7 satellite. The experimental results show that Titan provides good performance for global queries and interactive response times for local queries.	ICDE	database
4774	ICDE	On Incremental Cache Coherency Schemes in Mobile Computing Environments.	Jun Cai,Kian-Lee Tan,Beng Chin Ooi	1997	Re-examines the cache coherency problem in a mobile computing environment in the context of relational operations (i.e. selection, projection and join). We propose a taxonomy of cache coherency schemes, and as case studies, we pick several schemes for further study. These schemes are novel in several ways. First, they are incremental. Second, they are an integration of (and built on) techniques in view maintenance in centralized systems and cache invalidation in client-server computing environments. We conducted extensive studies based on a simulation model. Our study shows the effectiveness of these algorithms in reducing uplink transmission and average access times. Moreover, the class of algorithms that exploit collaboration between the client and server performs best in most cases. We also study extended versions of this class of algorithms to further cut down on the work performed by the server.	ICDE	database
4775	ICDE	A Generic Query-Translation Framework for a Mediator Architecture.	Jacques Calmet,Sebastian Jekutsch,Joachim Schü	1997	A mediator is a domain-specific tool to support uniform access to multiple heterogeneous information sources and to abstract and combine data from different but related databases to gain new information. This middleware product is urgently needed for these frequently occurring tasks in a decision support environment. In order to provide a front end, a mediator usually defines a new language. If an application or a user submits a question to the mediator, it has to be decomposed into several queries to the underlying information sources. Since these sources can only be accessed using their own query language, a query translator is needed. This paper presents a new approach for implementing query translators. It supports conjunctive queries as well as negation. Care is taken to enable information sources of which processing capabilities do not allow conjunctive queries in general. Rapid implementation is guided by reusing previously prepared code. The specification of the translator is done declaratively and domain--independent.	ICDE	database
4776	ICDE	Failure Handling for Transaction Hierarchies.	Qiming Chen,Umeshwar Dayal	1997	Previously, failure recovery mechanisms have been developed separately for nested transactions and for transactional workflows specified as flat flow graphs. The paper develops unified techniques for complex business processes modeled as cooperative transaction hierarchies. Multiple cooperative transaction hierarchies often have operational dependencies, thus a failure occurring in one transaction hierarchy may need to be transferred to another. The existing transaction models do not support failure handling across transaction hierarchies. The authors introduce the notion of transaction execution history tree which allows one to develop a unified hierarchical failure recovery mechanism applicable to both nested and flat transaction structures. They also develop a cross-hierarchy undo mechanism for determining failure scopes and supporting backward and forward failure recovery over multiple transaction hierarchies. These mechanisms form a structured and unified approach for handling failures in flat transactional workflows, along a transaction hierarchy, and across transaction hierarchies.	ICDE	database
4777	ICDE	Semantic Dictionary Design for Database Interoperability.	Silvana Castano,Valeria De Antonellis	1997	Criteria and techniques to support the establishment of a semantic dictionary for database interoperability are described. The techniques allow the analysis of conceptual schemas of databases in a federation and the definition and maintenance of concept hierarchies. Similarity-based criteria are used to evaluate concept closeness and, consequently, to generate concept hierarchies. Experimentation of the techniques in the public administration domain is discussed.	ICDE	database
4778	ICDE	New and Forgotten Dreams in Database Research (Panel).	Surajit Chaudhuri,Rakesh Agrawal,Klaus R. Dittrich,Andreas Reuter,Abraham Silberschatz,Gerhard Weikum	1997	New and Forgotten Dreams in Database Research (Panel).	ICDE	database
4779	ICDE	Subquery Elimination: A Complete Unnesting Algorithm for an Extended Relational Algebra.	Pedro Celis,Hansjörg Zeller	1997	Summary form only given, as follows. Research in the area of subquery unnesting algorithms has mostly focused on the problem of making queries more efficient at run-time by transforming subqueries into joins. Unnesting rules describe a transformation of a nested query tree or a nested SQL query into an equivalent tree or SQL query that is no longer nested. However, it is not possible to express all nested queries in a non-nested form, unless the used language (relational algebra or ISO/ANSI SQL) is extended. This means that a database system must continue to have the ability to process subqueries. When working on a new optimizer and executor design for NonStop SQL, our development team was faced with a slightly different problem: we wanted to eliminate the need for optimization and execution of nested queries altogether and were looking for a complete subquery unnesting process. Such a process would allow us to develop a query optimizer and executor that do not need to process subqueries. Our goal was to make use of the existing unnesting algorithms and to extend them in a way that does not necessarily improve or change the execution characteristics of nested queries, but that leads to complete unnesting of all forms of nested queries, as defined by the full level of the ISO/ANSI SQL92 standard. To indicate this different approach we call it subquery elimination rather than subquery unnesting.	ICDE	database
4780	ICDE	Developing and Accessing Scientific Databases with the OPM Data Management Tools.	I-Min A. Chen,Anthony Kosky,Victor M. Markowitz,Ernest Szeto	1997	Summary form only given. The Object-Protocol Model (OPM) data management tools provide facilities for rapid development, documentation, and flexible exploration of scientific databases. The tools are based on OPM, an object-oriented data model which is similar to the ODMG standard, but also supports extensions for modeling scientific data. Databases designed using OPM can be implemented using a variety of commercial relational DBMSs, using schema translation tools that generate complete DBMS database definitions from OPM schemas. Further, OPM schemas can be retrofitted on top of existing databases defined using a variety of notations, such as the relational data model or the ASN.1 data exchange format, using OPM retrofitting tools. Several archival molecular biology databases have been designed and implemented using the OPM tools, including the Genome Database (GDB) and the Protein Data Bank (PDB), while other scientific databases, such as the Genome Sequence Database (GSDB), have been retrofitted with semantically enhanced views using the OPM tools.	ICDE	database
4781	ICDE	The IDEA Tool Set.	Stefano Ceri,Piero Fraternali,Stefano Paraboschi	1997	The IDEA Tool Set.	ICDE	database
4782	ICDE	Data Mining: Where is it Heading? (Panel).	Jiawei Han	1997	Data mining is a promising field in which research and development activities are flourishing. It is also a young field with vast, unexplored territories. How can we contribute significantly to this fast expanding, multi-disciplinary field? This panel will bring database researchers together to share different views and insights on the issues in the field. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player	ICDE	database
4783	ICDE	Indexing OODB Instances based on Access Proximity.	Chee Yong Chan,Cheng Hian Goh,Beng Chin Ooi	1997	Queries in object-oriented databases (OODBs) may be asked with respect to different class scopes: a query may either request for object-instances which belong exclusively to a given class c, or those which belong to any class in the hierarchy rooted at c. To facilitate retrieval of objects both from a single class as well as from multiple classes in a class hierarchy, we propose a multi-dimensional class-hierarchy index called the /spl chi/-tree. The /spl chi/-tree dynamically partitions the data space using both the class and indexed attribute dimensions by taking into account the semantics of the class dimension as well as access patterns of queries. Experimental results show that it is an efficient index.	ICDE	database
4784	ICDE	Partial Video Sequence Caching Scheme for VOD Systems with Heterogeneous Clients.	Y. M. Chiu,K. H. Yeung	1997	Video on Demand is one of the key application in the information era. An hinge factor to its wide booming is the huge bandwidth required to transmit digitized video to a large group of clients with widely varying requirements. This paper addresses issues due to heterogeneous clients by proposing a program caching scheme called Partial Video Sequence (PVS) Caching Scheme. PVS Caching Scheme decomposes video sequences into a number of parts by using a scalable video compression algorithm. Video parts are selected to be cached in local video servers based on the amount of bandwidth it would be demanded from the distribution network and central video server if it is only kept in central video server. In this paper, we also show that PVS Caching Scheme is suitable for handling vastly varying client requirements.	ICDE	database
4785	ICDE	NAOS Protyotype - Version 2.2.	Christine Collet,Thierry Coupaye,Luc Fayolle,Claudia Roncancio	1997	Summary form only given. The Native Active Object System (NAOS) incorporates an active behavior within the object-oriented database management system O/sub 2/. NAOS rules are event-condition-action (EGA) rules belonging to an O/sub 2/ database schema. The authors focus on user and temporal event detection as well as composite event detection.	ICDE	database
4786	ICDE	Adaptive Broadcast Protocols to Support Power Conservant Retrieval by Mobile Users.	Anindya Datta,Aslihan Celik,Jeong G. Kim,Debra E. VanderMeer,Vijay Kumar	1997	Mobile computing has the potential for managing information globally. Data management issues in mobile computing have received some attention in recent times, and the design of adaptive broadcast protocols has been posed as an important problem. Such protocols are employed by database servers to decide on the content of broadcasts dynamically, in response to client mobility and demand patterns. In this paper we design such protocols and also propose efficient retrieval strategies that may be employed by clients to download information from broadcasts. The goal is to design cooperative strategies between server and client to provide access to information in such a way as to minimize energy expenditure by clients. We evaluate the performance of our protocols analytically.	ICDE	database
4787	ICDE	WOL: A Language for Database Transformations and Constraints.	Susan B. Davidson,Anthony Kosky	1997	The need to transform data between heterogeneous databases arises from a number of critical tasks in data management. These tasks are complicated by schema evolution in the underlying databases and by the presence of non-standard database constraints. We describe a declarative language called WOL (Well-founded Object Logic) for specifying such transformations, and its implementation in a system called Morphase (an enzyme for morphing data). WOL is designed to allow transformations between the complex data structures which arise in object-oriented databases as well as in complex relational databases, and to allow for reasoning about the interactions between database transformations and constraints.	ICDE	database
4788	ICDE	Media Asset Management: Managing Complex Data as a Re-Engineering Exercise.	Peter DeVries	1997	Building a media asset management application involves the storing, searching, and retrieving of complex data. How this data is managed can be viewed from two perspectives-in terms of the internal representation required to allow for high-speed searching and transferring of these items between systems, but also from the end-user perspective. This paper focuses on the perspective that media asset management is a re-engineering exercise whose fundamental goal is to eliminate the file system and its underlying classification model. The paper discusses the following topics: folder/director classification schemes; file system security; cross platform file transfers; traditional searching techniques and constraints; the data characteristics of a media asset management solution; an architectural mapping of elements required to manage complex data, including source, proxy, and metadata; a media asset management approach to classification including business semantics; content based search algorithms; and the feasibility of a database replacing the file system.	ICDE	database
4789	ICDE	ROCK & ROLL: A Deductive Object-Oriented Database with Active and Spatial Extensions.	Andrew Dinn,M. Howard Williams,Norman W. Paton	1997	ROCK & ROLL is a deductive object-oriented database system that supports two languages, one imperative and the other deductive, both derived from the same object-oriented data model. As the languages share a common type system, they can be integrated without manifesting impedance mismatches, and thus programmers can conveniently exploit both deductive and imperative features in a single application. The basic ROCK & ROLL system provides comprehensive modelling and programming facilities, but recent work has extended it with both active rules and spatial data types, thereby demonstrating how the core design is amenable to extensions in its behavioural and structural facilities.	ICDE	database
4790	ICDE	Object Related Plus: A Practical Tool for Developing Enhanced Object Databases.	Bryon K. Ehlmann,Gregory A. Riccardi	1997	Object Relater Plus is a practical tool currently being used for research and development of enhanced object databases (ODBs). The tool, which is a prototype Object Database Management System (ODBMS), provides two languages that are compatible with the ODMG-93 ODBMS standard yet enhance it in some significant ways. The Object Database Definition Language (ODDL) allows object relationships to be better defined and supported; provides for the specification and separation of external, conceptual, and internal views; and facilitates the implementation of domain specific ODB extensions. The Object Database Manipulation Language (ODML) augments ODDL by providing a C++ interface for database creation, access, and manipulation based on an ODDL specification. In this paper we give an overview of Object Relater Plus, emphasizing its salient features. We also briefly discuss its architecture and implementation and its use in developing scientific databases.	ICDE	database
4791	ICDE	System Design for Digital Media Asset Management.	Pamela D. Fisher	1997	Client-server computing is only now able to deliver genuine gains to broadcasters, publishers, creative agencies and production facilities. These new users are entering the distributed computing domain just as media object technologies and commercial broadband services emerge from infancy. This paper discusses the complex process of decision-making and system design for digital media asset management. The Cinebase Digital Media Management System is described and used to illustrate critical points. The digital media server architecture must accommodate extremely large datasets, scaleable content retrieval and rapid network query response. Cinebase installations are currently in place containing 100s of Terabytes of media content, and 100s of local and remote users. Cinebase has recently been ported to ObjectStore by Object Design Inc. (ODI). The presentation discusses how, in combination, the Cinebase application and ODI extensions can be used to deliver a complete object management environment for production-quality content. Examples of the new workflows, and the technical issues complex networks raise for database architecture, are also discussed.	ICDE	database
4792	ICDE	Quantifying Complexity and Performance Gains of Distributed Caching in a Wireless Mobile Computing Environment.	Cedric C. F. Fong,John C. S. Lui,Man Hon Wong	1997	In a mobile computing system, the wireless communication bandwidth is a scarce resource that needs to be managed carefully. In this paper, we investigate the use of distributed caching as an approach to reduce the wireless bandwidth consumption for data access. We find that conventional caching techniques cannot fully utilize the dissemination feature of the wireless channel. We thus propose a novel distributed caching protocol that can minimize the overall system bandwidth consumption at the cost of CPU processing time at the server side. This protocol allows the server to select data items into a broadcast set, based on a performance gain parameter called the bandwidth gain, and then send the broadcast set to all the mobile computers within the server's cell. We show that in general, this selection process is NP-hard, and therefore we propose a heuristic algorithm that can attain a near-optimal performance. We also propose an analytical model for the protocol and derive closed-form performance measures, such as the bandwidth utilization and the expected response time of data access by mobile computers. Experiments show that our distributed caching protocol can greatly reduce the bandwidth consumption so that the wireless network environment can accommodate more users and, at the same time, vastly improve the expected response time for data access by mobile computers.	ICDE	database
4793	ICDE	Teaching an OLTP Database Kernel Advanced Data Warehousing Techniques.	Clark D. French	1997	Most, if not all, of the major commercial database products available today were written more than 10 years ago. Their internal designs have always been heavily optimized for OLTP applications. Over the last couple of years as DSS and data warehousing have become more important, database companies have attempted to increase their performance with DSS-type applications. Most of their attempts have been in the form of added features like parallel table scans and simple bitmap indexing techniques. These were chosen because they could be quickly implemented (1-2 years), giving some level of increased query performance. The paper contends that the real performance gains for the DSS application have not yet been realized. The performance gains for DSS will not come from parallel table scans, but from major changes to the low level database storage management used by OLTP systems. One Sybase product, Sybase-IQ has pioneered some of these new techniques. The paper discusses a few of these techniques and how they could be integrated into an existing OLTP database kernel.	ICDE	database
4794	ICDE	FLORID: A Prototype for F-Logic.	Jürgen Frohn,Rainer Himmeröder,Paul-Thomas Kandzia,Georg Lausen,Christian Schlepphorst	1997	FLORID - F-LOgic Reasoning In Databases - is a deductive object-oriented database system incorporating F-logic as data definition and query language and combining the advantages of deductive databases with the rich modelling capabilities of object oriented concepts. F-logic provides complex objects, uniform handling of data and metadata, rule-defined class hierarchy and signatures, non-monotonic multiple inheritance, equating of objects by rules and variables ranging over methods and classes. Moreover, FLORID extends F-logic by path expressions to facilitate object navigation.	ICDE	database
4795	ICDE	Interfacing Parallel Applications and Parallel Databases.	Vibby Gottemukkala,Anant Jhingran,Sriram Padmanabhan	1997	The use of parallel database systems to deliver high performance has become quite common. Although queries submitted to these database systems are executed in parallel, the interaction between applications and current parallel database systems is serial. As the complexity of the applications and the amount of data they access increases, the need to parallelize applications also increases. In this parallel application environment, a serial interface to the database could become the bottleneck in the performance of the application. Hence, parallel database systems should support interfaces that allow the applications to interact with the database system in parallel. We present a taxonomy of such parallel interfaces, namely the Single Coordinator, Multiple Coordinator, Hybrid Parallel, and Pure Parallel interfaces. Furthermore, we discuss how each of these interfaces can be realized and in the process introduce new constructs that enable the implementation of the interfaces. We also qualitatively evaluate each of the interfaces with respect to their restrictiveness and performance impact.	ICDE	database
4796	ICDE	Semantic Query Optimization for Object Databases.	John Grant,Jarek Gryz,Jack Minker,Louiqa Raschid	1997	Semantic Query Optimization for Object Databases.	ICDE	database
4797	ICDE	Distributing Semantic Constraints Between Heterogeneous Databases.	Stefan Grufman,Fredrik Samson,Suzanne M. Embury,Peter M. D. Gray,Tore Risch	1997	In recent years, research on distributing databases over networks has become increasingly important. In this paper, we concentrate on the issues of the interoperability of heterogeneous DBMSs and enforcing integrity across a multi-database made in this fashion. This has been done through a cooperative project between Aberdeen and Linko/spl uml/ping universities, with database modules distributed between the sites. In the process, we have shown the advantage of using DBMSs based on variants of the functional data model (FDM), which has made it remarkably straightforward to interoperate queries and schema definitions. Further, we have used the constraint transformation facilities of P/FDM (Prolog implementation of FDM) to compile global constraints into active rules installed locally on one or more AMOS (Active Mediators Object System) servers. We present the theory behind this, and the conditions for it to improve performance.	ICDE	database
4798	ICDE	Index Selection for OLAP.	Himanshu Gupta,Venky Harinarayan,Anand Rajaraman,Jeffrey D. Ullman	1997	On-line analytical processing (OLAP) is a recent and important application of database systems. Typically, OLAP data is presented as a multidimensional data cube. OLAP queries are complex and can take many hours or even days to run, if executed directly on the raw data. The most common method of reducing execution time is to precompute some of the queries into summary tables (subcubes of the data cube) and then to build indexes on these summary tables. In most commercial OLAP systems today, the summary tables that are to be precomputed are picked first, followed by the selection of the appropriate indexes on them. A trial-and-error approach is used to divide the space available between the summary tables and the indexes. This two-step process can perform very poorly. Since both summary tables and indexes consume the same resource-space-their selection should be done together for the most efficient use of space. The authors give algorithms that automate the selection of summary tables and indexes. In particular, they present a family of algorithms of increasing time complexities, and prove strong performance bounds for them. The algorithms with higher complexities have better performance bounds. However, the increase in the performance bound is diminishing, and they show that an algorithm of moderate complexity can perform fairly close to the optimal.	ICDE	database
4799	ICDE	Oracle Parallel Warehouse Server.	Gary Hallmark	1997	Oracle is the leading supplier of data warehouse servers, yet little has been published about Oracle's parallel warehouse architecture. After a brief review of Oracle's market, performance, and platform strengths, we present two novel features of the Oracle parallel database architecture. First, the data flow model achieves scalability while using a fixed number of threads that is independent of the complexity of the query plan. Second, a new load shipping architecture combines the best aspects of data shipping and function shipping, and runs on shared everything, shared disk, and shared nothing hardware.	ICDE	database
4800	ICDE	Improving the Quality of Technical Data for Developing Case Based Reasoning Diagnostic Software for Aircraft Maintenance.	Richard Heider	1997	Summary form only given. Time spent by airline maintenance operators to solve engine failures and the related costs (flight delays or cancellations) are a major concern to SNECMA which manufacture engines for civilian aircraft such as BOEING 737s and Airbus A340s. The use of an intelligent diagnostic software contributes to improving customer support and reduces the cost of ownership by improving troubleshooting accuracy and reducing airplane downtime. However, classical rule based or model based expert systems are costly to develop and maintain. Our goal has been to improve the development of troubleshooting systems through case based reasoning (CBR) and data mining. These technologies reason from past cases, whose solution is known, rather than rules. New problems are solved by searching for similar problem solving experiences and by adapting the solutions that worked in the past, Our second objective was to acquire the capacity to produce systems which match the quality standard in the aeronautic industry in the given time frame. We aim at both assuring the quality of the core data mining and CBR software as well as the quality of the technical information that is fed into the system (case knowledge).	ICDE	database
4801	ICDE	The CORD Appraoch to Extensible Concurrency Control.	George T. Heineman,Gail E. Kaiser	1997	Database management systems (DBMSs) have been increasingly used for advanced application domains, such as software development environments, workflow management systems, computer-aided design and manufacturing, and managed healthcare. In these domains, the standard correctness model of serializability is often too restrictive. We introduce the notion of a Concurrency Control Language (CCL) that allows a database application designer to specify concurrency control policies to tailor the behavior of a transaction manager. A well-crafted set of policies defines an extended transaction model. The necessary semantic information required by the CCL run-time engine is extracted from a task manager, a (logical) module by definition included in all advanced applications. This module stores task models that encode the semantic information about the transactions submitted to the DBMS. We have designed a rule-based CCL, called CORD, and have implemented a run-time engine that can be hooked to a conventional transaction manager to implement the sophisticated concurrency control required by advanced database applications. We present an architecture for systems based on CORD and describe how we integrated the CORD engine with the Exodus Storage Manager to implement Altruistic Locking.	ICDE	database
4802	ICDE	Integrated Query Processing Strategies for Spatial Path Queries.	Yun-Wu Huang,Ning Jing,Elke A. Rundensteiner	1997	We investigate optimization strategies for processing path queries with embedded spatial constraints, such as avoiding areas with certain characteristics. To resolve complex spatial constraints during path finding, we consider two decisions: (1) the spatial relation operations (e.g., intersect) between areas and links can be preprocessed or intermixed with path finding and (2) areas satisfying the query constraint can be prefiltered or dynamically selected during path finding. Based on these two decisions, we propose and implement the resulting four integrated query processing strategies, utilizing state-of-the-art technologies such as spatial joins for intersect computation, R-tree access structure for spatial overlap search, and spatial clustering for efficient path search. In this paper, we also report an experimental evaluation to show which strategies perform best in different scenarios.	ICDE	database
4803	ICDE	Scalable Versioning in Distributed Databases with Commuting Updates.	H. V. Jagadish,Inderpal Singh Mumick,Michael Rabinovich	1997	We present a multiversioning scheme for a distributed system with the workload consisting of read-only transactions and update transactions, (most of) which commute on individual nodes. The scheme introduces a version advancement protocol that is completely asynchronous with user transactions, thus allowing the system to scale to very high transaction rates and frequent version advancements. Moreover, the scheme never creates more than three copies of a data item. Combined with existing techniques to avoid global concurrency control for commuting transactions that execute in a particular version, our multiversioning scheme results in a protocol where no user transaction on a node can be delayed by any activity (either version advancement or another transaction) occurring on another node. Non-commuting transactions are gracefully handled. Our technique is of particular value to distributed recording systems where guaranteeing global serializability is often desirable, but rarely used because of the high performance cost of running distributed transactions. Examples include calls on a telephone network, inventory management in a point-of-sale'' system, operations monitoring systems in automated factories, and medical information management systems.	ICDE	database
4804	ICDE	A Persistent Hyper-Programming System.	Graham N. C. Kirby,Ronald Morrison,David S. Munro,Richard C. H. Connor,Quintin I. Cutts	1997	We demonstrate the use of a hyper-programming system in building persistent applications. This allows program representations to contain type-safe links to persistent objects embedded directly within the source code. The benefits include improved efficiency and potential for static program checking, reduced programming effort and the ability to display meaningful source-level representations for first-class procedure values. Hyper-programming represents a completely new style of programming which is only possible in a persistent programming system.	ICDE	database
4805	ICDE	A Priority Ceiling Protocol with Dynamic Adjustment of Serialization Order.	Kwok-Wa Lam,Sang Hyuk Son,Sheung-lun Hung	1997	The difficulties of providing a guarantee of meeting transaction deadlines in hard real-time database systems lie in the problems of priority inversion and of deadlocks. Priority inversion and deadlock problems ensue when concurrency control protocols are adapted in priority-driven scheduling. The blocking delay due to priority inversion can be unbounded, which is unacceptable in the mission-critical real-time applications. Some priority ceiling protocols have been proposed to tackle these two problems. However, they are too conservative in scheduling transactions for the single-blocking and deadlock-free properties, leading to many unnecessary transaction blockings. In this paper, we analyze the unnecessary transaction blocking problem inherent in these priority ceiling protocols and investigate the conditions for allowing a higher priority transaction to preempt a lower priority transaction using the notion of dynamic adjustment of serialization order. A new priority ceiling protocol is proposed to solve the unnecessary blocking problem, thus enhancing schedulability. We also devise the worst-case schedulability analysis for the new protocol which provides a better schedulability condition than other protocols.	ICDE	database
4806	ICDE	Physical Database Design for Data Warehouses.	Wilburt Labio,Dallan Quass,Brad Adelberg	1997	Data warehouses collect copies of information from remote sources into a single database. Since the remote data is cached at the warehouse, it appears as local relations to the users of the warehouse. To improve query response time, the warehouse administrator will often materialize views defined on the local relations to support common or complicated queries. Unfortunately, the requirement to keep the views consistent with the local relations creates additional overhead when the remote sources change. The warehouse is often kept only loosely consistent with the sources: it is periodically refreshed with changes sent from the source. When this happens, the warehouse is taken off-line until the local relations and materialized views can be updated. Clearly, the users would prefer as little down time as possible. Often the down time can be reduced by adding carefully selected materialized views or indexes to the physical schema. This paper studies how to select the sets of supporting views and of indexes to materialize to minimize the down time. We call this the view index selection (VIS) problem. We present an A* search based solution to the problem as well as rules of thumb. We also perform additional experiments to understand the space-time tradeoff as it applies to data warehouses.	ICDE	database
4807	ICDE	Modeling Business Rules with Situation/Activation Diagrams.	Peter Lang,Werner Obermair,Michael Schrefl	1997	Business rules are statements about business policies and can be formulated according to the event-condition-action structure of rules in active database systems. However, modeling business rules at the conceptual level from an external user's perspective requires a different set of concepts than currently provided by active database systems. This paper identifies requirements on the event language and on the semantics of rule execution for modeling business rules and presents a graphical object-oriented language, called Situation/Activation diagrams, meeting these requirements.	ICDE	database
4808	ICDE	W3QS - A System for WWW Querying.	David Konopnicki,Oded Shmueli	1997	W3QL is a, SQL-like, high level language for accessing World-Wide Web (WWW) resident data and services. W3QL is declarative. A W3QL query specifies a graph to be matched with portions of the WWW (graph nodes corresponding to WWW pages, edges to hypertext links). A query can specify complex conditions on nodes' contents and their relationships. A W3QL query may use existing search services (e.g. AltaVista). W3QL is extensible as users may use their own data analysis tools (e.g. image analysis). W3QS is a system that manages W3QS queries. W3QS is accessible via the WWW or by using a programming based interface (API). On the WWW, W3QS provides several interfaces: intuitive graphic interfaces, templates of frequently posed queries, and direct programming.	ICDE	database
4809	ICDE	A Propagation Mechanism for Populated Schema Versions.	Sven-Eric Lautemann	1997	Object-oriented database systems (OODBMS) offer powerful modeling concepts as required by advanced application domains like CAD/CAM/CAE or office automation. Typical applications have to handle large and complex structured objects which frequently change their value and their structure. As the structure is described in the schema of the database, support for schema evolution is a highly required feature. Therefore, a set of schema update primitives must be provided which can be used to perform the required changes, even in the presence of populated databases and running applications. In this paper, we use the versioning approach to schema evolution to support schema updates as a complex design task. The presented propagation mechanism is based on conversion functions that map objects between different types and can be used to support schema evolution and schema integration.	ICDE	database
4810	ICDE	Clustering Association Rules.	Brian Lent,Arun N. Swami,Jennifer Widom	1997	The authors consider the problem of clustering two-dimensional association rules in large databases. They present a geometric-based algorithm, BitOp, for performing the clustering, embedded within an association rule clustering system, ARCS. Association rule clustering is useful when the user desires to segment the data. They measure the quality of the segmentation generated by ARCS using the minimum description length (MDL) principle of encoding the clusters on several databases including noise and errors. Scale-up experiments show that ARCS, using the BitOp algorithm, scales linearly with the amount of data.	ICDE	database
4811	ICDE	Buffer and I/O Resource Pre-allocation for Implementing Batching and Buffering Techniques for Video-on-Demand Systems.	M. Y. Y. Leung,John C. S. Lui,Leana Golubchik	1997	To design a cost effective VOD server, it is important to carefully manage the system resources so that the number of concurrent viewers can be maximized. Previous research results use data sharing techniques, such as batching, buffering and piggybacking, to reduce the demand for I/O resources in a VOD system. However, these techniques still suffer from the problem that additional I/O resources are needed in the system for providing VCR functionality --- without careful resource management, the benefits of these data sharing techniques can be lost. In this paper, we first introduce a model for determining the amount of resources required for supporting both normal playback and VCR functionality to satisfy predefined performance characteristics. Consequently, this model allows us to maximize the benefits of data sharing techniques. Furthermore, one important application of this model is its use in making system sizing decisions. Proper system sizing will result in a more cost-effective VOD system.	ICDE	database
4812	ICDE	STR: A Simple and Efficient Algorithm for R-Tree Packing.	Scott T. Leutenegger,J. M. Edgington,Mario A. Lopez	1997	In this paper we present the results from an extensive comparison study of three R-tree packing algorithms, including a new easy to implement algorithm. The algorithms are evaluated using both synthetic and actual data from various application domains including VLSI design, GIS (tiger), and computational fluid dynamics. Our studies also consider the impact that various degrees of buffering have on query performance. Experimental results indicate that none of the algorithms is best for all types of data. In general, our new algorithm requires up to 50\% fewer disk accesses than the best previously proposed algorithm for point and region queries on uniformly distributed or mildly skewed point and region data, and approximately the same for highly skewed point and region data.	ICDE	database
4813	ICDE	Delegation: Efficiently Rewriting History.	Cris Pedregal Martin,Krithi Ramamritham	1997	Transaction delegation, as introduced in ACTA, allows a transaction to transfer responsibility for the operations that it has performed on an object to another transaction. Delegation can be used to broaden the visibility of the delegatee, and to tailor the recovery properties of a transaction model. Delegation has been shown to be useful in synthesizing advanced transaction models. With an efficient implementation of delegation it becomes practicable to realize various advanced transaction models whose requirements are specified at a high level language instead of the current expensive practice of building them from scratch. The authors identify the issues in efficiently supporting delegation and hence advanced transaction models, and illustrate this with our solution in ARIES, an industrial-quality system that uses UNDO/REDO recovery. Since delegation is tantamount to rewriting history, a naive implementation can entail frequent, costly log accesses, and can result in complicated recovery protocols. The algorithm achieves the effect of rewriting history without rewriting the log, resulting in an implementation that realizes the semantics of delegation at minimal additional overhead and incurs no overhead when delegation is not used. The work indicates that it is feasible to build efficient and robust, general-purpose machinery for advanced transaction models. It is also a step towards making recovery a first-class concept within advanced transaction models.	ICDE	database
4814	ICDE	The Multikey Type Index for Persistent Object Sets.	Thomas A. Mück,Martin L. Polaschek	1997	Multikey index structures for type hierarchies are a recently discussed alternative to traditional B/sup +/-tree indexing schemes. We describe an efficient implementation of this alternative called the multikey type index (MT-index). A prerequisite for our approach is an optimal linearization of the type hierarchy that allows us to map queries in object type hierarchies to minimal-volume range queries in multi-attribute search structures. This provides access to an already-existing large and versatile tool-box. The outline of an index implementation by means of a multi-attribute search structure (e.g. the hB-tree or any other structure with comparable performance) is followed by an analytical performance evaluation. Selected performance figures are compared to previous approaches, in particular to the H-tree and the class hierarchy tree. The comparison results allow for practically relevant conclusions with respect to index selection based on query profiles.	ICDE	database
4815	ICDE	Relational Joins for Data on Tertiary Storage.	Jussi Myllymaki,Miron Livny	1997	Despite the steady decrease in secondary storage prices, the data storage requirements of many organizations cannot be met economically using secondary storage alone. Tertiary storage offers a lower-cost alternative but is viewed as a second-class citizen in many systems. For instance, the typical solution in bringing tertiary-resident data under the control of a DBMS is to use operating system facilities to copy the data to secondary storage, and then to perform query optimization and execution as if the data had been in secondary storage all along. This approach fails to recognize the opportunities for saving execution time and storage space if the data were accessed directly on tertiary devices and in parallel with other I/Os. In this paper we explore how to join two DBMS relations stored on magnetic tapes. Both relations are assumed to be larger than available disk space. We show how Grace Hash Join can be modified to handle a range of tape relation sizes. The modified algorithms access data directly on tapes and exploit parallelism between disk and tape I/Os. We also provide performance results of an experimental implementation of the algorithms.	ICDE	database
4816	ICDE	Active Customization of GIS User Interfaces.	Juliano Lopes de Oliveira,Claudia Bauzer Medeiros,Mariano Cilia	1997	This paper presents a new approach to user interface customization in Geographic Information Systems (GIS). This approach is based on the integration of three main components: a GIS user interface architecture; an active database mechanism; and a generic interface builder. The GIS interface architecture provides the default interface behavior, while the active system allows customization of interfaces according to the specific context. The generic interface builder relies on a library of interface objects to dynamically construct generic and customized interfaces. The main advantage of this approach is that it decreases the costs associated with developing customized \gis\ interfaces.	ICDE	database
4817	ICDE	Representative Objects: Concise Representations of Semistructured, Hierarchial Data.	Svetlozar Nestorov,Jeffrey D. Ullman,Janet L. Wiener,Sudarshan S. Chawathe	1997	Introduces the concept of representative objects, which uncover the inherent schema(s) in semi-structured, hierarchical data sources and provide a concise description of the structure of the data. Semi-structured data, unlike data stored in typical relational or object-oriented databases, does not have a fixed schema that is known in advance and stored separately from the data. With the rapid growth of the World Wide Web, semi-structured hierarchical data sources are becoming widely available to the casual user. The lack of external schema information currently makes browsing and querying these data sources inefficient at best, and impossible at worst. We show how representative objects make schema discovery efficient and facilitate the generation of meaningful queries over the data.	ICDE	database
4818	ICDE	Databases and the Web: What's in it for Databases? (Panel).	Erich J. Neuhold,Karl Aberer	1997	Databases and the Web: What's in it for Databases? (Panel).	ICDE	database
4819	ICDE	Periodic Retrieval of Videos from Disk Arrays.	Banu Özden,Rajeev Rastogi,Abraham Silberschatz	1997	A growing number of applications need access to video data stored in digital form on secondary storage devices (e.g., video-on-demand, multimedia messaging). As a result, video servers that are responsible for the storage and retrieval, at fixed rates, of hundreds of videos from disks are becoming increasingly important. Since video data tends to be voluminous, several disks are usually used in order to store the videos. A challenge is to devise schemes for the storage and retrieval of videos that distribute the workload evenly across disks, reduce the cost of the server and at the same time, provide good response times to client requests for video data. In this paper, we present schemes that retrieve videos periodically from disks in order to provide better response times to client requests. We present two schemes that stripe videos across multiple disks in order to distribute the workload uniformly among them. For the two striping schemes, we show that the problem of retrieving videos periodically is equivalent to that of scheduling periodic tasks on a multiprocessor. For the multiprocessor scheduling problems, we present and compare schemes for computing start times for the tasks, if it is determined that they are scheduleable.	ICDE	database
4820	ICDE	Adding Full Text Indexing to the Operating System.	Kyle Peltonen	1997	Many challenges must be faced when incorporating full text retrieval into the operating system. The search engine must be a nearly invisible, natural extension to the operating system, just like the file system and the network. The search engine must meet user expectations of an operating system, specifically in areas such as performance, fault tolerance, and security. It must handle a very heterogeneous collection of documents, in many formats, many languages and many styles. The search engine must scale with the operating system, from small laptop computers to large multiprocessor servers. The paper is an overview of the challenges faced when incorporating full text indexing into the Microsoft Windows NT/sup TM/ operating system. Specific solutions used by the Microsoft 'Tripoli' search engine, are offered.	ICDE	database
4821	ICDE	A Rule Engine for Query Transformation in Starburst and IBM DB2 C/S DBMS.	Hamid Pirahesh,T. Y. Cliff Leung,Waqar Hasan	1997	The complexity of queries in relational DBMSs is increasing, particularly in the decision support area and interactive client sewer environments. This calls for a more powerful and flexible optimization of complex queries. H. Pirahesh et al. (1992) introduced query rewrite as a distinct query optimization phase mainly targeted to responding to this requirement. This approach has enabled us to extensively enrich the optimization rules in our system. Further, it has made it easier to incrementally enrich and adapt the system as need arises. Examples of such query optimizations are predicate pushdown, subquery and magic sets transformations, and decorrelating subquery. We describe the design and implementation of a rule engine for query rewrite optimization. Each transformation is implemented as a rule which consists of a pair of rule condition and action. Rules can be grouped into rule classes for higher efficiency, better understandability and more extensibility. The rule engine has a number of novelties in that it supports a full spectrum of control-from totally data driven to totally procedural. Furthermore, it incorporates a budget control scheme for controlling the resources taken for query optimization as well as guaranteeing the termination of rule execution. The rule engine and a suite of query rewrite rules have been implemented in Starburst relational DBMS prototype and a significant portion of this technology has been integrated into IBM DB2 Common Server relational DBMS.	ICDE	database
4822	ICDE	High-Dimensional Similarity Joins.	Kyuseok Shim,Ramakrishnan Srikant,Rakesh Agrawal	1997	Many emerging data mining applications require a similarity join between points in a high-dimensional domain. We present a new algorithm that utilizes a new index structure, called the $\epsilon$ tree, for fast spatial similarity joins on high-dimensional points. This index structure reduces the number of neighboring leaf nodes that are considered for the join test, as well as the traversal cost of finding appropriate branches in the internal nodes. The storage cost for internal nodes is independent of the number of dimensions. Hence, the proposed index structure scales to high-dimensional data. We analyze the cost of the join for the $\epsilon$ tree and the R-tree family, and show that the $\epsilon$ tree will perform better for high-dimensional joins. Empirical evaluation, using synthetic and real-life data sets, shows that similarity join using the $\epsilon$ tree is twice to an order of magnitude faster than the $R^+$ tree, with the performance gap increasing with the number of dimensions. We also discuss how some of the ideas of the $\epsilon$ tree can be applied to the R-tree family. These biased R-trees perform better than the corresponding traditional R-trees for high-dimensional similarity joins, but do not match the performance of the $\epsilon$ tree.	ICDE	database
4823	ICDE	A Cost-Model-Based Online Method for Ditributed Caching.	Markus Sinnwell,Gerhard Weikum	1997	The paper presents a method for distributed caching to exploit the aggregate memory of networks of workstations in data-intensive applications. In contrast to prior work, the approach is based on a detailed cost model as the basis for optimizing the placement of variable-size data objects in a distributed, possibly heterogeneous two-level storage hierarchy. To address the online problem with a priori unknown and evolving workload parameters, the method employs dynamic load tracking procedures and an approximative, low-overhead version of the cost model for continuous reoptimization steps that are embedded in the decisions of the underlying local cache managers. The method is able to automatically find a good tradeoff between an egoistic and an altruistic behavior of the network nodes, and proves its practical viability in a detailed simulation study under a variety of workload and system configurations.	ICDE	database
4824	ICDE	Modeling and Querying Moving Objects.	A. Prasad Sistla,Ouri Wolfson,Sam Chamberlain,Son Dao	1997	In this paper we propose a data model for representing moving objects in database systems. It is called the Moving Objects Spatio-Temporal (MOST) data model. We also propose Future Temporal Logic (FTL) as the query language for the MOST model, and devise an algorithm for processing FTL queries in MOST.	ICDE	database
4825	ICDE	Similarity Based Retrieval of Videos.	A. Prasad Sistla,Clement T. Yu,R. Venkatasubrahmanian	1997	Similarity Based Retrieval of Videos.	ICDE	database
4826	ICDE	Designing the Reengineering Services for the DOK Federated Database System.	Zahir Tari,John Stokes	1997	Addresses the design of the reengineering service for the DOK (Distributed Object Kernel) federated database. This service allows the hiding of the heterogeneity of databases involved in a federation by generating object-oriented representations from their corresponding schemata. We propose a complete methodology that supports the identification and the translation of both the explicit and implicit information. The identification of object-oriented constructs is performed by classifying a relational schema into different categories of relations, namely base, dependent and composite relations. The main difficulty in designing the reengineering service relies on the distinction between the different types of relationships amongst classes. Our approach deals with this problem by analysing relations according two types of correlation: (i) the degree of correlation between the external and primary keys, and (ii) the degree of correlation between sets of tuples in the relations. Examining these correlations uncovers implicit relationships contained as well-hidden classes in a relational schema.	ICDE	database
4827	ICDE	Graphical Tools for Rule Development in the Active DBMS SAMOS.	Anca Vaduva,Stella Gatziu,Klaus R. Dittrich	1997	Summary form only given. Active database management systems (active DBMS) support the definition, management and execution of event/condition/action rules specifying reactive application behavior. Although the advantages of active mechanisms are nowadays well known, there is still no wide use in practice. One main problem is that especially for large rule sets, defined by different persons at different points in time, potential conflicts and dependencies between rules are hard to predict and rule behavior is difficult to control. Therefore, tools are needed to assist the development and maintenance of rule bases. These tools should provide for graphical interfaces supporting both, static activities (performed during rule specification) such as rule editing, browsing, design, rule analysis, and dynamic activities (performed at runtime, during the execution of an application) such as testing, debugging and understanding of rule behavior. The aim of the article is to show the use of three of these tools, namely the rule editor, the browser and the termination analyzer in the process of developing applications for the active object oriented DBMS SAMOS.	ICDE	database
4828	ICDE	Memory Management for Scalable Web Data Servers.	Shivakumar Venkataraman,Miron Livny,Jeffrey F. Naughton	1997	Popular web sites are already experiencing very heavy loads, and these loads will only increase as the number of users accessing them grows. These loads create both CPU and I/O bottlenecks. One promising solution already being employed to eliminate the CPU bottleneck is to replace a single processor server with a cluster of servers. Our goal in this paper is to develop buffer management algorithms that exploit the aggregate memory capacity of the machines in such a server cluster to attack the I/O bottleneck. The key challenge in designing such buffer management algorithms turns out to be controlling data replication so as to achieve a good balance between intra-cluster network traffic and disk I/O. At one extreme, the straightforward application of client-server memory management techniques to this cluster architecture causes duplication in memory among the servers and this tends to reduce network traffic but increases disk I/O, whereas at the other extreme, eliminating all duplicates tends to increase network traffic while reducing disk I/O. Accordingly, we present a new algorithm, Hybrid, that dynamically controls the amount of duplication. Through a detailed simulation, we show that on workloads characteristic of those experienced by Web servers, the Hybrid algorithm correctly trades off intra-cluster network traffic and disk I/O to minimize average response time.	ICDE	database
4829	ICDE	Data Integration and Interrogation.	J. Verso	1997	Summary form only given. One major concern of the Verso group at Inria is the development of technology for data integration and interrogation, especially for non traditional data formats such as structured text. The article describes aspects of Verso's technology as partly sponsored by the European Community (AQUARELLE project, Esprit IV projects OPAL and WIRE).	ICDE	database
4830	ICDE	The WHIPS Prototype for Data Warehouse Creation and Maintenance.	Janet L. Wiener,Himanshu Gupta,Wilburt Labio,Yue Zhuge,Hector Garcia-Molina	1997	Summary form only given. The goal of the Whips project (WareHousing Information Project at Stanford) is to develop algorithms and tools for the creation and maintenance of a data warehouse (J. Wiener et al., 1996). In particular, we have developed an architecture and implemented a prototype for identifying data changes at distributed heterogeneous sources, transforming them and summarizing them in accordance with warehouse specifications, and incrementally integrating them into the warehouse. In effect, the warehouse stores materialized views of the source data. The Whips architecture is designed specifically to fulfil several important and interrelated goals: sources and warehouse views can be added and removed dynamically; it is scalable by adding more internal modules; changes at the sources are detected automatically; the warehouse may be updated continuously as the sources change, without requiring down time; and the warehouse is always kept consistent with the source data by the integration algorithms. The Whips system is composed of many distinct modules that potentially reside on different machines. Each module is implemented as a CORBA object. They communicate with each other using ILU, a COBRA compliant object library developed by Xerox PARC.	ICDE	database
4831	ICDE	A Data Model and Semantics of Objects with Dynamic Roles.	Raymond K. Wong,H. Lewis Chau,Frederick H. Lochovsky	1997	Although the concept of roles is becoming a popular research issue in object-oriented databases and has been proven to be useful for dynamic and evolving applications, it has only been described conceptually in most of the previous work. Moreover, the important issues such as the semantics of roles (e.g., message passing) are seldom discussed. Furthermore, none of the previous work has investigated the idea of role player qualification, which models the fact that not every object is qualified to play a particular role. In this paper, we present a data model and the semantics of roles. We discuss each of the above issues and illustrate the ideas with examples. From these examples, we can easily see that the problems we discussed are fundamental and indeed exist in many complex applications.	ICDE	database
4832	ICDE	Supporting Fine-grained Data Lineage in a Database Visualization Environment.	Allison Woodruff,Michael Stonebraker	1997	The lineage of a datum records its processing history. Because such information can be used to trace the source of anomalies and errors in processed data sets, it is valuable to users for a variety of applications, including the investigation of anomalies and debugging. Traditional data lineage approaches rely on metadata. However, metadata does not scale well to fine-grained lineage, especially in large data sets. For example, it is not feasible to store all of the information that is necessary to trace from a specific floating-point value in a processed data set to a particular satellite image pixel in a source data set. In this paper, we propose a novel method to support fine-grained data lineage. Rather than relying on metadata, our approach lazily computes the lineage using a limited amount of information about the processing operators and the base data. We introduce the notions of weak inversion and verification. While our system does not perfectly invert the data, it uses weak inversion and verification to provide a number of guarantees about the lineage it generates. We propose a design for the implementation of weak inversion and verification in an object-relational database management system.	ICDE	database
4833	ICDE	Selectivity Estimation in the Presence of Alphanumeric Correlations.	Min Wang,Jeffrey Scott Vitter,Balakrishna R. Iyer	1997	Query optimization is an integral part of relational database management systems. One important task in query optimization is selectivity estimation, that is, given a query P, we need to estimate the fraction of records in the database that satisfy P. Almost all previous work dealt with the estimation of numeric selectivity, i.e., the query contains only numeric variables. The general problem of estimating alphanumeric selectivity is much more difficult and has attracted attention only very recently, and the focus has been on the special case when only one column is involved. In this paper, we consider the more general case when there are two correlated alphanumeric columns. We develop efficient algorithms to build storage structures that can fit in a database catalog. Results from our extensive experiments to test our algorithms, on the basis of error analysis and space requirements, are given to guide DBMS implementors.	ICDE	database
4834	ICDE	Content is King, (If You Can Find It): A New Model for Knowledge Storage and Retrieval.	Fred L. Wurden	1997	The technology for acquiring and storing vast amounts of complex data is accelerating at a much faster rate than the technology for retrieving and analyzing that data. While progress has been made with OODB, OLAP, and knowledge discovery (KD) systems, users of these systems are still required to know and supply missing semantic information. When dealing with complex real-world representations, this is often nearly impossible to do. We discuss a new model that provides significant improvements in storing, correlating, and navigating information. We first provide a brief background looking at other relevant knowledge representation approaches, then describe our patented Contiguous Connection Model. Finally we discuss the impact this technology has had on a large, high-value, digital media knowledge base.	ICDE	database
4835	ICDE	Multiple View Consistency for Data Warehousing.	Yue Zhuge,Hector Garcia-Molina,Janet L. Wiener	1997	A data warehouse stores integrated information from multiple distributed data sources. In effect, the warehouse stores materialized views over the source data. The problem of ensuring data consistency at the warehouse can be divided into two components: ensuring that each view reflects a consistent state of the base data, and ensuring that multiple views are mutually consistent. In this paper we study the latter problem, that of guaranteeing multiple view consistency (MVC). We identify and define formally three layers of consistency for materialized views in a distributed environment. We present a scalable architecture for consistently handling multiple views in a data warehouse, which we have implemented in the WHIPS(WareHousing Information Project at Stanford) prototype. Finally, we develop simple, scalable, algorithms for achieving MVC at a warehouse.	ICDE	database
4836	SIGMOD Conference	MDM: a Multiple-Data-Model Tool for the Management of Heterogeneous Database Schemes.	Paolo Atzeni,Riccardo Torlone	1997	MDM is a tool that enables the users to define schemes of different data models and to perform translations of schemes from one model to another. These functionalities can be at the basis of a customizable and integrated CASE environment supporting the analysis and design of information systems. MDM has two main components: the Model Manager and the Schema Manager. The Model Manager supports a specialized user, the model engineer, in the definition of a variety of models, on the basis of a limited set of metaconstructs covering almost all known conceptual models. The Schema Manager allows designers to create and modify schemes over the defined models, and to generate at each time a translation of a scheme into any of the data models currently available. Translations between models are automatically derived, at definition time, by combining a predefined set of elementary transformations, which implement the standard translations between simple combinations of constructs.	SIGMOD Conferen	database
4837	SIGMOD Conference	The STRIP Rule System For Efficiently Maintaining Derived Data.	Brad Adelberg,Hector Garcia-Molina,Jennifer Widom	1997	Derived data is maintained in a database system to correlate and summarize base data which records real world facts. As base data changes, derived data needs to be recomputed. This is often implemented by writing active rules that are triggered by changes to base data. In a system with rapidly changing base data, a database with a standard rule system may consume most of its resources running rules to recompute data. This paper presents the rule system implemented as part of the STandard Real-time Information Processor (STRIP). The STRIP rule system is an extension of SQL3-type rules that allows groups of rule actions to be batched together to reduce the total recomputation load on the system. In this paper we describe the syntax and semantics of the STRIP rule system, present an example set of rules to maintain stock index and theoretical option prices in a program trading application, and report the results of experiments performed on the running system. The experiments verify that STRIP's rules allow much more efficient derived data maintenance than conventional rules without batching.	SIGMOD Conferen	database
4838	SIGMOD Conference	Balancing Push and Pull for Data Broadcast.	Swarup Acharya,Michael J. Franklin,Stanley B. Zdonik	1997	The increasing ability to interconnect computers through internet-working, wireless networks, high-bandwidth satellite, and cable networks has spawned a new class of information-centered applications based on data dissemination. These applications employ broadcast to deliver data to very large client populations. We have proposed the Broadcast Disks paradigm [Zdon94, Acha95b] for organizing the contents of a data broadcast program and for managing client resources in response to such a program. Our previous work on Broadcast Disks focused exclusively on the &ldquo;push-based&rdquo; approach, where data is sent out on the broadcast channel according to a periodic schedule, in anticipation of client requests. In this paper, we study how to augment the push-only model with a &ldquo;pull-based&rdquo; approach of using a backchannel to allow clients to send explicit requests for data to the server. We analyze the scalability and performance of a broadcast-based system that integrates push and pull and study the impact of this integration on both the steady state and warm-up performance of clients. Our results show that a client backchannel can provide significant performance improvement in the broadcast environment, but that unconstrained use of the backchannel can result in scalability problems due to server saturation. We propose and investigate a set of three techniques that can delay the onset of saturation and thus, enhance the performance and scalability of the system.	SIGMOD Conferen	database
4839	SIGMOD Conference	Efficient View Maintenance at Data Warehouses.	Divyakant Agrawal,Amr El Abbadi,Ambuj K. Singh,Tolga Yurek	1997	We present incremental view maintenance algorithms for a data warehouse derived from multiple distributed autonomous data sources. We begin with a detailed framework for analyzing view maintenance algorithms for multiple data sources with concurrent updates. Earlier approaches for view maintenance in the presence of concurrent updates typically require two types of messages: one to compute the view change due to the initial update and the other to compensate the view change due to interfering concurrent updates. The algorithms developed in this paper instead perform the compensation locally by using the information that is already available at the data warehouse. The first algorithm, termed SWEEP, ensures complete consistency of the view at the data warehouse in the presence of concurrent updates. Previous algorithms for incremental view maintenance either required a quiescent state at the data warehouse or required an exponential number of messages in terms of the data sources. In contrast, this algorithm does not require that the data warehouse be in a quiescent state for incorporating the new views and also the message complexity is linear in the number of data sources. The second algorithm, termed Nested SWEEP, attempts to compute a composite view change for multiple updates that occur concurrently while maintaining strong consistency.	SIGMOD Conferen	database
4840	SIGMOD Conference	Fast Parallel Similarity Search in Multimedia Databases.	Stefan Berchtold,Christian Böhm,Bernhard Braunmüller,Daniel A. Keim,Hans-Peter Kriegel	1997	Most similarity search techniques map the data objects into some high-dimensional feature space. The similarity search then corresponds to a nearest-neighbor search in the feature space which is computationally very intensive. In this paper, we present a new parallel method for fast nearest-neighbor search in high-dimensional feature spaces. The core problem of designing a parallel nearest-neighbor algorithm is to find an adequate distribution of the data onto the disks. Unfortunately, the known declustering methods to not perform well for high-dimensional nearest-neighbor search. In contrast, our method has been optimized based on the special properties of high-dimensional spaces and therefore provides a near-optimal distribution of the data items among the disks. The basic idea of our data declustering technique is to assign the buckets corresponding to different quadrants of the data space to different disks. We show that our technique - in contrast to other declustering methods - guarantees that all buckets corresponding to neighboring quadrants are assigned to different disks. We evaluate our method using large amounts of real data (up to 40 MBytes) and compare it with the best known data declustering method, the Hilbert curve. Our experiments show that our method provides an almost linear speed-up and a constant scale-up. Additionally, it outperforms the Hilbert approach by a factor of up to 5.	SIGMOD Conferen	database
4841	SIGMOD Conference	S3: Similarity Search in CAD Database Systems.	Stefan Berchtold,Hans-Peter Kriegel	1997	S3 is the prototype of a database system supporting the management and similarity retrieval of industrial CAD parts. The major goal of the system is to reduce the cost for developing and producing new parts by maximizing the reuse of existing parts. S3 supports the following three types of similarity queries: query by example (of an existing part in the database), query by sketch and thematic similarity query. S3 is an object-oriented system offering an adequate graphical user interface. On top of providing various state-of-the-art algorithms and index structures for geometry-based similarity retrieval, it is an excellent testbed for developing and testing new similarity algorithms and index structures.	SIGMOD Conferen	database
4842	SIGMOD Conference	High-Performance Sorting on Networks of Workstations.	Andrea C. Arpaci-Dusseau,Remzi H. Arpaci-Dusseau,David E. Culler,Joseph M. Hellerstein,David A. Patterson	1997	We report the performance of NOW-Sort, a collection of sorting implementations on a Network of Workstations (NOW). We find that parallel sorting on a NOW is competitive to sorting on the large-scale SMPs that have traditionally held the performance records. On a 64-node cluster, we sort 6.0 GB in just under one minute, while a 32-node cluster finishes the Datamation benchmark in 2.41 seconds. Our implementations can be applied to a variety of disk, memory, and processor configurations; we highlight salient issues for tuning each component of the system. We evaluate the use of commodity operating systems and hardware for parallel sorting. We find existing OS primitives for memory management and file access adequate. Due to aggregate communication and disk bandwidth requirements, the bottleneck of our system is the workstation I/O bus.	SIGMOD Conferen	database
4843	SIGMOD Conference	InfoSleuth: Semantic Integration of Information in Open and Dynamic Environments (Experience Paper).	Roberto J. Bayardo Jr.,William Bohrer,Richard S. Brice,Andrzej Cichocki,Jerry Fowler,Abdelsalam Helal,Vipul Kashyap,Tomasz Ksiezyk,Gale Martin,Marian H. Nodine,Mosfeq Rashid,Marek Rusinkiewicz,Ray Shea,C. Unnikrishnan,Amy Unruh,Darrell Woelk	1997	InfoSleuth: Semantic Integration of Information in Open and Dynamic Environments (Experience Paper).	SIGMOD Conferen	database
4844	SIGMOD Conference	The InfoSleuth Project.	Roberto J. Bayardo Jr.,William Bohrer,Richard S. Brice,Andrzej Cichocki,Jerry Fowler,Abdelsalam Helal,Vipul Kashyap,Tomasz Ksiezyk,Gale Martin,Marian H. Nodine,Mosfeq Rashid,Marek Rusinkiewicz,Ray Shea,C. Unnikrishnan,Amy Unruh,Darrell Woelk	1997	The InfoSleuth Project.	SIGMOD Conferen	database
4845	SIGMOD Conference	Distance-Based Indexing for High-Dimensional Metric Spaces.	Tolga Bozkaya,Z. Meral Özsoyoglu	1997	Distance-Based Indexing for High-Dimensional Metric Spaces.	SIGMOD Conferen	database
4846	SIGMOD Conference	The COntext INterchange Mediator Prototype.	Stéphane Bressan,Cheng Hian Goh,Kofi Fynn,Marta Jessica Jakobisiak,Karim Hussein,Henry B. Kon,Thomas Lee,Stuart E. Madnick,Tito Pena,Jessica Qu,Annie W. Shum,Michael Siegel	1997	The Context Interchange strategy presents a novel approach for mediated data access in which semantic conflicts among heterogeneous systems are not identified a priori, but are detected and reconciled by a context mediator through comparison of contexts. This paper reports on the implementation of a Context Interchange Prototype which provides a concrete demonstration of the features and benefits of this integration strategy.	SIGMOD Conferen	database
4847	SIGMOD Conference	Beyond Market Baskets: Generalizing Association Rules to Correlations.	Sergey Brin,Rajeev Motwani,Craig Silverstein	1997	One of the most well-studied problems in data mining is mining for association rules in market basket data. Association rules, whose significance is measured via support and confidence, are intended to identify rules of the type, &ldquo;A customer purchasing item A often also purchases item B.&rdquo; Motivated by the goal of generalizing beyond market baskets and the association rules used with them, we develop the notion of mining rules that identify correlations (generalizing associations), and we consider both the absence and presence of items as a basis for generating rules. We propose measuring significance of associations via the chi-squared test for correlation from classical statistics. This leads to a measure that is upward closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between correlated and uncorrelated itemsets in the lattice. We develop pruning strategies and devise an efficient algorithm for the resulting problem. We demonstrate its effectiveness by testing it on census data and finding term dependence in a corpus of text documents, as well as on synthetic data.	SIGMOD Conferen	database
4848	SIGMOD Conference	Dynamic Itemset Counting and Implication Rules for Market Basket Data.	Sergey Brin,Rajeev Motwani,Jeffrey D. Ullman,Shalom Tsur	1997	We consider the problem of analyzing market-basket data and present several important contributions. First, we present a new algorithm for finding large itemsets which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling. We investigate the idea of item reordering, which can improve the low-level efficiency of the algorithm. Second, we present a new way of generating &ldquo;implication rules,&rdquo; which are normalized based on both the antecedent and the consequent and are truly implications (not simply a measure of co-occurrence), and we show how they produce more intuitive results than other methods. Finally, we show how different characteristics of real data, as opposed by synthetic data, can dramatically affect the performance of the system and the form of the results.	SIGMOD Conferen	database
4849	SIGMOD Conference	The BUCKY Object-Relational Benchmark (Experience Paper).	Michael J. Carey,David J. DeWitt,Jeffrey F. Naughton,Mohammad Asgarian,Paul Brown,Johannes Gehrke,Dhaval Shah	1997	The BUCKY Object-Relational Benchmark (Experience Paper).	SIGMOD Conferen	database
4850	SIGMOD Conference	On Saying Enough Already! in SQL.	Michael J. Carey,Donald Kossmann	1997	On Saying Enough Already! in SQL.	SIGMOD Conferen	database
4851	SIGMOD Conference	Object-Relational Database Systems: Principles, Products, and Challenges (Tutorial).	Michael J. Carey,Nelson Mendonça Mattos,Anil Nori	1997	Object-Relational Database Systems: Principles, Products, and Challenges (Tutorial).	SIGMOD Conferen	database
4852	SIGMOD Conference	SENTINEL: An Object-Oriented DBMS With Event-Based Rules.	Sharma Chakravarthy	1997	SENTINEL: An Object-Oriented DBMS With Event-Based Rules.	SIGMOD Conferen	database
4853	SIGMOD Conference	Query Optimization at the Crossroads (Panel).	Surajit Chaudhuri	1997	Query Optimization at the Crossroads (Panel).	SIGMOD Conferen	database
4854	SIGMOD Conference	Data Warehousing and OLAP for Decision Support (Tutorial).	Surajit Chaudhuri,Umeshwar Dayal	1997	Data Warehousing and OLAP for Decision Support (Tutorial).	SIGMOD Conferen	database
4855	SIGMOD Conference	Meaningful Change Detection in Structured Data.	Sudarshan S. Chawathe,Hector Garcia-Molina	1997	Detecting changes by comparing data snapshots is an important requirement for difference queries, active databases, and version and configuration management. In this paper we focus on detecting meaningful changes in hierarchically structured data, such as nested-object data. This problem is much more challenging than the corresponding one for relational or flat-file data. In order to describe changes better, we base our work not just on the traditional &ldquo;atomic&rdquo; insert, delete, update operations, but also on operations that move an entire sub-tree of nodes, and that copy an entire sub-tree. These operations allows us to describe changes in a semantically more meaningful way. Since this change detection problem is NP-hard, in this paper we present a heuristic change detection algorithm that yields close to &ldquo;minimal&rdquo; descriptions of the changes, and that has fewer restrictions than previous algorithms. Our algorithm is based on transforming the change detection problem to a problem of computing a minimum-cost edge cover of a bipartite graph. We study the quality of the solution produced by our algorithm, as well as the running time, both analytically and experimentally.	SIGMOD Conferen	database
4856	SIGMOD Conference	Supporting Multiple View Maintenance Policies.	Latha S. Colby,Akira Kawaguchi,Daniel F. Lieuwen,Inderpal Singh Mumick,Kenneth A. Ross	1997	Materialized views and view maintenance are becoming increasingly important in practice. In order to satisfy different data currency and performance requirements, a number of view maintenance policies have been proposed. Immediate maintenance involves a potential refresh of the view after every update to the deriving tables. When staleness of views can be tolerated, a view may be refreshed periodically or (on-demand) when it is queried. The maintenance policies that are chosen for views have implications on the validity of the results of queries and affect the performance of queries and updates. In this paper, we investigate a number of issues related to supporting multiple views with different maintenance policies. We develop formal notions of consistency for views with different maintenance policies. We then introduce a model based on view groupings for view maintenance policy assignment, and provide algorithms, based on the viewgroup model, that allow consistency of views to be guaranteed. Next, we conduct a detailed study of the performance aspects of view maintenance policies based on an actual implementation of our model. The performance study investigates the trade-offs between different maintenance policy assignments. Our analysis of both the consistency and performance aspects of various view maintenance policies are important in making correct maintenance policy assignments.	SIGMOD Conferen	database
4857	SIGMOD Conference	Delaunay: A Database Visualization System.	Isabel F. Cruz,Michael Averbuch,Wendy T. Lucas,Melissa Radzyminski,Kirby Zhang	1997	Visual query systems have traditionally supported a set of pre-defined visual displays. We describe the Delaunay system, which supports visualizations of object-oriented databases specified by the user with a visual constraint-based query language. The highlights of our approach are the expressiveness of the visual query language, the efficiency of the query engine, and the overall flexibility and extensibility of the framework. The user interface is implemented using Java and is available on the WWW.	SIGMOD Conferen	database
4858	SIGMOD Conference	Database Performance in the Real World - TPC-D and SAP R/3 (Experience Paper).	Jochen Doppelhammer,Thomas Höppler,Alfons Kemper,Donald Kossmann	1997	Database Performance in the Real World - TPC-D and SAP R/3 (Experience Paper).	SIGMOD Conferen	database
4859	SIGMOD Conference	STRUDEL: A Web-site Management System.	Mary F. Fernández,Daniela Florescu,Jaewoo Kang,Alon Y. Levy,Dan Suciu	1997	STRUDEL: A Web-site Management System.	SIGMOD Conferen	database
4860	SIGMOD Conference	Picture Programming Project.	Nita Goyal,Charles Hoch,Ravi Krishnamurthy,Brian Meckler,Michael Suckow,Moshé M. Zloof	1997	Picture Programming Project.	SIGMOD Conferen	database
4861	SIGMOD Conference	STARTS: Stanford Proposal for Internet Meta-Searching (Experience Paper).	Luis Gravano,Kevin Chen-Chuan Chang,Hector Garcia-Molina,Andreas Paepcke	1997	STARTS: Stanford Proposal for Internet Meta-Searching (Experience Paper).	SIGMOD Conferen	database
4862	SIGMOD Conference	A Toolkit for Negotiation Support Interfaces to Multi-Dimensional Data.	Michael Gebhardt,Matthias Jarke,Stephan Jacobs	1997	CoDecide is an experimental user interface toolkit that offers an extension to spreadsheet concepts specifically geared towards support for cooperative analysis of the kinds of multi-dimensional data encountered in data warehousing. It is distinguished from previous proposals by direct support for drill-down/roll-up analysis without redesign of an interface; more importantly, CoDecide can link multiple views on a data cube for synchronous or asynchronoous cooperation by multiple analysts, through a conceptual model visualizing the problem dimensions on so-called tapes. Tapes generalize the ideas of ranging and pivoting in current data warehouses for the multi-perspective and multi-user case. CoDecide allows the rapid composition of multi-matrix interfaces and their linkage to underlying data sources. A LAN version of CoDecide has been used in a number of design decision support applications. A WWW version representing externally materialized views on databases is currently under development.	SIGMOD Conferen	database
4863	SIGMOD Conference	A Framework for Implementing Hypothetical Queries.	Timothy Griffin,Richard Hull	1997	Previous approaches to supporting hypothetical queries have been &ldquo;eager&rdquo;: some representation of the hypothetical state (or the corresponding delta) is materialized, and query evaluation is filtered through that representation. This paper develops a framework for evaluating hypothetical queries using a &ldquo;lazy&rdquo; approach, or using a hybrid of eager and lazy approaches. We focus on queries having the form &ldquo;Q when {{U}}&rdquo; where Q is a relational algebra query and U is an update expression. The value assigned to this query in state DB is the value that Q would return in the state resulting from executing U on DB. Nesting of the keyword when is permitted, and U may involve a sequence of several atomic updates. We present an equational theory for queries involving when that can be used as a basis for optimization. This theory is very different from traditional rules for the relational algebra, because the semantics of when is unlike the semantics of the algebra operators. Our theory is based on the observation that hypothetical states can be represented as substitutions, similar to those arising in functional and logic programming. Furthermore, hypothetical queries of the form Q when {{U}} can be thought of as representing the suspended application of a substitution. Using the equational theory we develop an approach to optimizing the evaluation of hypothetical queries that uses deltas in the sense of Heraclitus, and permits a range of evaluation strategies from lazy to eager.	SIGMOD Conferen	database
4864	SIGMOD Conference	Infomaster: An Information Integration System.	Michael R. Genesereth,Arthur M. Keller,Oliver M. Duschka	1997	Infomaster is an information integration system that provides integrated access to multiple distributed heterogeneous information sources on the Internet, thus giving the illusion of a centralized, homogeneous information system. We say that Infomaster creates a virtual data warehouse. The core of Infomaster is a facilitator that dynamically determines an efficient way to answer the user's query using as few sources as necessary and harmonizes the heterogeneities among these sources. Infomaster handles both structural and content translation to resolve differences between multiple data sources and the multiple applications for the collected data. Infomaster connects to a variety of databases using wrappers, such as for Z39.50, SQL databases through ODBC, EDI transactions, and other World Wide Web (WWW) sources. There are several WWW user interfaces to Infomaster, including forms based and textual. Infomaster also includes a programmatic interface and it can download results in structured form onto a client computer. Infomaster has been in production use for integrating rental housing advertisements from several newspapers (since fall 1995), and for meeting room scheduling (since winter 1996). Infomaster is also being used to integrate heterogeneous electronic product catalogs.	SIGMOD Conferen	database
4865	SIGMOD Conference	Secure Transaction Processing in Firm Real-Time Database Systems.	Binto George,Jayant R. Haritsa	1997	Many real-time database applications arise in safety-critical installations and military systems where enforcing security is crucial to the success of the enterprise. A secure real-time database system has to simultaneously satisfy who requirements guarantee data security and minimize the number of missed transaction deadlines. We investigate here the performance implications, in terms of missed deadlines, of guaranteeing security in a real-time database system. In particular, we focus on the concurrency control aspects of this issue. Our main contributions are the following: First, we identify which among the previously proposed real-time concurrency control protocols are capable of providing protection against both direct and indirect (covert channels) means of unauthorized access to data. Second, using a detailed simulation model of a firm-deadline real-time database system, we profile the real-time performance of a representative set of these secure concurrency control protocols. Our experiments show that a prioritized optimistic concurrency control protocol. OPT-WAIT, provides the best overall performance. Third, we propose and evaluate a novel dual approach to secure transaction concurrency control that allows the real-time database system to simultaneously use different concurrency control mechanisms for guaranteeing security and for improving real-time performance. By appropriately choosing these different mechanisms, we have been able to design hybrid concurrency control algorithms that provide even better performance than OPT-WAIT.	SIGMOD Conferen	database
4866	SIGMOD Conference	Languages for Multi-database Interoperability.	Frédéric Gingras,Laks V. S. Lakshmanan,Iyer N. Subramanian,Despina Papoulis,Nematollaah Shiri	1997	Languages for Multi-database Interoperability.	SIGMOD Conferen	database
4867	SIGMOD Conference	Revisiting Commit Processing in Distributed Database Systems.	Ramesh Gupta,Jayant R. Haritsa,Krithi Ramamritham	1997	A significant body of literature is available on distributed transaction commit protocols. Surprisingly, however, the relative merits of these protocols have not been studied with respect to their quantitative impact on transaction processing performance. In this paper, using a detailed simulation model of a distributed database system, we profile the transaction throughput performance of a representative set of commit protocols. A new commit protocol, OPT, that allows transactions to &ldquo;optimistically&rdquo; borrow uncommitted data in a controlled manner is also proposed and evaluated. The new protocol is easy to implement and incorporate in current systems, and can coexist with most other optimizations proposed earlier. For example, OPT can be combined with current industry standard protocols such as Presumed Commit and Presumed Abort. The experimental results show that distributed commit processing can have considerably more influence than distributed data processing on the throughput performance and that the choice of commit protocol clearly affects the magnitude of this influence. Among the protocols evaluated, the new optimistic commit protocol provides the best transaction throughput performance for a variety of workloads and system configurations. In fact, OPT's peak throughput is often close to the upper bound on achievable performance. Even more interestingly, a three-phase (i.e., non-blocking) version of OPT provides better peak throughput performance than all of the standard two-phase (i.e., blocking protocols evaluated in our study.	SIGMOD Conferen	database
4868	SIGMOD Conference	Template-Based Wrappers in the TSIMMIS System.	Joachim Hammer,Hector Garcia-Molina,Svetlozar Nestorov,Ramana Yerneni,Markus M. Breunig,Vasilis Vassalos	1997	In order to access information from a variety of heterogeneous information sources, one has to be able to translate queries and data from one data model into another. This functionality is provided by so-called (source) wrappers [4,8] which convert queries into one or more commands/queries understandable by the underlying source and transform the native results into a format understood by the application. As part of the TSIMMIS project [1, 6] we have developed hard-coded wrappers for a variety of sources (e.g., Sybase DBMS, WWW pages, etc.) including legacy systems (Folio). However, anyone who has built a wrapper before can attest that a lot of effort goes into developing and writing such a wrapper. In situations where it is important or desirable to gain access to new sources quickly, this is a major drawback. Furthermore, we have also observed that only a relatively small part of the code deals with the specific access details of the source. The rest of the code is either common among wrappers or implements query and data transformation that could be expressed in a high level, declarative fashion. Based on these observations, we have developed a wrapper implementation toolkit [7] for quickly building wrappers. The toolkit contains a library for commonly used functions, such as for receiving queries from the application and packaging results. It also contains a facility for translating queries into source-specific commands, and for translating results into a model useful to the application. The philosophy behind our &ldquo;template-based&rdquo; translation methodology is as follows. The wrapper implementor specifies a set of templates (rules) written in a high level declarative language that describe the queries accepted by the wrapper as well as the objects that it returns. If an application query matches a template, an implementor-provided action associated with the template is executed to provide the native query for the underlying source1. When the source returns the result of the query, the wrapper transforms the answer which is represented in the data model of the source into a representation that is used by the application. Using this toolkit one can quickly design a simple wrapper with a few templates that cover some of the desired functionality, probably the one that is most urgently needed. However, templates can be added gradually as more functionality is required later on. Another important use of wrappers is in extending the query capabilities of a source. For instance, some sources may not be capable of answering queries that have multiple predicates. In such cases, it is necessary to pose a native query to such a source using only predicates that the source is capable of handling. The rest of the predicates are automatically separated from the user query and form a filter query. When the wrapper receives the results, a post-processing engine applies the filter query. This engine supports a set of built-in predicates based on the comparison operators =,&ne;,<,>, etc. In addition, the engine supports more complex predicates that can be specified as part of the filter query. The postprocessing engine is common to wrappers of all sources and is part of the wrapper toolkit. Note that because of postprocessing, the wrapper can handle a much larger class of queries than those that exactly match the templates it has been given. Figure 1 shows an overview of the wrapper architecture as it is currently implemented in our TSIMMIS testbed. Shaded components are provided by the toolkit, the white component is source-specific and must be generated by the implementor. The driver component controls the translation process and invokes the following services: the parser which parses the templates, the native schema, as well as the incoming queries into internal data structures, the matcher which matches a query against the set of templates and creates a filter query for postprocessing if necessary, the native component which submits the generated action string to the source, and extracts the data from the native result using the information given in the source schema, and the engine, which transforms and packages the result and applies a postprocessing filter if one has been created by the matcher. We now describe the sequence of events that occur at the wrapper during the translation of a query and its result using an example from our prototype system. The queries are formulated using a rule-based language called MSL that has been developed as a template specification and query language for the TSIMMIS project. Data is represented using our Object Exchange Model (OEM). We will briefly describe MSL and OEM in the next section. Details on MSL can be found in [5], a full introduction to OEM is given in [1].	SIGMOD Conferen	database
4869	SIGMOD Conference	Scalable Parallel Data Mining for Association Rules.	Eui-Hong Han,George Karypis,Vipin Kumar	1997	In this paper, we propose two new parallel formulations of the Apriori algorithm that is used for computing association rules. These new formulations, IDD and HD, address the shortcomings of two previously proposed parallel formulations CD and DD. Unlike the CD algorithm, the IDD algorithm partitions the candidate set intelligently among processors to efficiently parallelize the step of building the hash tree. The IDD algorithm also eliminates the redundant work inherent in DD, and requires substantially smaller communication overhead than DD. But IDD suffers from the added cost due to communication of transactions among processors. HD is a hybrid algorithm that combines the advantages of CD and DD. Experimental results on a 128-processor Cray T3E show that HD scales just as well as the CD algorithm with respect to the number of transactions, and scales as well as IDD with respect to increasing candidate set size.	SIGMOD Conferen	database
4870	SIGMOD Conference	GeoMiner: A System Prototype for Spatial Data Mining.	Jiawei Han,Krzysztof Koperski,Nebojsa Stefanovic	1997	Spatial data mining is to mine high-level spatial information and knowledge from large spatial databases. A spatial data mining system prototype, GeoMiner, has been designed and developed based on our years of experience in the research and development of relational data mining system, DBMiner, and our research into spatial data mining. The data mining power of GeoMiner includes mining three kinds of rules: characteristic rules, comparison rules, and association rules, in geo-spatial databases, with a planned extension to include mining classification rules and clustering rules. The SAND (Spatial And Nonspatial Data) architecture is applied in the modeling of spatial databases, whereas GeoMiner includes the spatial data cube construction module, spatial on-line analytical processing (OLAP) module, and spatial data mining modules. A spatial data mining language, GMQL (Geo-Mining Query Language), is designed and implemented as an extension to Spatial SQL [3], for spatial data mining. Moreover, an interactive, user-friendly data mining interface is constructed and tools are implemented for visualization of discovered spatial knowledge.	SIGMOD Conferen	database
4871	SIGMOD Conference	Online Aggregation.	Joseph M. Hellerstein,Peter J. Haas,Helen J. Wang	1997	Aggregation in traditional database systems is performed in batch mode: a query is submitted, the system processes a large volume of data over a long period of time, and, eventually, the final answer is returned. This archaic approach is frustrating to users and has been abandoned in most other areas of computing. In this paper we propose a new online aggregation interface that permits users to both observe the progress of their aggregation queries and control execution on the fly. After outlining usability and performance requirements for a system supporting online aggregation, we present a suite of techniques that extend a database system to meet these requirements. These include methods for returning the output in random order, for providing control over the relative rate at which different aggregates are computed, and for computing running confidence intervals. Finally, we report on an initial implementation of online aggregation in POSTGRES.	SIGMOD Conferen	database
4872	SIGMOD Conference	Range Queries in OLAP Data Cubes.	Ching-Tien Ho,Rakesh Agrawal,Nimrod Megiddo,Ramakrishnan Srikant	1997	A range query applies an aggregation operation over all selected cells of an OLAP data cube where the selection is specified by providing ranges of values for numeric dimensions. We present fast algorithms for range queries for two types of aggregation operations: SUM and MAX. These two operations cover techniques required for most popular aggregation operations, such as those supported by SQL. For range-sum queries, the essential idea is to precompute some auxiliary information (prefix sums) that is used to answer ad hoc queries at run-time. By maintaining auxiliary information which is of the same size as the data cube, all range queries for a given cube can be answered in constant time, irrespective of the size of the sub-cube circumscribed by a query. Alternatively, one can keep auxiliary information which is 1/bd of the size of the d-dimensional data cube. Response to a range query may now require access to some cells of the data cube in addition to the access to the auxiliary information, but the overall time complexity is typically reduced significantly. We also discuss how the precomputed information is incrementally updated by batching updates to the data cube. Finally, we present algorithms for choosing the subset of the data cube dimensions for which the auxiliary information is computed and the blocking factor to use for each such subset. Our approach to answering range-max queries is based on precomputed max over balanced hierarchical tree structures. We use a branch-and-bound-like procedure to speed up the finding of max in a region. We also show that with a branch-and-bound procedure, the average-case complexity is much smaller than the worst-case complexity.	SIGMOD Conferen	database
4873	SIGMOD Conference	ZOO: A Desktop Emperiment Management Environment.	Yannis E. Ioannidis,Miron Livny,Anastassia Ailamaki,Anand Narayanan,Andrew Therber	1997	ZOO: A Desktop Emperiment Management Environment.	SIGMOD Conferen	database
4874	SIGMOD Conference	A Unified Framework for Enforcing Multiple Access Control Policies.	Sushil Jajodia,Pierangela Samarati,V. S. Subrahmanian,Elisa Bertino	1997	Although several access control policies can be devised for controlling access to information, all existing authorization models, and the corresponding enforcement mechanisms, are based on a specific policy (usually the closed policy). As a consequence, although different policy choices are possible in theory, in practice only a specific policy can be actually applied within a given system. However, protection requirements within a system can vary dramatically, and no single policy may simultaneously satisfy them all. In this paper we present a flexible authorization manager (FAM) that can enforce multiple access control policies within a single, unified system. FAM is based on a language through which users can specify authorizations and access control policies to be applied in controlling execution of specific actions on given objects. We formally define the language and properties required to hold on the security specifications and prove that this language can express all security specifications. Furthermore, we show that all programs expressed in this language (called FAM/CAM-programs) are also guaranteed to be consistent (i.e., no conflicting access decisions occur) and CAM-programs are complete (i.e., every access is either authorized or denied). We then illustrate how several well-known protection policies proposed in the literature can be expressed in the FAM/CAM language and how users can customize the access control by specifying their own policies. The result is an access control mechanism which is flexible, since different access control policies can all coexist in the same data system, and extensible, since it can be augmented with any new policy a specific application or user may require.	SIGMOD Conferen	database
4875	SIGMOD Conference	The SR-tree: An Index Structure for High-Dimensional Nearest Neighbor Queries.	Norio Katayama,Shin'ichi Satoh	1997	Recently, similarity queries on feature vectors have been widely used to perform content-based retrieval of images. To apply this technique to large databases, it is required to develop multidimensional index structures supporting nearest neighbor queries efficiently. The SS-tree had been proposed for this purpose and is known to outperform other index structures such as the R*-tree and the K-D-B-tree. One of its most important features is that it employs bounding spheres rather than bounding rectangles for the shape of regions. However, we demonstrate in this paper that bounding spheres occupy much larger volume than bounding rectangles with high-dimensional data and that this reduces search efficiency. To overcome this drawback, we propose a new index structure called the SR-tree (Sphere/Rectangle-tree) which integrates bounding spheres and bounding rectangles. A region of the SR-tree is specified by the intersection of a bounding sphere and a bounding rectangle. Incorporating bounding rectangles permits neighborhoods to be partitioned into smaller regions than the SS-tree and improves the disjointness among regions. This enhances the performance on nearest neighbor queries especially for high-dimensional and non-uniform data which can be practical in actual image/video similarity indexing. We include the performance test results the verify this advantage of the SR-tree and show that the SR-tree outperforms both the SS-tree and the R*-tree.	SIGMOD Conferen	database
4876	SIGMOD Conference	Efficiently Supporting Ad Hoc Queries in Large Datasets of Time Sequences.	Flip Korn,H. V. Jagadish,Christos Faloutsos	1997	Ad hoc querying is difficult on very large datasets, since it is usually not possible to have the entire dataset on disk. While compression can be used to decrease the size of the dataset, compressed data is notoriously difficult to index or access. In this paper we consider a very large dataset comprising multiple distinct time sequences. Each point in the sequence is a numerical value. We show how to compress such a dataset into a format that supports ad hoc querying, provided that a small error can be tolerated when the data is uncompressed. Experiments on large, real world datasets (AT&T customer calling patterns) show that the proposed method achieves an average of less than 5% error in any data value after compressing to a mere 2.5% of the original space (i.e., a 40:1 compression ratio), with these numbers not very sensitive to dataset size. Experiments on aggregate queries achieved a 0.5% reconstruction error with a space requirement under 2%.	SIGMOD Conferen	database
4877	SIGMOD Conference	Concurrency and Recovery in Generalized Search Trees.	Marcel Kornacker,C. Mohan,Joseph M. Hellerstein	1997	This paper presents general algorithms for concurrency control in tree-based access methods as well as a recovery protocol and a mechanism for ensuring repeatable read. The algorithms are developed in the context of the Generalized Search Tree (GiST) data structure, an index structure supporting an extensible set of queries and data types. Although developed in a GiST context, the algorithms are generally applicable to many tree-based access methods. The concurrency control protocol is based on an extension of the link technique originally developed for B-trees, and completely avoids holding node locks during I/Os. Repeatable read isolation is achieved with a novel combination of predicate locks and two-phase locking of data records. To our knowledge, this is the first time that isolation issues have been addressed outside the context of B-trees. A discussion of the fundamental structural differences between B-trees and more general tree structures like GiSTs explains why the algorithms developed here deviate from their B-tree counterparts. An implementation of GiSTs emulating B-trees in DB2/Common Server is underway.	SIGMOD Conferen	database
4878	SIGMOD Conference	Size Separation Spatial Join.	Nick Koudas,Kenneth C. Sevcik	1997	We introduce a new algorithm to compute the spatial join of two or more spatial data sets, when indexes are not available on them. Size Separation Spatial Join (S3J) imposes a hierarchical decomposition of the data space and, in contrast with previous approaches, requires no replication of entities from the input data sets. Thus its execution time depends only on the sizes of the joined data sets. We describe S3J and present an analytical evaluation of its I/O and processor requirements comparing them with those of previously proposed algorithms for the same problem. We show that S3J has relatively simple cost estimation formulas that can be exploited by a query optimizer. S3J can be efficiently implemented using software already present in many relational systems. In addition, we introduce Dynamic Spatial Bitmaps (DSB), a new technique that enables S3J to dynamically or statically exploit bitmap query processing techniques. Finally, we present experimental results for a prototype implementation of S3J involving real and synthetic data sets for a variety of data distributions. Our experimental results are consistent with our analytical observations and demonstrate the performance benefits of S3J over alternative approaches that have been proposed recently.	SIGMOD Conferen	database
4879	SIGMOD Conference	Databases on the Web: Technologies for Federation Architectures and Case Studies (Tutorial).	Ralf Kramer	1997	Databases on the Web: Technologies for Federation Architectures and Case Studies (Tutorial).	SIGMOD Conferen	database
4880	SIGMOD Conference	The WHIPS Prototype for Data Warehouse Creation and Maintenance.	Wilburt Labio,Yue Zhuge,Janet L. Wiener,Himanshu Gupta,Hector Garcia-Molina,Jennifer Widom	1997	A data warehouse is a repository of integrated information from distributed, autonomous, and possibly heterogeneous, sources. In effect, the warehouse stores one or more materialized views of the source data. The data is then readily available to user applications for querying and analysis. Figure 1 shows the basic architecture of a warehouse: data is collected from each source, integrated with data from other sources, and stored at the warehouse. Users then access the data directly from the warehouse. As suggested by Figure 1, there are two major components in a warehouse system: the integration component, responsible for collecting and maintaining the materialized views, and the query and analysis component, responsible for fulfilling the information needs of specific end users. Note that the two components are not independent. For example, which views the integration component materializes depends on the expected needs of end users. Most current commercial warehousing systems (e.g., Redbrick, Sybase, Arbor) focus on the query and analysis component, providing specialized index structures at the warehouse and extensive querying facilities for the end user. In the WHIPS (WareHousing Information Project at Stanford) project, on the other hand, we focus on the integration component. In particular, we have developed an architecture and implemented a prototype for identifying data changes at heterogeneous sources, transforming them and summarizing them in accordance to warehouse specifications, and incrementally integrating them into the warehouse. We propose to demonstrate our prototype at SIGMOD, illustrating the main features of our architecture. Our architecture is modular and we designed it specifically to fulfill several important and interrelated goals: data sources and warehouse views can be added and removed dynamically; it is scalable by adding more internal modules; changes at the sources are detected automatically; the warehouse may be updated continuously as the sources change, without requiring &ldquo;down time;&rdquo; and the warehouse is always kept consistent with the source data by the integration algorithms. More details on these goals and how we achieve them are provided in [WGL+96].	SIGMOD Conferen	database
4881	SIGMOD Conference	DEVise: Integrated Querying and Visualization of Large Datasets.	Miron Livny,Raghu Ramakrishnan,Kevin S. Beyer,Guangshun Chen,Donko Donjerkovic,Shilpa Lawande,Jussi Myllymaki,R. Kent Wenger	1997	DEVise: Integrated Querying and Visualization of Large Datasets.	SIGMOD Conferen	database
4882	SIGMOD Conference	SEMCOG: An Object-based Image Retrieval System and Its Visual Query Interface.	Wen-Syan Li,K. Selçuk Candan,Kyoji Hirata,Yoshinori Hara	1997	SEMCOG: An Object-based Image Retrieval System and Its Visual Query Interface.	SIGMOD Conferen	database
4883	SIGMOD Conference	DEVise: Integrated Querying and Visual Exploration of Large Datasets (Demo Abstract).	Miron Livny,Raghu Ramakrishnan,Kevin S. Beyer,Guangshun Chen,Donko Donjerkovic,Shilpa Lawande,Jussi Myllymaki,R. Kent Wenger	1997	DEVise: Integrated Querying and Visual Exploration of Large Datasets (Demo Abstract).	SIGMOD Conferen	database
4884	SIGMOD Conference	Partitioned Garbage Collection of Large Object Store.	Umesh Maheshwari,Barbara Liskov	1997	Partitioned Garbage Collection of Large Object Store.	SIGMOD Conferen	database
4885	SIGMOD Conference	Eliminating Costly Redundant Computations from SQL Trigger Executions.	François Llirbat,Françoise Fabret,Eric Simon	1997	Active database systems are now in widespread use. The use of triggers in these systems, however, is difficult because of the complex interaction between triggers, transactions, and application programs. Repeated calculations of rules may incur costly redundant computations in rule conditions and actions. In this paper, we focus on active relational database systems supporting SQL triggers. In this context, we provide a powerful and complete solution to eliminate redundant computations of SQL triggers when they are costly. We define a model to describe programs, rules and their interactions. We provide algorithms to extract invariant subqueries from trigger's condition and action. We define heuristics to memorize the most &ldquo;profitable&rdquo; invariants. Finally, we develop a rewriting technique that enables to generate and execute the optimized code of SQL triggers.	SIGMOD Conferen	database
4886	SIGMOD Conference	Temporal Aggregation in Active Database Rules.	Iakovos Motakis,Carlo Zaniolo	1997	An important feature of many advanced active database prototypes is support for rules triggered by complex patterns of events. Their composite event languages provide powerful primitives for event-based temporal reasoning. In fact, with one important exception, their expressive power matches and surpasses that of sophisticated languages offered by Time Series Management Systems (TSMS), which have been extensively used for temporal data analysis and knowledge discovery. This exception pertains to temporal aggregation, for which, current active database systems offer only minimal support, if any. In this paper, we introduce the language TREPL, which addresses this problem. The TREPL prototype, under development at UCLA, offers primitives for temporal aggregation that exceed the capabilities of state-of-the-art composite event languages, and are comparable to those of TSMS languages. TREPL also demonstrates a rigorous and general approach to the definition of composite event language semantics. The meaning of a TREPL rule is formally defined by mapping it into a set of Datalog1S rules, whose logic-based semantics characterizes the behavior of the original rule. This approach handles naturally temporal aggregates, including user-defined ones, and is also applicable to other composite event languages, such as ODE, Snoop and SAMOS.	SIGMOD Conferen	database
4887	SIGMOD Conference	Maintenance of Data Cubes and Summary Tables in a Warehouse.	Inderpal Singh Mumick,Dallan Quass,Barinderpal Singh Mumick	1997	Data warehouses contain large amounts of information, often collected from a variety of independent sources. Decision-support functions in a warehouse, such as on-line analytical processing (OLAP), involve hundreds of complex aggregate queries over large volumes of data. It is not feasible to compute these queries by scanning the data sets each time. Warehouse applications therefore build a large number of summary tables, or materialized aggregate views, to help them increase the system performance. As changes, most notably new transactional data, are collected at the data sources, all summary tables at the warehouse that depend upon this data need to be updated. Usually, source changes are loaded into the warehouse at regular intervals, usually once a day, in a batch window, and the warehouse is made unavailable for querying while it is updated. Since the number of summary tables that need to be maintained is often large, a critical issue for data warehousing is how to maintain the summary tables efficiently. In this paper we propose a method of maintaining aggregate views (the summary-delta table method), and use it to solve two problems in maintaining summary tables in a warehouse: (1) how to efficiently maintain a summary table while minimizing the batch window needed for maintenance, and (2) how to maintain a large set of summary tables defined over the same base tables. While several papers have addressed the issues relating to choosing and materializing a set of summary tables, this is the first paper to address maintaining summary tables efficiently.	SIGMOD Conferen	database
4888	SIGMOD Conference	Improved Query Performance with Variant Indexes.	Patrick E. O'Neil,Dallan Quass	1997	The read-mostly environment of data warehousing makes it possible to use more complex indexes to speed up queries than in situations where concurrent updates are present. The current paper presents a short review of current indexing technology, including row-set representation by Bitmaps, and then introduces two approaches we call Bit-Sliced indexing and Projection indexing. A Projection index materializes all values of a column in RID order, and a Bit-Sliced index essentially takes an orthogonal bit-by-bit view of the same data. While some of these concepts started with the MODEL 204 product, and both Bit-Sliced and Projection indexing are now fully realized in Sybase IQ, this is the first rigorous examination of such indexing capabilities in the literature. We compare algorithms that become feasible with these variant index types against algorithms using more conventional indexes. The analysis demonstrates important performance advantages for variant indexes in some types of SQL aggregation, predicate evaluation, and grouping. The paper concludes by introducing a new method whereby multi-dimensional group-by queries, reminiscent of OLAP/Datacube queries but with more flexibility, can be very efficiently performed.	SIGMOD Conferen	database
4889	SIGMOD Conference	On-Line Warehouse View Maintenance.	Dallan Quass,Jennifer Widom	1997	Data warehouses store materialized views over base data from external sources. Clients typically perform complex read-only queries on the views. The views are refreshed periodically by maintenance transactions, which propagate large batch updates from the base tables. In current warehousing systems, maintenance transactions usually are isolated from client read activity, limiting availability and/or size of the warehouse. We describe an algorithm called 2VNL that allows warehouse maintenance transactions to run concurrently with readers. By logically maintaining two versions of the database, no locking is required and serializability is guaranteed. We present our algorithm, explain its relationship to other multi-version concurrency control algorithms, and describe how it can be implemented on top of a conventional relational DBMS using a query rewrite approach.	SIGMOD Conferen	database
4890	SIGMOD Conference	Similarity-Based Queries for Time Series Data.	Davood Rafiei,Alberto O. Mendelzon	1997	We study a set of linear transformations on the Fourier series representation of a sequence that can be used as the basis for similarity queries on time-series data. We show that our set of transformations is rich enough to formulate operations such as moving average and time warping. We present a query processing algorithm that uses the underlying R-tree index of a multidimensional data set to answer similarity queries efficiently. Our experiments show that the performance of this algorithm is competitive to that of processing ordinary (exact match) queries using the index, and much faster than sequential scanning. We relate our transformations to the general framework for similarity queries of Jagadish et al.	SIGMOD Conferen	database
4891	SIGMOD Conference	Building a Scaleable Geo-Spatial DBMS: Technology, Implementation, and Evaluation.	Jignesh M. Patel,Jie-Bing Yu,Navin Kabra,Kristin Tufte,Biswadeep Nag,Josef Burger,Nancy E. Hall,Karthikeyan Ramasamy,Roger Lueder,Curt J. Ellmann,Jim Kupsch,Shelly Guo,David J. DeWitt,Jeffrey F. Naughton	1997	Building a Scaleable Geo-Spatial DBMS: Technology, Implementation, and Evaluation.	SIGMOD Conferen	database
4892	SIGMOD Conference	Cubetree: Organization of and Bulk Updates on the Data Cube.	Nick Roussopoulos,Yannis Kotidis,Mema Roussopoulos	1997	Cubetree: Organization of and Bulk Updates on the Data Cube.	SIGMOD Conferen	database
4893	SIGMOD Conference	PREDATOR: An OR-DBMS with Enhanced Data Types.	Praveen Seshadri,Mark Paskin	1997	PREDATOR: An OR-DBMS with Enhanced Data Types.	SIGMOD Conferen	database
4894	SIGMOD Conference	Lessons from Wall Street: Case Studies in Configuration, Tuning, and Distribution (Tutorial).	Dennis Shasha	1997	Lessons from Wall Street: Case Studies in Configuration, Tuning, and Distribution (Tutorial).	SIGMOD Conferen	database
4895	SIGMOD Conference	Wave-Indices: Indexing Evolving Databases.	Narayanan Shivakumar,Hector Garcia-Molina	1997	In many applications, new data is being generated every day. Often an index of the data of a past window of days is required to answer queries efficiently. For example, in a warehouse one may need an index on the sales records of the last week for efficient data mining, or in a Web service one may provide an index of Netnews articles of the past month. In this paper, we propose a variety of wave indices where the data of a new day can be efficiently added, and old data can be quickly expired, to maintain the required window. We compare these schemes based on several system performance measures, such as storage, query response time, and maintenance work, as well as on their simplicity and ease of coding.	SIGMOD Conferen	database
4896	SIGMOD Conference	The Distributed Information Search Component (Disco) and the World Wide Web.	Anthony Tomasic,Rémy Amouroux,Philippe Bonnet,Olga Kapitskaia,Hubert Naacke,Louiqa Raschid	1997	The Distributed Information Search COmponent (DISCO) is a prototype heterogeneous distributed database that accesses underlying data sources. The DISCO prototype currently focuses on three central research problems in the context of these systems. First, since the capabilities of each data source is different, transforming queries into subqueries on data source is difficult. We call this problem the weak data source problem. Second, since each data source performs operations in a generally unique way, the cost for performing an operation may vary radically from one wrapper to another. We call this problem the radical cost problem. Finally, existing systems behave rudely when attempting to access an unavailable data source. We call this problem the ungraceful failure problem. DISCO copes with these problems. For the weak data source problem, the database implementor defines precisely the capabilities of each data source. For the radical cost problem, the database implementor (optionally) defines cost information for some of the operations of a data source. The mediator uses this cost information to improve its cost model. To deal with ungraceful failures, queries return partial answers. A partial answer contains the part of the final answer to the query that was produced by the available data sources. The current working prototype of DISCO contains implementations of these solutions and operations over a collection of wrappers that access information both in files and on the World Wide Web.	SIGMOD Conferen	database
4897	SIGMOD Conference	Database Buffer Size Investigation for OLTP Workloads (Experience Paper).	Thin-Fong Tsuei,Allan Packer,Keng-Tai Ko	1997	Database Buffer Size Investigation for OLTP Workloads (Experience Paper).	SIGMOD Conferen	database
4898	SIGMOD Conference	Structural Matching and Discovery in Document Databases.	Jason Tsong-Li Wang,Dennis Shasha,George Jyh-Shian Chang,Liam Relihan,Kaizhong Zhang,Girish Patel	1997	Structural matching and discovery in documents such as SGML and HTML is important for data warehousing [6], version management [7, 11], hypertext authoring, digital libraries [4] and Internet databases. As an example, a user of the World Wide Web may be interested in knowing changes in an HTML document [2, 5, 10]. Such changes can be detected by comparing the old and new version of the document (referred to as structural matching of documents). As another example, in hypertext authoring, a user may wish to find the common portions in the history list of a document or in a database of documents (referred to as structural discovery of documents). In SIGMOD 95 demo sessions, we exhibited a software package, called TreeDiff [13], for comparing two latex documents and showing their differences. Given two documents, the tool represents the documents as ordered labeled trees and finds an optimal sequence of edit operations to transform one document (tree) to the other. An edit operation could be an insert, delete, or change of a node in the trees. The tool is so named because documents are represented and compared using approximate tree matching techniques [9, 12, 14].	SIGMOD Conferen	database
4899	SIGMOD Conference	The MENTOR Workbench for Enterprise-wide Workflow Management.	Dirk Wodtke,Jeanine Weißenfels,Gerhard Weikum,Angelika Kotz Dittrich,Peter Muth	1997	MENTOR (&ldquo;Middleware for Enterprise-Wide Workflow Management&rdquo;) is a joint project of the University of the Saarland, the Union Bank of Switzerland, and ETH Zurich [1, 2, 3]. The focus of the project is on enterprise-wide workflow management. Workflows in this category may span multiple organizational units each unit having its own workflow server, involve a variety of heterogeneous information systems, and require many thousands of clients to interact with the workflow management system (WFMS). The project aims to develop a scalable and highly available environment for the execution and monitoring of workflows, seamlessly integrated with a specification and verification environment. For the specification of workflows, MENTOR utilizes the formalism of state and activity charts. The mathematical rigor of the specification method establishes a basis for both correctness reasoning and for partitioning of a large workflow into a number of subworkflows according to the organizational responsibilities of the enterprise. For the distributed execution of the partitioned workflow specification, MENTOR relies mostly on standard middleware components and adds own components only where the standard components fall short of functionality or scalability. In particular, the run-time environment is based on a TP monitor and a CORBA implementation.	SIGMOD Conferen	database
4900	SIGMOD Conference	Association Rules over Interval Data.	Renée J. Miller,Yuping Yang	1997	We consider the problem of mining association rules over interval data (that is, ordered data for which the separation between data points has meaning). We show that the measures of what rules are most important (also called rule interest) that are used for mining nominal and ordinal data do not capture the semantics of interval data. In the presence of interval data, support and confidence are no longer intuitive measures of the interest of a rule. We propose a new definition of interest for association rules that takes into account the semantics of interval data. We developed an algorithm for mining association rules under the new definition and overview our experience using the algorithm on large real-life datasets.	SIGMOD Conferen	database
4901	SIGMOD Conference	Highly Concurrent Cache Consistency for Indices in Client-Server Database Systems.	Markos Zaharioudakis,Michael J. Carey	1997	In this paper, we present four approaches to providing highly concurrent B+-tree indices in the context of a data-shipping, client-server OODBMS architecture. The first performs all index operations at the server, while the other approaches support varying degrees of client caching and usage of index pages. We have implemented the four approaches, as well as the 2PL approach, in the context of the SHORE OODB system at Wisconsin, and we present experimental results from a performance study based on running SHORE on an IBM SP2 multicomputer. Our results emphasize the need for non-2PL approaches and demonstrate the tradeoffs between 2PL, no-caching, and the three caching alternatives.	SIGMOD Conferen	database
4902	SIGMOD Conference	An Array-Based Algorithm for Simultaneous Multidimensional Aggregates.	Yihong Zhao,Prasad Deshpande,Jeffrey F. Naughton	1997	Computing multiple related group-bys and aggregates is one of the core operations of On-Line Analytical Processing (OLAP) applications. Recently, Gray et al. [GBLP95] proposed the &ldquo;Cube&rdquo; operator, which computes group-by aggregations over all possible subsets of the specified dimensions. The rapid acceptance of the importance of this operator has led to a variant of the Cube being proposed for the SQL standard. Several efficient algorithms for Relational OLAP (ROLAP) have been developed to compute the Cube. However, to our knowledge there is nothing in the literature on how to compute the Cube for Multidimensional OLAP (MOLAP) systems, which store their data in sparse arrays rather than in tables. In this paper, we present a MOLAP algorithm to compute the Cube, and compare it to a leading ROLAP algorithm. The comparison between the two is interesting, since although they are computing the same function, one is value-based (the ROLAP algorithm) whereas the other is position-based (the MOLAP algorithm). Our tests show that, given appropriate compression techniques, the MOLAP algorithm is significantly faster than the ROLAP algorithm. In fact, the difference is so pronounced that this MOLAP algorithm may be useful for ROLAP systems as well as MOLAP systems, since in many cases, instead of cubing a table directly, it is faster to first convert the table to an array, cube the array, then convert the result back to a table.	SIGMOD Conferen	database
4903	VLDB	Distributed Processing over Stand-alone Systems and Applications.	Gustavo Alonso,Claus Hagen,Hans-Jörg Schek,Markus Tresch	1997	Distributed Processing over Stand-alone Systems and Applications.	VLDB	database
4904	VLDB	A One-Pass Algorithm for Accurately Estimating Quantiles for Disk-Resident Data.	Khaled Alsabti,Sanjay Ranka,Vineet Singh	1997	A One-Pass Algorithm for Accurately Estimating Quantiles for Disk-Resident Data.	VLDB	database
4905	VLDB	Garbage Collection in Object Oriented Databases Using Transactional Cyclic Reference Counting.	Srinivas Ashwin,Prasan Roy,S. Seshadri,Abraham Silberschatz,S. Sudarshan	1997	Garbage Collection in Object Oriented Databases Using Transactional Cyclic Reference Counting.	VLDB	database
4906	VLDB	To Weave the Web.	Paolo Atzeni,Giansalvatore Mecca,Paolo Merialdo	1997	To Weave the Web.	VLDB	database
4907	VLDB	Materialized Views Selection in a Multidimensional Database.	Elena Baralis,Stefano Paraboschi,Ernest Teniente	1997	Materialized Views Selection in a Multidimensional Database.	VLDB	database
4908	VLDB	The Microsoft Repository.	Philip A. Bernstein,Brian Harry,Paul Sanders,David Shutt,Jason Zander	1997	The Microsoft Repository.	VLDB	database
4909	VLDB	Geo/Environmental and Medical Data Management in the RasDaMan System.	Peter Baumann,Paula Furtado,Roland Ritsch,Norbert Widmann	1997	Geo/Environmental and Medical Data Management in the RasDaMan System.	VLDB	database
4910	VLDB	A Generic Approach to Bulk Loading Multidimensional Index Structures.	Jochen Van den Bercken,Bernhard Seeger,Peter Widmayer	1997	A Generic Approach to Bulk Loading Multidimensional Index Structures.	VLDB	database
4911	VLDB	Logical and Physical Versioning in Main Memory Databases.	Rajeev Rastogi,S. Seshadri,Philip Bohannon,Dennis W. Leinbaugh,Abraham Silberschatz,S. Sudarshan	1997	Logical and Physical Versioning in Main Memory Databases.	VLDB	database
4912	VLDB	Integrating Reliable Memory in Databases.	Wee Teck Ng,Peter M. Chen	1997	Recent results in the Rio project at the University of Michigan show that it is possible to create an area of main memory that is as safe as disk from operating system crashes. This paper explores how to integrate the reliable memory provided by the Rio file cache into a database system. Prior studies have analyzed the performance benefits of reliable memory; we focus instead on how different designs affect reliability. We propose three designs for integrating reliable memory into databases: non-persistent database buffer cache, persistent database buffer cache, and persistent database buffer cache with protection. Non-persistent buffer caches use an I/O interface to reliable memory and require the fewest modifications to existing databases. However, they waste memory capacity and bandwidth due to double buffering. Persistent buffer caches use a memory interface to reliable memory by mapping it into the database address space. This places reliable memory under complete database control and eliminates double buffering, but it may expose the buffer cache to database errors. Our third design reduces this exposure by write protecting the buffer pages. Extensive fault tests show that mapping reliable memory into the database address space does not significantly hurt reliability. This is because wild stores rarely touch dirty, committed pages written by previous transactions. As a result, we believe that databases should use a memory interface to reliable memory.	VLDB	database
4913	VLDB	The Oracle Universal Server Buffer.	William Bridge,Ashok Joshi,M. Keihl,Tirthankar Lahiri,Juan Loaiza,N. MacNaughton	1997	The Oracle Universal Server Buffer.	VLDB	database
4914	VLDB	Using Taxonomy, Discriminants, and Signatures for Navigating in Text Databases.	Soumen Chakrabarti,Byron Dom,Rakesh Agrawal,Prabhakar Raghavan	1997	Using Taxonomy, Discriminants, and Signatures for Navigating in Text Databases.	VLDB	database
4915	VLDB	Effective Memory Use in a Media Server.	Edward Y. Chang,Hector Garcia-Molina	1997	Effective Memory Use in a Media Server.	VLDB	database
4916	VLDB	Groupwise Processing of Relational Queries.	Damianos Chatziantoniou,Kenneth A. Ross	1997	Groupwise Processing of Relational Queries.	VLDB	database
4917	VLDB	Principles of Optimally Placing Data in Tertiary Storage Libraries.	Stavros Christodoulakis,Peter Triantafillou,Fenia Zioga	1997	Principles of Optimally Placing Data in Tertiary Storage Libraries.	VLDB	database
4918	VLDB	An Efficient Cost-Driven Index Selection Tool for Microsoft SQL Server.	Surajit Chaudhuri,Vivek R. Narasayya	1997	An Efficient Cost-Driven Index Selection Tool for Microsoft SQL Server.	VLDB	database
4919	VLDB	M-tree: An Efficient Access Method for Similarity Search in Metric Spaces.	Paolo Ciaccia,Marco Patella,Pavel Zezula	1997	M-tree: An Efficient Access Method for Similarity Search in Metric Spaces.	VLDB	database
4920	VLDB	Optimizing Queries with Universal Quantification in Object-Oriented and Object-Relational Databases.	Jens Claußen,Alfons Kemper,Guido Moerkotte,Klaus Peithner	1997	Optimizing Queries with Universal Quantification in Object-Oriented and Object-Relational Databases.	VLDB	database
4921	VLDB	Towards an ODMG-Compliant Visual Object Query Language.	Manoj Chavda,Peter T. Wood	1997	Towards an ODMG-Compliant Visual Object Query Language.	VLDB	database
4922	VLDB	Integrating SQL Databases with Content-Specific Search Engines.	Stefan Deßloch,Nelson Mendonça Mattos	1997	Integrating SQL Databases with Content-Specific Search Engines.	VLDB	database
4923	VLDB	Finding Data in the Neighborhood.	André Eickler,Alfons Kemper,Donald Kossmann	1997	Finding Data in the Neighborhood.	VLDB	database
4924	VLDB	Recovering Information from Summary Data.	Christos Faloutsos,H. V. Jagadish,Nikolaos Sidiropoulos	1997	Recovering Information from Summary Data.	VLDB	database
4925	VLDB	Resource Scheduling in Enhanced Pay-Per-View Continuous Media Databases.	Minos N. Garofalakis,Banu Özden,Abraham Silberschatz	1997	Resource Scheduling in Enhanced Pay-Per-View Continuous Media Databases.	VLDB	database
4926	VLDB	Using Probabilistic Information in Data Integration.	Daniela Florescu,Daphne Koller,Alon Y. Levy	1997	Using Probabilistic Information in Data Integration.	VLDB	database
4927	VLDB	Fast Incremental Maintenance of Approximate Histograms.	Phillip B. Gibbons,Yossi Matias,Viswanath Poosala	1997	Many commercial database systems maintain histograms to summarize the contents of large relations and permit efficient estimation of query result sizes for use in query optimizers. Delaying the propagation of database updates to the histogram often introduces errors into the estimation. This article presents new sampling-based approaches for incremental maintenance of approximate histograms. By scheduling updates to the histogram based on the updates to the database, our techniques are the first to maintain histograms effectively up to date at all times and avoid computing overheads when unnecessary. Our techniques provide highly accurate approximate histograms belonging to the equidepth and Compressed classes. Experimental results show that our new approaches provide orders of magnitude more accurate estimation than previous approaches.An important aspect employed by these new approaches is a backing sample, an up-to-date random sample of the tuples currently in a relation. We provide efficient solutions for maintaining a uniformly random sample of a relation in the presence of updates to the relation. The backing sample techniques can be used for any other application that relies on random samples of data.	VLDB	database
4928	VLDB	Data Manager for Evolvable Real-time Command and Control Systems.	Eric Hughes,Roman Ginis,Bhavani M. Thuraisingham,Peter C. Krupp,John A. Maurer	1997	Data Manager for Evolvable Real-time Command and Control Systems.	VLDB	database
4929	VLDB	DataGuides: Enabling Query Formulation and Optimization in Semistructured Databases.	Roy Goldman,Jennifer Widom	1997	DataGuides: Enabling Query Formulation and Optimization in Semistructured Databases.	VLDB	database
4930	VLDB	Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources.	Minos N. Garofalakis,Yannis E. Ioannidis	1997	Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources.	VLDB	database
4931	VLDB	Merging Ranks from Heterogeneous Internet Sources.	Luis Gravano,Hector Garcia-Molina	1997	Merging Ranks from Heterogeneous Internet Sources.	VLDB	database
4932	VLDB	A Foundation for Multi-dimensional Databases.	Marc Gyssens,Laks V. S. Lakshmanan	1997	A Foundation for Multi-dimensional Databases.	VLDB	database
4933	VLDB	Optimizing Queries Across Diverse Data Sources.	Laura M. Haas,Donald Kossmann,Edward L. Wimmers,Jun Yang	1997	Optimizing Queries Across Diverse Data Sources.	VLDB	database
4934	VLDB	Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates.	Sven Helmer,Guido Moerkotte	1997	Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates.	VLDB	database
4935	VLDB	Spatial Joins Using R-trees: Breadth-First Traversal with Global Optimizations.	Yun-Wu Huang,Ning Jing,Elke A. Rundensteiner	1997	Spatial Joins Using R-trees: Breadth-First Traversal with Global Optimizations.	VLDB	database
4936	VLDB	1-Safe Algorithms for Symmetric Site Configurations.	Rune Humborstad,Maitrayi Sabaratnam,Svein-Olaf Hvasshovd,Øystein Torbjørnsen	1997	1-Safe Algorithms for Symmetric Site Configurations.	VLDB	database
4937	VLDB	Multiple-View Self-Maintenance in Data Warehousing Environments.	Nam Huyn	1997	Multiple-View Self-Maintenance in Data Warehousing Environments.	VLDB	database
4938	VLDB	Innovation in Database Management: Computer Science vs. Engineering.	Kenneth R. Jacobs	1997	Innovation in Database Management: Computer Science vs. Engineering.	VLDB	database
4939	VLDB	Incremental Organization for Data Recording and Warehousing.	H. V. Jagadish,P. P. S. Narayan,S. Seshadri,S. Sudarshan,Rama Kanneganti	1997	Incremental Organization for Data Recording and Warehousing.	VLDB	database
4940	VLDB	Implementing Abstract Objects with Inheritance in Datalog.	Hasan M. Jamil	1997	Implementing Abstract Objects with Inheritance in Datalog.	VLDB	database
4941	VLDB	Mining Insurance Data at Swiss Life.	Jörg-Uwe Kietz,Ulrich Reimer,Martin Staudt	1997	Mining Insurance Data at Swiss Life.	VLDB	database
4942	VLDB	Vertical Data Migration in Large Near-Line Document Archives Based on Markov-Chain Predictions.	Achim Kraiss,Gerhard Weikum	1997	Vertical Data Migration in Large Near-Line Document Archives Based on Markov-Chain Predictions.	VLDB	database
4943	VLDB	Caprera: An Activity Framework for Transaction Processing on Wide-Area Networks.	Suresh Kumar,Eng-Kee Kwang,Divyakant Agrawal	1997	Caprera: An Activity Framework for Transaction Processing on Wide-Area Networks.	VLDB	database
4944	VLDB	A Region Splitting Strategy for Physical Database Design of Multidimensional File Organizations.	Jong-Hak Lee,Young-Koo Lee,Kyu-Young Whang,Il-Yeol Song	1997	A Region Splitting Strategy for Physical Database Design of Multidimensional File Organizations.	VLDB	database
4945	VLDB	Facilitating Multimedia Database Exploration through Visual Interfaces and Perpetual Query Reformulations.	Wen-Syan Li,K. Selçuk Candan,Kyoji Hirata,Yoshinori Hara	1997	Facilitating Multimedia Database Exploration through Visual Interfaces and Perpetual Query Reformulations.	VLDB	database
4946	VLDB	Using Versions in Update Transactions: Application to Integrity Checking.	François Llirbat,Eric Simon,Dimitri Tombroff	1997	Using Versions in Update Transactions: Application to Integrity Checking.	VLDB	database
4947	VLDB	The Network as a Global Database: Challenges of Interoperability, Proactivity, Interactiveness, Legacy.	Peter C. Lockemann,Ulrike Kölsch,Arne Koschel,Ralf Kramer,Ralf Nikolai,Mechtild Wallrath,Hans-Dirk Walter	1997	The Network as a Global Database: Challenges of Interoperability, Proactivity, Interactiveness, Legacy.	VLDB	database
4948	VLDB	Critical Database Technologies for High Energy Physics.	David M. Malon,Edward N. May	1997	Critical Database Technologies for High Energy Physics.	VLDB	database
4949	VLDB	A Language for Manipulating Arrays.	Arunprasad P. Marathe,Kenneth Salem	1997	A Language for Manipulating Arrays.	VLDB	database
4950	VLDB	Efficient Construction of Regression Trees with Range and Region Splitting.	Yasuhiko Morimoto,Hiromu Ishii,Shinichi Morishita	1997	Efficient Construction of Regression Trees with Range and Region Splitting.	VLDB	database
4951	VLDB	The Complexity of Transformation-Based Join Enumeration.	Arjan Pellenkoft,César A. Galindo-Legaria,Martin L. Kersten	1997	The Complexity of Transformation-Based Join Enumeration.	VLDB	database
4952	VLDB	Selectivity Estimation Without the Attribute Value Independence Assumption.	Viswanath Poosala,Yannis E. Ioannidis	1997	Selectivity Estimation Without the Attribute Value Independence Assumption.	VLDB	database
4953	VLDB	Fast Computation of Sparse Datacubes.	Kenneth A. Ross,Divesh Srivastava	1997	Fast Computation of Sparse Datacubes.	VLDB	database
4954	VLDB	Don't Scrap It, Wrap It! A Wrapper Architecture for Legacy Data Sources.	Mary Tork Roth,Peter M. Schwarz	1997	Don't Scrap It, Wrap It! A Wrapper Architecture for Legacy Data Sources.	VLDB	database
4955	VLDB	Efficient User-Adaptable Similarity Search in Large Multimedia Databases.	Thomas Seidl,Hans-Peter Kriegel	1997	Efficient User-Adaptable Similarity Search in Large Multimedia Databases.	VLDB	database
4956	VLDB	Multidimensional Access Methods: Trees Have Grown Everywhere.	Timos K. Sellis,Nick Roussopoulos,Christos Faloutsos	1997	Multidimensional Access Methods: Trees Have Grown Everywhere.	VLDB	database
4957	VLDB	The Case for Enhanced Abstract Data Types.	Praveen Seshadri,Miron Livny,Raghu Ramakrishnan	1997	Support for complex data in object-relational database systems is based on abstract data types (ADTs). We argue that the current ADT approach inhibits the performance of queries that involve expensive operations on data types. Instead, we propose the Enhanced Abstract Data Type (E-ADT) paradigm, which treats operations on data types as declarative expressions that can be optimized. In this paper, we describe the E-ADT paradigm and PREDATOR, an object-relational database system based on E-ADTs. An E-ADT is an abstract data type enhanced with query optimization. Not only does an E-ADT provide operations (or methods) that can be used in SQL queries, it also supports internal interfaces that can be invoked to optimize these operations. This added functionality is provided without compromising the modularity of data types and the extensibility of the type system. Building such a database system requires fundamental changes in the architecture of the query processing engine; we present the system-level interfaces of PREDATOR that support E-ADTs, and describe the internal design details. Initial performance results from supporting image, time-series, and audio data as E-ADTs demonstrate an order of magnitude in performance improvements over the current ADT approach. Further, we describe how the E-ADT paradigm enables future research that can improve several aspects of object-relational query optimization. Consequently, we make the case that next-generation object-relational database systems should be based on E-ADT technology.	VLDB	database
4958	VLDB	Parallel Algorithms for High-dimensional Similarity Joins for Data Mining Applications.	John C. Shafer,Rakesh Agrawal	1997	Parallel Algorithms for High-dimensional Similarity Joins for Data Mining Applications.	VLDB	database
4959	VLDB	Concurrent Garbage Collection in O2.	Marcin Skubiszewski,Patrick Valduriez	1997	Concurrent Garbage Collection in O2.	VLDB	database
4960	VLDB	Adaptive Data Broadcast in Hybrid Networks.	Konstantinos Stathatos,Nick Roussopoulos,John S. Baras	1997	Adaptive Data Broadcast in Hybrid Networks.	VLDB	database
4961	VLDB	Data Warehouse Configuration.	Dimitri Theodoratos,Timos K. Sellis	1997	Data Warehouse Configuration.	VLDB	database
4962	VLDB	On-Demand Data Elevation in Hierarchical Multimedia Storage Servers.	Peter Triantafillou,Thomas Papadakis	1997	On-Demand Data Elevation in Hierarchical Multimedia Storage Servers.	VLDB	database
4963	VLDB	Describing and Using Query Capabilities of Heterogeneous Sources.	Vasilis Vassalos,Yannis Papakonstantinou	1997	Describing and Using Query Capabilities of Heterogeneous Sources.	VLDB	database
4964	VLDB	STING: A Statistical Information Grid Approach to Spatial Data Mining.	Wei Wang,Jiong Yang,Richard R. Muntz	1997	STING: A Statistical Information Grid Approach to Spatial Data Mining.	VLDB	database
4965	VLDB	GTE SuperPages: Using IR Techniques for Searching Complex Objects.	Steven D. Whitehead,Himanshu Sinha,Michael Murphy	1997	GTE SuperPages: Using IR Techniques for Searching Complex Objects.	VLDB	database
4966	VLDB	Efficient Testing of High Performance Transaction Processing Systems.	D. Wildfogel,Ramana Yerneni	1997	Efficient Testing of High Performance Transaction Processing Systems.	VLDB	database
4967	VLDB	Algorithms for Materialized View Design in Data Warehousing Environment.	Jian Yang,Kamalakar Karlapalem,Qing Li	1997	Algorithms for Materialized View Design in Data Warehousing Environment.	VLDB	database
4968	VLDB	Dynamic Memory Adjustment for External Mergesort.	Weiye Zhang,Per-Åke Larson	1997	Dynamic Memory Adjustment for External Mergesort.	VLDB	database
4969	SIGMOD Record	Integrating Modelling Systems for Environmental Management Information Systems.	David J. Abel,Kerry L. Taylor,Dean Kuo	1997	Special purpose modelling packages can become more accessible and more effective for decision support when integrated into a spatial information system. Integration is made difficult by differences in the models due to scope, underlying data models, and command languages. This paper extends a federated information systems design methodology and architecture by identifying parallels of the model integration problem with the database integration problem in federated database design. A schema architecture is proposed together with associated schema translation functions. The role of a problem statement, analogous to a federated database query, is defined. Our design approach is demonstrated in HYDRA, a decision support system for water quality management.	SIGMOD Record	database
4970	SIGMOD Record	Semistructured und Structured Data in the Web: Going Back and Forth.	Paolo Atzeni,Giansalvatore Mecca,Paolo Merialdo	1997	Semistructured und Structured Data in the Web: Going Back and Forth.	SIGMOD Record	database
4971	SIGMOD Record	Intelligent Access to Heterogeneous Information Sources: Report on the 4th Workshop on Knowledge Representation Meets Databases.	Franz Baader,Manfred A. Jeusfeld,Werner Nutt	1997	Intelligent Access to Heterogeneous Information Sources: Report on the 4th Workshop on Knowledge Representation Meets Databases.	SIGMOD Record	database
4972	SIGMOD Record	Wrapper Generation for Semi-structured Internet Sources.	Naveen Ashish,Craig A. Knoblock	1997	With the current explosion of information on the World Wide Web (WWW) a wealth of information on many different subjects has become available on-line. Numerous sources contain information that can be classified as semi-structured. At present, however, the only way to access the information is by browsing individual pages. We cannot query web documents in a database-like fashion based on their underlying structure. However, we can provide database-like querying for semi-structured WWW sources by building wrappers around these sources. We present an approach for semi-automatically generating such wrappers. The key idea is to exploit the formatting information in pages from the source to hypothesize the underlying structure of a page. From this structure the system generates a wrapper that facilitates querying of a source and possibly integrating it with other sources. We demonstrate the ease with which we are able to build wrappers for a number of internet sources in different domains using our implemented wrapper generation toolkit.	SIGMOD Record	database
4973	SIGMOD Record	Quasi-Cubes: Exploiting Approximations in Multidimensional Databases.	Daniel Barbará,Mark Sullivan	1997	A data cube is a popular organization for summary data. A cube is simply a multidimensional structure that contains at each point an aggregate value, i.e., the result of applying an aggregate function to an underlying relation. In practical situations, cubes can require a large amount of storage. The typical approach to reducing storage cost is to materialize parts of the cube on demand. Unfortunately, this lazy evaluation can be a time-consuming operation. In this paper, we describe an approximation technique that reduces the storage cost of the cube without incurring the run time cost of lazy evaluation. The idea is to provide an incomplete description of the cube and a method of estimating the missing entries with a certain level of accuracy. The description, of course, should take a fraction of the space of the full cube and the estimation procedure should be faster than computing the data from the underlying relations. Since cubes are used to support data analysis and analysts are rarely interested in the precise values of the aggregates (but rather in trends), providing approximate answers is, in most cases, a satisfactory compromise. Alternatively, the technique can be used to implement a multiresolution system in which a tradeoff is established between the execution time of queries and the errors the user is willing to tolerate. By only going to the disk when it is necessary (to reduce the errors), the query can be executed faster. This idea can be extended to produce a system that incrementally increases the accuracy of the answer while the user is looking at it, supporting on-line aggregation.	SIGMOD Record	database
4974	SIGMOD Record	Mediator Languages - a Proposal for a Standard.	Peter Buneman,Louiqa Raschid,Jeffrey D. Ullman	1997	Mediator Languages - a Proposal for a Standard.	SIGMOD Record	database
4975	SIGMOD Record	An Overview of Data Warehousing and OLAP Technology.	Surajit Chaudhuri,Umeshwar Dayal	1997	Data warehousing and on-line analytical processing (OLAP) are essential elements of decision support, which has increasingly become a focus of the database industry. Many commercial products and services are now available, and all of the principal database management system vendors now have offerings in these areas. Decision support places some rather different requirements on database technology compared to traditional on-line transaction processing applications. This paper provides an overview of data warehousing and OLAP technologies, with an emphasis on their new requirements. We describe back end tools for extracting, cleaning and loading data into a data warehouse; multidimensional data models typical of OLAP; front end client tools for querying and data analysis; server extensions for efficient query processing; and tools for metadata management and for managing the warehouse. In addition to surveying the state of the art, this paper also identifies some promising research issues, some of which are related to problems that the database research community has worked on for years, but others are only just beginning to be addressed. This overview is based on a tutorial that the authors presented at the VLDB Conference, 1996.	SIGMOD Record	database
4976	SIGMOD Record	OGDI: Toward Interoperability among Geospatial Databases.	Gilles Clement,Christian Larouche,Denis Gouin,Paul Morin,Henry Kucera	1997	The growth of the geomatics industry is stunted by the difficulty of obtaining and transforming suitable spatial data. This paper describes a remedy: the Open Geospatial Datastore Interface (OGDI), which permits application software to access a variety of spatial data products. The discussion compares the OGDI approach to other standards efforts and describes the characteristics and use of OGDI, which is in the public domain.	SIGMOD Record	database
4977	SIGMOD Record	Research Issues in Federated Database Systems: Report of EFDBS '97 Workshop.	Stefan Conrad,Barry Eaglestone,Wilhelm Hasselbring,Mark Roantree,Fèlix Saltor,Martin Schönhoff,Markus Strässler,Mark W. W. Vermeer	1997	Research Issues in Federated Database Systems: Report of EFDBS '97 Workshop.	SIGMOD Record	database
4978	SIGMOD Record	The Database and Information System Research Group at the University of Ulm.	Peter Dadam,Wolfgang Klas	1997	The University of Ulm was founded in 1967 with focus on medicine and natural sciences. In 1989 the University established two new faculties: Engineering Sciences and Computer Science. This enlargement took place within the framework of the so-called Science City Ulm. In a joint effort, the State of Baden-W&uuml;rttemberg, industrial companies, the University, and the City of Ulm successfully established a research and development infrastructure at or nearby the university campus consisting of the university's research labs, university-related research institutes like the Research Institute for Applied Knowledge Processing (FAW), and industrial research and development labs, especially a large research center of Daimler-Benz AG. Today, the Faculty of Computer Science consists of seven divisions (called 'departments'), each of which equipped with two professor positions: Theoretical Computer Science Artificial Intelligence Distributed Systems Databases and Information Systems Software Technology and Compiler Construction Computer Structures Neural Information Processing. The Dept. of Databases and Information Systems (DBIS) became operational at the beginning of 1990 when Peter Dadam joined the faculty. He came from the IBM Heidelberg Science Center (HDSC) where he managed the research department for Advanced Information Management (AIM). At the HDSC he was working on advanced database technology and applications and contributed to the development of the AIM-P system (see [1]). The second professor position was first occupied by Marc Scholl, who belonged to the DBIS department from 1992 to 1994. In 1996 Wolfgang Klas joined the DBIS department as second professor. He came from the GMD Institute for Integrated Publication and Information Systems (IPSI) where he managed the research division Distributed Multimedia Information Systems and was working on advanced object-oriented database systems technology, interoperable database systems, and multimedia information systems. At present, the DBIS team consists of the teaching and research assistants Thomas Bauer, Susanne Boll, Christian Heinlein, Clemens Hensinger, Erich M&uuml;ller, Manfred Reichert, Birgit Schulthei&bgr;, the system engineer Rudi Seifert, the secretary Christiane K&ouml;ppl, and the doctoral students Thomas Beuter and Anita Kr&auml;mer. In the following, we concentrate on the research and development work performed previously and presently in the research groups of Peter Dadam and of Wolfgang Klas. For references to Marc Scholl's work please visit http://www.informatik.uni-konstanz.de/dbis.	SIGMOD Record	database
4979	SIGMOD Record	Query Previews for Networked Information Systems: A Case Study with NASA Environmental Data.	Khoa Doan,Catherine Plaisant,Ben Shneiderman,Tom Bruns	1997	Formulating queries on networked information systems is laden with problems: data diversity, data complexity, network growth, varied user base, and slow network access. This paper proposes a new approach to a network query user interface which consists of two phases: query preview and query refinement. This new approach is based on dynamic queries and tight coupling, guiding users to rapidly and dynamically eliminate undesired items, reduce the data volume to a manageable size, and refine queries locally before submission over a network. A two-phase dynamic query system for NASA's Earth Observing Systems--Data Information Systems (EOSDIS) is presented. The prototype was well received by the team of scientists who evaluated the interface.	SIGMOD Record	database
4980	SIGMOD Record	Converting Relational to Object-Oriented Databases.	Joseph Fong	1997	As object-oriented model becomes the trend of database technology, there is a need to convert relational to object-oriented database system to improve productivity and flexibility. The changeover includes schema translation, data conversion and program conversion. This paper describes a methodology for integrating schema translation and data conversion. Schema translation involves semantic reconstruction and the mapping of relational schema into object-oriented schema. Data conversion involves unloading tuples of relations into sequential files and reloading them into object-oriented classes files. The methodology preserves the constraints of the relational database by mapping the equivalent data dependencies.	SIGMOD Record	database
4981	SIGMOD Record	Editor's Notes.	Michael J. Franklin	1997	Editor's Notes.	SIGMOD Record	database
4982	SIGMOD Record	Editor's Notes.	Michael J. Franklin	1997	Editor's Notes.	SIGMOD Record	database
4983	SIGMOD Record	Editor's Notes.	Michael J. Franklin	1997	Editor's Notes.	SIGMOD Record	database
4984	SIGMOD Record	A Query Language for a Web-Site Management System.	Mary F. Fernandez,Daniela Florescu,Alon Y. Levy,Dan Suciu	1997	A Query Language for a Web-Site Management System.	SIGMOD Record	database
4985	SIGMOD Record	Data Management for Earth System Science.	James Frew,Jeff Dozier	1997	Earth system science is a relatively recent scientific discipline that seeks a global-scale understanding of the components, interactions, and evolution of the entire Earth system. The data being collected in support of Earth system science are rapidly approaching petabytes per year. The intrinsic problems of archiving, searching, and distributing such a huge dataset are compounded by both the heterogeneity of the data, and the heterogeneous nature of Earth system science inquiry, which synthesizes models, observations, and knowledge bases from a several traditional scientific disciplines.A successful data management environment for Earth system science must provide seamless access to arbitrary subsets and combinations of both local and remote data, and must be compatible with the rich data analysis environments already deployed. We describe a prototype of such an environment, built at UCSB using database technology pioneered by the Sequoia 2000 Project. We specifically address its application to a problem that requires combining point observations with gridded satellite imagery.	SIGMOD Record	database
4986	SIGMOD Record	Open GIS and On-Line Environmental Libraries.	Kenn Gardels	1997	An essential component of an Environmental Information System is geographic or geospatial data coupled with geoprocessing functions. Traditional Geographic Information Systems (GIS) do not address the requirements of complex digital environmental libraries, but are now incorporating strategies for geodatabase federation, catalogs, and data mining. These strategies, however, depend on increased interoperability among diverse data stores, formats, and models. Open GIS&trade; is an abstration of geodata and a specification for methods on geographic features and coverages that enables compliant applications to exchange information and processing services. For EIS, Open GIS provides an architecture for selecting geodata at its most atomic level, fusing those data into structured information frameworks, analysing information using spatial operators, and viewing the results in informative, decision-supporting ways.	SIGMOD Record	database
4987	SIGMOD Record	The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules of Thumb.	Jim Gray,Goetz Graefe	1997	Simple economic and performance arguments suggest appropriate lifetimes for main memory pages and suggest optimal page sizes. The fundamental tradeoffs are the prices and bandwidths of RAMs and disks. The analysis indicates that with today's technology, five minutes is a good lifetime for randomly accessed pages, one minute is a good lifetime for two-pass sequentially accessed pages, and 16 KB is a good size for index pages. These rules-of-thumb change in predictable ways as technology ratios change. They also motivate the importance of the new Kaps, Maps, Scans, and $/Kaps, $/Maps, $/TBscan metrics.	SIGMOD Record	database
4988	SIGMOD Record	Environment Information Systems - Guest Editor's Foreword.	Oliver Günther	1997	Environment Information Systems - Guest Editor's Foreword.	SIGMOD Record	database
4989	SIGMOD Record	Virtual Database technology.	Ashish Gupta,Venky Harinarayan,Anand Rajaraman	1997	Virtual Database technology.	SIGMOD Record	database
4990	SIGMOD Record	Information Systems Research at George Mason University.	Sushil Jajodia,Daniel Barbará,Alexander Brodsky,Larry Kerschberg,Amihai Motro,Edgar H. Sibley,Xiaoyang Sean Wang	1997	George Mason University began as an independent state university in 1972. Its development has been marked by rapid growth and innovative planning, resulting in an enrollment of more than 24,000 students in 1997. It is located in Fairfax, Virginia&mdash;about fifteen miles southwest of Washington, DC&mdash;near many governmental agencies and industrial firms specializing in information-intensive products and services. Information and Software Systems Engineering (ISSE) is one of six departments in GMU's School of Information Technology and Engineering (SITE). Established in 1985, SITE has approximately 90 faculty and ISSE has 13 full time faculty. ISSE is a rapidly growing department with wide-ranging teaching and research interests. The department offers no undergraduate degree programs and Master of Science degrees in Information Systems (MSIS) and Software Engineering (SWSE). MSIS has about 800 students and the SWSE has approximately 400 students enrolled. The MSIS program graduates about 120 students and the SWSE program awards 40 degrees per year. ISSE faculty participate in the SITE doctoral program in Information Technology. ISSE Faculty chair the committees of more than one third of the doctoral students in the SITE program, which currently graduates about 30 PhDs per year. Two research centers are associated with the department: The Center for Secure Information Systems (Sushil Jajodia, Director) and the Center for Information Systems Integration and Evolution (Larry Kerschberg, Director). Departmental research in information systems is supported by grants and contracts from several sources. The following awards have been received so far for the academic year 1997-1998 and beyond: Knowledge Rovers: A Family of Intelligent Software Agents for Logistics for the Warrior. Defense Advanced Research Projects Agency (co-PIs: Kerschberg, Gomaa, Jajodia, Motro) Electronic Commerce for Logistics, Teaming Agreement with American Management Systems for DARPA BAA 95-25 Logistics Research and Development (co-PIs: Kerschberg, Gomaa, Jajodia, Motro) Linear Constraint Databases, NSF Research Initiation Award (PI: Brodsky) Linear Constraint Programming, ONR (co-PI: Brodsky with late Kannelakis (PI), Van Hentenryck, and Lassez) Towards Expressive and Efficient Queries on Sequenced Data, NSF Research Initiation Award (PI: Wang) Supporting Multiple time granularities in Query Evaluation and Data Mining, NSF (co-PIs: Jajodia, Wang) Fine Granularity Access Controls in World Wide Web, NSA (PI: Jajodia) Information Flow Control in Object-Oriented Systems NSA (PI: Jajodia) Exploring Steganography: Seeing the Unseen, NSA (PI: Jajodia) Trusted Recovery from Information Attacks, Rome Laboratory (co-PIs: Jajodia, Ammann) A Unified Framework for Supporting Multiple Access Control Policies, DARPA (PI: Jajodia) The remainder of this article provides a brief overview of our research followed by a selected list of publications. More detailed information is available at www.isse.gmu.edu.	SIGMOD Record	database
4991	SIGMOD Record	An Extended Entity-Relationship Model for Geographic Applications.	Thanasis Hadzilacos,Nectaria Tryfona	1997	A special-purpose extension of the Entity-Relationship model for the needs of conceptual modeling of geographic applications, called the Geo-ER Model, is presented. Handling properties associated to objects not because of the objects' nature but because of the objects' position, calls for dealing -at the semantic modeling level-with space, location and dimensionality of objects, spatial relationships, space-depending attributes, and scale and generalization of representations. In order to accomplish this in the framework of ER and its derivatives, we introduce special entity sets, relationships, and add new constructs. The rationale as well as examples of usage of the Geo-ER model from actual projects are presented.	SIGMOD Record	database
4992	SIGMOD Record	Asserting Beliefs in MLS Relational Models.	Nenad Jukic,Susan V. Vrbsky	1997	Multilevel relations, based on the current multilevel secure (MLS) relational data models, can present a user with information that is difficult to interpret and may display an inconsistent outlook about the views of other users. Such ambiguity is due to the lack of a comprehensive method for asserting and interpreting beliefs about lower level information. In this paper we identify different beliefs that can be held by higher level users about lower level information, and we introduce the new concept of a mirage tuple. We present a mechanism for asserting beliefs about all accessible tuples, including lower level tuples. This mechanism provides every user of an MLS database with an unambiguous interpretation of all viewable information and presents a consistent account of the views at all levels below the user's level.	SIGMOD Record	database
4993	SIGMOD Record	Min-Max Compression Methods for Medical Image Databases.	Kosmas Karadimitriou,John M. Tyler	1997	The volume of medical imaging data produced per year is rapidly increasing, overtaxing the capabilities of Picture Archival and Communication (PACS) systems. Image compression methods can lessen the problem by encoding digital images into more space-efficient forms. Image compression is achieved by reducing redundancy in the imaging data. Existing methods reduce redundancy in individual images. However, these methods ignore an additional source of redundancy, which is based on the common information stored in more than one image in a set of similar images. We use the term set redundancy to describe this type of redundancy. Medical image databases contain large sets of similar images, therefore they also contain significant amounts of set redundancy.This paper presents two methods that extract set redundancy from medical imaging data: the Min-Max Differential (MMD), and the Min-Max Predictive (MMP) methods. These methods can improve compression of standard image compression techniques for sets of medical images. Our tests compressing CT brain scans have shown an average of as much as 129% improvement for Huffman encoding, 93% for Arithmetic Coding, and 37% for Lempel-Ziv compression when they are combined with Min-Max methods. Both MMD and MMP are based on reversible operations, hence they provide lossless compression.	SIGMOD Record	database
4994	SIGMOD Record	Research in Databases and Data-Intensive Applications - Computer Science Department and FZI, University of Karlsruhe.	Birgitta König-Ries,Peter C. Lockemann	1997	The future world of computing will be governed by large networks of communicating and interacting persons and machines, geographic mobility, temporary attachment to networks, the disintegration of formerly monolithic organizations and systems into autonomously acting units, the substitution of cooperation regimes for centralized control, and an ever-increasing spectrum of ever more ambitious applications. In such a world the methods, techniques and tools of database technology will play new and more diversified roles, not so much in combination as parts of all-inclusive database systems but rather individually as indispensable ingredients of or desirable enhancements to novel communication, control and application systems. The two information systems groups whose work is presented in this report aim at meeting these new challenges. Our contributions are in the large field of what we call &ldquo;distributed data-intensive applications&rdquo;.	SIGMOD Record	database
4995	SIGMOD Record	WWW-UDK: A Web-based Environmental Meta-Information System.	Ralf Kramer,Ralf Nikolai,Arne Koschel,Claudia Rolker,Peter C. Lockemann,Andree Keitel,Rudolf Legat,Konrad Zirm	1997	The environmental data catalogue Umweltdatenkatalog UDK is a standard meta-information system for environmental data for use by state authorities and the public. Technically, the UDK consists of a database together with a front-end tailored to the needs of environmental specialists. FZI's contribution has been to develop a front-end that makes the UDK database available using the tools and techniques of the World-Wide Web. Among the features of WWW-UDK are several query modes for the UDK objects and addresses, an environmental thesaurus, on-line access to some of the underlying data (e.g., databases and environmental reports), multilingual query and result forms, and an on-line help system. Currently, several installations of WWW-UDK are used in Austria and in Germany on the Internet and on Intranets. WWW-UDK can be easily integrated into a federation architecture which is based on CORBA, WWW, and Java.	SIGMOD Record	database
4996	SIGMOD Record	Extracting Entity Profiles from Semistructured Information Spaces.	Robert A. Nado,Scott B. Huffman	1997	A semistructured information space consists of multiple collections of textual documents containing fielded or tagged sections. The space can be highly heterogeneous, because each collection has its own schema, and there are no enforced keys or formats for data items across collections. Thus, structured methods like SQL cannot be easily employed, and users often must make do with only full-text search. In this paper, we describe an approach that provides structured querying for particular types of entities, such as companies and people. Entity-based retrieval is enabled by normalizing entity references in a heuristic, type-dependent manner. The approach can be used to retrieve documents and can also be used to construct entity profiles &mdash; summaries of commonly sought information about an entity based on the documents' content. The approach requires only a modest amount of meta-information about the source collections, much of which is derived automatically.	SIGMOD Record	database
4997	SIGMOD Record	Workshop on Workflow Management in Scientific and Engineering Applications - Report.	Richard McClatchey,Gottfried Vossen	1997	Workshop on Workflow Management in Scientific and Engineering Applications - Report.	SIGMOD Record	database
4998	SIGMOD Record	Lore: A Database Management System for Semistructured Data.	Jason McHugh,Serge Abiteboul,Roy Goldman,Dallan Quass,Jennifer Widom	1997	Lore (for Lightweight Object Repository) is a DBMS designed specifically for managing semistructured information. Implementing Lore has required rethinking all aspects of a DBMS, including storage management, indexing, query processing and optimization, and user interfaces. This paper provides an overview of these aspects of the Lore system, as well as other novel features such as dynamic structural summaries and seamless access to data from external sources.	SIGMOD Record	database
4999	SIGMOD Record	Integrating Dynamically-Fetched External Information into a DBMS for Semistructured Data.	Jason McHugh,Jennifer Widom	1997	We describe the external data manager component of the Lore database system for semistructured data. Lore's external data manager enables dynamic retrieval and integration of data from arbitrary, heterogeneous external sources during query processing. The distinction between Lore-resident and external data is invisible to the user. We introduce a flexible notion of arguments that limits the amount of data fetched from an external source, and we have incorporated optimizations to reduce the number of calls to an external source.	SIGMOD Record	database
5000	SIGMOD Record	Infering Structure in Semistructured Data.	Svetlozar Nestorov,Serge Abiteboul,Rajeev Motwani	1997	When dealing with semistructured data such as that available on the Web, it becomes important to infer the inherent structure, both for the user (e.g., to facilitate querying) and for the system (e.g., to optimize access). In this paper, we consider the problem of identifying some underlying structure in large collections of semistructured data. Since we expect the data to be fairly irregular, this structure consists of an approximate classification of objects into a hierarchical collection of types. We propose a notion of a type hierarchy for such data, and outline a method for deriving the type hierarchy, and rules for assigning types to data elements.	SIGMOD Record	database
